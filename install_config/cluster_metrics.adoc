= Enabling Cluster Metrics
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

== Overview

The
link:../architecture/infrastructure_components/kubernetes_infrastructure.html#kubelet[kubelet]
exposes metrics that can be collected and stored in back-ends by
link:https://github.com/GoogleCloudPlatform/heapster[Heapster].

As an OpenShift administrator, you can view a cluster's metrics from all
containers and components in one user interface.  These metrics are also
used by link:../dev_guide/pod_autoscaling.html[horizontal pod autoscalers]
in order to determine when and how to scale.

This topic describes using
link:https://github.com/hawkular/hawkular-metrics[Hawkular Metrics]
as a metrics engine which stores the data persistently in a
link:http://cassandra.apache.org/[Cassandra] database. When this is
configured, CPU and memory-based metrics are viewable from the OpenShift
web console and are available for use by
link:../dev_guide/pod_autoscaling.html[horizontal pod autoscalers].

Heapster retrieves a list of all nodes from the master server, then contacts
each node individually through the `/stats` endpoint. From there, Heapster
scrapes the metrics for CPU & memory usage and exports them into Hawkular
Metrics.

Browsing individual pods in the web console displays separate sparkline charts
for memory and CPU. The time range displayed is selectable, and these charts
automatically update every 30 seconds. If there are multiple containers on the
pod, then you can select a specific container to display its metrics.

If you have link:../dev_guide/limits.html[resource limits] defined for your
project, then you can also see a donut chart for each pod. The donut chart
displays usage against the resource limit. For example: `145 Available of 200
MiB`, with the donut chart showing `55 MiB Used`.

ifdef::openshift-origin[]
For more information about the metrics integration, please refer to the
link:https://github.com/openshift/origin-metrics[Origin Metrics] GitHub project.
endif::[]

== Before You Begin

ifdef::openshift-origin[]
[WARNING]
====
If your OpenShift installation was originally performed on a version previous to
v1.0.8, even if it has since been updated to a newer version, you will need to
follow these steps outlined in the
link:upgrades.html#updating-node-certificates[update] document. If the node
certificate does not contain the IP address of the node, then Heapster will fail
to retrieve any metrics.
====
endif::[]

The components for cluster metrics must be deployed to the `openshift-infra`
project. This allows link:../dev_guide/pod_autoscaling.html[horizontal pod
autoscalers] to discover the heapster service and use it to retrieve metrics
that can be used for autoscaling.

All of the following commands in this topic must be executed under the
`openshift-infra` project. To switch to the `openshift-infra` project:

[options="nowrap"]
----
$ oc project openshift-infra
----

Next: To enable cluster metrics, configure the:

. link:../install_config/cluster_metrics.html#service-accounts[Service Accounts]
. link:../install_config/cluster_metrics.html#metric-data-storage[Metric Data Storage]
. link:../install_config/cluster_metrics.html#metrics-deployer[Metrics Deployer]

== Service Accounts

You must configure service accounts for:

* link:../install_config/cluster_metrics.html#metrics-deployer-service[Metrics Deployer]
* link:../install_config/cluster_metrics.html#heapster-service[Heapster]

[[metrics-deployer-service]]

=== Metrics Deployer Service Account

Create a service account for the *metrics deployer*:

[options="nowrap"]
----
$ oc create -f - <<API
apiVersion: v1
kind: ServiceAccount
metadata:
  name: metrics-deployer
secrets:
- name: metrics-deployer
API
----

Before it can deploy components, the metrics-deployer service account must be
granted the `edit` permission for the _openshift-infra_ project:

[options="nowrap"]
----
$ oadm policy add-role-to-user edit system:serviceaccount:openshift-infra:metrics-deployer
----

[[heapster-service]]

=== Heapster Service Account

The Heapster component requires access to the master server to list all
available nodes and access the `/stats` endpoint for each node. Before it can do
this, the Heapster service account requires the `cluster-reader` permission:

[options="nowrap"]
----
$ oadm policy add-cluster-role-to-user cluster-reader system:serviceaccount:openshift-infra:heapster
----

== Metric Data Storage

You can store the metrics data to either
link:../architecture/additional_concepts/storage.html[persistent storage]
or to a temporary
link:../dev_guide/volumes.html[pod volume].

=== Persistent Storage

Running OpenShift cluster metrics with persistent storage means that your
metrics will be stored to a
link:../architecture/additional_concepts/storage.html#persistent-volumes[persistent
volume] and be able to survive a pod being restarted or recreated. This is ideal
if you require your metric data to be guarded from data loss.

For cluster metrics to work with persistent storage, ensure that the persistent volume has the *ReadWriteOnce* access mode. If not, the persistent volume claim will not be able to find the persistent volume, and Cassandra will fail to start.

To use persistent storage with the metric components, ensure that a
link:../architecture/additional_concepts/storage.html#persistent-volumes[persistent
volume] of sufficient size is available. The creation of
link:../architecture/additional_concepts/storage.html#persistent-volume-claims[persistent
volume claims] is handled by the
link:../install_config/cluster_metrics.html#metrics-deployer[*metrics
deployer*].

=== Non-Persistent Storage

Running OpenShift cluster metrics with non-persistent storage means that any
stored metrics will be deleted when the pod is deleted. While it is much easier
to run cluster metrics with non-persistent data, running with non-persistent
data does come with the risk of permanent data loss. However, metrics can still
survive a container being restarted.

In order to use non-persistent storage, you will need to set the
`*USE_PERSISTENT_STORAGE*`
link:../install_config/cluster_metrics.html#creating-the-deployer-template[template
option] to `false` for the *metrics deployer*.

[[metrics-deployer]]

== Metrics Deployer

The *metrics deployer* deploys and configures all of the metrics components. You
can configure it by passing in information from
link:../dev_guide/secrets.html[secrets] and by passing parameters to the
*metrics deployer*'s link:../dev_guide/templates.html[template].

=== Metrics Deployer Secrets

By default, the *metrics deployer* auto-generates self-signed certificates for
use between components. To provide your own certificates, you can pass these
values as link:../dev_guide/secrets.html[secrets] to the *metrics deployer*.

[WARNING]
====
By default, the Hawkular Metrics service uses self-signed certificates, which
can cause problems when the console accesses it in a web browser. As an
alternative, you can specify your own *_hawkular-metrics.pem_* secret to use a
certificate that is trusted by the browser.

When supplying your own certificate for the Hawkular Metrics service, it must
contain both the host name specified for the route as well as the internally
used *hawkular-metrics* host name.
====

Optionally, provide your own certificate that is configured to be trusted by
your browser by pointing your secret to the certificate's *_.pem_* and
certificate authority certificate files:

[options="nowrap"]
----
$ oc secrets new metrics-deployer hawkular-metrics.pem=/home/openshift/metrics/hm.pem \
hawkular-metrics-ca.cert=/home/openshift/metrics/hm-ca.cert
----

The Metrics Deployer can accept multiple certificates using secrets. If a
certificate is not passed as a secret, the deployer will generate a self-signed
certificate to be used instead. For the deployer to generate certificates for
you, a secret is still required before it can be deployed. In this case, create
a "dummy" secret that does not specify a certificate value:

[options="nowrap"]
----
$ oc secrets new metrics-deployer nothing=/dev/null
----

The following table contains more advanced configuration options, detailing all
the secrets which can be used by the deployer:

[cols="2,4",options="header"]
|===

|Secret Name |Description

|*_hawkular-metrics.pem_*
|The *_pem_* file to use for the Hawkular Metrics certificate. This certificate
must contain the *hawkular-metrics* host name as well as the publicly available
host name used by the route. This file is auto-generated if unspecified.

|*_hawkular-metrics-ca.cert_*
|The certificate for the CA used to sign the *_hawkular-metrics.pem_*. This
option is ignored if the *_hawkular-metrics.pem_* option is not specified.

|*_hawkular-cassandra.pem_*
|The *_.pem_* file to use for the Cassandra certificate. This certificate must
contain the *hawkular-cassandra* host name. This file is auto-generated if
unspecified.

|*_hawkular-cassandra-ca.cert_*
|The certificate for the CA used to sign the *_hawkular-cassandra.pem_*. This
option is ignored if the *_hawkular-cassandra.pem_* option is not specified.

|*_heapster.cert_*
|The certificate for Heapster to use. This is auto-generated if unspecified.

|*_heapster.key_*
|The key to use with the Heapster certificate. This is ignored if
*_heapster.cert_* is not specified

|*_heapster_client_ca.cert_*
|The certificate that generates *_heapster.cert_*. This is required if
*_heapster.cert_* is specified.  Otherwise, the main CA for the OpenShift
installation is used. In order for
link:../dev_guide/pod_autoscaling.html[horizontal pod autoscaling] to function
properly, this should not be overridden.

|*_heapster_allowed_users_*
|A file containing a comma-separated list of CN to accept from certificates
signed with the specified CA. By default, this is set to allow the OpenShift
service proxy to connect.  If you override this, make sure to add
`system:master-proxy` to the list in order to allow
link:../dev_guide/pod_autoscaling.html[horizontal pod autoscaling] to function
properly.

|===

=== Creating the Deployer Template

The following is the
link:../architecture/core_concepts/templates.html[template]
used to deploy the metrics components.

By default, the OpenShift installer creates this template, and it can be found
at the following path:

ifdef::openshift-origin[]
====
----
/usr/share/openshift/examples/infrastructure-templates/origin/metrics-deployer.yaml
----
====
endif::[]
ifdef::openshift-enterprise[]
====
----
/usr/share/openshift/examples/infrastructure-templates/enterprise/metrics-deployer.yaml
----
====
endif::[]


You will need to save your completed file with the file name *_metrics.yaml_*.

[[deployer-template-parameters]]
==== Deployer Template Parameters

The deployer template parameter options and their defaults are listed above in
the *_metrics.yaml_* file. If required, you can override these values when
creating the *metrics deployer*.

The only required parameter is `*HAWKULAR_METRICS_HOSTNAME*`. This value is
required when creating the deployer because it specifies the hostname for the
Hawkular Metrics link:../architecture/core_concepts/routes.html[route]. This
value should correspond to a fully qualified domain name. You will need to know
the value of `*HAWKULAR_METRICS_HOSTNAME*` when
link:../install_config/cluster_metrics.html#configuring-openshift-metrics[configuring
the console] for metrics access.

All of the other parameters are optional and allow for greater customization.
For instance, if you have a custom install in which the Kubernetes master is not
available under `https://kubernetes.default.svc:443` you can specify the value
to use instead with the `*HAWKULAR_METRICS_HOSTNAME*` parameter. If you wish to
deploy a specific version of the metrics components, you can do so with the `*IMAGE_VERSION*` parameter.

== Deploying the Metric Components

Since deploying and configuring all the metric components is handled by the
*metrics deployer*, you can simply deploy everything in one step.

The following examples show you how to deploy metrics with and without
persistent storage using the default template parameters. Optionally, you can
specify any of the
link:../install_config/cluster_metrics.html#deployer-template-parameters[template
parameters] when calling these commands.

.Deploying with Persistent Storage
====
The following command sets the Hawkular Metrics route to use
`hawkular-metrics.example.com` and is deployed using persistent storage.

You must have a persistent volume of sufficient size available.

[options="nowrap"]
----
$ oc process -f metrics.yaml -v \
HAWKULAR_METRICS_HOSTNAME=hawkular-metrics.example.com | oc create -f -
----
====

.Deploying without Persistent Storage
====
The following command sets the Hawkular Metrics route to use
`hawkular-metrics.example.com` and is deployed without persistent storage.
Remember, this is being deployed without persistent storage, so metric data loss
can occur.

[options="nowrap"]
----
$ oc process -f metrics.yaml -v \
HAWKULAR_METRICS_HOSTNAME=hawkular-metrics.example.com,USE_PERSISTENT_STORAGE=false \
| oc create -f -
----
====

[[configuring-openshift-metrics]]

== Configuring OpenShift

The OpenShift web console uses the data coming from the Hawkular Metrics service
to display its graphs. The URL for accessing the Hawkular Metrics service must
be configured via the `*metricsPublicURL*` option in the
link:../install_config/master_node_configuration.html#master-configuration-files[master-config.yaml]
file. This URL corresponds to the route created with the
`*HAWKULAR_METRICS_HOSTNAME*` template parameter during the
link:../install_config/cluster_metrics.html#deploying-the-metric-components[deployment]
of the metrics components.

[NOTE]
====
You must be able to resolve the `*HAWKULAR_METRICS_HOSTNAME*` from the browser
accessing the console.
====

For example, if your `*HAWKULAR_METRICS_HOSTNAME*` corresponds to
`hawkular-metrics.example.com`, then you must make the following change in the
*_master-config.yaml_* file:

====
[source,yaml,]
.master-config.yaml
----
  assetConfig:
    ...
    metricsPublicURL: "https://hawkular-metrics.example.com/hawkular/metrics"
----
====

Once you have updated and saved the *_master-config.yaml_* file, you must
restart your OpenShift instance.

When your OpenShift server is back up and running, metrics will be displayed on
the pod overview pages.

[CAUTION]
====
If you are using self-signed certificates, remember that the Hawkular Metrics
service is hosted under a different hostname and uses different certificates
than the console. You may need to explicitly open a browser tab to the value
specified in `*metricsPublicURL*` and accept that certificate.

To avoid this issue, use certificates which are configured to be acceptable by
your browser.
====

ifdef::openshift-origin[]
== Accessing Hawkular Metrics Directly

If you wish to access and manage metrics more directly, you can do so via the Hawkular Metrics API.

The link:http://www.hawkular.org/docs/rest/rest-metrics.html[Hawkular Metrics documentation] covers 
how to use the API, but there are a few differences when dealing with the version of Hawkular Metrics 
configured for use on OpenShift:

=== OpenShift Projects & Hawkular Tenants

Hawkular Metrics is a multi-tenanted application. The way its been configured is that a project in 
OpenShift corresponds to a tenant in Hawkular Metrics.

As such, when accessing metrics for a project named `MyProject` you will need to set the 
link:http://www.hawkular.org/docs/rest/rest-metrics.html#_tenant_header[Hawkular-tenant] header to
`MyProject`

There is also a special tenant named `_system` which contains system level metrics. This will require
either a `cluster-reader` or `cluster-admin` level privileges to access.

=== Authorization

The Hawkular Metrics service will authenticate the user against OpenShift to determine if the user has
access to the project it is trying to access.

When accessing the Hawkular Metrics API, you will need to pass a bearer token in the `Authorization` header.

For more information how how to access the Hawkular Metrics in OpenShift, please see the
link:https://github.com/openshift/origin-metrics/blob/master/docs/hawkular_metrics.adoc[Origin Metrics documentation]

== Accessing Heapster Directly

Heapster has been configured to be only accessible via the
link:../rest_api/kubernetes_v1.html#proxy-get-requests-to-service[API proxy]. Accessing it will required
either a cluster-reader or cluster-admin privileges.

For example, to access the Heapster `validate` page, you would need to access it using something similar to:

----
$ curl -H "Authorization: Bearer XXXXXXXXXXXXXXXXX" \
       -X GET https://${KUBERNETES_MASTER}/api/v1/proxy/namespaces/openshift-infra/services/https:heapster:/validate
----

For more information about Heapster and how to access its APIs, please refer the 
link:https://github.com/kubernetes/heapster/[Heapster] project.

endif::[]

[[metrics-cleanup]]
== Cleanup
You can remove your metrics deployment by running:
----
$ oc project openshift-infra
$ for i in $(oc get secret | egrep "(hawkular|heapster|metrics)" | awk '{ print $1 }'); do
    oc delete secret $i
  done
$ oc delete rc hawkular-metrics heapster hawkular-cassandra-1
$ oc delete svc hawkular-cassandra hawkular-cassandra-nodes hawkular-metrics heapster
$ oc delete route hawkular-metrics
$ oc delete sa cassandra hawkular heapster metrics-deployer
$ oc delete template hawkular-cassandra-node-emptydir hawkular-cassandra-node-pv \
  hawkular-cassandra-services \
  hawkular-heapster hawkular-metrics \
  hawkular-support
$ oc delete pvc metrics-cassandra-1
----
