[[install-config-persistent-storage-dynamically-provisioning-pvs]]
= Dynamic provisioning and creating storage classes
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

== Overview
The _StorageClass_ resource object describes and classifies storage that can be
requested, as well as provides a means for passing parameters for
*dynamically provisioned storage* on demand. _StorageClass_ objects can also serve as
a management mechanism for controlling different levels of storage and access
to the storage. Cluster Administrators (`cluster-admin`) or Storage
Administrators (`storage-admin`) define and create the _StorageClass_ objects
that users can request without needing any intimate knowledge about the
underlying storage volume sources.

The {product-title}
xref:../../architecture/additional_concepts/storage.adoc#architecture-additional-concepts-storage[persistent volume]
framework enables this functionality and allows administrators to provision a
cluster with persistent storage. The framework also gives users a way to request
those resources without having any knowledge of the underlying infrastructure.

Many storage types are available for use as persistent volumes in
{product-title}. While all of them can be statically provisioned by an
administrator, some types of storage are created dynamically using the
built-in provider and plug-in APIs.

[NOTE]
====
To enable dynamic provisioning, add the
`openshift_master_dynamic_provisioning_enabled` variable to the `[OSEv3:vars]`
section of the Ansible inventory file and set its value to `True`.

[source]
----
[OSEv3:vars]

openshift_master_dynamic_provisioning_enabled=True
----

====


[[available-dynamically-provisioned-plug-ins]]
== Available dynamically provisioned plug-ins

{product-title} provides the following _provisioner plug-ins_, which have
generic implementations for dynamic provisioning that use the cluster's
configured provider's API to create new storage resources:


[options="header"]
|===

|Storage Type |Provisioner Plug-in Name |Required Configuration| Notes

|OpenStack Cinder
|`kubernetes.io/cinder`
|xref:../../install_config/configuring_openstack.adoc#install-config-configuring-openstack[Configuring for OpenStack]
|

|AWS Elastic Block Store (EBS)
|`kubernetes.io/aws-ebs`
|xref:../../install_config/configuring_aws.adoc#install-config-configuring-aws[Configuring for AWS]
|For dynamic provisioning when using multiple clusters in different zones, tag each
node with `*Key=kubernetes.io/cluster/xxxx,Value=clusterid*` where `xxxx` and `clusterid` are unique
per cluster.

|GCE Persistent Disk (gcePD)
|`kubernetes.io/gce-pd`
|xref:../../install_config/configuring_gce.adoc#install-config-configuring-gce[Configuring for GCE]
|In multi-zone configurations, it is advisable to run one Openshift cluster per GCE project to avoid PVs from getting created in zones where no node from current cluster exists.

|GlusterFS
|`kubernetes.io/glusterfs`
|xref:../../install_config/persistent_storage/persistent_storage_glusterfs.adoc#install-config-persistent-storage-persistent-storage-glusterfs[Configuring GlusterFS]
|

|Ceph RBD
|`kubernetes.io/rbd`
|xref:../../install_config/persistent_storage/persistent_storage_ceph_rbd.adoc#install-config-persistent-storage-persistent-storage-ceph-rbd[Configuring Ceph RBD]
|

|Trident from NetApp
|`netapp.io/trident`
|link:https://github.com/NetApp/trident[Configuring for Trident]
|Storage orchestrator for NetApp ONTAP, SolidFire, and E-Series storage.


|link:https://www.vmware.com/support/vsphere.html[VMware vSphere]
|`kubernetes.io/vsphere-volume`
|link:http://kubernetes.io/docs/getting-started-guides/vsphere/[Getting Started with vSphere and Kubernetes]
|

|Azure Disk
|`kubernetes.io/azure-disk`
|xref:../../install_config/configuring_azure.adoc#install-config-configuring-azure[Configuring for Azure]
|

|HPE Nimble Storage
|`hpe.com/nimble`
|link:https://infosight.hpe.com/InfoSight/media/cms/active/public/tmg_HPE_Nimble_Storage_Integration_Guide_for_Red_Hat_OpenShift_and_OpenShift_Origin_doc_version_family.whz/index.html[Configuring HPE Nimble Kube Storage Controller]
|Dynamic provisioning of HPE Nimble Storage resources using the HPE Nimble Kube Storage Controller.

|===


[IMPORTANT]
====
Any chosen provisioner plug-in also requires configuration for the relevant
cloud, host, or third-party provider as per the relevant documentation.
====

[[defining-storage-classes]]
== Defining a StorageClass

_StorageClass_ objects are currently a globally scoped object and need to be
created by `cluster-admin` or `storage-admin` users.

[NOTE]
====
For GCE and AWS, a default StorageClass is created during {product-title} installation. You can xref:change-default-storage-class[change the default StorageClass] or delete it.
====

There are currently six
plug-ins that are supported. The following sections describe the basic object
definition for a _StorageClass_ and specific examples for each of the supported
plug-in types.

[[basic-spec-definition]]
=== Basic StorageClass object definition

.StorageClass Basic object definition
[source,yaml]
----
kind: StorageClass <1>
apiVersion: storage.k8s.io/v1 <2>
metadata:
  name: foo <3>
  annotations: <4>
     ...
provisioner: kubernetes.io/plug-in-type <5>
parameters: <6>
  param1: value
  ...
  paramN: value

----
<1> (required) The API object type.
<2> (required) The current apiVersion.
<3> (required) The name of the StorageClass.
<4> (optional) Annotations for the StorageClass
<5> (required) The type of provisioner associated with this storage class.
<6> (optional) The parameters required for the specific provisioner, this will change
from plug-in to plug-in.

[[storage-class-annotations]]
=== StorageClass annotations

To set a _StorageClass_ as the cluster-wide default:
----
   storageclass.kubernetes.io/is-default-class: "true"
----
This enables any Persistent Volume Claim (PVC) that does not specify a specific
volume to automatically be provisioned through the _default_ StorageClass

[NOTE]
====
Beta annotation `storageclass.beta.kubernetes.io/is-default-class` is still
working. However it will be removed in a future release.
====

To set a _StorageClass_ description:
----
   kubernetes.io/description: My StorageClass Description
----


[[openstack-cinder-spec]]
=== OpenStack Cinder object definition

.cinder-storageclass.yaml
[source,yaml]
----
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: gold
provisioner: kubernetes.io/cinder
parameters:
  type: fast  <1>
  availability: nova <2>
  fsType: ext4 <3>
----
<1> Volume type created in Cinder. Default is empty.
<2> Availability Zone. If not specified, volumes are generally round-robined across all active zones where the {product-title} cluster has a node.
<3> File system that is created on dynamically provisioned volumes. This value is
copied to the `fsType` field of dynamically provisioned persistent volumes and
the file system is created when the volume is mounted for the first time. The
default value is `ext4`.

[[aws-elasticblockstore-ebs]]
=== AWS ElasticBlockStore (EBS) object definition

.aws-ebs-storageclass.yaml
[source,yaml]
----
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: slow
provisioner: kubernetes.io/aws-ebs
parameters:
  type: io1 <1>
  zone: us-east-1d <2>
  iopsPerGB: "10" <3>
  encrypted: "true" <4>
  kmsKeyId: keyvalue <5>
  fsType: ext4 <6>

----
<1> Select from `io1`, `gp2`, `sc1`, `st1`. The default is `gp2`. See
link:http://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html[AWS documentation] for valid  Amazon Resource Name (ARN) values.
<2> AWS zone. If no zone is specified, volumes are generally round-robined across
all active zones where the {product-title} cluster has a node. Zone and zones
parameters must not be used at the same time.
<3> Only for *io1* volumes. I/O operations per second per GiB. The AWS volume
plug-in multiplies this with the size of the requested volume to compute IOPS of
the volume. The value cap is 20,000 IOPS, which is the maximum supported by AWS.
See
link:http://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html[AWS
documentation] for further details.
<4> Denotes whether to encrypt the EBS volume. Valid values are `true` or `false`.
<5> Optional. The full ARN of the key to use when encrypting the volume. If none
is supplied, but `encypted` is set to `true`, then AWS generates a key. See
link:http://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html[AWS
documentation] for a valid ARN value.
<6> File system that is created on dynamically provisioned volumes. This value is
copied to the `fsType` field of dynamically provisioned persistent volumes and
the file system is created when the volume is mounted for the first time. The
default value is `ext4`.

[[gce-persistentdisk-gcePd]]
=== GCE PersistentDisk (gcePD) object definition

.gce-pd-storageclass.yaml
[source,yaml]
----
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: slow
provisioner: kubernetes.io/gce-pd
parameters:
  type: pd-standard  <1>
  zone: us-central1-a  <2>
  zones: us-central1-a, us-central1-b, us-east1-b  <3>
  fsType: ext4 <4>

----
<1> Select either `pd-standard` or `pd-ssd`. The default is `pd-ssd`.
<2> GCE zone. If no zone is specified, volumes are generally round-robined
across all active zones where the {product-title} cluster has a node. Zone and
zones parameters must not be used at the same time.
<3> A comma-separated list of GCE zone(s). If no zone is specified, volumes are
generally round-robined across all active zones where the {product-title}
cluster has a node. Zone and zones parameters must not be used at the same time.
<4> File system that is created on dynamically provisioned volumes. This value is
copied to the `fsType` field of dynamically provisioned persistent volumes and
the file system is created when the volume is mounted for the first time. The
default value is `ext4`.

[[glusterfs]]
=== GlusterFS object definition

include::install_config/persistent_storage/topics/glusterfs_storageclass.adoc[]

[[ceph-persistentdisk-cephRBD]]
=== Ceph RBD object definition

.ceph-storageclass.yaml
[source,yaml]
----
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast
provisioner: kubernetes.io/rbd
parameters:
  monitors: 10.16.153.105:6789  <1>
  adminId: admin  <2>
  adminSecretName: ceph-secret  <3>
  adminSecretNamespace: kube-system  <4>
  pool: kube  <5>
  userId: kube  <6>
  userSecretName: ceph-secret-user  <7>
  fsType: ext4 <8>

----
<1> Ceph monitors, comma-delimited. It is required.
<2> Ceph client ID that is capable of creating images in the pool. Default is "admin".
<3> Secret Name for `adminId`. It is required. The provided secret must have type "kubernetes.io/rbd".
<4> The namespace for `adminSecret`. Default is "default".
<5> Ceph RBD pool. Default is "rbd".
<6> Ceph client ID that is used to map the Ceph RBD image. Default is the same as `adminId`.
<7> The name of Ceph Secret for `userId` to map Ceph RBD image. It must exist in the same namespace as PVCs. It is required.
<8> File system that is created on dynamically provisioned volumes. This value is
 copied to the `fsType` field of dynamically provisioned persistent volumes and
 the file system is created when the volume is mounted for the first time. The
 default value is `ext4`.

[[trident]]
=== Trident object definition

.trident.yaml
[source,yaml]
----
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: gold
provisioner: netapp.io/trident <1>
parameters: <2>
  media: "ssd"
  provisioningType: "thin"
  snapshots: "true"

----
Trident uses the parameters as selection criteria for the different pools of
storage that are registered with it. Trident itself is configured separately.

<1> For more information about installing Trident with {product-title}, see the link:https://github.com/NetApp/trident[Trident documentation].
<2> For more information about supported parameters, see the link:https://github.com/NetApp/trident#storage-attributes[storage attributes] section of the Trident documentation.

[[vsphere]]
=== VMware vSphere object definition

.vsphere-storageclass.yaml
[source,yaml]
----
kind: StorageClass
apiVersion: storage.k8s.io/v1beta1
metadata:
  name: slow
provisioner: kubernetes.io/vsphere-volume <1>
parameters:
  diskformat: thin <2>

----
<1> For more information about using VMware vSphere with {product-title}, see the link:https://vmware.github.io/vsphere-storage-for-kubernetes/documentation/index.html[VMware vSphere documentation].
<2>  `diskformat`: `thin`, `zeroedthick` and `eagerzeroedthick`. See vSphere docs for details. Default: `thin`

[[azure-file-secret-permission]]
=== Azure File object definition

To configure Azure file dynamic provisioning:

. Create the role in the user's project:
+
----
$ cat azf-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: system:controller:persistent-volume-binder
  namespace: <user's project name>
rules:
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["create", "get", "delete"]
----

. Create the role binding to the `persistent-volume-binder` service account in the `kube-system` project:
+
----
$ cat azf-rolebind.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: system:controller:persistent-volume-binder
  namespace: <user's project>
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: system:controller:persistent-volume-binder
subjects:
- kind: ServiceAccount
  name: persistent-volume-binder
namespace: kube-system
----

. Add the service account as `admin` to the user's project:
+
----
$ oc policy add-role-to-user admin system:serviceaccount:kube-system:persistent-volume-binder -n <user's project>
----

. Create a storage class for the Azure file:
+
----
$ cat azfsc.yaml | oc create -f -
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: azfsc
provisioner: kubernetes.io/azure-file
mountOptions:
  - dir_mode=0777
  - file_mode=0777
----

The user can now create a PVC that uses this storage class.

[[azure-advanced-disk]]
=== Azure Disk object definition

.azure-advanced-disk-storageclass.yaml
[source,yaml]
----
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: slow
provisioner: kubernetes.io/azure-disk
parameters:
  storageAccount: azure_storage_account_name  <1>
  storageaccounttype: Standard_LRS  <2>
  kind: Dedicated  <3>
----
<1> Azure storage account name. This must reside in the same resource group as the
cluster. If a storage account is specified, the `location` is ignored. If a
storage account is not specified, a new storage account gets created in the same
resource group as the cluster. If you are specifying a `storageAccount`, the
value for `kind` must be `Dedicated`.
<2> Azure storage account SKU tier. Default is empty. *Note:* Premium VM can attach
both _Standard_LRS_ and _Premium_LRS_ disks, Standard VM can only attach
_Standard_LRS_ disks, Managed VM can only attach managed disks, and unmanaged VM
can only attach unmanaged disks.
<3> Possible values are `Shared` (default), `Dedicated`, and `Managed`.
+
.. If `kind` is set to `Shared`, Azure creates all unmanaged disks in a few shared
storage accounts in the same resource group as the cluster.
.. If `kind` is set to `Managed`, Azure creates new managed disks.
.. If `kind` is set to `Dedicated` and a `storageAccount` is specified, Azure uses
the specified storage account for the new unmanaged disk in the same resource
group as the cluster. For this to work:
 * The specified storage account must be in the same region.
 * Azure Cloud Provider must have a write access to the storage account.
 .. If `kind` is set to `Dedicated` and a `storageAccount` is not specified, Azure
creates a new dedicated storage account for the new unmanaged disk in the same
resource group as the cluster.

[[nimble]]
=== HPE Nimble Storage Object Definition

.nimble.yaml
[source,yaml]
----
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: transactionaldb
provisioner: hpe.com/nimble <1>
parameters: <2>
  description: "Persistent Volume provisioned from the transactionaldb StorageClass"
  pool: "allflash"
  folder: "Production"
  protectionTemplate: "Local48h-Cloud90d"
  perfPolicy: "SQL Server"
  limitIOPS: "10000"
  dedupe: "true"
  fsMode: "0770"
----
<1> To specify this provisioner, you must first install and configure the HPE
Nimble Kube Storage Controller for {product-title}. See link:https://infosight.hpe.com/InfoSight/media/cms/active/public/tmg_HPE_Nimble_Storage_Integration_Guide_for_Red_Hat_OpenShift_and_OpenShift_Origin_doc_version_family.whz/index.html[HPE Nimble Storage Integration Guide for Red Hat OpenShift and OKD].
<2> For a complete list of parameters the dynamic provisioner and the FlexVolume driver support, see link:https://infosight.hpe.com/InfoSight/media/cms/active/public/tmg_HPE_Nimble_Storage_Integration_Guide_for_Red_Hat_OpenShift_and_OpenShift_Origin_doc_version_family.whz/cnj1529443914400.html[Supported StorageClass parameters].

[NOTE]
====
The HPE Nimble Kube Storage Controller relies on a
xref:../../install_config/persistent_storage/persistent_storage_flex_volume.adoc#flex-volume-drivers[FlexVolume driver]
that is included in the HPE Nimble Storage Linux Toolkit, which HPE Nimble
Storage customers and partners can obtain at link:https://infosight.hpe.com[HPE InfoSight].

For a brief overview, see link:https://hub.openshift.com/primed/133-hpe-nimble-storage[HPE Nimble Storage]
on the Primed Partners page.
====

[[change-default-storage-class]]
== Changing the default StorageClass
If you are using GCE and AWS, use the following process to change the default StorageClass:

. List the StorageClass:
+
[source,bash]
----
$ oc get storageclass

NAME                 TYPE
gp2 (default)        kubernetes.io/aws-ebs <1>
standard             kubernetes.io/gce-pd
----
<1> `(default)` denotes the default StorageClass.

. Change the value of the annotation `storageclass.kubernetes.io/is-default-class` to `false` for the default StorageClass:
+
[source,bash]
----
$ oc patch storageclass gp2 -p '{"metadata": {"annotations": \
    {"storageclass.kubernetes.io/is-default-class": "false"}}}'
----

. Make another StorageClass the default by adding or modifying the annotation as `storageclass.kubernetes.io/is-default-class=true`.
+
[source,bash]
----
$ oc patch storageclass standard -p '{"metadata": {"annotations": \
    {"storageclass.kubernetes.io/is-default-class": "true"}}}'
----

[NOTE]
====
If more than one StorageClass is marked as default, a PVC can only be created if the `storageClassName` is explicitly specified. Therefore, only one StorageClass should be set as the default.
====

. Verify the changes:
+
[source,bash]
----
$ oc get storageclass

NAME                 TYPE
gp2                  kubernetes.io/aws-ebs
standard (default)   kubernetes.io/gce-pd
----

[[moreinfo]]
== Additional information and examples

- xref:../../install_config/storage_examples/storage_classes_dynamic_provisioning.adoc#install-config-storage-examples-storage-classes-dynamic-provisioning[Examples and uses of StorageClasses for Dynamic Provisioning]

- xref:../../install_config/storage_examples/storage_classes_legacy.adoc#install-config-storage-examples-storage-classes-legacy[Examples and uses of StorageClasses without Dynamic Provisioning]
