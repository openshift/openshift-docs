[[install-config-persistent-storage-dynamically-provisioning-pvs]]
= Dynamically Provisioning Persistent Volumes
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

== Overview
You can provision your OpenShift cluster with storage dynamically when running
in a cloud environment. The Kubernetes
xref:../../architecture/additional_concepts/storage.adoc#architecture-additional-concepts-storage[persistent volume]
framework allows administrators to provision a cluster with persistent storage
and gives users a way to request those resources without having any knowledge of
the underlying infrastructure.

Many storage types are available for use as persistent volumes in OpenShift.
While all of them can be statically provisioned by an administrator, some types
of storage can be created dynamically using an API. These types of storage can
be provisioned in an OpenShift cluster using the new and experimental dynamic
storage feature.

[IMPORTANT]
====
ifdef::openshift-enterprise[]
Dynamic provisioning of persistent volumes is currently a Technology Preview
feature, introduced in OpenShift Enterprise 3.1.1.
endif::[]
This feature is experimental and expected to change in the future as it matures
and feedback is received from users. New ways to provision the cluster are
planned and the means by which one accesses this feature is going to change.
Backwards compatibility is not guaranteed.
====

[[enabling-provisioner-plugins]]
== Enabling Provisioner Plug-ins

OpenShift provides the following _provisioner plug-ins_, which have generic
implementations for dynamic provisioning that use the cluster's configured cloud
provider's API to create new storage resources:

[options="header"]
|===

|Storage Type |Provisioner Plug-in Name |Required Cloud Configuration

|OpenStack Cinder
|`kubernetes.io/cinder`
|xref:../../install_config/configuring_openstack.adoc#install-config-configuring-openstack[Configuring for OpenStack]

|AWS Elastic Block Store (EBS)
|`kubernetes.io/aws-ebs`
|xref:../../install_config/configuring_aws.adoc#install-config-configuring-aws[Configuring for AWS]

|GCE Persistent Disk (gcePD)
|`kubernetes.io/gce-pd`
|xref:../../install_config/configuring_gce.adoc#install-config-configuring-gce[Configuring for GCE]
|In multi-zone configurations, PVs must be created in the same region/zone as
the master node. Do this by setting the
`*failure-domain.beta.kubernetes.io/region*` and
`*failure-domain.beta.kubernetes.io/zone*` PV labels to match the master node.

|Trident from NetApp
|`netapp.io/trident`
|link:https://github.com/NetApp/trident[Configuring for Trident]
|Storage orchestrator for NetApp ONTAP, SolidFire, and E-Series storage.

|===

[IMPORTANT]
====
Any chosen provisioner plug-in also requires configuration for the relevant
cloud, host, or third-party provider as per the relevant documentation.
====

[[defining-storage-classes]]
== Defining a StorageClass

_StorageClass_ objects are currently a globally scoped object and need to be
created by `cluster-admin` or `storage-admin` users. There are currently five
plug-ins that are supported. The following sections describe the basic object
definition for a _StorageClass_ and specific examples for each of the supported
plug-in types.

[[basic-spec-defintion]]
=== Basic StorageClass Object Definition

.StorageClass Basic Object Definition
[source,yaml]
----
kind: StorageClass <1>
apiVersion: storage.k8s.io/v1beta1 <2>
metadata:
  name: foo <3>
  annotations: <4>
     ...
provisioner: kubernetes.io/plug-in-type <5>
parameters: <6>
  param1: value
  ...
  paramN: value

----
<1> (required) The API object type.
<2> (required) The current apiVersion.
<3> (required) The name of the StorageClass.
<4> (optional) Annotations for the StorageClass
<5> (required) The type of provisioner associated with this storage class.
<6> (optional) The parameters required for the specific provisioner, this will change
from plug-in to plug-in.

When your OpenShift cluster is configured for EBS, GCE, or Cinder, the
associated provisioner plug-in is implied and automatically enabled. No
additional OpenShift configuration by the cluster administration is required for
dynamic provisioning.

For example, if your OpenShift cluster is configured to run in AWS, the EBS
provisioner plug-in is automatically available for creating
xref:dynamic-pvs-requesting-storage[dynamically provisioned storage requested
by a user].

Future provisioner plug-ins will include the many types of storage a single
provider offers. AWS, for example, has several types of EBS volumes to offer,
each with its own performance characteristics; there is also an NFS-like storage
option. More provisioner plug-ins will be implemented for the supported storage
types available in OpenShift.

[[openstack-cinder-spec]]
=== OpenStack Cinder Object Defintion

.cinder-storageclass.yaml
[source,yaml]
----
kind: StorageClass
apiVersion: storage.k8s.io/v1beta1
metadata:
  name: gold
provisioner: kubernetes.io/cinder
parameters:
  type: fast  <1>
  availability: nova <2>

----
<1> VolumeType created in Cinder. Default is empty.
<2> Availability Zone. Default is empty.

Users can request dynamically provisioned storage by including a storage class
annotation in their xref:../../dev_guide/persistent_volumes.adoc#dev-guide-persistent-volumes[persistent
volume claim]:

.aws-ebs-storageclass.yaml
[source,yaml]
----
kind: "PersistentVolumeClaim"
apiVersion: "v1"
metadata:
  name: slow
provisioner: kubernetes.io/aws-ebs
parameters:
  type: io1 <1>
  zone: us-east-1d <2>
  iopsPerGB: "10" <3>
  encrypted: true <4>
  kmsKeyId: keyvalue <5>

----

<1> Select from `io1`, `gp2`, `sc1`, `st1`. The default is `gp2`. link:http://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html[See AWS docs for valid ARN value].
<2> AWS zone. If not specified, the zone is randomly selected from zones where {product-title} cluster has a node.
<3> Only for io1 volumes. I/O operations per second per GiB. The AWS volume plug-in multiplies this with the size of the requested volume to compute IOPS of the volume. The value cap is 20,000 IOPS, which is the maximum supported by AWS. See AWS documentation for further details.
<4> Denotes whether to encrypt the EBS volume. Valid values are `true` or `false`.
<5> (optional) The full Amazon Resource Name (ARN) of the key to use when encrypting the volume. If none is supplied but encrypted is true, AWS generates a key. link:http://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html[See AWS docs for valid ARN value].

[[gce-persistentdisk-gcePd]]
=== GCE PersistentDisk (gcePD) Object Defintion

.gce-pd-storageclass.yaml
[source,yaml]
----
kind: StorageClass
apiVersion: storage.k8s.io/v1beta1
metadata:
  name: slow
provisioner: kubernetes.io/gce-pd
parameters:
  type: pd-standard  <1>
  zone: us-central1-a  <2>
----
<1> Select either `pd-standard` or `pd-ssd`. The default is `pd-ssd`.
<2> GCE zone. If not specified, the zone is randomly chosen from zones in the same region as `controller-manager`.


[[glusterfs]]
=== GlusterFS Object Defintion

.glusterfs-storageclass.yaml
[source,yaml]
----
kind: StorageClass
apiVersion: storage.k8s.io/v1beta1
metadata:
  name: slow
provisioner: kubernetes.io/glusterfs
parameters:
  resturl: "http://127.0.0.1:8081" <1>
  restuser: "admin" <2>
  secretName: "heketi-secret" <3>
  secretNamespace: "default" <4>
  gidMin: "40000" <5>
  gidMax: "50000" <6>
----
<1> Gluster REST service/Heketi service URL that provisions Gluster
volumes on demand. The general format should be
`{http/https}://{IPaddress}:{Port}`. This is a mandatory parameter for the
GlusterFS dynamic provisioner. If the Heketi service is exposed as a routable
service in the {product-title}, it will have a resolvable fully qualified domain
name and Heketi service URL. For additional information and configuration, See
link:https://access.redhat.com/documentation/en/red-hat-gluster-storage/3.1/single/container-native-storage-for-openshift-container-platform/[Container-Native
Storage for OpenShift Container Platform].
<2> Gluster REST service/Heketi user who has access to create
volumes in the Gluster Trusted Pool.
<3> Identification of a Secret instance that contains a user password to use when
talking to the Gluster REST service. Optional; an empty password will be used
when both `secretNamespace` and `secretName` are omitted. The provided secret
must be of type `"kubernetes.io/glusterfs"`.
<4> The namespace of mentioned `secretName`. Optional; an empty password will be used
when both `secretNamespace` and `secretName` are omitted. The provided secret
must be of type `"kubernetes.io/glusterfs"`.
<5> Optional. The minimum value of GID range for the storage class.
<6> Optional. The maximum value of GID range for the storage class.

|JSON-in-description
|GCE PD
|====

[[ceph-persistentdisk-cephRBD]]
=== Ceph RBD Object Definition

.ceph-storageclass.yaml
[source,yaml]
----
apiVersion: storage.k8s.io/v1beta1
kind: StorageClass
metadata:
  name: fast
provisioner: kubernetes.io/rbd
parameters:
  monitors: 10.16.153.105:6789  <1>
  adminId: kube  <2>
  adminSecretName: ceph-secret  <3>
  adminSecretNamespace: kube-system  <4>
  pool: kube  <5>
  userId: kube  <6>
  userSecretName: ceph-secret-user  <7>

----
<1> Ceph monitors, comma delimited. It is required.
<2> Ceph client ID that is capable of creating images in the pool. Default is "admin".
<3> Secret Name for `adminId`. It is required. The provided secret must have type "kubernetes.io/rbd".
<4> The namespace for `adminSecret`. Default is "default".
<5> Ceph RBD pool. Default is "rbd".
<6> Ceph client ID that is used to map the Ceph RBD image. Default is the same as `adminId`.
<7> The name of Ceph Secret for `userId` to map Ceph RBD image. It must exist in the same namespace as PVCs. It is required.

[[trident]]
=== Trident Object Definition

.trident.yaml
[source,yaml]
----
apiVersion: storage.k8s.io/v1beta1
kind: StorageClass
metadata:
  name: gold
provisioner: netapp.io/trident <1>
parameters: <2>
  media: "ssd"
  provisioningType: "thin"
  snapshots: "true"

----
Trident uses the parameters as selection criteria for the different pools of
storage that are registered with it. Trident itself is configured separately.

<1> For more information about installing Trident with {product-title}, see the link:https://github.com/NetApp/trident[Trident documentation].
<2> For more information about supported parameters, see the link:https://github.com/NetApp/trident#storage-attributes[storage attributes] section of the Trident documentation.

- OpenShift terminates unexpectedly and the dynamically provisioned
AWS EBS
contains useful data that must be recovered.
The OpenShift users provide the storage administrators with a list of
affected projects and their PVCs:
+
[cols="1,1"]
|====
|Project Name |PVC Name

|app-server
|a-pv-01

|
|a-pv-02

|notifications
|n-pv-01
|====
+
The storage administrators search for the orphaned volumes,
matching project names and PVC names to the
`kubernetes.io/created-for/pvc/namespace` and
`kubernetes.io/created-for/pvc/name` tags, respectively.
They find them and arrange to make them available again for data-recovery efforts.

- The users do not explicitly delete the dynamically provisioned storage
volumes when they are finished with a project.
The storage administrators find the defunct volumes and delete them.
Unlike the preceding scenario, they need match only the project names
to `kubernetes.io/created-for/pvc/namespace`.


[[dynamic-pvs-volume-recycling]]
== Volume Recycling

Volumes created dynamically by a provisioner have their
`*persistentVolumeReclaimPolicy*` set to *Delete*. When a persistent volume
claim is deleted, its backing persistent volume is considered released of its
claim, and that resource can be reclaimed by the cluster. Dynamic provisioning
utilizes the provider's API to delete the volume from the provider and then
removes the persistent volume from the cluster.
