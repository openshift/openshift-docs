// Module included in the following assemblies:
//
// * install_config/configuring_for_vsphere.adoc

[id='vsphere-configuring-storage_{context}']
= Configuring {product-title} to use vSphere storage

{product-title} supports VMware vSphere's Virtual Machine Disk (VMDK) volumes.
You can provision your {product-title} cluster with
xref:../architecture/additional_concepts/storage.adoc#architecture-additional-concepts-storage[persistent
storage] using link:https://www.vmware.com/au/products/vsphere.html[VMware
vSphere]. Some familiarity with Kubernetes and VMware vSphere is assumed.

{product-title} creates the disk in vSphere and attaches the disk to the proper
instance.


The {product-title}
xref:../architecture/additional_concepts/storage.adoc#architecture-additional-concepts-storage[persistent
volume (PV)] framework allows administrators to provision a cluster with persistent
storage and gives users a way to request those resources without having any
knowledge of the underlying infrastructure. vSphere VMDK volumes can be
xref:../install_config/persistent_storage/dynamically_provisioning_pvs.adoc#install-config-persistent-storage-dynamically-provisioning-pvs[provisioned
dynamically].

PVs are not bound to a single project or namespace; they can be
shared across the {product-title} cluster.
xref:../architecture/additional_concepts/storage.adoc#persistent-volume-claims[PV claims], however, are specific to a project or namespace and can be
requested by users.

[IMPORTANT]
====
High availability of storage in the infrastructure is left to the underlying
storage provider.
====


[discrete]
== Prerequisites

Before creating PVs using vSphere, ensure your
{product-title} cluster meets the following requirements:

* {product-title} must first be for vSphere Cloud Provider
* Each node host in the infrastructure must match the vSphere VM name.
* Each node host must be in the same resource group.

[IMPORTANT]
====
Create VMDK using one of the following methods before using them.

* Create using `vmkfstools`:
+
Access ESX through Secure Shell (SSH) and then use following command to create a VMDK volume:
+
[source, bash]
----
vmkfstools -c 2G /vmfs/volumes/DatastoreName/volumes/myDisk.vmdk
----

* Create using `vmware-vdiskmanager`:
+
[source, bash]
----
shell vmware-vdiskmanager -c -t 0 -s 40GB -a lsilogic myDisk.vmdk
----
====

[[vsphere-provisioning]]
== Provisioning VMware vSphere volumes

Storage must exist in the underlying infrastructure before it can be mounted as
a volume in {product-title}. After ensuring {product-title} is
configured for vSphere, all that is required for {product-title} and vSphere is a VM folder path, file system type, and the `PersistentVolume` API.

[[vsphere-creating-persistent-volume]]
=== Creating persistent volumes

. Define a PV object definition, for example *_vsphere-pv.yaml_*:
+
[source, yaml]
----
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv0001 <1>
spec:
  capacity:
    storage: 2Gi <2>
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  vsphereVolume: <3>
    volumePath: "[datastore1] volumes/myDisk" <4>
    fsType: ext4 <5>
----
<1> The name of the volume. This must be how it is identified by xref:../../architecture/additional_concepts/storage.adoc#architecture-additional-concepts-storage[PV claims] or from pods.
<2> The amount of storage allocated to this volume.
<3> The volume type being used. This example uses `vsphereVolume`, and the label is used to mount a vSphere VMDK volume into pods. The contents of a volume are preserved when it is unmounted. The volume type supports VMFS and VSAN datastore.
<4> This VMDK volume must exist, and you must include brackets ([]) in the volume definition.
<5> The file system type to mount. For example, `ext4`, `xfs`, or other file-systems.

[IMPORTANT]
====
Changing the value of the `fsType` parameter after the volume is formatted and
provisioned can result in data loss and pod failure.
====

. Create the PV:
+
[source, bash]
----
$ oc create -f vsphere-pv.yaml
  persistentvolume "pv0001" created
----

. Verify that the PV was created:
+
[source, bash]
----
$ oc get pv
NAME    LABELS  CAPACITY  ACCESSMODES   STATUS    CLAIM   REASON  AGE
pv0001  <none>  2Gi       RWO           Available                 2s
----

Now you can
xref:../../dev_guide/persistent_volumes.adoc#dev-guide-persistent-volumes[request
storage using PV claims], which can now use your PV.

[IMPORTANT]
====
PV claims only exist in the user's namespace and can only be referenced by a pod
within that same namespace. Any attempt to access a PV from a different
namespace causes the pod to fail.
====

[[volume-format-vsphere]]
=== Formatting VMware vSphere volumes

Before {product-title} mounts the volume and passes it to a container, it checks
that the volume contains a file system as specified by the `fsType` parameter in
the PV definition. If the device is not formatted with the file
system, all data from the device is erased, and the device is automatically
formatted with the given file system.

This allows unformatted vSphere volumes to be used as PVs, because
{product-title} formats them before the first use.


== Provisioning VMware vSphere volumes via a Storage Class

. {product-title} creates the following `storageclass` when you use the `vsphere-volume`
provisioner and if you use the `openshift_cloudprovider_kind=vsphere` and
`openshift_vsphere_*` variables in the Ansible inventory. Otherwise, you can create
it manually:
+
[source,yaml]
----
$ oc get --export storageclass vsphere-standard -o yaml
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: "vsphere-standard" <1>
provisioner: kubernetes.io/vsphere-volume <2>
parameters:
    diskformat: zeroedthick <3>
    datastore: "ose3-vmware" <4>
reclaimPolicy: Delete
----
<1> The name of the storage class.
<2> The type of storage provisioner: vsphere-volume
<3> The type of disk: zeroedthick, thin.
<4> The source datastore where the disk will be created.


. After you request a PV and using the storageclass shown in the previous step,
{product-title} creates VMDK disks in the vSphere infrastructure. To verify that the disks were created:
+
[source,bash]
----
$ ls /vmfs/volumes/ose3-vmware/kubevols | grep kubernetes
kubernetes-dynamic-pvc-790615e8-a22a-11e8-bc85-0050568e2982.vmdk
----

[NOTE]
====
vSphere-volume disks are `ReadWriteOnce` access mode, which means the volume can
be mounted as read-write by a single node. See
xref:../architecture/additional_concepts/storage.html#pv-access-modes[the Access
modes section of the Architecture guide] for more information.
====
