////
Module included in the following assemblies:

install_config/configuring_rhv.adoc
////

[id='configuring-rhv-objects_{context}']
= Configuring Red Hat Virtualization

To integrate {product-title} with Red Hat Virtualization, perform the following actions as part of your xref:../install/host_preparation.adoc#install-config-install-host-preparation[host preparation].

== Creating the bastion virtual machine

The bastion virtual machine is used to install {product-title} on Red Hat Virtualization.

.Procedure

. Log in to the Manager machine using SSH.
. Create a temporary bastion installation directory, for example, *_/bastion_installation_*, for the installation files.
. Create an encrypted file, *_/bastion_installation/secure_vars.yaml_*:
+
[options="nowrap" subs="+quotes,verbatim"]
----
# ansible-vault create secure_vars.yaml
----

. Add the following variables to *_secure_vars.yaml_*:
+
[options="nowrap" subs="+quotes,verbatim"]
----
engine_password: <Manager_password>
bastion_root_password: <bastion_root_password>
rh_password: <Red_Hat_Subscription_Manager_password>
root_password: <VM_root_password>
----

. Save the file and record the vault password.

. Create the installation playbook, *_/bastion_installation/create-bastion-machine-playbook.yaml_*, and update its parameters:
+
[source,yml]
----
---
- name: Create a bastion machine
  hosts: localhost
  connection: local
  gather_facts: false

  vars:
    engine_url: https://_Manager_FQDN_/ovirt-engine/api
    engine_user: <admin@internal>
    engine_password: {{ engine_password }}
    engine_cafile:

    qcow_url: <1>
    template_cluster: Default
    template_name: rhelguest76
    template_memory: 4GiB
    template_cpu: 2
    wait_for_ip: True

    vms:
      name: rhel-bastion
      cluster: Default
      profile:
        cores: 2
        template: "{{ template_name }}"
        root_password: {{ root_password }}
        ssh_key: "{{ lookup('file', '~/.ssh/id_rsa.pub') }}"
        state: running
      cloud-init:
        rh_subscription:
          username: <Red_Hat_Subscription_Manager_username>
          password: {{ rh_password }}
          auto-attach: True
          enable-repo: ['rhel-7-server-rpms', 'rhel-7-server-extras-rpms', 'rhel-7-server-ansible-2.7-rpms', 'rhel-7-server-ose-3.11-rpms', 'rhel-7-server-supplementary-rpms', 'rhel-7-server-rhv-4.2-manager-rpms']
        packages:
          - ansible
          - ovirt-ansible-roles
          - openshift-ansible
          - ovirt-engine-sdk-python
  roles:
    - oVirt.image-template
    - oVirt.vm-infra
----

<1> `<qcow_url>` is the URL for downloading the *_RHEL-guest-image_*. You can copy the URL from link:https://access.redhat.com/downloads/content/69/ver=/rhel---7/latest/x86_64/product-software[]:
.. In the *Product Software* tab, locate the *_Red Hat Enterprise Linux KVM Guest Image_*.
.. Right-click the *Download Now* button and copy the URL.
+
[NOTE]
====
This link expires after some time. Save the link when you are ready to run the playbook.
====

. Create the bastion virtual machine:
+
[options="nowrap" subs="+quotes,verbatim"]
----
# ansible-playbook -i localhost create-bastion-machine-playbook.yaml -e @secure_vars.yaml --ask-vault-pass
----

. Verify that the bastion virtual machine, *_rhel-bastion_*, was created successfully in the Administration Portal.

== Installing {product-title} on Red Hat Virtualization

You can install {product-title} using the bastion virtual machine:

. Log in to *_rhel-bastion_*.
. Create a temporary directory, for example, *_/{product-title}_installation_*, for the installation files.
. Create an encrypted file, *_/{product-title}_installation/secure_vars.yaml_*:
+
[options="nowrap" subs="+quotes,verbatim"]
----
# ansible-vault create secure_vars.yaml
----

. Add the following variables to *_secure_vars.yaml_*:
+
[options="nowrap" subs="+quotes,verbatim"]
----
engine_password: <Manager_password>
root_password: <VM_root_password>
----

. Save the file and record the vault password.

. Create *_/{product-title}_installation/vars.yaml_* and update its parameters:
+
[source,yml]
----
---
# For more comprehensive list of arguments please see
# openshift_ovirt role args   - https://github.com/openshift/openshift-ansible/tree/master/roles/openshift_ovirt#role-variables
# openshift installation args - https://github.com/openshift/openshift-ansible/tree/master/inventory
engine_url: https://<Manager_VQDN>/ovirt-engine/api
engine_user: admin@internal
engine_password: {{ engine_password }}
engine_insecure: true
engine_cafile:

openshift_ovirt_vm_manifest:
  - name: 'master'
    count: 1
    profile: 'master_vm'
  - name: 'node'
    count: 0
    profile: 'node_vm'
  - name: 'lb'
    count: 0
    profile: 'node_vm'

openshift_ovirt_all_in_one: true
openshift_ovirt_cluster: Default
openshift_ovirt_data_store: data
openshift_ovirt_ssh_key: "{{ lookup('file', 'id_rsa.pub') }}"

public_hosted_zone:
# Uncomment to disable install-time checks, for smaller scale installations
#openshift_disable_check: memory_availability,disk_availability,docker_image_availability

qcow_url: <1>
image_path: /var/tmp
template_name: rhel7
template_cluster: "{{ openshift_ovirt_cluster }}"
template_memory: 4GiB
template_cpu: 1
template_disk_storage: "{{ openshift_ovirt_data_store }}"
template_disk_size: 10GiB
template_nics:
  - name: nic1
    profile_name: ovirtmgmt
    interface: virtio

debug_vm_create: true
wait_for_ip: true
vm_infra_wait_for_ip_retries: 30
vm_infra_wait_for_ip_delay: 20

openshift_ovirt_vm_profile:
  master_vm:
    cluster: "{{ openshift_ovirt_cluster }}"
    template: "{{ template_name }}"
    memory: "{{ vm_memory | default('8GiB') }}"
    cores: "{{ vm_cores | default(2) }}"
    high_availability: true
    disks:
      - size: 10GiB
        storage_domain: "{{ openshift_ovirt_data_store }}"
        name: docker_disk
        interface: virtio
    state: running
    cloud_init:
      root_password: {{ root_password }}
      authorized_ssh_keys: "{{ openshift_ovirt_ssh_key }}"
      custom_script: "{{ cloud_init_script_master }}"

##########################
# Cloud Init Script
##########################
# Use the following if RHEL 7.4 (or earlier) VMs are being created on a RHV 4.2 (or later) engine
#    - sed -i 's@^# device =.*@device = /dev/virtio-ports/ovirt-guest-agent.0@' /etc/ovirt-guest-agent.conf
#    - sed -i 's@com.redhat.rhevm.vdsm@ovirt-guest-agent.0@' /etc/udev/rules.d/55-ovirt-guest-agent.rules
#    - 'udevadm trigger --subsystem-match="virtio-ports"'

cloud_init_script_master: |
  yum_repos:
    centos-ovirt42:
      baseurl: http://mirror.centos.org/centos/7/virt/x86_64/ovirt-4.2
      enabled: true
      gpgcheck: false
  packages:
    - ovirt-guest-agent
    - epel-release
    - centos-release-openshift-origin311
  runcmd:
    - sed -i 's/# ignored_nics =.*/ignored_nics = docker0, tun0 /' /etc/ovirt-guest-agent.conf
    - systemctl enable ovirt-guest-agent
    - systemctl start ovirt-guest-agent
    - mkdir -p /var/lib/docker
    - /usr/sbin/mkfs.xfs -L dockervo /dev/vdb
  mounts:
    - [ '/dev/vdb', '/var/lib/docker', 'xfs', 'defaults,gquota' ]
  power_state:
    mode: reboot
    message: cloud init finished - boot and install openshift
    condition: True
### oVirt Metrics ###
# The following variables are specific to metrics installation
#openshift_ovirt_vm_profile:
#  master_vm:
#    cluster: "{{ openshift_ovirt_cluster }}"
#    template: "{{ template_name }}"
#    memory: "{{ vm_memory | default('10GiB') }}"
#    cores: "{{ vm_cores | default(2) }}"
#    high_availability: true
#    disks:
#      - size: 10GiB
#        storage_domain: "{{ openshift_ovirt_data_store }}"
#        name: docker_disk
#        interface: virtio
#      - size: 20GiB
#        storage_domain: "{{ openshift_ovirt_data_store }}"
#        name: elasticsearch_disk
#        interface: virtio
#    state: running
#    cloud_init:
#      root_password: admin
#      authorized_ssh_keys: "{{ openshift_ovirt_ssh_key }}"
#      custom_script: "{{ cloud_init_script_master }}"
#
## Metrics specific cloud init script
#cloud_init_script_master: |
#  yum_repos:
#    centos-ovirt42:
#      baseurl: http://mirror.centos.org/centos/7/virt/x86_64/ovirt-4.2
#      enabled: true
#      gpgcheck: false
#  packages:
#    - ovirt-guest-agent
#    - epel-release
#    - centos-release-openshift-origin311
#  runcmd:
#    - sed -i 's/# ignored_nics =.*/ignored_nics = docker0, tun0 /' /etc/ovirt-guest-agent.conf
#    - systemctl enable ovirt-guest-agent
#    - systemctl start ovirt-guest-agent
#    - mkdir -p /var/lib/docker
#    - /usr/sbin/mkfs.xfs -L dockervo /dev/vdb
#    - mkdir -p /var/lib/elasticsearch
#    - /usr/sbin/mkfs.xfs -L elasticvo /dev/vdc
#    - chgrp 65534 /var/lib/elasticsearch
#    - semanage fcontext -a -t container_file_t "/var/lib/elasticsearch(/.*)?"
#    - restorecon -R -v /var/lib/elasticsearch
#  mounts:
#    - [ '/dev/vdb', '/var/lib/docker', 'xfs', 'defaults,gquota' ]
#    - [ '/dev/vdc', '/var/lib/elasticsearch', 'xfs', 'defaults,gquota' ]
#  power_state:
#    mode: reboot
#    message: cloud init finished - boot and install openshift
#    condition: True
#
## Metrics static host storage - In the future we should use ovirt flex/csi storage provisioner
#openshift_logging_es_nodeselector: {'node-role.kubernetes.io/infra': 'true'}
#openshift_logging_install_logging: True
#openshift_logging_es_allow_external: True
#openshift_logging_mux_file_buffer_storage_type: hostmount
#openshift_logging_elasticsearch_storage_type: hostmount
#openshift_logging_elasticsearch_hostmount_path: /var/lib/elasticsearch
#openshift_logging_mux_namespaces:
#  - ovirt-metrics-engine
#  - ovirt-logs-engine
#
## The tmp directory to download the template to.
#image_path: "/var/tmp/"
### oVirt Metrics ###
#
----
<1> `<qcow_url>` is the URL for downloading the *_RHEL-guest-image_*. You can copy the URL from link:https://access.redhat.com/downloads/content/69/ver=/rhel---7/latest/x86_64/product-software[]:
.. In the *Product Software* tab, locate the *_Red Hat Enterprise Linux KVM Guest Image_*.
.. Right-click the *Download Now* button and copy the URL.
+
[NOTE]
====
This link expires after some time. Save the link when you are ready to run the playbook.
====
+
Optionally, uncomment the *_ovirt Metrics_* section if you are installing Metrics Store.

. Create *_/{product-title}_installation/install_okd.yaml_* with the following content:
+
[source,yml]
----
---
- name: Openshift Origin on oVirt
  hosts: localhost
  connection: local
  gather_facts: false

  vars_files:
    - vars.yaml
    - secure_vars.yaml

  pre_tasks:
    - ovirt_auth:
        url:      "{{ engine_url }}"
        username: "{{ engine_user }}"
        password: "{{ engine_password }}"
        insecure: "{{ engine_insecure }}"
        ca_file:  "{{ engine_username | default(omit) }}"

  roles:
    - role: openshift_ovirt

- import_playbook: setup_dns.yaml
- import_playbook: playbooks/prerequisites.yml
- import_playbook: playbooks/openshift-node/network_manager.yml
- import_playbook: playbooks/deploy_cluster.yml
----

. Create *_/{product-title}_installation/setup_dns.yaml_* with the following content:
+
[source,yml]
----
- hosts: masters
  strategy: free
  tasks:
    - shell: "echo {{ ansible_default_ipv4.address }} {{ inventory_hostname }} etcd.{{ inventory_hostname.split('.', 1)[1] }} openshift-master.{{ inventory_hostname.split('.', 1)[1] }} openshift-public-master.{{ inventory_hostname.split('.', 1)[1] }} docker-registry-default.apps.{{ inventory_hostname.split('.', 1)[1] }} webconsole.openshift-web-console.svc registry-console-default.apps.{{ inventory_hostname.split('.', 1)[1] }} >> /etc/hosts"
      when: openshift_ovirt_all_in_one is defined | ternary((openshift_ovirt_all_in_one | bool), false)
----

. Create an Ansible inventory file, *_/etc/ansible/openshift_3_11.hosts_*, with the following content:
+
[source,yaml]
----
[workstation]
localhost ansible_connection=local
[all:vars]
engine_url=
engine_user=
engine_password=
engine_insecure=
engine_cafile=
compatibility_version=4.2
public_hosted_zone=
template_name=rhel7
qcow_url=
openshift_ovirt_all_in_one=true
openshift_ovirt_dns_zone="{{ public_hosted_zone }}"
openshift_ovirt_data_store=filedomain2
openshift_ovirt_ssh_key="{{ lookup('file', '~/.ssh/id_rsa.pub') }}"
openshift_ovirt_cluster=Default
openshift_web_console_install=true
openshift_master_overwrite_named_certificates=true
openshift_master_cluster_hostname="openshift-master.{{ public_hosted_zone }}"
openshift_master_cluster_public_hostname="openshift-public-master.{{ public_hosted_zone }}"
openshift_master_default_subdomain="{{ public_hosted_zone }}"
openshift_public_hostname="{{openshift_master_cluster_public_hostname}}"
openshift_deployment_type=origin
openshift_disable_check=memory_availability,disk_availability,docker_image_availability
canonical_registry=index.docker.io
openshift_service_catalog_image_version="{{ openshift_image_tag }}"

[OSEv3:vars]
# General variables
debug_level=1
containerized=False
ansible_ssh_user=root
os_firewall_use_firewalld=True
openshift_deployment_type=origin
openshift_enable_excluders=false
openshift_install_examples=false
openshift_clock_enabled=true
openshift_debug_level="{{ debug_level }}"
openshift_node_debug_level="{{ node_debug_level | default(debug_level,true) }}"
osn_storage_plugin_deps=[]
openshift_master_bootstrap_auto_approve=true
openshift_master_bootstrap_auto_approver_node_selector={"node-role.kubernetes.io/master":"true"}
osm_controller_args={"experimental-cluster-signing-duration": ["20m"]}
osm_default_node_selector="node-role.kubernetes.io/compute=true"
openshift_enable_service_catalog=False

# Docker
#container_runtime_docker_storage_setup_device=/dev/vdb
container_runtime_docker_storage_type=overlay2
openshift_docker_use_system_container=False

# ANSIBLE BROKER
ansible_service_broker_etcd_image_prefix=quay.io/coreos/
ansible_service_broker_registry_type=quay
ansible_service_broker_registry_name=quay.io
ansible_service_broker_registry_url=https://quay.io
ansible_service_broker_registry_user=
ansible_service_broker_registry_password=
ansible_service_broker_registry_organization=
ansible_service_broker_registry_tag=latest
ansible_service_broker_registry_whitelist=[.*-apb$]
ansible_service_broker_registry_blacklist=[.*automation-broker-apb$]

[OSEv3:children]
nodes
masters
etcd

[masters]
;master0.example.com openshift_node_group_name="node-config-all-in-one" openshift_schedulable=true
[etcd]
;master0.example.com
[nodes]
;master0.example.com openshift_hostname=master0.example.com openshift_node_group_name="node-config-all-in-one"
----

. Export the environment variables and run the {product-title} installation playbook:
+
[options="nowrap" subs="+quotes,verbatim"]
----
# export ANSIBLE_ROLES_PATH="/usr/share/ansible/roles/:/usr/share/ansible/openshift-ansible/roles"
# export ANSIBLE_JINJA2_EXTENSIONS="jinja2.ext.do"
# ansible-playbook -i openshift_3_11.hosts install_okd.yaml
----

. Create DNS entries for the routers. Provide entries for all infrastructure instances and configure a round-robin strategy so that the router can pass traffic to applications.

. Create a DNS entry for the {product-title} web console. Specify the IP address of the load balancer node.

. Continue to install the cluster following the xref:../install/running_install.adoc#install-running-installation-playbooks[Installing {product-title}] steps. During that process, make any changes to your inventory file that your cluster needs.
