[[install-config-install-planning]]
= Planning
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

[[inital-planning]]
== Initial Planning

For production environments, several factors influence installation. Consider
the following questions as you read through the documentation:

* _Which installation method do you want to use?_ The xref:installation-methods[Installation Methods]
section provides some information about the quick and advanced installation
methods.

* _How many hosts do you require in the cluster?_ The xref:environment-scenarios[Environment Scenarios]
section provides multiple examples of Single Master and Multiple Master
configurations.

* _How many pods are required in your cluster?_ The xref:sizing[Sizing Considerations]
section provides limits for nodes and pods so you can calculate how large your
environment needs to be.

* _Is xref:../../admin_guide/high_availability.adoc#admin-guide-high-availability[high availability]
required?_ High availability is recommended for fault tolerance. In this
situation, you might aim to use the xref:multi-masters-using-native-ha[Multiple Masters Using Native HA]
example as a basis for your environment.

* _Which installation type do you want to use: xref:rpm-vs-containerized[RPM or containerized]?_
Both installations provide a working {product-title} environment, but you might
have a preference for a particular
method of installing, managing, and updating your services.

[[installation-methods]]
== Installation Methods

Both the quick and advanced installations methods are supported for development and production environments. If you want to quickly get OpenShift Container Platform up and running to try out for the first time, use the quick installer and let the interactive CLI guide you through the configuration options relevant to your environment.

For the most control over your cluster’s configuration, you can use the advanced installation method. This method is particularly suited if you are already familiar with Ansible. However, following along with the OpenShift Container Platform documentation should equip you with enough information to reliably deploy your cluster and continue to manage its configuration post-deployment using the provided Ansible playbooks directly.

If you install initially using the quick installer, you can always further tweak your cluster’s configuration and adjust the number of hosts in the cluster using the same installer tool. If you wanted to later switch to using the advanced method, you can create an inventory file for your configuration and carry on that way.


[[sizing]]
== Sizing Considerations
Determine how many nodes and pods you require for your {product-title} cluster.
The following table provides the sizing limits for nodes and pods:

[cols="8,2",options="header"]
|===
|Type |Maximum

|Maximum nodes per cluster |1000

|Maximum pods per cluster |120,000

|Maximum pods per nodes |250

|Maximum pods per core |10

|===

For example, if you require 2200 pods, you need at least 20 nodes in your
environment.

This also means the maximum number of pods that can run safely in your
environment is 33,000.

[IMPORTANT]
====
Oversubscribing the physical resources on a node affects resource guarantees the
Kubernetes scheduler makes during pod placement. Learn what measures you can
take to xref:../../admin_guide/overcommit.adoc#disabling-swap-memory[avoid memory swapping].
====

[[environment-scenarios]]
== Environment Scenarios

This section outlines different examples of scenarios for your {product-title}
environment. Use these scenarios as a basis for planning your own
{product-title} cluster.

[NOTE]
====
Moving from a single master cluster to multiple masters after installation is
not supported.
====

[[single-master-multi-node]]
=== Single Master and Multiple Nodes

The following table describes an example environment for a single
xref:../../architecture/infrastructure_components/kubernetes_infrastructure.adoc#master[master] (with embedded *etcd*)
and two
xref:../../architecture/infrastructure_components/kubernetes_infrastructure.adoc#node[nodes]:

[options="header"]
|===

|Host Name |Infrastructure Component to Install

|*master.example.com*
|Master and node

|*node1.example.com*
.2+.^|Node

|*node2.example.com*
|===

[[single-master-multi-etcd-multi-node]]
=== Single Master, Multiple etcd, and Multiple Nodes

The following table describes an example environment for a single
xref:../../architecture/infrastructure_components/kubernetes_infrastructure.adoc#master[master],
three
xref:../../architecture/infrastructure_components/kubernetes_infrastructure.adoc#master[*etcd*]
hosts, and two
xref:../../architecture/infrastructure_components/kubernetes_infrastructure.adoc#node[nodes]:

[options="header"]
|===

|Host Name |Infrastructure Component to Install

|*master.example.com*
|Master and node

|*etcd1.example.com*
.3+.^|*etcd*

|*etcd2.example.com*

|*etcd3.example.com*

|*node1.example.com*
.2+.^|Node

|*node2.example.com*
|===

[NOTE]
====
When specifying multiple *etcd* hosts, external *etcd* is installed and
configured. Clustering of {product-title}'s embedded *etcd* is not supported.
====

[[multi-masters-using-native-ha]]
=== Multiple Masters Using Native HA

The following describes an example environment for three
xref:../../architecture/infrastructure_components/kubernetes_infrastructure.adoc#master[masters],
one HAProxy load balancer, three
xref:../../architecture/infrastructure_components/kubernetes_infrastructure.adoc#master[*etcd*]
hosts, and two
xref:../../architecture/infrastructure_components/kubernetes_infrastructure.adoc#node[nodes]
using the `native` HA method:

[options="header"]
|===

|Host Name |Infrastructure Component to Install

|*master1.example.com*
.3+.^|Master (clustered using native HA) and node

|*master2.example.com*

|*master3.example.com*

|*lb.example.com*
|HAProxy to load balance API master endpoints

|*etcd1.example.com*
.3+.^|*etcd*

|*etcd2.example.com*

|*etcd3.example.com*

|*node1.example.com*
.2+.^|Node

|*node2.example.com*
|===

[NOTE]
====
When specifying multiple *etcd* hosts, external *etcd* is installed and
configured. Clustering of {product-title}'s embedded *etcd* is not supported.
====

[[planning-stand-alone-registry]]
=== Stand-alone Registry

You can also install {product-title} to act as a stand-alone registry using the
{product-title}'s integrated registry. See
xref:../../install_config/install/stand_alone_registry.adoc#install-config-installing-stand-alone-registry[Installing
a Stand-alone Registry] for details on this scenario.

[[rpm-vs-containerized]]
== RPM vs Containerized

An RPM installation installs all services through package
management and configures services to run within the same user space, while a
containerized installation configures installs services using container images
and runs separate services in individual containers.

The default method for installing {product-title} on
ifdef::openshift-origin[]
Fedora, CentOS, or RHEL
endif::[]
ifdef::openshift-enterprise[]
Red Hat Enterprise Linux (RHEL)
endif::[]
uses RPMs. Alternatively, you can use the containerized method, which deploys
containerized {product-title} master and node components. When targeting a RHEL
Atomic Host system, the containerized method is the only available option, and
is automatically selected for you based on the detection of the
*_/run/ostree-booted_* file.

The following table outlines the differences between the RPM and Containerized
methods:

[cols="4,4,4,",options="header"]
|===
|Type |RPM  |Containerized

|Installation Method |Packages via `yum` |Container images via `docker`
|Service Management |`systemd` |`docker` and `systemd` units
|Operating System | Red Hat Enterprise Linux | Red Hat Enterprise Linux or Red Hat Atomic Host
|===

The xref:rpm_vs_containerized.adoc#install-config-install-rpm-vs-containerized[Containerized Installation Preparation]
section provides more details on configuring your installation to use
containerized services.
