[[install-config-install-planning]]
= Planning
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

[[inital-planning]]
== Initial Planning

For production environments, several factors influence installation. Consider
the following questions as you read through the documentation:

* _Which installation method do you want to use?_ The xref:installation-methods[Installation Methods]
section provides some information about the quick and advanced installation
methods.

* _How many hosts do you require in the cluster?_ The xref:environment-scenarios[Environment Scenarios]
section provides multiple examples of Single Master and Multiple Master
configurations.

* _How many pods are required in your cluster?_ The xref:sizing[Sizing Considerations]
section provides limits for nodes and pods so you can calculate how large your
environment needs to be.

* _Is xref:../../admin_guide/high_availability.adoc#admin-guide-high-availability[high availability]
required?_ High availability is recommended for fault tolerance. In this
situation, you might aim to use the xref:multi-masters-using-native-ha[Multiple Masters Using Native HA]
example as a basis for your environment.

* _Which installation type do you want to use: xref:rpm-vs-containerized[RPM or
 containerized]?_ Both installations provide a working {product-title}
 environment, but you might have a preference for a particular method of
 installing, managing, and updating your services.

* _Is my installation supported if integrating with other technologies?_ See the link:https://access.redhat.com/articles/2176281[OpenShift Container Platform Tested Integrations] for a list of tested integrations.

[[installation-methods]]
== Installation Methods

Both the quick and advanced installations methods are supported for development and production environments. If you want to quickly get OpenShift Container Platform up and running to try out for the first time, use the quick installer and let the interactive CLI guide you through the configuration options relevant to your environment.

For the most control over your cluster’s configuration, you can use the advanced installation method. This method is particularly suited if you are already familiar with Ansible. However, following along with the OpenShift Container Platform documentation should equip you with enough information to reliably deploy your cluster and continue to manage its configuration post-deployment using the provided Ansible playbooks directly.

If you install initially using the quick installer, you can always further tweak your cluster’s configuration and adjust the number of hosts in the cluster using the same installer tool. If you wanted to later switch to using the advanced method, you can create an inventory file for your configuration and carry on that way.


[[sizing]]
== Sizing Considerations
Determine how many nodes and pods you require for your {product-title} cluster.
Cluster scalability correlates to the number of pods in a cluster environment.
That number influences the other numbers in your setup.

The following table provides the maximum sizing limits for nodes and pods:

[cols="8,2",options="header"]
|===
|Type |Maximum

|Maximum nodes per cluster |1000

|Maximum pods per cluster |120,000

|Maximum pods per node |250

|Maximum pods per core |10

|===

[IMPORTANT]
====
Oversubscribing the physical resources on a node affects resource guarantees the
Kubernetes scheduler makes during pod placement. Learn what measures you can
take to xref:../../admin_guide/overcommit.adoc#disabling-swap-memory[avoid memory swapping].
====

Determine how many pods are expected to fit per node:

----
Maximum Pods per Cluster / Expected Pods per Node = Total Number of Nodes
----

.Example Scenario

If you want to scope your cluster for 2200 pods per cluster, you would need at
least 9 nodes, assuming that there are 250 maximum pods per node:

----
2200 / 250 = 8.8
----

If you increase the number of nodes to 20, then the pod distribution changes to
110 pods per node:

----
2200 / 20 = 110
----

[[environment-scenarios]]
== Environment Scenarios

This section outlines different examples of scenarios for your {product-title}
environment. Use these scenarios as a basis for planning your own
{product-title} cluster.

[NOTE]
====
Moving from a single master cluster to multiple masters after installation is
not supported.
====

[[single-master-multi-node]]
=== Single Master and Multiple Nodes

The following table describes an example environment for a single
xref:../../architecture/infrastructure_components/kubernetes_infrastructure.adoc#master[master] (with embedded *etcd*)
and two
xref:../../architecture/infrastructure_components/kubernetes_infrastructure.adoc#node[nodes]:

[options="header"]
|===

|Host Name |Infrastructure Component to Install

|*master.example.com*
|Master and node

|*node1.example.com*
.2+.^|Node

|*node2.example.com*
|===

[[single-master-multi-etcd-multi-node]]
=== Single Master, Multiple etcd, and Multiple Nodes

The following table describes an example environment for a single
xref:../../architecture/infrastructure_components/kubernetes_infrastructure.adoc#master[master],
three
xref:../../architecture/infrastructure_components/kubernetes_infrastructure.adoc#master[*etcd*]
hosts, and two
xref:../../architecture/infrastructure_components/kubernetes_infrastructure.adoc#node[nodes]:

[options="header"]
|===

|Host Name |Infrastructure Component to Install

|*master.example.com*
|Master and node

|*etcd1.example.com*
.3+.^|*etcd*

|*etcd2.example.com*

|*etcd3.example.com*

|*node1.example.com*
.2+.^|Node

|*node2.example.com*
|===

[NOTE]
====
When specifying multiple *etcd* hosts, external *etcd* is installed and
configured. Clustering of {product-title}'s embedded *etcd* is not supported.
====

[[multi-masters-using-native-ha]]
=== Multiple Masters Using Native HA

The following describes an example environment for three
xref:../../architecture/infrastructure_components/kubernetes_infrastructure.adoc#master[masters],
one HAProxy load balancer, three
xref:../../architecture/infrastructure_components/kubernetes_infrastructure.adoc#master[*etcd*]
hosts, and two
xref:../../architecture/infrastructure_components/kubernetes_infrastructure.adoc#node[nodes]
using the `native` HA method:

[options="header"]
|===

|Host Name |Infrastructure Component to Install

|*master1.example.com*
.3+.^|Master (clustered using native HA) and node

|*master2.example.com*

|*master3.example.com*

|*lb.example.com*
|HAProxy to load balance API master endpoints

|*etcd1.example.com*
.3+.^|*etcd*

|*etcd2.example.com*

|*etcd3.example.com*

|*node1.example.com*
.2+.^|Node

|*node2.example.com*
|===

[NOTE]
====
When specifying multiple *etcd* hosts, external *etcd* is installed and
configured. Clustering of {product-title}'s embedded *etcd* is not supported.
====

[[planning-stand-alone-registry]]
=== Stand-alone Registry

You can also install {product-title} to act as a stand-alone registry using the
{product-title}'s integrated registry. See
xref:../../install_config/install/stand_alone_registry.adoc#install-config-installing-stand-alone-registry[Installing
a Stand-alone Registry] for details on this scenario.

[[rpm-vs-containerized]]
== RPM vs Containerized

An RPM installation installs all services through package management and
configures services to run within the same user space, while a containerized
installation installs services using container images and runs separate services
in individual containers.

See the
xref:rpm_vs_containerized.adoc#install-config-install-rpm-vs-containerized[Installing on
Containerized Hosts] topic for more details on configuring your
installation to use containerized services.
