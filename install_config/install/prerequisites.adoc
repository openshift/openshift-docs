= Prerequisites
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

== Overview

ifdef::openshift-origin[]
OpenShift
link:../../architecture/infrastructure_components/kubernetes_infrastructure.html[infrastructure
components] can be installed across multiple hosts. The following sections
outline the system requirements and instructions for preparing your environment
and hosts before installing OpenShift.
endif::[]

ifdef::openshift-enterprise[]
OpenShift
link:../../architecture/infrastructure_components/kubernetes_infrastructure.html[infrastructure
components] can be installed across multiple hosts. The following sections
outline the system requirements and instructions for preparing your environment
and hosts before installing OpenShift.
endif::[]

[[system-requirements]]

== System Requirements

ifdef::openshift-enterprise[]
You must have an active OpenShift Enterprise subscription on your Red Hat
account to proceed. If you do not, contact your sales representative for more
information.
endif::[]

The system requirements vary per host type:

[cols="1,7"]
|===
|link:../../architecture/infrastructure_components/kubernetes_infrastructure.html#master[Masters]
a|- Physical or virtual system, or an instance running on a public IaaS
ifdef::openshift-origin[]
- Base OS: Fedora 21, CentOS 7.1, or RHEL 7.1 with "Minimal" installation option
endif::[]
ifdef::openshift-enterprise[]
- Base OS: Red Hat Enterprise Linux (RHEL) 7.1  with "Minimal" installation
option
endif::[]
- 2 vCPU
- Minimum 8 GB RAM
- Minimum 30 GB hard disk space

|link:../../architecture/infrastructure_components/kubernetes_infrastructure.html#node[Nodes]
a| - Physical or virtual system, or an instance running on a public IaaS
ifdef::openshift-origin[]
- Base OS: Fedora 21, CentOS 7.1, or RHEL 7.1 with "Minimal" installation option
endif::[]
ifdef::openshift-enterprise[]
- Base OS: Red Hat Enterprise Linux (RHEL) 7.1 with "Minimal" installation
option
endif::[]
- Docker 1.6.2 or later
- 1 vCPU
- Minimum 8 GB RAM
- Minimum 15 GB hard disk space
- An additional minimum 15 GB unallocated space to be configured using
*docker-storage-setup*; see link:#configuring-docker-storage[Configuring
Docker Storage] below.

|===

[[persistent-storage]]

*Persistent Storage*

The Kubernetes
link:../../architecture/additional_concepts/storage.html[persistent volume]
framework allows you to provision an OpenShift cluster with persistent storage
using networked storage available in your environment. This can be done after
completing the initial OpenShift installation depending on your application
needs, giving users a way to request those resources without having any
knowledge of the underlying infrastructure.

ifdef::openshift-enterprise[]
Currently link:../../admin_guide/persistent_storage/persistent_storage_nfs.html[NFS is fully
supported], however other options are available as
link:../../whats_new/ose_3_0_release_notes.html#technology-preview[Technology
Preview].
endif::[]
ifdef::openshift-origin[]
The Administrator Guide provides instructions on provisioning an OpenShift
cluster with link:../../admin_guide/persistent_storage/persistent_storage_nfs.html[persistent
storage using NFS].
endif::[]

[[configuring-core-usage]]

*Configuring Core Usage*

By default, OpenShift masters and nodes use all available cores in the system they run on.
You can choose the number of cores you want OpenShift to use by setting the
https://golang.org/pkg/runtime/[`*GOMAXPROCS*` environment variable].

For example, run the following before starting the server to make OpenShift only
run on one core:

====
----
# export GOMAXPROCS=1
----
====

ifdef::openshift-origin[]
Alternatively, if you plan to
link:../../getting_started/administrators.html#running-in-a-docker-container[run
OpenShift in a Docker container], add `-e GOMAXPROCS=1` to the `docker run`
command when launching the server.
endif::[]

[[security-warning]]

*Security Warning*

OpenShift runs
link:../../architecture/core_concepts/containers_and_images.html#containers[Docker
containers] on your hosts, and in some cases, such as build operations and the
registry service, it does so using privileged containers. Furthermore, those
containers access your host's Docker daemon and perform `docker build` and
`docker push` operations. As such, you should be aware of the inherent security
risks associated with performing `docker run` operations on arbitrary images as
they effectively have root access.

For more information, see these articles:

- http://opensource.com/business/14/7/docker-security-selinux
- https://docs.docker.com/articles/security/

To address these risks, OpenShift uses
link:../../architecture/additional_concepts/authorization.html#security-context-constraints[security
context constraints] that control the actions that pods can perform and what it
has the ability to access.

== Environment Requirements

[[prereq-dns]]

*DNS*

A wildcard for a DNS zone must ultimately resolve to the IP address of the
OpenShift link:../../architecture/core_concepts/routes.html#routers[router].

For example, create a wildcard DNS entry for *cloudapps*, or something similar,
that has a low TTL and points to the public IP address of the host where the
router will be deployed:

----
*.cloudapps.example.com. 300 IN  A 192.168.133.2
----

In almost all cases, when referencing VMs you must use host names, and the host
names that you use must match the output of the `hostname -f` command on each
node.

[[prereq-networking]]

*Networking*

A shared network must exist between the master and node hosts.

If you plan to configure
link:../../architecture/infrastructure_components/kubernetes_infrastructure.html#high-availability-masters[multiple
masters for high-availability] using the link:advanced_install.html[advanced
installation method], you must also select an IP to be configured as your
link:../../architecture/infrastructure_components/kubernetes_infrastructure.html#master-components[virtual
IP] (VIP) during the installation process. The IP that you select must be
routable between all of your nodes, and if you configure using a FQDN it should
resolve on all nodes. The VIP is then managed by
link:../../architecture/infrastructure_components/kubernetes_infrastructure.html#master-components[Pacemaker].

[[prereq-git]]

*Git*

You must have either Internet access and a GitHub account, or read and write
access to an internal, HTTP-based Git server.

[[host-preparation]]

== Host Preparation

Before installing OpenShift, you must first prepare each host per the following.

ifdef::openshift-origin[]
[NOTE]
====
If you are using https://www.vagrantup.com[Vagrant] to run OpenShift Origin, you
do not need to go through the following sections. These changes are only
necessary when you are setting up the host yourself. If you are using Vagrant,
see the
https://github.com/openshift/origin/blob/master/CONTRIBUTING.adoc#develop-on-virtual-machine-using-vagrant[Contributing
Guide], then you can skip directly to trying out the
link:../../getting_started/administrators.html#try-it-out[sample applications].
====
endif::[]

ifdef::openshift-enterprise[]

[[software-prerequisites]]

=== Software Prerequisites

*Installing Red Hat Enterprise Linux 7*

A base installation of Red Hat Enterprise Linux (RHEL) 7.1 is required for
master or node hosts. See the
https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Installation_Guide/index.html[Red
Hat Enterprise Linux 7.1 Installation Guide] for more information.

*Registering the Hosts*

Each host must be registered using Red Hat Subscription Manager (RHSM) and have
an active OpenShift Enterprise subscription attached to access the required
packages.

. On each host, register with RHSM:
+
----
# subscription-manager register --username=<user_name> --password=<password>
----

. List the available subscriptions:
+
----
# subscription-manager list --available
----

. In the output for the previous command, find the pool ID for an OpenShift
Enterprise subscription and attach it:
+
----
# subscription-manager attach --pool=<pool_id>
----

. Disable all repositories and enable only the required ones:
+
----
# subscription-manager repos --disable="*"
# subscription-manager repos \
    --enable="rhel-7-server-rpms" \
    --enable="rhel-7-server-extras-rpms" \
    --enable="rhel-7-server-ose-3.0-rpms"
----

. If you plan to configure
link:../../architecture/infrastructure_components/kubernetes_infrastructure.html#high-availability-masters[multiple
masters for high-availability] using the link:advanced_install.html[advanced
installation method], you must also enable the
https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/High_Availability_Add-On_Overview/index.html[High
Availability Add-on for Red Hat Enterprise Linux] repository:
+
----
# subscription-manager repos \
    --enable="rhel-ha-for-rhel-7-server-rpms"
----
endif::[]

*Managing Base Packages*

. Install the following packages:
+
----
# yum install wget git net-tools bind-utils iptables-services bridge-utils bash-completion
----

ifdef::openshift-enterprise[]
. If you plan to use the link:quick_install.html[quick installation method], you
must also install the GNU Compiler Collection (*gcc*) and Python Virtual
Environment (*python-virtualenv*) packages:
+
----
# yum install gcc python-virtualenv
----
endif::[]

. Update the system to the latest packages:
+
----
# yum update
----

*Installing Docker*

Docker version 1.6.2 or later
ifdef::openshift-enterprise[]
from the *rhel-7-server-ose-3.0-rpms* repository
endif::[]
must be installed and running on master and node hosts before installing
OpenShift.

. Install Docker:
+
----
# yum install docker
----

. Edit the *_/etc/sysconfig/docker_* file and add `--insecure-registry
172.30.0.0/16` to the `*OPTIONS*` parameter. For example:
+
----
OPTIONS='--selinux-enabled --insecure-registry 172.30.0.0/16'
----
+
The `--insecure-registry` option instructs the Docker daemon to trust any Docker
registry on the indicated subnet, rather than
link:docker_registry.html#securing-the-registry[requiring a certificate].
+
After installing OpenShift, you can choose to
link:docker_registry.html#securing-the-registry[secure the integrated Docker
registry], which involves adjusting the `--insecure-registry` option
accordingly.
+
[IMPORTANT]
172.30.0.0/16 is the default value of the `*servicesSubnet*` variable in the
*_master-config.yaml_* file. If this has changed, then the `--insecure-registry`
value in the above step should be adjusted to match, as it is indicating the
subnet for the registry to use. Note that the `*openshift_master_portal_net*`
variable can be set in the Ansible inventory file and used during the
link:advanced_install.html#configuring-ansible[advanced installation]
method to modify the `*servicesSubnet*` variable.


[[configuring-docker-storage]]

=== Configuring Docker Storage

Docker containers and the images they are created from are stored in Docker's
storage back end. This storage is ephemeral and separate from any
link:../../dev_guide/persistent_volumes.html[persistent storage] allocated to
meet the needs of your applications.

The default storage back end is a thin pool on loopback devices which is not
supported for production use and only appropriate for proof of concept
environments. For production environments, you must create a thin pool logical
volume and re-configure Docker to use that volume.

You can use the *docker-storage-setup* script included with Docker to create a
thin pool device and configure Docker's storage driver. This can be done after
installing Docker and should be done before creating images or containers. The
script reads configuration options from the
*_/etc/sysconfig/docker-storage-setup_* file and supports three options for
creating the logical volume:

- *Option A)* Use an additional block device.
- *Option B)* Use an existing, specified volume group.
- *Option C)* Use the remaining free space from the volume group where your root
file system is located.

Option A is the most robust option, however it requires adding an additional
block device to your host before configuring Docker storage. Options B and C
both require leaving free space available when provisioning your host.

[NOTE]
====
See the https://access.redhat.com/articles/1492923[Managing Storage with Docker
Formatted Containers on Red Hat Enterprise Linux and Red Hat Enterprise Linux
Atomic Host] Knowledgebase article for more details about *docker-storage-setup*
and basic instructions on storage management in Red Hat Enterprise Linux 7.
====

. Create the *docker-pool* volume using one of the following three options:

** [[docker-storage-a]]*Option A) Use an additional block device.*
+
In *_/etc/sysconfig/docker-storage-setup_*, set *DEVS* to the path of the block
device you wish to use. Set *VG* to the volume group name you wish to create;
*docker-vg* is a reasonable choice. For example:
+
====
----
# cat <<EOF > /etc/sysconfig/docker-storage-setup
DEVS=/dev/vdc
VG=docker-vg
EOF
----
====
+
Then run *docker-storage-setup* and review the output to ensure the
*docker-pool* volume was created:
+
====
----
# docker-storage-setup                                                                                                                                                                                                                                [5/1868]
0
Checking that no-one is using this disk right now ...
OK

Disk /dev/vdc: 31207 cylinders, 16 heads, 63 sectors/track
sfdisk:  /dev/vdc: unrecognized partition table type

Old situation:
sfdisk: No partitions found

New situation:
Units: sectors of 512 bytes, counting from 0

   Device Boot    Start       End   #sectors  Id  System
/dev/vdc1          2048  31457279   31455232  8e  Linux LVM
/dev/vdc2             0         -          0   0  Empty
/dev/vdc3             0         -          0   0  Empty
/dev/vdc4             0         -          0   0  Empty
Warning: partition 1 does not start at a cylinder boundary
Warning: partition 1 does not end at a cylinder boundary
Warning: no primary partition is marked bootable (active)
This does not matter for LILO, but the DOS MBR will not boot this disk.
Successfully wrote the new partition table

Re-reading the partition table ...

If you created or changed a DOS partition, /dev/foo7, say, then use dd(1)
to zero the first 512 bytes:  dd if=/dev/zero of=/dev/foo7 bs=512 count=1
(See fdisk(8).)
  Physical volume "/dev/vdc1" successfully created
  Volume group "docker-vg" successfully created
  Rounding up size to full physical extent 16.00 MiB
  Logical volume "docker-poolmeta" created.
  Logical volume "docker-pool" created.
  WARNING: Converting logical volume docker-vg/docker-pool and docker-vg/docker-poolmeta to pool's data and metadata volumes.
  THIS WILL DESTROY CONTENT OF LOGICAL VOLUME (filesystem etc.)
  Converted docker-vg/docker-pool to thin pool.
  Logical volume "docker-pool" changed.
----
====

** [[docker-storage-b]]*Option B) Use an existing, specified volume group.*
+
In *_/etc/sysconfig/docker-storage-setup_*, set *VG* to the desired volume
group. For example:
+
====
----
# cat <<EOF > /etc/sysconfig/docker-storage-setup
VG=docker-vg
EOF
----
====
+
Then run *docker-storage-setup* and review the output to ensure the
*docker-pool* volume was created:
+
====
----
# docker-storage-setup
  Rounding up size to full physical extent 16.00 MiB
  Logical volume "docker-poolmeta" created.
  Logical volume "docker-pool" created.
  WARNING: Converting logical volume docker-vg/docker-pool and docker-vg/docker-poolmeta to pool's data and metadata volumes.
  THIS WILL DESTROY CONTENT OF LOGICAL VOLUME (filesystem etc.)
  Converted docker-vg/docker-pool to thin pool.
  Logical volume "docker-pool" changed.
----
====

** [[docker-storage-c]]*Option C) Use the remaining free space from the volume
 group where your root file system is located.*
+
Verify that the volume group where your root file system resides has the desired
free space, then run *docker-storage-setup* and review the output to ensure the
*docker-pool* volume was created:
+
====
----
# docker-storage-setup
  Rounding up size to full physical extent 32.00 MiB
  Logical volume "docker-poolmeta" created.
  Logical volume "docker-pool" created.
  WARNING: Converting logical volume rhel/docker-pool and rhel/docker-poolmeta to pool's data and metadata volumes.
  THIS WILL DESTROY CONTENT OF LOGICAL VOLUME (filesystem etc.)
  Converted rhel/docker-pool to thin pool.
  Logical volume "docker-pool" changed.
----
====

. Verify your configuration. You should have a *dm.thinpooldev* value in the
*_/etc/sysconfig/docker-storage_* file and a *docker-pool* logical volume:
+
====
----
# cat /etc/sysconfig/docker-storage
DOCKER_STORAGE_OPTIONS=--storage-opt dm.fs=xfs --storage-opt
dm.thinpooldev=/dev/mapper/docker--vg-docker--pool

# lvs
  LV          VG   Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  docker-pool rhel twi-a-t---  9.29g             0.00   0.12
----
====
+
[IMPORTANT]
====
Before using Docker or OpenShift, verify that the *docker-pool* logical volume
is large enough to meet your needs. The *docker-pool* volume should be 60% of
the available volume group and will grow to fill the volume group via LVM
monitoring.
====

. Re-initialize Docker.
+
[WARNING]
====
This will destroy any Docker containers or images currently on the host.
====
+
----
# systemctl stop docker
# rm -rf /var/lib/docker/*
# systemctl restart docker
----

[[reconfiguring-docker-storage]]
*Reconfiguring Docker Storage*

Should you need to reconfigure Docker storage after having created the
*docker-pool*, you should first remove the *docker-pool* logical volume. If you
are using a dedicated volume group, you should also remove the volume group and
any associated physical volumes before reconfiguring *docker-storage-setup*
according to the instructions above.

See
link:https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Logical_Volume_Manager_Administration/index.html[Logical
Volume Manager Administration] for more detailed information on LVM management.

[[ensuring-host-access]]

== Ensuring Host Access

ifdef::openshift-origin[]
The link:advanced_install.html[advanced installation] method requires
endif::[]
ifdef::openshift-enterprise[]
The link:quick_install.html[quick] and link:advanced_install.html[advanced
installation] methods require
endif::[]
a user that has access to all hosts. If you want to run the installer as a
non-root user, passwordless *sudo* rights must be configured on each destination
host.

For example, you can generate an SSH key on the host where you will invoke the
installation process:

----
# ssh-keygen
----

Do *not* use a password.

An easy way to distribute your SSH keys is by using a `bash` loop:

----
# for host in master.example.com \
    node1.example.com \
    node2.example.com; \
    do ssh-copy-id -i ~/.ssh/id_rsa.pub $host; \
    done
----

Modify the host names in the above command according to your configuration.

== What's Next?

ifdef::openshift-enterprise[]
Now that your environment and hosts are properly set up, you can install
OpenShift Enterprise using the
link:quick_install.html#installing-openshift[quick installation] or
link:advanced_install.html#installing-ansible[advanced installation] method.
endif::[]

ifdef::openshift-origin[]
If you came here from link:../../getting_started/administrators.html[Getting
Started for Administrators], you can now continue there by choosing an
link:../../getting_started/administrators.html#installation-methods[installation
method]. Alternatively, you can install OpenShift using the
link:advanced_install.html#installing-ansible[advanced installation] method.
endif::[]
