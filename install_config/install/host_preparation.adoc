[[install-config-install-host-preparation]]
= Host Preparation
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

ifdef::openshift-enterprise[]

[[software-prerequisites]]
== Operating System Requirements

A base installation of RHEL 7.3 or 7.4 (with the latest packages from the Extras
channel) or RHEL Atomic Host 7.4.2 or later is required for master and node
hosts. See the following documentation for the respective installation
instructions, if required:

- https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Installation_Guide/index.html[Red Hat Enterprise Linux 7 Installation Guide]
- https://access.redhat.com/documentation/en/red-hat-enterprise-linux-atomic-host/version-7/installation-and-configuration-guide/[Red Hat Enterprise Linux Atomic Host 7 Installation and Configuration Guide]

[[host-registration]]
== Host Registration

Each host must be registered using Red Hat Subscription Manager (RHSM) and have
an active {product-title} subscription attached to access the required
packages.

. On each host, register with RHSM:
+
----
# subscription-manager register --username=<user_name> --password=<password>
----

. Pull the latest subscription data from RHSM:
+
----
# subscription-manager refresh
----

. List the available subscriptions:
+
----
# subscription-manager list --available --matches '*OpenShift*'
----

. In the output for the previous command, find the pool ID for an {product-title} subscription and attach it:
+
----
# subscription-manager attach --pool=<pool_id>
----

. Disable all yum repositories:
.. Disable all the enabled RHSM repositories:
+
----
# subscription-manager repos --disable="*"
----

.. List the remaining yum repositories and note their names under `repo id`, if any:
+
----
# yum repolist
----

.. Use `yum-config-manager` to disable the remaining yum repositories:
+
----
# yum-config-manager --disable <repo_id>
----
+
Alternatively, disable all repositories:
+
----
 yum-config-manager --disable \*
----
+
Note that this could take a few minutes if you have a large number of available repositories

. Enable only the repositories required by {product-title} 3.9:
+
----
# subscription-manager repos \
    --enable="rhel-7-server-rpms" \
    --enable="rhel-7-server-extras-rpms" \
    --enable="rhel-7-server-ose-3.9-rpms" \
    --enable="rhel-7-fast-datapath-rpms" \
    --enable="rhel-7-server-ansible-2.4-rpms"
----
+
[NOTE]
====
The addition of the *rhel-7-server-ansible-2.4-rpms* repository is a new
requirement as of {product-title} 3.9.
====
endif::[]

[[installing-base-packages]]
== Installing Base Packages

For RHEL 7 systems:

. Install the following base packages:
+
----
# yum install wget git net-tools bind-utils iptables-services bridge-utils bash-completion kexec-tools sos psacct
----

. Update the system to the latest packages:
+
----
# yum update
----

ifdef::openshift-enterprise[]
. If you plan to use the
xref:../../install_config/install/advanced_install.adoc#running-the-advanced-installation-rpm[RPM-based installer] to run an advanced installation, you can skip this step. However, if
you plan to use the
xref:../../install_config/install/advanced_install.adoc#running-the-advanced-installation-system-container[containerized installer]:

.. Install the *atomic* package:
+
----
# yum install atomic
----

.. Skip to xref:installing-docker[Installing Docker].

. Install the following package, which provides RPM-based {product-title}
installer utilities and pulls in other tools required by the
xref:../../install_config/install/quick_install.adoc#install-config-install-quick-install[quick]
and
xref:../../install_config/install/advanced_install.adoc#install-config-install-advanced-install[advanced installation] methods, such as Ansible and related configuration files:
+
----
# yum install atomic-openshift-utils
----
endif::[]

For RHEL Atomic Host 7 systems:

. Ensure the host is up to date by upgrading to the latest Atomic tree if one is
available:
+
----
# atomic host upgrade
----

. After the upgrade is completed and prepared for the next boot, reboot the
host:
+
----
# systemctl reboot
----


ifdef::openshift-origin[]
[[preparing-for-advanced-installations-origin]]

== Preparing for Advanced Installations

If you plan to use the
xref:../../install_config/install/advanced_install.adoc#running-the-advanced-installation-system-container[containerized installer] to run an advanced installation (currently a Technology Preview
feature):

. Install the *atomic* package:
+
----
# yum install atomic
----

. Skip to xref:installing-docker[Installing Docker].

If you plan to use the
xref:../../install_config/install/advanced_install.adoc#running-the-advanced-installation-rpm[RPM-based installer] to run an advanced installation:

. Install Ansible. For convenience, the following steps are provided if you want to use EPEL as a
package source for Ansible:

.. Install the EPEL repository:
+
----
# yum -y install \
    https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
----

.. Disable the EPEL repository globally so that it is not accidentally used during
later steps of the installation:
+
----
# sed -i -e "s/^enabled=1/enabled=0/" /etc/yum.repos.d/epel.repo
----

.. Install the packages for Ansible:
+
----
# yum -y --enablerepo=epel install ansible pyOpenSSL
----

. Clone the *openshift/openshift-ansible* repository from GitHub, which provides
the required playbooks and configuration files:
+
----
# cd ~
# git clone https://github.com/openshift/openshift-ansible
# git checkout release-3.9
# cd openshift-ansible
----
+
[NOTE]
====
Be sure to use the release branch of the *openshift-ansible*
repository which corresponds to the desired {product-title} version
when running an advanced installation. Stay on the *master* branch
when targeting the version of {product-title} in development.
====
endif::[]

[[installing-docker]]
== Installing Docker

At this point, you should install Docker on all master and node hosts. This
allows you to configure your xref:configuring-docker-storage[Docker storage
options] before installing {product-title}.

For RHEL 7 systems, install Docker 1.13:

[NOTE]
====
On RHEL Atomic Host 7 systems, Docker should already be installed, configured,
and running by default.
====
----
# yum install docker-1.13.1
----

After the package installation is complete, verify that version 1.13 was
installed:

----
# rpm -V docker-1.13.1
# docker version
----

[NOTE]
====
The
xref:../../install_config/install/advanced_install.adoc#install-config-install-advanced-install[Advanced
Installation] method automatically changes *_/etc/sysconfig/docker_*.
====

The `--insecure-registry` option instructs the Docker daemon to trust any Docker
registry on the indicated subnet, rather than
xref:../registry/securing_and_exposing_registry.adoc#securing-the-registry[requiring a certificate].

[IMPORTANT]
====
172.30.0.0/16 is the default value of the `*servicesSubnet*` variable in the
*_master-config.yaml_* file. If this has changed, then the `--insecure-registry`
value in the above step should be adjusted to match, as it is indicating the
subnet for the registry to use. Note that the `*openshift_master_portal_net*`
variable can be set in the Ansible inventory file and used during the
xref:advanced_install.adoc#configuring-ansible[advanced installation]
method to modify the `*servicesSubnet*` variable.
====

[NOTE]
====
After the initial {product-title} installation is complete, you can choose to
xref:../registry/securing_and_exposing_registry.adoc#securing-the-registry[secure the integrated Docker
registry], which involves adjusting the `--insecure-registry` option
accordingly.
====

[[configuring-docker-storage]]
== Configuring Docker Storage

Containers and the images they are created from are stored in Docker's
storage back end. This storage is ephemeral and separate from any
xref:../../dev_guide/persistent_volumes.adoc#dev-guide-persistent-volumes[persistent storage] allocated to
meet the needs of your applications.

.For RHEL Atomic Host

The default storage back end for Docker on RHEL Atomic Host is a thin pool
logical volume, which is supported for production environments. You must ensure
that enough space is allocated for this volume per the Docker storage
requirements mentioned in
xref:../../install_config/install/prerequisites.adoc#system-requirements[System
Requirements].

If you do not have enough allocated, see
link:https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_atomic_host/7/html-single/managing_containers/#managing_storage_with_docker_formatted_containers[Managing
Storage with Docker Formatted Containers] for details on using
*docker-storage-setup* and basic instructions on storage management in RHEL
Atomic Host.

.For RHEL

The default storage back end for Docker on RHEL 7 is a thin pool on loopback
devices, which is not supported for production use and only appropriate for
proof of concept environments. For production environments, you must create a
thin pool logical volume and re-configure Docker to use that volume.

You can use the *docker-storage-setup* script included with Docker to create a
thin pool device and configure Docker's storage driver. This can be done after
installing Docker and should be done before creating images or containers. The
script reads configuration options from the
*_/etc/sysconfig/docker-storage-setup_* file and supports three options for
creating the logical volume:

- *Option A)* Use an additional block device.
- *Option B)* Use an existing, specified volume group.
- *Option C)* Use the remaining free space from the volume group where your root
file system is located.

Option A is the most robust option, however it requires adding an additional
block device to your host before configuring Docker storage. Options B and C
both require leaving free space available when provisioning your host. Option C
is known to cause issues with some applications, for example Red Hat Mobile
Application Platform (RHMAP).

. Create the *docker-pool* volume using one of the following three options:

** [[docker-storage-a]]*Option A)* Use an additional block device.
+
In *_/etc/sysconfig/docker-storage-setup_*, set *DEVS* to the path of the block
device you wish to use. Set *VG* to the volume group name you wish to create;
*docker-vg* is a reasonable choice. For example:
+
----
# cat <<EOF > /etc/sysconfig/docker-storage-setup
DEVS=/dev/vdc
VG=docker-vg
EOF
----
+
Then run *docker-storage-setup* and review the output to ensure the
*docker-pool* volume was created:
+
----
# docker-storage-setup                                                                                                                                                                                                                                [5/1868]
0
Checking that no-one is using this disk right now ...
OK

Disk /dev/vdc: 31207 cylinders, 16 heads, 63 sectors/track
sfdisk:  /dev/vdc: unrecognized partition table type

Old situation:
sfdisk: No partitions found

New situation:
Units: sectors of 512 bytes, counting from 0

   Device Boot    Start       End   #sectors  Id  System
/dev/vdc1          2048  31457279   31455232  8e  Linux LVM
/dev/vdc2             0         -          0   0  Empty
/dev/vdc3             0         -          0   0  Empty
/dev/vdc4             0         -          0   0  Empty
Warning: partition 1 does not start at a cylinder boundary
Warning: partition 1 does not end at a cylinder boundary
Warning: no primary partition is marked bootable (active)
This does not matter for LILO, but the DOS MBR will not boot this disk.
Successfully wrote the new partition table

Re-reading the partition table ...

If you created or changed a DOS partition, /dev/foo7, say, then use dd(1)
to zero the first 512 bytes:  dd if=/dev/zero of=/dev/foo7 bs=512 count=1
(See fdisk(8).)
  Physical volume "/dev/vdc1" successfully created
  Volume group "docker-vg" successfully created
  Rounding up size to full physical extent 16.00 MiB
  Logical volume "docker-poolmeta" created.
  Logical volume "docker-pool" created.
  WARNING: Converting logical volume docker-vg/docker-pool and docker-vg/docker-poolmeta to pool's data and metadata volumes.
  THIS WILL DESTROY CONTENT OF LOGICAL VOLUME (filesystem etc.)
  Converted docker-vg/docker-pool to thin pool.
  Logical volume "docker-pool" changed.
----

** [[docker-storage-b]]*Option B)* Use an existing, specified volume group.
+
In *_/etc/sysconfig/docker-storage-setup_*, set *VG* to the desired volume
group. For example:
+
----
# cat <<EOF > /etc/sysconfig/docker-storage-setup
VG=docker-vg
EOF
----
+
Then run *docker-storage-setup* and review the output to ensure the
*docker-pool* volume was created:
+
----
# docker-storage-setup
  Rounding up size to full physical extent 16.00 MiB
  Logical volume "docker-poolmeta" created.
  Logical volume "docker-pool" created.
  WARNING: Converting logical volume docker-vg/docker-pool and docker-vg/docker-poolmeta to pool's data and metadata volumes.
  THIS WILL DESTROY CONTENT OF LOGICAL VOLUME (filesystem etc.)
  Converted docker-vg/docker-pool to thin pool.
  Logical volume "docker-pool" changed.
----

** [[docker-storage-c]]*Option C)* Use the remaining free space from the volume
 group where your root file system is located.
+
Verify that the volume group where your root file system resides has the desired
free space, then run *docker-storage-setup* and review the output to ensure the
*docker-pool* volume was created:
+
----
# docker-storage-setup
  Rounding up size to full physical extent 32.00 MiB
  Logical volume "docker-poolmeta" created.
  Logical volume "docker-pool" created.
  WARNING: Converting logical volume rhel/docker-pool and rhel/docker-poolmeta to pool's data and metadata volumes.
  THIS WILL DESTROY CONTENT OF LOGICAL VOLUME (filesystem etc.)
  Converted rhel/docker-pool to thin pool.
  Logical volume "docker-pool" changed.
----

. Verify your configuration. You should have a *dm.thinpooldev* value in the
*_/etc/sysconfig/docker-storage_* file and a *docker-pool* logical volume:
+
----
# cat /etc/sysconfig/docker-storage
DOCKER_STORAGE_OPTIONS=--storage-opt dm.fs=xfs --storage-opt
dm.thinpooldev=/dev/mapper/docker--vg-docker--pool

# lvs
  LV          VG   Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  docker-pool rhel twi-a-t---  9.29g             0.00   0.12
----
+
[IMPORTANT]
====
Before using Docker or {product-title}, verify that the *docker-pool* logical volume
is large enough to meet your needs. The *docker-pool* volume should be 60% of
the available volume group and will grow to fill the volume group via LVM
monitoring.
====

. Check if Docker is running:
+
----
# systemctl is-active docker
----

. If Docker has not yet been started on the host, enable and start the service:
+
----
# systemctl enable docker
# systemctl start docker
----
+
If Docker is already running, re-initialize Docker:
+
[WARNING]
====
This will destroy any containers or images currently on the host.
====
+
----
# systemctl stop docker
# rm -rf /var/lib/docker/*
# systemctl restart docker
----
+
If there is any content in *_/var/lib/docker/_*, it must be deleted. Files
will be present if Docker has been used prior to the installation of {product-title}.

[[reconfiguring-docker-storage]]
=== Reconfiguring Docker Storage

Should you need to reconfigure Docker storage after having created the
*docker-pool*, you should first remove the *docker-pool* logical volume. If you
are using a dedicated volume group, you should also remove the volume group and
any associated physical volumes before reconfiguring *docker-storage-setup*
according to the instructions above.

See
link:https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Logical_Volume_Manager_Administration/index.html[Logical
Volume Manager Administration] for more detailed information on LVM management.

[[enabling-image-signature-support]]
=== Enabling Image Signature Support

{product-title} is capable of cryptographically verifying images are from
trusted sources. The
xref:../../security/deployment.adoc#security-deployment-from-where-images-deployed[Container Security Guide] provides a high-level description of how image signing works.

You can configure image signature verification using the `atomic` command line
interface (CLI), version 1.12.5 or greater.
ifdef::openshift-enterprise[]
The `atomic` CLI is pre-installed on RHEL Atomic Host systems.

[NOTE]
====
For more on the `atomic` CLI, see the
link:https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_atomic_host/7/html/cli_reference/prerequisites[Atomic CLI documentation].
====
endif::[]

Install the *atomic* package if it is not installed on the host system:

----
$ yum install atomic
----

The **atomic trust** sub-command manages trust configuration. The default
configuration is to whitelist all registries. This means no signature
verification is configured.

----
$ atomic trust show
* (default)                         accept
----

A reasonable configuration might be to whitelist a particular registry or
namespace, blacklist (reject) untrusted registries, and require signature
verification on a vendor registry. The following set of commands performs this
example configuration:

.Example Atomic Trust Configuration
----
$ atomic trust add --type insecureAcceptAnything 172.30.1.1:5000

$ atomic trust add --sigstoretype atomic \
  --pubkeys pub@example.com \
  172.30.1.1:5000/production

$ atomic trust add --sigstoretype atomic \
  --pubkeys /etc/pki/example.com.pub \
  172.30.1.1:5000/production

$ atomic trust add --sigstoretype web \
  --sigstore https://access.redhat.com/webassets/docker/content/sigstore \
  --pubkeys /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release \
  registry.access.redhat.com

$ sudo atomic trust show
* (default)                         accept
172.30.1.1:5000                     accept
172.30.1.1:5000/production          signed security@example.com
registry.access.redhat.com          signed security@redhat.com,security@redhat.com
----

When all the signed sources are verified, nodes may be further hardened with a
global `reject` default:

----
$ atomic trust default reject

$ atomic trust show
* (default)                         reject
172.30.1.1:5000                     accept
172.30.1.1:5000/production          signed security@example.com
registry.access.redhat.com          signed security@redhat.com,security@redhat.com
----

Use the `atomic` man page `man atomic-trust` for additional examples.

The following files and directories comprise the trust configuration of a host:

- *_/etc/containers/registries.d/*_*
- *_/etc/containers/policy.json_*

The trust configuration may be managed directly on each node or the generated
files managed on a separate host and distributed to the appropriate nodes using
Ansible, for example. See the
link:https://access.redhat.com/articles/2750891#automating-cluster-configuration[Container
Image Signing Integration Guide] for an example of automating file distribution
with Ansible.

[[managing-docker-container-logs]]
=== Managing Container Logs

Sometimes a container's log file (the
*_/var/lib/docker/containers/<hash>/<hash>-json.log_* file on the node where the
container is running) can increase to a problematic size. You can manage this by
configuring Docker's `json-file` logging driver to restrict the size and number
of log files.

[options="header"]
|===

|Option |Purpose

|`--log-opt max-size`
|Sets the size at which a new log file is created.

|`--log-opt max-file`
|Sets the maximum number of log files to be kept per host.
|===

For example, to set the maximum file size to 1MB and always keep the last three
log files, edit the *_/etc/sysconfig/docker_* file to configure `max-size=1M`
and `max-file=3`:
====
----
OPTIONS='--insecure-registry=172.30.0.0/16 --selinux-enabled --log-opt max-size=1M --log-opt max-file=3'
----
====

Next, restart the Docker service:
----
# systemctl restart docker
----

[[viewing-available-container-logs]]
=== Viewing Available Container Logs

Container logs are stored in the *_/var/lib/docker/containers/<hash>/_*
directory on the node where the container is running. For example:
====
----
# ls -lh /var/lib/docker/containers/f088349cceac173305d3e2c2e4790051799efe363842fdab5732f51f5b001fd8/
total 2.6M
-rw-r--r--. 1 root root 5.6K Nov 24 00:12 config.json
-rw-r--r--. 1 root root 649K Nov 24 00:15 f088349cceac173305d3e2c2e4790051799efe363842fdab5732f51f5b001fd8-json.log
-rw-r--r--. 1 root root 977K Nov 24 00:15 f088349cceac173305d3e2c2e4790051799efe363842fdab5732f51f5b001fd8-json.log.1
-rw-r--r--. 1 root root 977K Nov 24 00:15 f088349cceac173305d3e2c2e4790051799efe363842fdab5732f51f5b001fd8-json.log.2
-rw-r--r--. 1 root root 1.3K Nov 24 00:12 hostconfig.json
drwx------. 2 root root    6 Nov 24 00:12 secrets
----
====

See Docker's documentation for additional information on how to
link:https://docs.docker.com/engine/admin/logging/overview/#/options[Configure
Logging Drivers].

[[ensuring-host-access]]

== Ensuring Host Access

ifdef::openshift-origin[]
The xref:advanced_install.adoc#install-config-install-advanced-install[advanced installation] method requires
endif::[]
ifdef::openshift-enterprise[]
The xref:quick_install.adoc#install-config-install-quick-install[quick] and xref:advanced_install.adoc#install-config-install-advanced-install[advanced
installation] methods require
endif::[]
a user that has access to all hosts. If you want to run the installer as a
non-root user, passwordless *sudo* rights must be configured on each destination
host.

For example, you can generate an SSH key on the host where you will invoke the
installation process:

----
# ssh-keygen
----

Do *not* use a password.

An easy way to distribute your SSH keys is by using a `bash` loop:

----
# for host in master.example.com \
    node1.example.com \
    node2.example.com; \
    do ssh-copy-id -i ~/.ssh/id_rsa.pub $host; \
    done
----

Modify the host names in the above command according to your configuration.

== What's Next?

ifdef::openshift-enterprise[]
If you are interested in installing {product-title} using the containerized method
(optional for RHEL but required for RHEL Atomic Host), see
xref:../../install_config/install/rpm_vs_containerized.adoc#install-config-install-rpm-vs-containerized[Installing on
Containerized Hosts]
to prepare your hosts.

When you are ready to proceed, you can install {product-title} using the
xref:quick_install.adoc#install-config-install-quick-install[quick installation] or
xref:advanced_install.adoc#install-config-install-advanced-install[advanced installation] method.

[IMPORTANT]
====
As of {product-title} 3.9, the quick installation method is deprecated. In a
future release, it will be removed completely. In addition, using the quick
installer to upgrade from version 3.7 to 3.9 is not supported.
====
endif::[]

ifdef::openshift-origin[]
If you are interested in installing {product-title} using the containerized method
(optional for Fedora, CentOS, or RHEL but required for RHEL Atomic Host), see
xref:../../install_config/install/rpm_vs_containerized.adoc#install-config-install-rpm-vs-containerized[Installing on
Containerized Hosts]
to prepare your hosts.

If you came here from xref:../../getting_started/administrators.adoc#getting-started-administrators[Getting
Started for Administrators], you can now continue there by choosing an
xref:../../getting_started/administrators.adoc#installation-methods[installation
method]. Alternatively, you can install {product-title} using the
xref:advanced_install.adoc#install-config-install-advanced-install[advanced installation] method.
endif::[]

If you are installing a stand-alone registry, continue with
xref:../../install_config/install/stand_alone_registry.adoc#registry-installation-methods[Installing a Stand-alone Registry].
