[[install-config-configuring-gce]]
= Configuring for GCE
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:

toc::[]

== Overview
{product-title} can be configured to access a
link:https://cloud.google.com/compute/docs/disks/[Google Compute Engine (GCE) infrastructure], including
xref:../install_config/persistent_storage/persistent_storage_gce.adoc#install-config-persistent-storage-persistent-storage-gce[using GCE
volumes as persistent storage] for application data. After GCE is configured
properly, some additional configurations will need to be completed on the
{product-title} hosts.

[[configuring-gcp-permissions]]
== Permissions
Configuring Google Cloud Platform (GCP) for {product-title} requires the following role:

[cols='1,3']
|===

| roles/owner
| To create service accounts, cloud storage, instances, images, templates, Cloud
DNS entries, and deploy load balancers and health checks. It is helpful to also
have `delete` permissions to be able to redeploy the environment while testing.

|===

[[gce-configuring-masters]]
== Configuring Masters

You can set the GCE configuration on your {product-title} master hosts in two ways:

- xref:gce-configuring-masters-ansible[Using Ansible and the advanced installation tool.]
- xref:gce-configuring-masters-manual[Manually by modifying the *_master-config.yaml_* file.]


[[gce-configuring-masters-ansible]]
=== Configuring {product-title} Masters for GCE with Ansible

During xref:../install_config/install/advanced_install.adoc#install-config-install-advanced-install[advanced installations], GCE can be configured using the `openshift_cloudprovider_kind` parameter, which is configurable in the inventory file.

.Example GCE Configuration with Ansible

----
# Cloud Provider Configuration
#
  openshift_cloudprovider_kind=gce
----



[NOTE]
====
When Ansible configures GCE, the following files are created for you:

- */etc/origin/cloudprovider/gce.conf*
- *_/etc/origin/master/master-config.yaml_*
- *_/etc/origin/node/node-config.yaml_*
====

The advanced installation configures multizone support by default.  If you want single-zone support, edit the */etc/origin/cloudprovider/gce.conf* as shown in Configuring Multizone Support in a GCE Deployment.

[[gce-configuring-masters-manual]]
=== Manually Configuring {product-title} Masters for GCE

To configure the {product-title} masters for GCE:

. Edit or
xref:../install_config/master_node_configuration.adoc#creating-new-configuration-files[create] the
master configuration file (*_/etc/origin/master/master-config.yaml_* by default) on all masters and update the
contents of the `*apiServerArguments*` and `*controllerArguments*` sections:
+
[source,yaml]
----
kubernetesMasterConfig:
  ...
  apiServerArguments:
    cloud-provider:
      - "gce"
    cloud-config:
      - "/etc/origin/cloudprovider/gce.conf"
  controllerArguments:
    cloud-provider:
      - "gce"
    cloud-config:
      - "/etc/origin/cloudprovider/gce.conf"
----
+
[IMPORTANT]
====
When triggering a containerized installation, only the directories of
*_/etc/origin_* and *_/var/lib/origin_* are mounted to the master and node
container. Therefore, *_master-config.yaml_* should be in *_/etc/origin/master_*
instead of *_/etc/_*.
====

. Start or restart the {product-title} services:
+
ifdef::openshift-enterprise[]
----
# systemctl restart atomic-openshift-master
----
endif::[]
ifdef::openshift-origin[]
----
# systemctl restart origin-master
----
endif::[]


[[gce-configuring-nodes]]
== Configuring Nodes

To configure the {product-title} nodes for GCE:

. Edit or
xref:../install_config/master_node_configuration.adoc#creating-new-configuration-files[create]
the node configuration file (*_/etc/origin/node/node-config.yaml_*
by default) on all nodes and update the contents of the `*kubeletArguments*` section:
+
====
[source,yaml]
----
kubeletArguments:
 cloud-provider:
    - "gce"
  cloud-config:
    - "/etc/origin/cloudprovider/gce.conf"

----
====

Currently, the `nodeName` *must* match the instance name in GCE in order
for the cloud provider integration to work properly.  The name must also be
RFC1123 compliant.

[IMPORTANT]
====
When triggering a containerized installation, only the directories of
*_/etc/origin_* and *_/var/lib/origin_* are mounted to the master and node
container. Therefore, *_node-config.yaml_* should be in *_/etc/origin/node_*
instead of *_/etc/_*.
====

. Start or restart the {product-title} services all nodes.
+
ifdef::openshift-enterprise[]
----
# systemctl restart atomic-openshift-node
----
endif::[]
ifdef::openshift-origin[]
----
# systemctl restart origin-node
----
endif::[]


[[configuring-gce-multizone]]

== Configuring Multizone Support in a GCE Deployment
If manually configuring GCE, multizone support is not configured by default.

[NOTE]
====
The advanced installation configures multizone support by default.
====

If you want multizone support:

. Edit or create a *_/etc/origin/cloudprovider/gce.conf_* file on all of your {product-title} hosts, both masters and nodes.
. Add the following contents:
+
----
[Global]
multizone = true
----

To return to single-zone support, set the `multizone` value to `false`.

[[gce-applying-configuration-changes]]
== Applying Configuration Changes

Start or restart {product-title} services on all master and node hosts to apply your
configuration changes:

ifdef::openshift-enterprise[]
----
# systemctl restart atomic-openshift-master
# systemctl restart atomic-openshift-node
----
endif::[]
ifdef::openshift-origin[]
----
# systemctl restart origin-master
# systemctl restart origin-node
----
endif::[]

Switching from not using a cloud provider to using a cloud provider produces an
error message. Adding the cloud provider tries to delete the node because the
node switches from using the *hostname* as the `*externalID*` (which would have
been the case when no cloud provider was being used) to using the GCE
`*instance-id*` (which is what the GCE cloud provider specifies). To resolve
this issue:

.  Log in to the CLI as a cluster administrator.
. Check and backup existing node labels:
+
[source, bash]
----
$ oc describe node <node_name> | grep -Poz '(?s)Labels.*\n.*(?=Taints)'
----
.  Delete the nodes:
+
[source, bash]
----
$ oc delete node <node_name>
----
.  On each node host, restart the {product-title} service.
+
ifdef::openshift-enterprise[]
----
$ systemctl restart atomic-openshift-node
----
endif::[]
ifdef::openshift-origin[]
----
$ systemctl restart origin-node
----
endif::[]
.  Add back any xref:../admin_guide/manage_nodes.adoc#updating-labels-on-nodes[labels on each node] that you previously had.
