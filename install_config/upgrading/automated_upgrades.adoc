[[install-config-upgrading-automated-upgrades]]
= Performing Automated Cluster Upgrades
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

== Overview

ifdef::openshift-enterprise[]
Starting with OpenShift 3.0.2,
endif::[]
ifdef::openshift-origin[]
Starting with Origin 1.0.6,
endif::[]
if you installed using the
xref:../../install_config/install/advanced_install.adoc#install-config-install-advanced-install[advanced installation]
and the inventory file that was used is available, you can use the upgrade
playbook to automate the OpenShift cluster upgrade process.
ifdef::openshift-enterprise[]
If you installed using the
xref:../../install_config/install/quick_install.adoc#install-config-install-quick-install[quick installation] method
and a *_~/.config/openshift/installer.cfg.yml_* file is available, you can use
the installer to perform the automated upgrade.
endif::[]

The automated upgrade performs the following steps for you:

* Applies the latest configuration.
* Upgrades and restart master services.
* Upgrades and restart node services.
* Applies the latest cluster policies.
* Updates the default router if one exists.
* Updates the default registry if one exists.
* Updates default image streams and InstantApp templates.

[IMPORTANT]
====
Ensure that you have met all
xref:../../install_config/install/prerequisites.adoc#install-config-install-prerequisites[prerequisites]
before proceeding with an upgrade. Failure to do so can result in a failed
upgrade.
====

ifdef::openshift-origin[]
[[running-upgrade-playbooks]]
== Running Upgrade Playbooks

Ensure that you have the latest *openshift-ansible* code checked out:

----
# cd ~/openshift-ansible
# git pull https://github.com/openshift/openshift-ansible master
----

Then run one of the following upgrade playbooks utilizing the inventory file you
used during the advanced installation. If your inventory file is located
somewhere other than the default *_/etc/ansible/hosts_*, add the `-i` flag to
specify the location.

[[upgrading-to-openshift-origin-1-1]]
=== Upgrading to OpenShift Origin 1.1

To upgrade from OpenShift Origin 1.0 to 1.1, run the following playbook:

----
# ansible-playbook \
    [-i </path/to/inventory/file>] \
    playbooks/byo/openshift-cluster/upgrades/v3_0_to_v3_1/upgrade.yml
----

[NOTE]
====
The *_v3_0_to_v3_1_* in the above path is a reference to the related OpenShift
Enterprise versions, however it is also the correct playbook to use when
upgrading from OpenShift Origin 1.0 to 1.1.
====

When the upgrade finishes, a recommendation will be printed to reboot all hosts.
After rebooting, continue to Updating Master and Node Certificates.

[[upgrading-to-openshift-origin-1-1-z-releases]]
=== Upgrading to OpenShift Origin 1.1.z Releases

To upgrade an existing OpenShift Origin 1.1 cluster to the latest 1.1.z release,
run the following playbook:

----
# ansible-playbook \
    [-i </path/to/inventory/file>] \
    playbooks/byo/openshift-cluster/upgrades/v3_1_minor/upgrade.yml
----

[NOTE]
====
The *v3_1_minor* in the above path is a reference to the related OpenShift
Enterprise versions, however it is also the correct playbook to use when
upgrading from OpenShift Origin 1.1 to the latest 1.1.z release.
====

When the upgrade finishes, a recommendation will be printed to reboot all hosts.
After rebooting, continue to xref:verifying-the-upgrade[Verifying the Upgrade].
endif::[]

ifdef::openshift-enterprise[]
[[preparing-for-an-automated-upgrade]]
== Preparing for an Automated Upgrade

[NOTE]
====
If you are on OpenShift Enterprise 3.0, you must first upgrade to 3.1 before
upgrading to 3.2. Further, if you are currently using the Pacemaker HA method,
you must first upgrade to the native HA method before upgrading to 3.2, as the
Pacemaker method is no longer supported starting with 3.2. See the
https://docs.openshift.com/enterprise/3.1/install_config/upgrading/index.html[OpenShift
Enterprise 3.1 upgrade documentation] for instructions.
====

[IMPORTANT]
====
Starting with
xref:../../release_notes/ose_3_2_release_notes.adoc#ose-32-relnotes-rhba-2016-1208[RHBA-2016:1208],
upgrades from {product-title} 3.1 to 3.2 are supported for clusters using the
containerized installation method. See
xref:../../release_notes/ose_3_2_release_notes.adoc#ose-32-known-issues[Known
Issues].
====

To prepare for an automated upgrade:

. If you are upgrading from OpenShift Enterprise 3.1 to 3.2, on each master and
node host you must manually disable the 3.1 channel and enable the 3.2 channel:
+
----
# subscription-manager repos --disable="rhel-7-server-ose-3.1-rpms" \
    --enable="rhel-7-server-ose-3.2-rpms"\
    --enable="rhel-7-server-extras-rpms"
# yum clean all
----

. For any upgrade path, always ensure that you have the latest version of the
*atomic-openshift-utils* package, which should also update the
*openshift-ansible-** packages:
+
----
# yum update atomic-openshift-utils
----

. Install or update to the following latest available **-excluder* packages on
each RHEL 7 system, which helps ensure your systems stay on the correct versions
of *atomic-openshift* and *docker* packages when you are not trying to upgrade,
according to the {product-title} version:
+
----
# yum install atomic-openshift-excluder atomic-openshift-docker-excluder
----
+
These packages add entries to the `exclude` directive in the host's
*_/etc/yum.conf_* file.

. You must be logged in as a cluster administrative user on the master host for
the upgrade to succeed:
+
----
$ oc login
----

There are two methods for running the automated upgrade:
xref:upgrading-using-the-installation-utility-to-upgrade[using the installer]
or xref:running-the-upgrade-playbook-directly[running the upgrade playbook
directly]. Choose and follow one method.

[[upgrading-using-the-installation-utility-to-upgrade]]
== Using the Installer to Upgrade

If you installed {product-title} using the
xref:../../install_config/install/quick_install.adoc#install-config-install-quick-install[quick installation] method,
you should have an installation configuration file located at
*_~/.config/openshift/installer.cfg.yml_*. The installer requires this file to
start an upgrade.

The installer supports upgrading between minor versions of {product-title}
(e.g., 3.1 to 3.2) as well as between
xref:../../release_notes/ose_3_2_release_notes.adoc#ose-32-asynchronous-errata-updates[asynchronous
errata updates] within a minor version (e.g., 3.2.z).

If you have an older format installation configuration file in
*_~/.config/openshift/installer.cfg.yml_* from an existing OpenShift Enterprise
3.0 or 3.1 installation, the installer will attempt to upgrade the file to the
new supported format. If you do not have an installation configuration file of
any format, you can
xref:../../install_config/install/quick_install.adoc#defining-an-installation-configuration-file[create
one manually].

To start the upgrade, run the installer with the `upgrade` subcommand:

. Satisfy the steps in xref:preparing-for-an-automated-upgrade[Preparing for an Automated Upgrade] to ensure you are using the latest upgrade playbooks.

. Run the following command on each host to remove the *atomic-openshift* packages
from the list of yum excludes on the host:
+
----
# atomic-openshift-excluder unexclude
----

. Run the installer with the `upgrade` subcommand:
+
----
# atomic-openshift-installer upgrade
----

. Follow the on-screen instructions to upgrade to the latest release.
// tag::automated_upgrade_after_reboot[]
. After all master and node upgrades have completed, a recommendation will be
printed to reboot all hosts. Before rebooting, run the following command on each
master and node host to add the *atomic-openshift* packages back to the list of
yum excludes on the host:
+
----
# atomic-openshift-excluder exclude
----
+
Then reboot all hosts.

. After rebooting, if there are no additional features enabled, you can
xref:verifying-the-upgrade[verify the upgrade]. Otherwise, the next step depends
on what additional features have you previously enabled.
+
[cols="1,4"]
|===
| Feature | Next Step

| Aggregated Logging
| xref:automated-upgrading-efk-logging-stack[Upgrade the EFK logging stack.]

| Cluster Metrics
| xref:automated-upgrading-cluster-metrics[Upgrade cluster metrics.]
|===
// end::automated_upgrade_after_reboot[]

[[running-the-upgrade-playbook-directly]]
== Running the Upgrade Playbook Directly

You can run the automated upgrade playbook using Ansible directly, similar
to the advanced installation method, if you have an inventory file.

The same *_v3_2_* upgrade playbook can be used to upgrade either of the
following to the latest 3.2 release:

- xref:upgrading-to-openshift-enterprise-3-2[Existing {product-title} 3.1 clusters]
- xref:upgrading-to-openshift-enterprise-3-2-asynchronous-releases[Existing {product-title} 3.2 clusters]

[[upgrading-to-openshift-enterprise-3-2]]
=== Upgrading to OpenShift Enterprise 3.2

Before running the upgrade, first ensure the `*deployment_type*` parameter in
your inventory file is set to `openshift-enterprise`.

If you have multiple masters configured and want to enable rolling, full system
restarts of the hosts, you can set the `*openshift_rolling_restart_mode*`
parameter in your inventory file to `system`. Otherwise, the default value
`services` performs rolling service restarts on HA masters, but does not reboot
the systems. See
xref:../install/advanced_install.adoc#configuring-cluster-variables[Configuring
Cluster Variables] for details.

Then, run the *_v3_2_* upgrade playbook. If your inventory file is
located somewhere other than the default *_/etc/ansible/hosts_*, add the `-i`
flag to specify the location. If you previously used the
`atomic-openshift-installer` command to run your installation, you can check
*_~/.config/openshift/.ansible/hosts_* for the last inventory file that was
used, if needed.

----
# ansible-playbook [-i </path/to/inventory/file>] \
    /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-cluster/upgrades/v3_2/upgrade.yml
----

[NOTE]
====
The upgrade playbook was previously located in a *_v3_1_to_v3_2_* directory.
Ensure you are using the latest playbooks per the
xref:preparing-for-an-automated-upgrade[Preparing for an Automated Upgrade]
section.
====

include::install_config/upgrading/automated_upgrades.adoc[tag=automated_upgrade_after_reboot]

[[upgrading-to-openshift-enterprise-3-2-asynchronous-releases]]
=== Upgrading to OpenShift Enterprise 3.2 Asynchronous Releases

To apply
xref:../../release_notes/ose_3_2_release_notes.adoc#ose-32-asynchronous-errata-updates[asynchronous
errata updates] to an existing {product-title} 3.2 cluster, first upgrade the
*atomic-openshift-utils* package on the Red Hat Enterprise Linux 7 system where
you will be running Ansible:

----
# yum update atomic-openshift-utils
----

Then, run the same *_v3_2_* upgrade playbook that is used for
xref:upgrading-to-openshift-enterprise-3-2[upgrading to {product-title} 3.2 from
3.1]. If your inventory file is located somewhere other than the default
*_/etc/ansible/hosts_*, add the `-i` flag to specify the location. If you
previously used the `atomic-openshift-installer` command to run your
installation, you can check *_~/.config/openshift/.ansible/hosts_* for the last
inventory file that was used, if needed.

----
# ansible-playbook [-i </path/to/inventory/file>] \
    /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-cluster/upgrades/v3_2/upgrade.yml
----

include::install_config/upgrading/automated_upgrades.adoc[tag=automated_upgrade_after_reboot]
endif::[]

ifdef::openshift-origin[]
:sect: automated
include::install_config/upgrading/manual_upgrades.adoc[tag=30to31updatingcerts]
endif::[]

[[automated-upgrading-efk-logging-stack]]
== Upgrading the EFK Logging Stack

If you have previously xref:../../install_config/aggregate_logging.adoc#install-config-aggregate-logging[deployed
the EFK logging stack] and want to upgrade to the latest logging component
images, the steps must be performed manually as shown in
xref:../../install_config/upgrading/manual_upgrades.adoc#manual-upgrading-efk-logging-stack[Manual
Upgrades].

[[automated-upgrading-cluster-metrics]]
== Upgrading Cluster Metrics

If you have previously
xref:../../install_config/cluster_metrics.adoc#install-config-cluster-metrics[deployed cluster metrics],
you must manually
xref:../../install_config/upgrading/manual_upgrades.adoc#manual-upgrading-cluster-metrics[update]
to the latest metric components.

[[verifying-the-upgrade]]
== Verifying the Upgrade

To verify the upgrade, first check that all nodes are marked as *Ready*:

====
----
# oc get nodes
NAME                 LABELS                                                                STATUS
master.example.com   kubernetes.io/hostname=master.example.com,region=infra,zone=default   Ready
node1.example.com    kubernetes.io/hostname=node1.example.com,region=primary,zone=east     Ready
----
====

Then, verify that you are running the expected versions of the *docker-registry*
and *router* images, if deployed:

====
----
ifdef::openshift-enterprise[]
# oc get -n default dc/docker-registry -o json | grep \"image\"
    "image": "openshift3/ose-docker-registry:v3.2.1.28",
# oc get -n default dc/router -o json | grep \"image\"
    "image": "openshift3/ose-haproxy-router:v3.2.1.28",
endif::[]
ifdef::openshift-origin[]
# oc get -n default dc/docker-registry -o json | grep \"image\"
    "image": "openshift/origin-docker-registry:v1.0.6",
# oc get -n default dc/router -o json | grep \"image\"
    "image": "openshift/origin-haproxy-router:v1.0.6",
endif::[]
----
====

ifdef::openshift-origin[]
If you upgraded from Origin 1.0 to Origin 1.1, verify in your old
*_/etc/sysconfig/openshift-master_* and *_/etc/sysconfig/openshift-node_* files
that any custom configuration is added to your new
*_/etc/sysconfig/origin-master_* and *_/etc/sysconfig/origin-node_* files.
endif::[]

After upgrading, you can use the diagnostics tool on the master to look for
common issues:

====
----
# oadm diagnostics
...
[Note] Summary of diagnostics execution:
[Note] Completed with no errors or warnings seen.
----
====
