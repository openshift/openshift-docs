[[install-config-upgrading-automated-upgrades]]
= Performing Automated In-place Cluster Upgrades
{product-author}
{product-version}
:latest-tag: v3.3.1.25
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

== Overview

If you installed using the
xref:../../install_config/install/advanced_install.adoc#install-config-install-advanced-install[advanced installation]
and the inventory file that was used is available, you can use the upgrade
playbook to automate the OpenShift cluster upgrade process.
ifdef::openshift-enterprise[]
If you installed using the
xref:../../install_config/install/quick_install.adoc#install-config-install-quick-install[quick installation] method
and a *_~/.config/openshift/installer.cfg.yml_* file is available, you can use
the installer to perform the automated upgrade.
endif::[]

The automated upgrade performs the following steps for you:

* Applies the latest configuration.
* Upgrades and restart master services.
* Upgrades and restart node services.
* Applies the latest cluster policies.
* Updates the default router if one exists.
* Updates the default registry if one exists.
* Updates default image streams and InstantApp templates.

[IMPORTANT]
====
Ensure that you have met all
xref:../../install_config/install/prerequisites.adoc#install-config-install-prerequisites[prerequisites]
before proceeding with an upgrade. Failure to do so can result in a failed
upgrade.
====

ifdef::openshift-origin[]
[[running-upgrade-playbooks]]
== Running Upgrade Playbooks

Ensure that you have the latest *openshift-ansible* code checked out:

----
# cd ~/openshift-ansible
# git pull https://github.com/openshift/openshift-ansible master
----

Then run one of the following upgrade playbooks utilizing the inventory file you
used during the advanced installation. If your inventory file is located
somewhere other than the default *_/etc/ansible/hosts_*, add the `-i` flag to
specify the location.

[[upgrading-to-openshift-origin-1-1]]
=== Upgrading to OpenShift Origin 1.1

To upgrade from OpenShift Origin 1.0 to 1.1, run the following playbook:

----
# ansible-playbook \
    [-i </path/to/inventory/file>] \
    playbooks/byo/openshift-cluster/upgrades/v3_0_to_v3_1/upgrade.yml
----

[NOTE]
====
The *_v3_0_to_v3_1_* in the above path is a reference to the related OpenShift
Enterprise versions, however it is also the correct playbook to use when
upgrading from OpenShift Origin 1.0 to 1.1.
====

When the upgrade finishes, a recommendation will be printed to reboot all hosts.
After rebooting, continue to Updating Master and Node Certificates.

[[upgrading-to-openshift-origin-1-1-z-releases]]
=== Upgrading to OpenShift Origin 1.1.z Releases

To upgrade an existing OpenShift Origin 1.1 cluster to the latest 1.1.z release,
run the following playbook:

----
# ansible-playbook \
    [-i </path/to/inventory/file>] \
    playbooks/byo/openshift-cluster/upgrades/v3_1_minor/upgrade.yml
----

[NOTE]
====
The *v3_1_minor* in the above path is a reference to the related OpenShift
Enterprise versions, however it is also the correct playbook to use when
upgrading from OpenShift Origin 1.1 to the latest 1.1.z release.
====

When the upgrade finishes, a recommendation will be printed to reboot all hosts.
After rebooting, continue to xref:verifying-the-upgrade[Verifying the Upgrade].
endif::[]

ifdef::openshift-enterprise[]
[[preparing-for-an-automated-upgrade]]
== Preparing for an Automated Upgrade

[IMPORTANT]
====
Before upgrading your cluster to {product-title} 3.3, the cluster must be
already upgraded to the
link:https://docs.openshift.com/enterprise/3.2/release_notes/ose_3_2_release_notes.html#ose-32-asynchronous-errata-updates[latest asynchronous release of version 3.2]. Cluster upgrades cannot span more than one
minor version at a time, so if your cluster is at version 3.0 or 3.1, you must
first upgrade incrementally (e.g., 3.0 to 3.1, then 3.1 or 3.2).
====

To prepare for an automated upgrade:

. If you are upgrading from version 3.2 to 3.3, manually disable the 3.2 channel and enable the 3.3 channel on each master and node host:
+
----
# subscription-manager repos --disable="rhel-7-server-ose-3.2-rpms" \
    --enable="rhel-7-server-ose-3.3-rpms"\
    --enable="rhel-7-server-rpms" \
    --enable="rhel-7-server-extras-rpms"
# yum clean all
----
. For any upgrade path, always ensure that you have the latest version of the
*atomic-openshift-utils* package, which should also update the
*openshift-ansible-** packages:
+
----
# yum update atomic-openshift-utils
----

. Install or update to the following latest available **-excluder* packages on
each RHEL 7 system, which helps ensure your systems stay on the correct versions
of *atomic-openshift* and *docker* packages when you are not trying to upgrade,
according to the {product-title} version:
+
----
# yum install atomic-openshift-excluder atomic-openshift-docker-excluder
----
+
These packages add entries to the `exclude` directive in the host's
*_/etc/yum.conf_* file.

. You must be logged in as a cluster administrative user on the master host for
the upgrade to succeed:
+
----
$ oc login
----

After satisfying these steps, there are two methods for running the automated
upgrade:

- xref:upgrading-using-the-installation-utility-to-upgrade[Using the installer]
- xref:running-the-upgrade-playbook-directly[Running the upgrade playbook directly]

Choose and follow one of these methods.

[[upgrading-using-the-installation-utility-to-upgrade]]
== Using the Installer to Upgrade

If you installed {product-title} using the
xref:../../install_config/install/quick_install.adoc#install-config-install-quick-install[quick installation] method,
you should have an installation configuration file located at
*_~/.config/openshift/installer.cfg.yml_*. The installer requires this file to
start an upgrade.

The installer supports upgrading between minor versions of {product-title}
(one minor version at a time, e.g., 3.2 to 3.3) as well as between
xref:../../release_notes/ocp_3_3_release_notes.adoc#ocp-33-asynchronous-errata-updates[asynchronous errata updates] within a minor version (e.g., 3.3.z).

If you have an older format installation configuration file in
*_~/.config/openshift/installer.cfg.yml_* from an installation of a previous
cluster version, the installer will attempt to upgrade the file to the new supported
format. If you do not have an installation configuration file of any format, you
can
xref:../../install_config/install/quick_install.adoc#defining-an-installation-configuration-file[create one manually].

To start an upgrade with the quick installer:

. Satisfy the steps in xref:preparing-for-an-automated-upgrade[Preparing for an Automated Upgrade] to ensure you are using the latest upgrade playbooks.

. Run the installer with the `upgrade` subcommand:
+
----
# atomic-openshift-installer upgrade
----
. Then, follow the on-screen instructions to upgrade to the latest release.
// tag::automated_upgrade_after_reboot[]
. After all master and node upgrades have completed, a recommendation will be
printed to reboot all hosts.

. After rebooting, if there are no additional features enabled, you can
xref:verifying-the-upgrade[verify the upgrade]. Otherwise, the next step depends
on what additional features have you previously enabled.
+
[cols="1,4"]
|===
| Feature | Next Step

| Aggregated Logging
| xref:automated-upgrading-efk-logging-stack[Upgrade the EFK logging stack.]

| Cluster Metrics
| xref:automated-upgrading-cluster-metrics[Upgrade cluster metrics.]
|===
// end::automated_upgrade_after_reboot[]

[[running-the-upgrade-playbook-directly]]
== Running the Upgrade Playbook Directly

You can run the automated upgrade playbook using Ansible directly, similar
to the advanced installation method, if you have an inventory file.

The same *_v3_3_* upgrade playbook can be used to upgrade either of the
following to the latest 3.3 release:

- xref:upgrading-to-ocp-3-3[Existing {product-title} 3.2 clusters]
- xref:upgrading-to-ocp-3-3-asynchronous-releases[Existing {product-title} 3.3 clusters]

[[upgrading-to-ocp-3-3]]
=== Upgrading to {product-title} 3.3

To run an upgrade from {product-title} 3.2 to 3.3:

. Satisfy the steps in xref:preparing-for-an-automated-upgrade[Preparing for an Automated Upgrade] to ensure you are using the latest upgrade playbooks.
. Ensure the `*deployment_type*` parameter in your inventory file is set to
`openshift-enterprise`.
. If you have multiple masters configured and want to enable rolling, full system
restarts of the hosts, you can set the `*openshift_rolling_restart_mode*`
parameter in your inventory file to `system`. Otherwise, the default value
`services` performs rolling service restarts on HA masters, but does not reboot
the systems. See
xref:../install/advanced_install.adoc#configuring-cluster-variables[Configuring
Cluster Variables] for details.
. Run the *_v3_3_* upgrade playbook. If your inventory file is located somewhere
other than the default *_/etc/ansible/hosts_*, add the `-i` flag to specify the
location. If you previously used the `atomic-openshift-installer` command to run
your installation, you can check *_~/.config/openshift/hosts_* (previously
located at *_~/.config/openshift/.ansible/hosts_*) for the last inventory file
that was used, if needed.
+
----
# ansible-playbook [-i </path/to/inventory/file>] \
    /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-cluster/upgrades/v3_3/upgrade.yml
----
include::install_config/upgrading/automated_upgrades.adoc[tag=automated_upgrade_after_reboot]

[[upgrading-to-ocp-3-3-asynchronous-releases]]
=== Upgrading to {product-title} 3.3 Asynchronous Releases

To apply
xref:../../release_notes/ocp_3_3_release_notes.adoc#ocp-33-asynchronous-errata-updates[asynchronous errata updates] to an existing {product-title} 3.3 cluster:

. Satisfy the steps in xref:preparing-for-an-automated-upgrade[Preparing for an Automated Upgrade] to ensure you are using the latest upgrade playbooks.
. Run the *_v3_3_* upgrade playbook (the same playbook that is used for
xref:upgrading-to-ocp-3-3[upgrading from {product-title} 3.2 to 3.3]). If your
inventory file is located somewhere other than the default
*_/etc/ansible/hosts_*, add the `-i` flag to specify the location. If you
previously used the `atomic-openshift-installer` command to run your
installation, you can check *_~/.config/openshift/hosts_* (previously located at
*_~/.config/openshift/.ansible/hosts_*) for the last inventory file that was
used, if needed.
+
----
# ansible-playbook [-i </path/to/inventory/file>] \
    /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-cluster/upgrades/v3_3/upgrade.yml
----
include::install_config/upgrading/automated_upgrades.adoc[tag=automated_upgrade_after_reboot]
endif::[]

ifdef::openshift-origin[]
:sect: automated
include::install_config/upgrading/manual_upgrades.adoc[tag=30to31updatingcerts]
endif::[]

[[automated-upgrading-efk-logging-stack]]
== Upgrading the EFK Logging Stack

If you have previously xref:../../install_config/aggregate_logging.adoc#install-config-aggregate-logging[deployed
the EFK logging stack] and want to upgrade to the latest logging component
images, the steps must be performed manually as shown in
xref:../../install_config/upgrading/manual_upgrades.adoc#manual-upgrading-efk-logging-stack[Manual
Upgrades].

[[automated-upgrading-cluster-metrics]]
== Upgrading Cluster Metrics

If you have previously
xref:../../install_config/cluster_metrics.adoc#install-config-cluster-metrics[deployed cluster metrics],
you must manually
xref:../../install_config/upgrading/manual_upgrades.adoc#manual-upgrading-cluster-metrics[update]
to the latest metric components.

[[verifying-the-upgrade]]
== Verifying the Upgrade

To verify the upgrade:

. First check that all nodes are marked as *Ready*:
+
----
# oc get nodes
NAME                        STATUS                     AGE
master.example.com          Ready,SchedulingDisabled   165d
node1.example.com           Ready                      165d
node2.example.com           Ready                      165d
----
. Then, verify that you are running the expected versions of the *docker-registry*
and *router* images, if deployed.
ifdef::openshift-enterprise[]
Replace `<tag>` with `{latest-tag}` for the latest version.
endif::[]
+
----
ifdef::openshift-enterprise[]
# oc get -n default dc/docker-registry -o json | grep \"image\"
    "image": "openshift3/ose-docker-registry:<tag>",
# oc get -n default dc/router -o json | grep \"image\"
    "image": "openshift3/ose-haproxy-router:<tag>",
endif::[]
ifdef::openshift-origin[]
# oc get -n default dc/docker-registry -o json | grep \"image\"
    "image": "openshift/origin-docker-registry:v1.0.6",
# oc get -n default dc/router -o json | grep \"image\"
    "image": "openshift/origin-haproxy-router:v1.0.6",
endif::[]
----
ifdef::openshift-origin[]
. If you upgraded from Origin 1.0 to Origin 1.1, verify in your old
*_/etc/sysconfig/openshift-master_* and *_/etc/sysconfig/openshift-node_* files
that any custom configuration is added to your new
*_/etc/sysconfig/origin-master_* and *_/etc/sysconfig/origin-node_* files.
endif::[]
. After upgrading, you can use the diagnostics tool on the master to look for
common issues:
+
----
# oadm diagnostics
...
[Note] Summary of diagnostics execution:
[Note] Completed with no errors or warnings seen.
----
