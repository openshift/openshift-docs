[[binding-pv-by-label]]
= Binding Persistent Volumes by Labels
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap:

toc::[]

[[binding-pv-by-label-overview]]
== Overview
This topic provides an end-to-end example for binding
xref:../../architecture/additional_concepts/storage.adoc#persistent-volume-claims[persistent
volume claims (PVCs)] to
xref:../../architecture/additional_concepts/storage.adoc#persistent-volumes[persistent
volumes (PVs)], by defining labels in the PV and matching selectors in the PVC.
This feature is available for all xref:../persistent_storage/index.adoc#install-config-persistent-storage-index[storage
options]. It is assumed that a {product-title} cluster contains persistent
storage resources which are available for binding by PVCs.

*A Note on Labels and Selectors*

Labels are an {product-title} feature that support user-defined tags (key-value
pairs) as part of an object's specification. Their primary purpose is to enable
the arbitrary grouping of objects by defining identical labels among them. These
labels can then be targeted by selectors to match all objects with specified
label values. It is this functionality we will take advantage of to enable our
PVC to bind to our PV. For a more in-depth look at labels, see
xref:../../architecture/core_concepts/pods_and_services.adoc#labels[Pods and Services].

[NOTE]
====
For this example, we will be using modified
xref:../persistent_storage/persistent_storage_glusterfs.adoc#install-config-persistent-storage-persistent-storage-glusterfs[GlusterFS]
PV and PVC specifications. However, implementation of selectors and labels is generic
across for all storage options. See the
xref:../persistent_storage/index.adoc#install-config-persistent-storage-index[relevant
storage option] for your volume provider to learn more about its unique
configuration.
====

[[binding-pv-by-label-assumptions]]
=== Assumptions
It is assumed that you have:

* An existing {product-title} cluster with at least one *master* and one *node*
* At least one supported  xref:../persistent_storage/index.adoc#install-config-persistent-storage-index[storage volume]
* A user with *cluster-admin* privileges

[[binding-pv-by-label-define]]
== Defining Specifications

[NOTE]
====
These specifications are tailored to *GlusterFS*. Consult the
xref:../persistent_storage/index.adoc#install-config-persistent-storage-index[relevant
storage option] for your volume provider to learn more about its unique
configuration.
====

[[binding-pv-by-label-pv-with-labels]]
=== Persistent Volume with Labels
.glusterfs-pv.yaml
====
[source,yaml]
----
apiVersion: v1
kind: PersistentVolume
metadata:
  name: gluster-volume
  labels: <1>
    storage-tier: gold
    aws-availability-zone: us-east-1
spec:
  capacity:
    storage: 2Gi
  accessModes:
    - ReadWriteMany
  glusterfs:
    endpoints: glusterfs-cluster <2>
    path: myVol1
    readOnly: false
  persistentVolumeReclaimPolicy: Retain
----
<1> Use labels to identify common attributes or characteristics shared among
 volumes. In this case, we defined the Gluster volume to have a custom attribute
 (key) named *storage-tier* with a value of *gold* assigned. A claim will be
 able to select a PV with `*storage-tier=gold*` to match this PV.
<2> Endpoints define the Gluster trusted pool and are discussed below.
====

[[binding-pv-by-label-pvc-with-selectors]]
=== Persistent Volume Claim with Selectors

A claim with a *selector* stanza (see example below) attempts to match existing,
unclaimed, and non-prebound PVs. The existence of a PVC selector ignores a PV's
capacity. However, *accessModes* are still considered in the matching criteria.

It is important to note that a claim must match *all* of the key-value pairs
included in its *selector* stanza. If no PV matches the claim, then the PVC
will remain unbound (Pending). A PV can subsequently be created and the
claim will automatically check for a label match.

.glusterfs-pvc.yaml
====
[source,yaml]
----
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: gluster-claim
spec:
  accessModes:
  - ReadWriteMany
  resources:
     requests:
       storage: 1Gi
  selector: <1>
    matchLabels:
      storage-tier: gold
      aws-availability-zone: us-east-1
----
<1> The *selector* stanza defines all labels necessary in a PV
    in order to match this claim.
====

[[binding-pv-by-label-volume-endpoints]]
=== Volume Endpoints

To attach the PV to the Gluster volume, endpoints should be configured before
creating our objects.

.glusterfs-ep.yaml
====
[source,yaml]
----
  apiVersion: v1
  kind: Endpoints
  metadata:
    name: glusterfs-cluster
  subsets:
    - addresses:
        - ip: 192.168.122.221
      ports:
        - port: 1
    - addresses:
        - ip: 192.168.122.222
      ports:
        - port: 1
----
====

[[binding-pv-by-label-deploy-pv-pvc-and-endpoints]]
=== Deploy the PV, PVC, and Endpoints

For this example, run the `oc` commands as a *cluster-admin*
privileged user. In a production environment, cluster clients might be expected
 to define and create the PVC.

----
# oc create -f glusterfs-ep.yaml
endpoints "glusterfs-cluster" created
# oc create -f glusterfs-pv.yaml
persistentvolume "gluster-volume" created
# oc create -f glusterfs-pvc.yaml
persistentvolumeclaim "gluster-claim" created
----

Lastly, confirm that the PV and PVC bound successfully.

----
# oc get pv,pvc
NAME              CAPACITY   ACCESSMODES      STATUS     CLAIM                     REASON    AGE
gluster-volume    2Gi        RWX              Bound      gfs-trial/gluster-claim             7s
NAME              STATUS     VOLUME           CAPACITY   ACCESSMODES               AGE
gluster-claim     Bound      gluster-volume   2Gi        RWX                       7s
----

[NOTE]
====
PVCs are local to a project, whereas PVs are a cluster-wide, global resource.
Developers and non-administrator users may not have access to see all (or any)
of the available PVs.
====
