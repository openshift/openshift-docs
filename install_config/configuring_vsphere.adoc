[[install-config-configuring-vsphere]]
= Configuring for VMware vSphere
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:

toc::[]

== Overview

You can configure {product-title} to access
link:https://www.vmware.com/au/products/vsphere.html[VMware vSphere] VMDK
Volumes. This includes
xref:../install_config/persistent_storage/persistent_storage_vsphere.adoc#install-config-persistent-storage-persistent-storage-vsphere[using
VMware vSphere VMDK Volumes as persistent storage] for application data.

The vSphere Cloud Provider allows using vSphere managed storage within {product-title} and supports:

* Volumes
* Persistent Volumes
* Storage Classes and provisioning of volumes

[[vsphere-enabling]]
== Enabling VMware vSphere Cloud Provider

[IMPORTANT]
====
Enabling VMware vSphere requires installing the VMware Tools on each Node VM.
See
link:https://docs.vmware.com/en/VMware-vSphere/6.7/com.vmware.vsphere.html.hostclient.doc/GUID-ED3ECA21-5763-4919-8947-A819A17980FB.html[Installing VMware tools] for more information.
====

To enable VMware vSphere cloud provider for {product-title}:

. Create
link:https://docs.vmware.com/en/VMware-vSphere/6.0/com.vmware.vsphere.vcenterhost.doc/GUID-031BDB12-D3B2-4E2D-80E6-604F304B4D0C.html[a
VM folder] and move {product-title} Node VMs to this folder.

. Verify that the Node VM names complies with the regex `[a-z](([-0-9a-z]+)?[0-9a-z])?(\.[a-z0-9](([-0-9a-z]+)?[0-9a-z])?)*`.
+
[IMPORTANT]
====
VM Names can not:

* begin with numbers.
* have any capital letters.
* have any special characters except `-`.
* be shorter than three characters and longer than 63 characters.
====

. Set the `disk.EnableUUID` parameter to `TRUE` for each Node VM. This ensures that the VMDK always presents a consistent UUID to the VM, allowing the disk to be mounted properly. For every virtual machine node that will be participating in the cluster, follow the steps below using the link:https://github.com/vmware/govmomi/tree/master/govc[GOVC tool]:
+
.. Set up the GOVC environment:
+
[source,bash]
----
export GOVC_URL='vCenter IP OR FQDN'
export GOVC_USERNAME='vCenter User'
export GOVC_PASSWORD='vCenter Password'
export GOVC_INSECURE=1
----
+
.. Find the Node VM paths:
+
[source,bash]
----
govc ls /datacenter/vm/<vm-folder-name>
----
.. Set disk.EnableUUID to true for all VMs:
+
[source,bash]
----
govc vm.change -e="disk.enableUUID=1" -vm='VM Path'
----
+
[NOTE]
====
If {product-title} node VMs are created from a template VM, then
`disk.EnableUUID=1` can be set on the template VM. VMs cloned from this
template, inherit this property.
====

. Create and assign roles to the vSphere Cloud Provider user and vSphere
entities. vSphere Cloud Provider requires the following privileges to interact
with vCenter. See the
link:https://docs.vmware.com/en/VMware-vSphere/6.5/com.vmware.vsphere.security.doc/GUID-18071E9A-EED1-4968-8D51-E0B4F526FDA3.html[vSphere
Documentation Center] for steps to create a custom role, user and role
assignment.
+
[cols="4*", width="100%",options="header"]
|===
|Roles
|Privileges
|Entities
|Propagate to Children

|manage-k8s-node-vms
|Resource.AssignVMToPool
System.Anonymous
System.Read
System.View
VirtualMachine.Config.AddExistingDisk
VirtualMachine.Config.AddNewDisk
VirtualMachine.Config.AddRemoveDevice
VirtualMachine.Config.RemoveDisk
VirtualMachine.Inventory.Create
VirtualMachine.Inventory.Delete
|Cluster,
Hosts,
VM Folder
|Yes

|manage-k8s-volumes
|Datastore.AllocateSpace
Datastore.FileManagement
System.Anonymous
System.Read
System.View
|Datastore
|No

|k8s-system-read-and-spbm-profile-view
|StorageProfile.View
System.Anonymous
System.Read
System.View
|vCenter
|No

|ReadOnly
|System.Anonymous
System.Read
System.View
|Datacenter,
Datastore Cluster,
Datastore Storage Folder
|No

|===

[NOTE]
====
See the link:https://vmware.github.io/vsphere-storage-for-kubernetes/documentation/existing.html#step-4-create-roles-add-privileges-to-roles-and-assign-them-to-the-vsphere-cloud-provider-user-and-vsphere-entities[Configurations on Existing Kubernetes Cluster] article for changes or updates to required roles.
====

[NOTE]
====
After enabling the vSphere Cloud Provider, node names are set to the VM names
from the vCenter Inventory.
====

[[vsphere-configuration-file]]
== The VMware vSphere Configuration File
Configuring {product-title} for VMware vSphere requires the
*_/etc/origin/cloudprovider/vsphere.conf_* file, on each node host.

If the file does not exist, create it, and add the following:

----
[Global] <1>
        user = "myusername" <2>
        password = "mypassword" <3>
        port = "443" <4>
        insecure-flag = "1" <5>
        datacenter = "mydatacenter" <6>

[VirtualCenter "1.2.3.4"] <7>
        user = "myvCenterusername"
        password = "password"

[VirtualCenter "1.2.3.5"]
        port = "448"
        insecure-flag = "0"

[Workspace] <8>
        server = "10.10.0.2" <9>
        datacenter = "mydatacenter"
        folder = "path/to/file" <10>
        datastore = "mydatastore" <11>
        resourcepool-path = "myresourcepoolpath" <12>

[Disk]
        scsicontrollertype = pvscsi

[Network]
        public-network = "VM Network" <13>
----
<1> Any properties set in the `[Global]` section are used for all specified vcenters unless overridden by the settings in the individual `[VirtualCenter]` sections.
<2> vCenter username for the vSphere cloud provider.
<3> vCenter password for the specified user.
<4> Optional. Port number for the vCenter server. Defaults to port `443`.
<5>  Set to `1` if the vCenter uses a self-signed cert.
<6> Name of the data center on which Node VMs are deployed.
<7> Override specific `[Global]` properties for this Virtual Center. Possible setting scan be `[Port]`, `[user]`, `[insecure-flag]`, `[datacenters]`. Any settings not specified are pulled from the `[Global]` section.
<8> Set any properties used for various vSphere Cloud Provider functionality. For example, dynamic provisioning, Storage Profile Based Volume provisioning, and others.
<9> IP Address or FQDN for the vCenter server.
<10> Path to the VM directory for node VMs.
<11> Set to the name of the datastore to use for provisioning volumes using the storage classes or dynamic provisioning. If the datastore is located in a storage directory or is a member of a datastore cluster, you must specify the full path.
<12> Optional. Set to the path to the resource pool where dummy VMs for Storage Profile Based volume provisioning should be created.
<13> Set to the network port group for vSphere to access the node, which is called VM Network by default. This is the node host's ExternalIP that is registered with Kubernetes.


[NOTE]
====
Don't forget to escape special characters from the `username` and `password` fields, ex. user = "domain\\username"
====

[[vsphere-configuring-masters]]
== Configuring Masters
Edit or
xref:../install_config/master_node_configuration.adoc#creating-new-configuration-files[create]
the master configuration file on all masters
(*_/etc/origin/master/master-config.yaml_* by default) and update the contents
of the `apiServerArguments` and `controllerArguments` sections with the
following:

[source, yaml]
----
kubernetesMasterConfig:
  admissionConfig:
    pluginConfig:
      {}
  apiServerArguments:
    runtime-config:
    - apis/settings.k8s.io/v1alpha1=true
    storage-backend:
    - etcd3
    storage-media-type:
    - application/vnd.kubernetes.protobuf
    cloud-provider: <1>
    - "vsphere"
    cloud-config:
    - "/etc/origin/cloudprovider/vsphere.conf"
  controllerArguments:
    cloud-provider:
    - "vsphere"
    cloud-config:
    - "/etc/origin/cloudprovider/vsphere.conf"
----
<1> Don't remove your current `apiServerArguments` params just add the `cloud-provider` and `cloud-config` after all of them.

[IMPORTANT]
====
When triggering a containerized installation, only the *_/etc/origin_* and
*_/var/lib/origin_* directories are mounted to the master and node container.
Therefore, *_master-config.yaml_* must be in *_/etc/origin/master_* rather than
*_/etc/_*.
====

[[vsphere-configuring-nodes]]
== Configuring Nodes

. Edit the appropriate xref:../admin_guide/manage_nodes.adoc#modifying-nodes[node configuration map]
and update the contents of the `kubeletArguments` section:
+
[source,yaml]
----
kubeletArguments:
  cloud-provider:
    - "vsphere"

----
+
[NOTE]
====
`cloud-config` field and deploy `vsphere.conf` file to all the nodes is only needed for Openshift versions lower than 3.9.
====
+
[IMPORTANT]
====
When triggering a containerized installation, only the *_/etc/origin_* and
*_/var/lib/origin_* directories are mounted to the master and node container.
Therefore, *_node-config.yaml_* must be in *_/etc/origin/node_* rather than
*_/etc/_*.
====

[[vsphere-applying-configuration-changes]]
== Applying Configuration Changes
include::install_config/topics/applying_configuration_changes.adoc[]

[[vsphere-backup]]
== Backup of Persistent Volumes
{product-title} provisions new volumes as *independent persistent disks* to
freely attach and detach the volume on any node in the cluster. As a consequence,
link:https://docs.vmware.com/en/VMware-vSphere/6.7/com.vmware.vsphere.vm_admin.doc/GUID-53F65726-A23B-4CF0-A7D5-48E584B88613.html[it is not possible to back up volumes that use snapshots].

To create a backup of PVs:

. Stop the application using the PV.
. Clone the persistent disk.
. Restart the application.
. Create a backup of the cloned disk.
. Delete the cloned disk.
