[[install-config-configuring-vsphere]]
= Configuring for VMWare vSphere
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:

toc::[]

== Overview
{product-title} can be configured to access
link:https://www.vmware.com/au/products/vsphere.html[VMWare vSphere] VMDK Volumes, including
xref:../install_config/persistent_storage/persistent_storage_vsphere.adoc#install-config-persistent-storage-persistent-storage-vsphere[using VMWare vSphere VMDK Volumes as persistent storage] for application data. After VMDL Volume is configured
properly, some additional configurations is needed to be completed on the
{product-title} hosts.

The vSphere Cloud Provider allows using vSphere managed storage within {product-title}. It supports:

* Volumes,
* Persistent Volumes, and
* Storage Classes and provisioning of volumes.

[[vsphere-enabling]]
== Enabling VMWare vSphere Cloud Provider

Use the steps below to enable VMWare vSphere cloud provider for {product-title}

. link:https://docs.vmware.com/en/VMware-vSphere/6.0/com.vmware.vsphere.vcenterhost.doc/GUID-031BDB12-D3B2-4E2D-80E6-604F304B4D0C.html[Create a VM folder] and move {product-title} Node VMs to this folder.

. Verify that the Node VM names complies with the regex `[a-z](([-0-9a-z]+)?[0-9a-z])?(\.[a-z0-9](([-0-9a-z]+)?[0-9a-z])?)*`.
+
[IMPORTANT]
====
VM Names should not:

* begin with numbers.
* have any capital letters.
* have any special characters except `.` and `-`.
* be shorter than three characters and longer than 63 characters.
====

. Set the `disk.EnableUUID` parameter to `TRUE` for each Node VM. Doing this ensures that the VMDK always presents a consistent UUID to the VM, thus allowing the disk to be mounted properly. For every virtual machine node that will be participating in the cluster, follow the steps below using the link:https://github.com/vmware/govmomi/tree/master/govc[GOVC tool]:
+
.. Set up the GOVC environment:
+
[source,bash]
----
export GOVC_URL='vCenter IP OR FQDN'
export GOVC_USERNAME='vCenter User'
export GOVC_PASSWORD='vCenter Password'
export GOVC_INSECURE=1
----
+
.. Find the Node VM paths.
+
[source,bash]
----
govc ls /datacenter/vm/<vm-folder-name>
----
.. Set disk.EnableUUID to true for all VMs
+
[source,bash]
----
govc vm.change -e="disk.enableUUID=1" -vm='VM Path'
----
+
[NOTE]
====
If {product-title} node VMs are created from a template VM then `disk.EnableUUID=1` can be set on the template VM. VMs cloned from this template, inherits this property.
====

. Create and assign Roles to the vSphere Cloud Provider user and vSphere entities. vSphere Cloud Provider requires the following privileges to interact with vCenter. See link:https://docs.vmware.com/en/VMware-vSphere/6.5/com.vmware.vsphere.security.doc/GUID-18071E9A-EED1-4968-8D51-E0B4F526FDA3.html[vSphere Documentation Center] to know about steps for creating a Custom Role, User and Role Assignment.
+
[cols="4*", width="100%",options="header"]
|===
|Roles
|Privileges
|Entities
|Propagate to Children

|manage-k8s-node-vms
|Resource.AssignVMToPool
System.Anonymous
System.Read
System.View
VirtualMachine.Config.AddExistingDisk
VirtualMachine.Config.AddNewDisk
VirtualMachine.Config.AddRemoveDevice
VirtualMachine.Config.RemoveDisk
VirtualMachine.Inventory.Create
VirtualMachine.Inventory.Delete
|Cluster,
Hosts,
VM Folder
|Yes

|manage-k8s-volumes
|Datastore.AllocateSpace
Datastore.FileManagement
System.Anonymous
System.Read
System.View
|Datastore
|No

|k8s-system-read-and-spbm-profile-view
|StorageProfile.View
System.Anonymous
System.Read
System.View
|vCenter
|No

|ReadOnly
|System.Anonymous
System.Read
System.View
|Datacenter,
Datastore Cluster,
Datastore Storage Folder
|No

|===

. Create the xref:../../install_config/persistence_storage/persistence_storage_vsphere.adoc#vsphere-configuration-file[vSphere cloud config file `vsphere.conf`] and place it in the shared directory which is accessible from kubelet container, controller-manager pod, and the API server pod.

.  Add following flags to kubelet running on every node and to the controller-manager and API server pods manifest files:
+
[source,bash]
----
--cloud-provider=vsphere
--cloud-config=<Path of the vsphere.conf file>
----

. Restart Kubelet on all nodes. To do this, reload kubelet systemd unit file using `systemctl daemon-reload` and then restart kubelet service using the command `systemctl restart kubelet.service`.
+
[NOTE]
====
After enabling the vSphere Cloud Provider, Node names are set to the VM names from the vCenter Inventory.
====

[[vsphere-configuration-file]]
== The VMWare vSphere Configuration File
Configuring {product-title} for VMWare vSphere requires the *_/etc/vsphere/vsphere.conf_* file, on each node host.

If the file does not exist, create it, and add the following:

----
[Global]
        user = "username" <1>
        password = "password" <2>
        server = "10.10.0.2" <3>
        port = "443" <4>
        insecure-flag = "1" <5>
        datacenter = "datacenter-name" <6>
        datastore = "datastore-name" <7>
        working-dir = "vm-folder-path" <8>
        vm-name = "vm-name-of-master-node" <9>
        vm-uuid = "vm-uuid" <10>
[Disk]
    scsicontrollertype = pvscsi
----
<1> vCenter username for the vSphere cloud provider.
<2> vCenter password for the spcified user.
<3> IP Address or FQDN for the vCenter server.
<4> (Optional) Port number for the vCenter server. (Defaults to port `443`)
<5> Set to 1 if the vCenter uses a self-signed cert.
<6> Name of the data center on which Node VMs are deployed.
<7> Name of the datastore to use for provisioning volumes using the storage classes or dynamic provisioning. If datastore is located in storage folder or datastore is member of datastore cluster, specify the full datastore path. Verify that vSphere Cloud Provider user has Read Privilege set on the datastore cluster or storage folder to be able to find datastore.
<8> The vCenter VM folder path, in which the node VMs are located.  It can be set to an empty path(`working-dir = ""`), if Node VMs are located in the root VM folder.
<9> (Optional) VM name of the Master Node. If this parameter is specified , `vsphere.conf` file on the worker node does not need vCenter credentials.
<10> (optional) VM Instance UUID of the Node VM. It can be set to empty (`vm-uuid = ""`). If this is set to empty, this is retrieved from *_/sys/class/dmi/id/product_serial_* file on virtual machine (requires root access).

[[vsphere-configuring-masters]]
== Configuring Masters
Edit or
xref:../install_config/master_node_configuration.adoc#creating-new-configuration-files[create] the
master configuration file on all masters
(*_/etc/origin/master/master-config.yaml_* by default) and update the
contents of the `apiServerArguments` and `controllerArguments` sections:

[source, yaml]
----
kubernetesMasterConfig:
  admissionConfig:
    pluginConfig:
      {}
  apiServerArguments:
    cloud-provider:
    - "vsphere"
    cloud-config:
    - "/etc/vsphere/vsphere.conf"
  controllerArguments:
    cloud-provider:
    - "vsphere"
    cloud-config:
    - "/etc/vsphere/vsphere.conf"
----

[IMPORTANT]
====
When triggering a containerized installation, only the *_/etc/origin_* and
*_/var/lib/origin_* directories are mounted to the master and node container.
Therefore, *_master-config.yaml_* must be in *_/etc/origin/master_* rather than *_/etc/_*.
====

[[vsphere-configuring-nodes]]
== Configuring Nodes

. Edit or
xref:../install_config/master_node_configuration.adoc#creating-new-configuration-files[create]
the node configuration file on all nodes (*_/etc/origin/node/node-config.yaml_*
by default) and update the contents of the `kubeletArguments` section:
+
[source,yaml]
----
kubeletArguments:
  cloud-provider:
    - "vsphere"
  cloud-config:
    - "/etc/vsphere/vsphere.conf"

----
+
[IMPORTANT]
====
When triggering a containerized installation, only the *_/etc/origin_* and
*_/var/lib/origin_* directories are mounted to the master and node container.
Therefore, *_node-config.yaml_* must be in *_/etc/origin/node_* rather than
*_/etc/_*.
====

. Start or restart the {product-title} services on the master and all nodes.
