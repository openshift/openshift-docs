[[install-config-adding-hosts-to-cluster]]
= Adding Hosts to an Existing Cluster
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

== Overview

Depending on how your {product-title} cluster was installed, you can add new
hosts (either nodes or masters) to your installation by using the install tool
for quick installations, or by using the *_scaleup.yml_* playbook for advanced
installations.

[[adding-nodes-or-reinstalling-quick]]
== Adding Hosts Using the Quick Installer Tool

If you used the quick install tool to install your {product-title} cluster, you
can use the quick install tool to add a new node host to your existing cluster.

[NOTE]
====
Currently, you can not use the quick installer tool to add new master hosts. You
must use the
xref:../install_config/install/advanced_install.adoc#install-config-install-advanced-install[advanced
installation] method to do so.
====

If you used the installer in either
xref:../install_config/install/quick_install.adoc#running-an-interactive-installation[interactive] or
xref:../install_config/install/quick_install.adoc#running-an-unattended-installation[unattended] mode, you can re-run the
installation as long as you have an
xref:../install_config/install/quick_install.adoc#defining-an-installation-configuration-file[installation configuration
file] at *_~/.config/openshift/installer.cfg.yml_* (or specify a different
location with the `-c` option).

////
If you installed using the
xref:../install_config/install/advanced_install.adoc#install-config-install-advanced-install[advanced
installation] method and therefore do not have an installation configuration
file, you can either try
xref:../install_config/install/quick_install.adoc#defining-an-installation-configuration-file[creating your own] based on
your cluster's current configuration, or see the advanced installation method on
how to
xref:adding-nodes-advanced[run the playbook for adding new nodes directly].
////

[IMPORTANT]
====
See the
xref:../scaling_performance/cluster_limits.adoc#scaling-performance-cluster-limits[cluster
limits] section for the recommended maximum number of nodes.
====

To add nodes to your installation:

. Ensure you have the latest installer and playbooks by updating the
*atomic-openshift-utils* package:
+
----
# yum update atomic-openshift-utils
----

. Run the installer with the `scaleup` subcommand in interactive or
unattended mode:
+
----
# atomic-openshift-installer [-u] [-c </path/to/file>] scaleup
----

. The installer detects your current environment and allows you to add additional nodes:
+
----
*** Installation Summary ***

Hosts:
- 100.100.1.1
  - OpenShift master
  - OpenShift node
  - Etcd (Embedded)
  - Storage

Total OpenShift masters: 1
Total OpenShift nodes: 1


---

We have detected this previously installed OpenShift environment.

This tool will guide you through the process of adding additional
nodes to your cluster.

Are you ready to continue? [y/N]:
----
+
Choose (y) and follow the on-screen instructions to complete your desired task.

[[adding-nodes-advanced]]
== Adding Hosts Using the Advanced Install

If you installed using the advanced install, you can add new hosts to your
cluster by running the *_scaleup.yml_* playbook. This playbook queries the
master, generates and distributes new certificates for the new hosts, then runs
the configuration playbooks on the new hosts only. Before running the
*_scaleup.yml_* playbook, complete all prerequisite
xref:../install_config/install/host_preparation.adoc#install-config-install-host-preparation[host
preparation] steps.

[IMPORTANT]
====
The scaleup playbook only configures the new host. It does not update *_NO_PROXY_* in master services and it does not restart master services.
====


ifdef::openshift-enterprise[]
This process is similar to re-running the installer in the
xref:adding-nodes-or-reinstalling-quick[quick installation method to add nodes],
however you have more configuration options available when using the advanced
method and when running the playbooks directly.
endif::[]

You must have an existing inventory file (for example, *_/etc/ansible/hosts_*)
that is representative of your current cluster configuration in order to run the
*_scaleup.yml_* playbook.
ifdef::openshift-enterprise[]
If you previously used the `atomic-openshift-installer` command to run your
installation, you can check *_~/.config/openshift/hosts_* (previously located at
*_~/.config/openshift/.ansible/hosts_*) for the last inventory file that the
installer generated, and use or modify that as needed as your inventory file.
You must then specify the file location with `-i` when calling
`ansible-playbook` later.
endif::[]

[IMPORTANT]
====
See the
xref:../scaling_performance/cluster_limits.adoc#scaling-performance-cluster-limits[cluster
limits] section for recommended maximum number of nodes.
====

To add a host to an existing cluster:

. Ensure you have the latest playbooks by updating the *atomic-openshift-utils*
package:
+
----
# yum update atomic-openshift-utils
----

. Edit your *_/etc/ansible/hosts_* file and add *new_<host_type>* to the
*[OSEv3:children]* section:
+
For example, to add a new node host, add *new_nodes*:
+
----
[OSEv3:children]
masters
nodes
new_nodes
----
+
To add new master hosts, add *new_masters*.

. Create a *[new_<host_type>]* section much like an existing section,
specifying host information for any new hosts you want to add. For example,
when adding a new node:
+
----
[nodes]
master[1:3].example.com
node1.example.com openshift_node_labels="{'region': 'primary', 'zone': 'east'}"
node2.example.com openshift_node_labels="{'region': 'primary', 'zone': 'west'}"
infra-node1.example.com openshift_node_labels="{'region': 'infra', 'zone': 'default'}"
infra-node2.example.com openshift_node_labels="{'region': 'infra', 'zone': 'default'}"

[new_nodes]
node3.example.com openshift_node_labels="{'region': 'primary', 'zone': 'west'}"
----
+
See
xref:../install_config/install/advanced_install.adoc#advanced-host-variables[Configuring
Host Variables] for more options.
+
When adding new masters, hosts added to the *[new_masters]* section must also be
added to the *[new_nodes]* section. This ensures the new master host is part of
the OpenShift SDN.
+
----
[masters]
master[1:2].example.com

[new_masters]
master3.example.com

[nodes]
master[1:2].example.com
node1.example.com openshift_node_labels="{'region': 'primary', 'zone': 'east'}"
node2.example.com openshift_node_labels="{'region': 'primary', 'zone': 'west'}"
infra-node1.example.com openshift_node_labels="{'region': 'infra', 'zone': 'default'}"
infra-node2.example.com openshift_node_labels="{'region': 'infra', 'zone': 'default'}"

[new_nodes]
master3.example.com
----
+
Masters are also automatically marked as unschedulable for pod placement by the
installer.
+
[IMPORTANT]
====
If you label a master host with the `region=infra` label and have no other
dedicated infrastructure nodes, you must also explicitly mark the host as
schedulable by adding `openshift_schedulable=true` to the entry. Otherwise, the
registry and router pods cannot be placed anywhere.
====

. Run the *_scaleup.yml_* playbook. If your inventory file is located somewhere
other than the default of *_/etc/ansible/hosts_*, specify the location with the
`-i option`.
+
For additional nodes:
+
----
# ansible-playbook [-i /path/to/file] \
    /usr/share/ansible/openshift-ansible/playbooks/openshift-node/scaleup.yml
----
+
For additional masters:
+
----
# ansible-playbook [-i /path/to/file] \
    /usr/share/ansible/openshift-ansible/playbooks/openshift-master/scaleup.yml
----

. After the playbook completes successfully,
xref:../install_config/install/advanced_install.adoc#advanced-verifying-the-installation[verify the installation].

. Finally, move any hosts you had defined in the *[new_<host_type>]* section
into their appropriate section (but leave the *[new_<host_type>]* section
definition itself in place) so that subsequent runs using this inventory file
are aware of the nodes but do not handle them as new nodes. For example, when
adding new nodes:
+
----
[nodes]
master[1:3].example.com
node1.example.com openshift_node_labels="{'region': 'primary', 'zone': 'east'}"
node2.example.com openshift_node_labels="{'region': 'primary', 'zone': 'west'}"
node3.example.com openshift_node_labels="{'region': 'primary', 'zone': 'west'}"
infra-node1.example.com openshift_node_labels="{'region': 'infra', 'zone': 'default'}"
infra-node2.example.com openshift_node_labels="{'region': 'infra', 'zone': 'default'}"

[new_nodes]
----

[[adding-etcd-hosts-to-existing-cluster]]
== Adding etcd Hosts to existing Cluster
You can add new etcd hosts to your cluster by running the _etcd scaleup_
playbook. This playbook queries the master, generates and distributes new
certificates for the new hosts, and then runs the configuration playbooks on the
new hosts only. Before running the etcd  *_scaleup.yml_* playbook, complete all
prerequisite
xref:../install_config/install/host_preparation.adoc#install-config-install-host-preparation[host
preparation] steps.

To add an etcd host to an existing cluster:

. Ensure you have the latest playbooks by updating the *atomic-openshift-utils* package:
+
[source, bash]
----
$ yum update atomic-openshift-utils
----

. Edit your *_/etc/ansible/hosts_* file, add *new_<host_type>* to the
*[OSEv3:children]* group and add hosts under the *new_<host_type>* group:
+
For example, to add a new etcd, add *new_etcd*:
+
----
[OSEv3:children]
masters
nodes
etcd
new_etcd

[etcd]
etcd1.example.com
etcd2.example.com

[new_etcd]
etcd3.example.com
----

. Run the etcd *_scaleup.yml_* playbook. If your inventory file is located somewhere other than the default of *_/etc/ansible/hosts_*, specify the location with the `-i` option.
+
[source, bash]
----
$ ansible-playbook [-i /path/to/file] \
  /usr/share/ansible/openshift-ansible/playbooks/openshift-etcd/scaleup.yml
----

. After the playbook completes successfully,
xref:../install_config/install/advanced_install.adoc#advanced-verifying-the-installation[verify the installation].
