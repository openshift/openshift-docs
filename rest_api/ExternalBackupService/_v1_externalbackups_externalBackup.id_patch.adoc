// Auto-generated by scripts. Do not edit.
:_mod-docs-content-type: ASSEMBLY
:context: _v1_externalbackups_externalBackup.id_patch





[id="UpdateExternalBackup_{context}"]
= UpdateExternalBackup

:toc: macro
:toc-title:

toc::[]


`PATCH /v1/externalbackups/{externalBackup.id}`

UpdateExternalBackup modifies a given external backup, with optional stored credential reconciliation.

== Description







== Parameters

=== Path Parameters

[cols="2,3,1,1,1"]
|===
|Name| Description| Required| Default| Pattern

| externalBackup.id
|
| X
| null
|

|===

=== Body Parameter

[cols="2,3,1,1,1"]
|===
|Name| Description| Required| Default| Pattern

| body
|  <<ExternalBackupServiceUpdateExternalBackupBody_{context}, ExternalBackupServiceUpdateExternalBackupBody>>
| X
|
|

|===





== Return Type

<<StorageExternalBackup_{context}, StorageExternalBackup>>


== Content Type

* application/json

== Responses

.HTTP Response Codes
[cols="2,3,1"]
|===
| Code | Message | Datatype


| 200
| A successful response.
|  <<StorageExternalBackup_{context}, StorageExternalBackup>>


| 0
| An unexpected error response.
|  <<GooglerpcStatus_{context}, GooglerpcStatus>>

|===

== Samples









ifdef::internal-generation[]
== Implementation



endif::internal-generation[]


[id="common-object-reference_{context}"]
== Common object reference



[id="ExternalBackupServiceUpdateExternalBackupBody_{context}"]
=== _ExternalBackupServiceUpdateExternalBackupBody_





[.fields-ExternalBackupServiceUpdateExternalBackupBody]
[cols="2,1,1,2,4,1"]
|===
| Field Name| Required| Nullable | Type| Description | Format

| externalBackup
|
|
| <<NextAvailableTag10_{context}, NextAvailableTag10>>
|
|

| updatePassword
|
|
|   Boolean
| When false, use the stored credentials of an existing external backup configuration given its ID.
|

|===



[id="GooglerpcStatus_{context}"]
=== _GooglerpcStatus_





[.fields-GooglerpcStatus]
[cols="2,1,1,2,4,1"]
|===
| Field Name| Required| Nullable | Type| Description | Format

| code
|
|
|   Integer
|
| int32

| message
|
|
|   String
|
|

| details
|
|
|   List   of <<ProtobufAny_{context}, ProtobufAny>>
|
|

|===



[id="NextAvailableTag10_{context}"]
=== _NextAvailableTag10_
 Next available tag: 10




[.fields-NextAvailableTag10]
[cols="2,1,1,2,4,1"]
|===
| Field Name| Required| Nullable | Type| Description | Format

| name
|
|
|   String
|
|

| type
|
|
|   String
|
|

| schedule
|
|
| <<StorageSchedule_{context}, StorageSchedule>>
|
|

| backupsToKeep
|
|
|   Integer
|
| int32

| s3
|
|
| <<StorageS3Config_{context}, StorageS3Config>>
|
|

| gcs
|
|
| <<StorageGCSConfig_{context}, StorageGCSConfig>>
|
|

| s3compatible
|
|
| <<StorageS3Compatible_{context}, StorageS3Compatible>>
|
|

| includeCertificates
|
|
|   Boolean
|
|

|===



[id="ProtobufAny_{context}"]
=== _ProtobufAny_


`Any` contains an arbitrary serialized protocol buffer message along with a
URL that describes the type of the serialized message.

Protobuf library provides support to pack/unpack Any values in the form
of utility functions or additional generated methods of the Any type.

Example 1: Pack and unpack a message in C++.

    Foo foo = ...;
    Any any;
    any.PackFrom(foo);
    ...
    if (any.UnpackTo(&foo)) {
      ...
    }

Example 2: Pack and unpack a message in Java.

    Foo foo = ...;
    Any any = Any.pack(foo);
    ...
    if (any.is(Foo.class)) {
      foo = any.unpack(Foo.class);
    }
    // or ...
    if (any.isSameTypeAs(Foo.getDefaultInstance())) {
      foo = any.unpack(Foo.getDefaultInstance());
    }

 Example 3: Pack and unpack a message in Python.

    foo = Foo(...)
    any = Any()
    any.Pack(foo)
    ...
    if any.Is(Foo.DESCRIPTOR):
      any.Unpack(foo)
      ...

 Example 4: Pack and unpack a message in Go

     foo := &pb.Foo{...}
     any, err := anypb.New(foo)
     if err != nil {
       ...
     }
     ...
     foo := &pb.Foo{}
     if err := any.UnmarshalTo(foo); err != nil {
       ...
     }

The pack methods provided by protobuf library will by default use
'type.googleapis.com/full.type.name' as the type URL and the unpack
methods only use the fully qualified type name after the last '/'
in the type URL, for example "foo.bar.com/x/y.z" will yield type
name "y.z".

==== JSON representation
The JSON representation of an `Any` value uses the regular
representation of the deserialized, embedded message, with an
additional field `@type` which contains the type URL. Example:

    package google.profile;
    message Person {
      string first_name = 1;
      string last_name = 2;
    }

    {
      "@type": "type.googleapis.com/google.profile.Person",
      "firstName": <string>,
      "lastName": <string>
    }

If the embedded message type is well-known and has a custom JSON
representation, that representation will be embedded adding a field
`value` which holds the custom JSON in addition to the `@type`
field. Example (for message [google.protobuf.Duration][]):

    {
      "@type": "type.googleapis.com/google.protobuf.Duration",
      "value": "1.212s"
    }


[.fields-ProtobufAny]
[cols="2,1,1,2,4,1"]
|===
| Field Name| Required| Nullable | Type| Description | Format

| @type
|
|
|   String
| A URL/resource name that uniquely identifies the type of the serialized protocol buffer message. This string must contain at least one \"/\" character. The last segment of the URL's path must represent the fully qualified name of the type (as in `path/google.protobuf.Duration`). The name should be in a canonical form (e.g., leading \".\" is not accepted).  In practice, teams usually precompile into the binary all types that they expect it to use in the context of Any. However, for URLs which use the scheme `http`, `https`, or no scheme, one can optionally set up a type server that maps type URLs to message definitions as follows:  * If no scheme is provided, `https` is assumed. * An HTTP GET on the URL must yield a [google.protobuf.Type][]   value in binary format, or produce an error. * Applications are allowed to cache lookup results based on the   URL, or have them precompiled into a binary to avoid any   lookup. Therefore, binary compatibility needs to be preserved   on changes to types. (Use versioned type names to manage   breaking changes.)  Note: this functionality is not currently available in the official protobuf release, and it is not used for type URLs beginning with type.googleapis.com. As of May 2023, there are no widely used type server implementations and no plans to implement one.  Schemes other than `http`, `https` (or the empty scheme) might be used with implementation specific semantics.
|

|===



[id="ScheduleDaysOfMonth_{context}"]
=== _ScheduleDaysOfMonth_
 1 for 1st, 2 for 2nd .... 31 for 31st




[.fields-ScheduleDaysOfMonth]
[cols="2,1,1,2,4,1"]
|===
| Field Name| Required| Nullable | Type| Description | Format

| days
|
|
|   List   of `integer`
|
| int32

|===



[id="ScheduleDaysOfWeek_{context}"]
=== _ScheduleDaysOfWeek_
 Sunday = 0, Monday = 1, .... Saturday =  6




[.fields-ScheduleDaysOfWeek]
[cols="2,1,1,2,4,1"]
|===
| Field Name| Required| Nullable | Type| Description | Format

| days
|
|
|   List   of `integer`
|
| int32

|===



[id="ScheduleIntervalType_{context}"]
=== _ScheduleIntervalType_







[.fields-ScheduleIntervalType]
[cols="1"]
|===
| Enum Values

| UNSET
| DAILY
| WEEKLY
| MONTHLY

|===


[id="ScheduleWeeklyInterval_{context}"]
=== _ScheduleWeeklyInterval_





[.fields-ScheduleWeeklyInterval]
[cols="2,1,1,2,4,1"]
|===
| Field Name| Required| Nullable | Type| Description | Format

| day
|
|
|   Integer
|
| int32

|===



[id="StorageExternalBackup_{context}"]
=== _StorageExternalBackup_
 Next available tag: 10




[.fields-StorageExternalBackup]
[cols="2,1,1,2,4,1"]
|===
| Field Name| Required| Nullable | Type| Description | Format

| id
|
|
|   String
|
|

| name
|
|
|   String
|
|

| type
|
|
|   String
|
|

| schedule
|
|
| <<StorageSchedule_{context}, StorageSchedule>>
|
|

| backupsToKeep
|
|
|   Integer
|
| int32

| s3
|
|
| <<StorageS3Config_{context}, StorageS3Config>>
|
|

| gcs
|
|
| <<StorageGCSConfig_{context}, StorageGCSConfig>>
|
|

| s3compatible
|
|
| <<StorageS3Compatible_{context}, StorageS3Compatible>>
|
|

| includeCertificates
|
|
|   Boolean
|
|

|===



[id="StorageGCSConfig_{context}"]
=== _StorageGCSConfig_





[.fields-StorageGCSConfig]
[cols="2,1,1,2,4,1"]
|===
| Field Name| Required| Nullable | Type| Description | Format

| bucket
|
|
|   String
|
|

| serviceAccount
|
|
|   String
| The service account for the storage integration. The server will mask the value of this credential in responses and logs.
|

| objectPrefix
|
|
|   String
|
|

| useWorkloadId
|
|
|   Boolean
|
|

|===



[id="StorageS3Compatible_{context}"]
=== _StorageS3Compatible_


S3Compatible configures the backup integration with an S3 compatible storage provider.
S3 compatible is intended for non-AWS providers. For AWS S3 use S3Config.


[.fields-StorageS3Compatible]
[cols="2,1,1,2,4,1"]
|===
| Field Name| Required| Nullable | Type| Description | Format

| bucket
|
|
|   String
|
|

| accessKeyId
|
|
|   String
| The access key ID to use. The server will mask the value of this credential in responses and logs.
|

| secretAccessKey
|
|
|   String
| The secret access key to use. The server will mask the value of this credential in responses and logs.
|

| region
|
|
|   String
|
|

| objectPrefix
|
|
|   String
|
|

| endpoint
|
|
|   String
|
|

| urlStyle
|
|
|  <<StorageS3URLStyle_{context}, StorageS3URLStyle>>
|
|    S3_URL_STYLE_UNSPECIFIED, S3_URL_STYLE_VIRTUAL_HOSTED, S3_URL_STYLE_PATH,

|===



[id="StorageS3Config_{context}"]
=== _StorageS3Config_


S3Config configures the backup integration with AWS S3.


[.fields-StorageS3Config]
[cols="2,1,1,2,4,1"]
|===
| Field Name| Required| Nullable | Type| Description | Format

| bucket
|
|
|   String
|
|

| useIam
|
|
|   Boolean
|
|

| accessKeyId
|
|
|   String
| The access key ID for the storage integration. The server will mask the value of this credential in responses and logs.
|

| secretAccessKey
|
|
|   String
| The secret access key for the storage integration. The server will mask the value of this credential in responses and logs.
|

| region
|
|
|   String
|
|

| objectPrefix
|
|
|   String
|
|

| endpoint
|
|
|   String
|
|

|===



[id="StorageS3URLStyle_{context}"]
=== _StorageS3URLStyle_







[.fields-StorageS3URLStyle]
[cols="1"]
|===
| Enum Values

| S3_URL_STYLE_UNSPECIFIED
| S3_URL_STYLE_VIRTUAL_HOSTED
| S3_URL_STYLE_PATH

|===


[id="StorageSchedule_{context}"]
=== _StorageSchedule_





[.fields-StorageSchedule]
[cols="2,1,1,2,4,1"]
|===
| Field Name| Required| Nullable | Type| Description | Format

| intervalType
|
|
|  <<ScheduleIntervalType_{context}, ScheduleIntervalType>>
|
|    UNSET, DAILY, WEEKLY, MONTHLY,

| hour
|
|
|   Integer
|
| int32

| minute
|
|
|   Integer
|
| int32

| weekly
|
|
| <<ScheduleWeeklyInterval_{context}, ScheduleWeeklyInterval>>
|
|

| daysOfWeek
|
|
| <<ScheduleDaysOfWeek_{context}, ScheduleDaysOfWeek>>
|
|

| daysOfMonth
|
|
| <<ScheduleDaysOfMonth_{context}, ScheduleDaysOfMonth>>
|
|

|===



