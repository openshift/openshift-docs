// Module included in the following assemblies:
//
// * virt/virtual_machines/importing_vms/virt-importing-virtual-machine-images-datavolumes.adoc

[id="virt-importing-vm-datavolume_{context}"]
= Importing a virtual machine image into a persistent volume claim by using a data volume

You can import a virtual machine image into a persistent volume claim (PVC) by using a data volume.

The virtual machine image can be hosted at an HTTP or HTTPS endpoint, or the image can be built into a container disk and stored in a container registry.

To create a virtual machine from an imported virtual machine image, specify the image or container disk endpoint in the `VirtualMachine` configuration file before you create the virtual machine.

.Prerequisites

* You have installed the OpenShift CLI (`oc`).
* Your cluster has at least one available persistent volume.
* To import a virtual machine image you must have the following:
** A virtual machine disk image in RAW, ISO, or QCOW2 format, optionally
compressed by using `xz` or `gz`.
** An HTTP endpoint where the image is hosted, along with any authentication
credentials needed to access the data source. For example: `http://www.example.com/path/to/data`
* To import a container disk you must have the following:
** A container disk built from a virtual machine image stored in your container image registry, along with any authentication credentials needed to access the data source. For example: `docker://registry.example.com/container-image`

.Procedure

. Optional: If your data source requires authentication credentials, edit the
`endpoint-secret.yaml` file, and apply the updated configuration to the cluster:
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: <endpoint-secret>
  labels:
    app: containerized-data-importer
type: Opaque
data:
  accessKeyId: "" <1>
  secretKey:   "" <2>
----
<1> Optional: your key or user name, base64 encoded
<2> Optional: your secret or password, base64 encoded
+
[source,terminal]
----
$ oc apply -f endpoint-secret.yaml
----

. Edit the virtual machine configuration file, specifying the data source for
the virtual machine image you want to import. In this example, a Fedora image is imported from an `http` source:
+
[source,yaml]
----
apiVersion: kubevirt.io/v1
kind: VirtualMachine
metadata:
  creationTimestamp: null
  labels:
    kubevirt.io/vm: vm-fedora-datavolume
  name: vm-fedora-datavolume
spec:
  dataVolumeTemplates:
  - metadata:
      creationTimestamp: null
      name: fedora-dv
    spec:
      pvc:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 10Gi
        storageClassName: local
      source:
        http: <1>
          url: "https://download.fedoraproject.org/pub/fedora/linux/releases/33/Cloud/x86_64/images/Fedora-Cloud-Base-33-1.2.x86_64.qcow2" <2>
          secretRef: "" <3>
          certConfigMap: "" <4>
    status: {}
  running: true
  template:
    metadata:
      creationTimestamp: null
      labels:
        kubevirt.io/vm: vm-fedora-datavolume
    spec:
      domain:
        devices:
          disks:
          - disk:
              bus: virtio
            name: datavolumedisk1
        machine:
          type: "" <5>
        resources:
          requests:
            memory: 1.5Gi
      terminationGracePeriodSeconds: 180
      volumes:
      - dataVolume:
          name: fedora-dv
        name: datavolumedisk1
status: {}
----
<1> The source type to import the image from. This example uses an HTTP endpoint. To import a container disk from a registry, replace `http` with `registry`.
<2> The source of the virtual machine image you want to import. This example references a virtual machine image at an HTTP endpoint. An example of a container registry endpoint is `url: "docker://kubevirt/fedora-cloud-container-disk-demo:latest"`.
<3> The `secretRef` parameter is optional.
<4> The `certConfigMap` is required for communicating with servers that use self-signed certificates or certificates not signed by the system CA bundle. The referenced config map must be in the same namespace as the data volume.
<5> Specify `type: dataVolume` or `type: ""`. If you specify any other value for `type`, such as `persistentVolumeClaim`, a warning is displayed, and the virtual machine does not start.

. Create the virtual machine:
+
[source,terminal]
----
$ oc create -f vm-<name>-datavolume.yaml
----
+
[NOTE]
====
The `oc create` command creates the data volume and the virtual machine. The CDI controller creates an underlying PVC with the correct annotation, and the import process begins. When the import completes, the data volume status changes to `Succeeded`, and the virtual machine is allowed to start.

Data volume provisioning happens in the background, so there is no need to monitor it. You can start the virtual machine, and it will not run until the import is complete.
====

.Verification
. The importer pod downloads the virtual machine image or container disk from the specified URL and stores it on the provisioned PV. View the status of the importer pod by running the following command:
+
[source,terminal]
----
$ oc get pods
----

. Monitor the data volume status until it shows `Succeeded` by running the following command:
+
[source,terminal]
----
$ oc describe dv <datavolume-name> <1>
----
<1> The name of the data volume as specified under `dataVolumeTemplates.metadata.name` in the virtual machine
configuration file. In the example configuration above, this is `fedora-dv`.

. To verify that provisioning is complete and that the VMI has started, try accessing its serial console by running the following command:
+
[source,terminal]
----
$ virtctl console <vm-fedora-datavolume>
----
