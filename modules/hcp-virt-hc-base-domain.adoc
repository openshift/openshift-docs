// Module included in the following assemblies:
//
// * hosted_control_planes/hcp-deploy-virt.adoc

:_mod-docs-content-type: PROCEDURE
[id="hcp-virt-hc-base-domain_{context}"]
= Deploying a hosted cluster that specifies the base domain

To create a hosted cluster that specifies a base domain, complete the following steps.

.Procedure

. Enter the following command:
+
[source,terminal]
----
$ hcp create cluster kubevirt \
  --name <hosted_cluster_name> \ <1>
  --node-pool-replicas <worker_count> \ <2>
  --pull-secret <path_to_pull_secret> \ <3>
  --memory <value_for_memory> \ <4>
  --cores <value_for_cpu> \ <5>
  --base-domain <basedomain> <6>
----
+
<1> Specify the name of your hosted cluster.
<2> Specify the worker count, for example, `2`.
<3> Specify the path to your pull secret, for example, `/user/name/pullsecret`.
<4> Specify a value for memory, for example, `6Gi`.
<5> Specify a value for CPU, for example, `2`.
<6> Specify the base domain, for example, `hypershift.lab`.
+
As a result, the hosted cluster has an ingress wildcard that is configured for the cluster name and the base domain, for example, `.apps.example.hypershift.lab`. The hosted cluster remains in `Partial` status because after you create a hosted cluster with unique base domain, you must configure the required DNS records and load balancer.

. View the status of your hosted cluster by entering the following command:
+
[source,terminal]
----
$ oc get --namespace clusters hostedclusters
----
+
.Example output
[source,terminal]
----
NAME            VERSION   KUBECONFIG                       PROGRESS   AVAILABLE   PROGRESSING   MESSAGE
example                   example-admin-kubeconfig         Partial    True        False         The hosted control plane is available
----

. Access the cluster by entering the following commands:
+
[source,terminal]
----
$ hcp create kubeconfig --name <hosted_cluster_name> > <hosted_cluster_name>-kubeconfig
----
+
[source,terminal]
----
$ oc --kubeconfig <hosted_cluster_name>-kubeconfig get co
----
+
.Example output
[source,terminal]
----
NAME                                       VERSION   AVAILABLE   PROGRESSING   DEGRADED   SINCE   MESSAGE
console                                    4.x.0     False       False         False      30m     RouteHealthAvailable: failed to GET route (https://console-openshift-console.apps.example.hypershift.lab): Get "https://console-openshift-console.apps.example.hypershift.lab": dial tcp: lookup console-openshift-console.apps.example.hypershift.lab on 172.31.0.10:53: no such host
ingress                                    4.x.0     True        False         True       28m     The "default" ingress controller reports Degraded=True: DegradedConditions: One or more other status conditions indicate a degraded state: CanaryChecksSucceeding=False (CanaryChecksRepetitiveFailures: Canary route checks for the default ingress controller are failing)
----
+
Replace `4.x.0` with the supported {product-title} version that you want to use.

.Next steps

To fix the errors in the output, complete the steps in _Setting up the load balancer_ and _Setting up a wildcard DNS_.

[NOTE]
====
If your hosted cluster is on bare metal, you might need MetalLB to set up load balancer services. For more information, see _Optional: Configuring MetalLB_.
====