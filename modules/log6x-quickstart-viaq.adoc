// Module included in the following assemblies:
//
// * observability/logging/logging-6.0/log6x-about.adoc

:_mod-docs-content-type: PROCEDURE
[id="quick-start-viaq_{context}"]
= Quick start with ViaQ

To use the default ViaQ data model, follow these steps:  

.Prerequisites
* Cluster administrator permissions

.Procedure

. Install the {clo}, {loki-op}, and {coo-first} from OperatorHub.

. Create a `LokiStack` custom resource (CR) in the `openshift-logging` namespace:
+
[source,yaml]
----
apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: logging-loki
  namespace: openshift-logging
spec:
  managementState: Managed
  size: 1x.extra-small
  storage:
    schemas:
    - effectiveDate: '2024-10-01'
      version: v13
    secret:
      name: logging-loki-s3
      type: s3
  storageClassName: gp3-csi
  tenants:
    mode: openshift-logging
----
+
[NOTE]
====
Ensure that the `logging-loki-s3` secret is created beforehand. The contents of this secret vary depending on the object storage in use. For more information, see Secrets and TLS Configuration.
====

. Create a service account for the collector:
+
[source,terminal]
----
$ oc create sa collector -n openshift-logging
----

. Allow the collector's service account to write data to the `LokiStack` CR:
+
[source,terminal]
----
$ oc adm policy add-cluster-role-to-user logging-collector-logs-writer -z collector
----
+
[NOTE]
====
The `ClusterRole` resource is created automatically during the Cluster Logging Operator installation and does not need to be created manually.
====

. Allow the collector's service account to collect logs:
+
[source,terminal]
----
$ oc project openshift-logging
----
+
[source,terminal]
----
$ oc adm policy add-cluster-role-to-user collect-application-logs -z collector
----
+
[source,terminal]
----
$ oc adm policy add-cluster-role-to-user collect-audit-logs -z collector
----
+
[source,terminal]
----
$ oc adm policy add-cluster-role-to-user collect-infrastructure-logs -z collector
----
+
[NOTE]
====
The example binds the collector to all three roles (application, infrastructure, and audit), but by default, only application and infrastructure logs are collected. To collect audit logs, update your `ClusterLogForwarder` configuration to include them. Assign roles based on the specific log types required for your environment.
====

. Create a `UIPlugin` CR to enable the *Log* section in the *Observe* tab:
+
[source,yaml]
----
apiVersion: observability.openshift.io/v1alpha1
kind: UIPlugin
metadata:
  name: logging
spec:
  type: Logging
  logging:
    lokiStack:
      name: logging-loki
----

. Create a `ClusterLogForwarder` CR to configure log forwarding:
+
[source,yaml]
----
apiVersion: observability.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: collector
  namespace: openshift-logging
spec:
  serviceAccount:
    name: collector
  outputs:
  - name: default-lokistack
    type: lokiStack
    lokiStack:
      authentication:
        token:
          from: serviceAccount
      target:
        name: logging-loki
        namespace: openshift-logging
    tls:
      ca:
        key: service-ca.crt
        configMapName: openshift-service-ca.crt
  pipelines:
  - name: default-logstore
    inputRefs:
    - application
    - infrastructure
    outputRefs:
    - default-lokistack
----
+
[NOTE]
====
The `dataModel` field is optional and left unset (`dataModel: ""`) by default. This allows the Cluster Logging Operator (CLO) to automatically select a data model. Currently, the CLO defaults to the ViaQ model when the field is unset, but this will change in future releases. Specifying `dataModel: ViaQ` ensures the configuration remains compatible if the default changes.
====

.Verification
* Verify that logs are visible in the *Log* section of the *Observe* tab in the OpenShift web console.