// Module included in the following assemblies:
//
// * hardware_accelerators/rdma-remote-direct-memory-access.adoc

:_mod-docs-content-type: PROCEDURE
[id="rdma-configuring-the-nmstate-operator_{context}"]

= Configuring the NMState Operator

You need to configure network interfaces on the nodes that were not configured at initial cluster creation time. The NMState operator is designed for those use cases. 

.Prerequisites

* You have installed the NMState Operator.

.Procedure

. Validate that the Operator is installed and running by looking at the pods in the `openshift-nmstate` namespace:
+
[source,terminal]
----
$ oc get pods -n openshift-nmstate
----
+
.Example output
[source,terminal]
----
NAME                               READY   STATUS    RESTARTS   AGE
nmstate-operator-d587966c9-qkl5m   1/1     Running   0          43s
----

. Create a custom resource file for the required nmstate instance:
+
[source,yaml]
----
apiVersion: nmstate.io/v1
kind: NMState
metadata:
  name: nmstate
----

. Create the instance on the cluster:
+
[source,terminal]
----
$ oc create -f nmstate-instance.yaml 
----
+
.Example output
[source,terminal]
----
nmstate.nmstate.io/nmstate created
----

. Validate the instance is running:
+
[source,terminal]
----
$ oc get pods -n openshift-nmstate
----
+
.Example output
[source,terminal]
----
NAME                                      READY   STATUS    RESTARTS   AGE
nmstate-cert-manager-6dc78dc6bf-ds7kj     1/1     Running   0          17s
nmstate-console-plugin-5b7595c56c-tgzbw   1/1     Running   0          17s
nmstate-handler-lxkd5                     1/1     Running   0          17s
nmstate-operator-d587966c9-qkl5m          1/1     Running   0          3m27s
nmstate-webhook-54dbd47d9d-cvsf6          0/1     Running   0          17s
----

. Build a `NodeNetworkConfigurationPolicy`. The example below configures a static ipaddress on the `ens8f0np0` interface on `vd-srv-32`.
+
[source,yaml]
----
apiVersion: nmstate.io/v1
kind: NodeNetworkConfigurationPolicy
metadata:
  name: ens8f0np0-policy 
spec:
  nodeSelector: 
    kubernetes.io/hostname: nvd-srv-32.nvidia.eng.rdu2.dc.redhat.com
  desiredState:
    interfaces:
    - name: ens8f0np0 
      description: Configuring ens8f0np0 on nvd-srv-32.nvidia.eng.rdu2.dc.redhat.com
      type: ethernet 
      state: up 
      ipv4:
        dhcp: false 
        address:
        - ip: 10.6.145.32
          prefix-length: 24
        enabled: true
----

. Create the custom resource file on the cluster:
+
[source,terminal]
----
$ oc create -f nncp-static-ip.yaml 
----
+
.Example output
[source,terminal]
----
nodenetworkconfigurationpolicy.nmstate.io/ens8f0np0-policy created
----

. Validate the policy is successfully configured:
+
[source,terminal]
----
$ oc get nncp -A
----
+
.Example output
[source,terminal]
----
NAME               STATUS      REASON
ens8f0np0-policy   Available   SuccessfullyConfigured
----

. Validate the ipaddress is set by viewing inside the node at the interface:
+
[source,terminal]
----
$ oc debug node/nvd-srv-32.nvidia.eng.rdu2.dc.redhat.com
Starting pod/nvd-srv-32nvidiaengrdu2dcredhatcom-debug-8mx6q ...
To use host binaries, run `chroot /host`
Pod IP: 10.6.135.11
If you don't see a command prompt, try pressing enter.
sh-5.1# chroot /host

sh-5.1# ip address show dev ens8f0np0
96: ens8f0np0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 58:a2:e1:e1:42:78 brd ff:ff:ff:ff:ff:ff
    altname enp160s0f0np0
    inet 10.6.145.32/24 brd 10.6.145.255 scope global noprefixroute ens8f0np0
       valid_lft forever preferred_lft forever
    inet6 fe80::c397:5afa:d618:e752/64 scope link noprefixroute 
       valid_lft forever preferred_lft forever
----
