// Module included in the following assemblies:
//
// * post_installation_configuration/aws-compute-edge-tasks.adoc

:_mod-docs-content-type: PROCEDURE
[id="installation-extend-edge-nodes-aws-local-zones_{context}"]
= Creating user workloads in {aws-service-name-full}
After you create an Amazon Web Service (AWS) {aws-service-name-single} environment, and you deploy your cluster, you can use edge worker nodes to create user workloads in {aws-service-name-single} subnets.

After you run the installation program and create the cluster, the installation program automatically specifies a taint effect of `NoSchedule` to each edge worker node. This means that a scheduler does not add a new pod, or deployment, to a node if the pod does not match the specified tolerations for a taint. You can modify the taint for better control over how nodes create workloads in each {aws-service-name-single} subnet.

The installation program creates the compute machine set manifests file with `node-role.kubernetes.io/edge` and `node-role.kubernetes.io/worker` labels applied to each edge worker node that is located in a {aws-service-name-single} subnet.

.Prerequisites

* You have access to the OpenShift CLI (`oc`).
* You deployed your cluster in a Virtual Private Cloud (VPC) with defined {aws-service-name-single} subnets.
* You ensured that the compute machine set for the edge workers on {aws-service-name-single} subnets specifies the taints for `node-role.kubernetes.io/edge`.

.Procedure

. Create a `deployment` resource YAML file for an example application to be deployed in the edge worker node
  that operates in a {aws-service-name-single} subnet. Ensure that you specify the correct tolerations that
  match the taints for the edge worker node.
+
.Example of a configured `deployment` resource for an edge worker node that operates in a {aws-service-name-single} subnet
[source,yaml]
----
kind: Namespace
apiVersion: v1
metadata:
  name: <edge_zone_application_namespace>
---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: <pvc_name>
  namespace: <edge_zone_application_namespace>
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: gp2-csi <1>
  volumeMode: Filesystem
---
apiVersion: apps/v1
kind: Deployment <2>
metadata:
  name: <edge_zone_application> <3>
  namespace: <edge_zone_application_namespace> <4>
spec:
  selector:
    matchLabels:
      app: <edge_zone_application>
  replicas: 1
  template:
    metadata:
      labels:
        app: <edge_zone_application>
        zone-group: ${ZONE_GROUP_NAME} <5>
    spec:
      securityContext:
        seccompProfile:
          type: RuntimeDefault
      nodeSelector: <6>
        machine.openshift.io/zone-group: ${ZONE_GROUP_NAME}
      tolerations: <7>
      - key: "node-role.kubernetes.io/edge"
        operator: "Equal"
        value: ""
        effect: "NoSchedule"
      containers:
        - image: openshift/origin-node
          command:
           - "/bin/socat"
          args:
            - TCP4-LISTEN:8080,reuseaddr,fork
            - EXEC:'/bin/bash -c \"printf \\\"HTTP/1.0 200 OK\r\n\r\n\\\"; sed -e \\\"/^\r/q\\\"\"'
          imagePullPolicy: Always
          name: echoserver
          ports:
            - containerPort: 8080
          volumeMounts:
            - mountPath: "/mnt/storage"
              name: data
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: <pvc_name>
----
<1> `storageClassName`: For the {aws-service-name-single} configuration, you must specify `gp2-csi`.
<2> `kind`: Defines the `deployment` resource.
<3> `name`: Specifies the name of your application. For example, `edge-zone-demo-app-nyc-1`.
<4> `namespace:` Defines the namespace for the application where you want to run the user workload. For example: `edge-zone-app-nyc-1a`.
<5> `zone-group`: Defines the group to where a zone belongs. For example, `us-east-1-iah-1`.
<6> `nodeSelector`: Targets edge worker nodes that match the specified labels.
<7> `tolerations`: Sets the values that match with the `taints` defined on the `MachineSet` manifest for the {aws-service-name-single} node.

. Create a `service` resource YAML file for the node. This resource exposes a pod from a targeted edge worker node to services that run inside the {aws-service-name-single} network.
+
.Example of a configured `service` resource for an edge worker node that operates in a {aws-service-name-single} subnet
[source,yaml]
----
apiVersion: v1
kind: Service <1>
metadata:
  name:  <edge_zone_application>
  namespace: <edge_zone_application_namespace>
spec:
  ports:
    - port: 80
      targetPort: 8080
      protocol: TCP
  type: NodePort
  selector: <2>
    app: <edge_zone_application>
----
<1> `kind`: Defines the `service` resource.
<2> `selector:` Specifies the label type applied to managed pods.
