// Module included in the following assemblies:
//
// * machine_management/creating_machinesets/creating-infrastructure-machinesets.adoc
// * machine_management/creating-machineset-azure.adoc

ifeval::["{context}" == "creating-infrastructure-machinesets"]
:infra:
endif::[]

:_mod-docs-content-type: REFERENCE
[id="machineset-yaml-azure_{context}"]
= Sample YAML for a compute machine set custom resource on Azure

This sample YAML defines a compute machine set that runs in the `1` Microsoft Azure zone in a region and creates nodes that are labeled with
ifndef::infra[`node-role.kubernetes.io/<role>: ""`.]
ifdef::infra[`node-role.kubernetes.io/infra: ""`.]

In this sample, `<infrastructure_id>` is the infrastructure ID label that is based on the cluster ID that you set when you provisioned the cluster, and
ifndef::infra[`<role>`]
ifdef::infra[`infra`]
is the node label to add.

[source,yaml]
----
apiVersion: machine.openshift.io/v1beta1
kind: MachineSet
metadata:
  labels:
    machine.openshift.io/cluster-api-cluster: <infrastructure_id> # <1>
ifndef::infra[]
    machine.openshift.io/cluster-api-machine-role: <role> # <2>
    machine.openshift.io/cluster-api-machine-type: <role>
  name: <infrastructure_id>-<role>-<region> # <3>
endif::infra[]
ifdef::infra[]
    machine.openshift.io/cluster-api-machine-role: infra # <2>
    machine.openshift.io/cluster-api-machine-type: infra
  name: <infrastructure_id>-infra-<region> # <3>
endif::infra[]
  namespace: openshift-machine-api
spec:
  replicas: 1
  selector:
    matchLabels:
      machine.openshift.io/cluster-api-cluster: <infrastructure_id>
ifndef::infra[]
      machine.openshift.io/cluster-api-machineset: <infrastructure_id>-<role>-<region>
endif::infra[]
ifdef::infra[]
      machine.openshift.io/cluster-api-machineset: <infrastructure_id>-infra-<region>
endif::infra[]
  template:
    metadata:
      creationTimestamp: null
      labels:
        machine.openshift.io/cluster-api-cluster: <infrastructure_id>
ifndef::infra[]
        machine.openshift.io/cluster-api-machine-role: <role>
        machine.openshift.io/cluster-api-machine-type: <role>
        machine.openshift.io/cluster-api-machineset: <infrastructure_id>-<role>-<region>
endif::infra[]
ifdef::infra[]
        machine.openshift.io/cluster-api-machine-role: infra
        machine.openshift.io/cluster-api-machine-type: infra
        machine.openshift.io/cluster-api-machineset: <infrastructure_id>-infra-<region>
endif::infra[]
    spec:
      metadata:
        creationTimestamp: null
        labels:
          machine.openshift.io/cluster-api-machineset: <machineset_name>
ifndef::infra[]
          node-role.kubernetes.io/<role>: ""
endif::infra[]
ifdef::infra[]
          node-role.kubernetes.io/infra: ""
endif::infra[]
      providerSpec:
        value:
          apiVersion: azureproviderconfig.openshift.io/v1beta1
          credentialsSecret:
            name: azure-cloud-credentials
            namespace: openshift-machine-api
          image: # <4>
            offer: ""
            publisher: ""
            resourceID: /resourceGroups/<infrastructure_id>-rg/providers/Microsoft.Compute/galleries/gallery_<infrastructure_id>/images/<infrastructure_id>-gen2/versions/latest # <5>
            sku: ""
            version: ""
          internalLoadBalancer: ""
          kind: AzureMachineProviderSpec
          location: <region> # <6>
          managedIdentity: <infrastructure_id>-identity
          metadata:
            creationTimestamp: null
          natRule: null
          networkResourceGroup: ""
          osDisk:
            diskSizeGB: 128
            managedDisk:
              storageAccountType: Premium_LRS
            osType: Linux
          publicIP: false
          publicLoadBalancer: ""
          resourceGroup: <infrastructure_id>-rg
          sshPrivateKey: ""
          sshPublicKey: ""
          tags:
            - name: <custom_tag_name> # <7>
              value: <custom_tag_value>
          subnet: <infrastructure_id>-<role>-subnet
          userDataSecret:
            name: worker-user-data
          vmSize: Standard_D4s_v3
          vnet: <infrastructure_id>-vnet
          zone: "1" # <8>
ifdef::infra[]
      taints: # <9>
      - key: node-role.kubernetes.io/infra
        effect: NoSchedule
endif::infra[]
----
<1> Specify the infrastructure ID that is based on the cluster ID that you set when you provisioned the cluster. If you have the OpenShift CLI installed, you can obtain the infrastructure ID by running the following command:
+
[source,terminal]
----
$ oc get -o jsonpath='{.status.infrastructureName}{"\n"}' infrastructure cluster
----
+
You can obtain the subnet by running the following command:
+
[source,terminal]
----
$  oc -n openshift-machine-api \
    -o jsonpath='{.spec.template.spec.providerSpec.value.subnet}{"\n"}' \
    get machineset/<infrastructure_id>-worker-centralus1
----
You can obtain the vnet by running the following command:
+
[source,terminal]
----
$  oc -n openshift-machine-api \
    -o jsonpath='{.spec.template.spec.providerSpec.value.vnet}{"\n"}' \
    get machineset/<infrastructure_id>-worker-centralus1
----
ifndef::infra[]
<2> Specify the node label to add.
<3> Specify the infrastructure ID, node label, and region.
endif::infra[]
ifdef::infra[]
<2> Specify the `infra` node label.
<3> Specify the infrastructure ID, `infra` node label, and region.
endif::infra[]
<4> Specify the image details for your compute machine set. If you want to use an Azure Marketplace image, see "Selecting an Azure Marketplace image".
<5> Specify an image that is compatible with your instance type. The Hyper-V generation V2 images created by the installation program have a `-gen2` suffix, while V1 images have the same name without the suffix.
<6> Specify the region to place machines on.
<7> Optional: Specify custom tags in your machine set. Provide the tag name in `<custom_tag_name>` field and the corresponding tag value in `<custom_tag_value>` field.
<8> Specify the zone within your region to place machines on. Be sure that your region supports the zone that you specify.
ifdef::infra[]
<9> Specify a taint to prevent user workloads from being scheduled on infra nodes.
+
[NOTE]
====
After adding the `NoSchedule` taint on the infrastructure node, existing DNS pods running on that node are marked as `misscheduled`. You must either delete or link:https://access.redhat.com/solutions/6592171[add toleration on `misscheduled` DNS pods].
====
endif::infra[]

ifeval::["{context}" == "creating-infrastructure-machinesets"]
:!infra:
endif::[]
ifeval::["{context}" == "cluster-tasks"]
:!infra:
endif::[]
