// Module included in the following assemblies:
//
// * machine_management/creating_machinesets/creating-infrastructure-machinesets.adoc
// * machine_management/creating_machinesets/creating-machineset-nutanix.adoc

ifeval::["{context}" == "creating-infrastructure-machinesets"]
:infra:
endif::[]

:_mod-docs-content-type: REFERENCE
[id="machineset-yaml-nutanix_{context}"]
= Sample YAML for a compute machine set custom resource on Nutanix

This sample YAML defines a Nutanix compute machine set that creates nodes that are labeled with
ifndef::infra[`node-role.kubernetes.io/<role>: ""`.]
ifdef::infra[`node-role.kubernetes.io/infra: ""`.]

In this sample, `<infrastructure_id>` is the infrastructure ID label that is based on the cluster ID that you set when you provisioned the cluster, and
ifndef::infra[`<role>`]
ifdef::infra[`<infra>`]
is the node label to add.

[discrete]
[id="machineset-yaml-nutanix-oc_{context}"]
== Values obtained by using the OpenShift CLI

In the following example, you can obtain some of the values for your cluster by using the OpenShift CLI (`oc`).

Infrastructure ID:: The `<infrastructure_id>` string is the infrastructure ID that is based on the cluster ID that you set when you provisioned the cluster. If you have the OpenShift CLI installed, you can obtain the infrastructure ID by running the following command:
+
[source,terminal]
----
$ oc get -o jsonpath='{.status.infrastructureName}{"\n"}' infrastructure cluster
----

[source,yaml]
----
apiVersion: machine.openshift.io/v1beta1
kind: MachineSet
metadata:
  labels:
    machine.openshift.io/cluster-api-cluster: <infrastructure_id> <1>
ifndef::infra[]
    machine.openshift.io/cluster-api-machine-role: <role> <2>
    machine.openshift.io/cluster-api-machine-type: <role>
  name: <infrastructure_id>-<role>-<zone> <3>
endif::infra[]
ifdef::infra[]
    machine.openshift.io/cluster-api-machine-role: <infra> <2>
    machine.openshift.io/cluster-api-machine-type: <infra>
  name: <infrastructure_id>-<infra>-<zone> <3>
endif::infra[]
  namespace: openshift-machine-api
  annotations: <4>
    machine.openshift.io/memoryMb: "16384"
    machine.openshift.io/vCPU: "4"
spec:
  replicas: 3
  selector:
    matchLabels:
      machine.openshift.io/cluster-api-cluster: <infrastructure_id>
ifndef::infra[]
      machine.openshift.io/cluster-api-machineset: <infrastructure_id>-<role>-<zone>
endif::infra[]
ifdef::infra[]
      machine.openshift.io/cluster-api-machineset: <infrastructure_id>-<infra>-<zone>
endif::infra[]
  template:
    metadata:
      labels:
        machine.openshift.io/cluster-api-cluster: <infrastructure_id>
ifndef::infra[]
        machine.openshift.io/cluster-api-machine-role: <role>
        machine.openshift.io/cluster-api-machine-type: <role>
        machine.openshift.io/cluster-api-machineset: <infrastructure_id>-<role>-<zone>
endif::infra[]
ifdef::infra[]
        machine.openshift.io/cluster-api-machine-role: <infra>
        machine.openshift.io/cluster-api-machine-type: <infra>
        machine.openshift.io/cluster-api-machineset: <infrastructure_id>-<infra>-<zone>
endif::infra[]
    spec:
      metadata:
        labels:
ifndef::infra[]
          node-role.kubernetes.io/<role>: ""
endif::infra[]
ifdef::infra[]
          node-role.kubernetes.io/infra: ""
endif::infra[]
      providerSpec:
        value:
          apiVersion: machine.openshift.io/v1
          bootType: "" <5>
          categories: <6>
          - key: <category_name>
            value: <category_value>
          cluster: <7>
            type: uuid
            uuid: <cluster_uuid>
          credentialsSecret:
            name: nutanix-credentials
          image:
            name: <infrastructure_id>-rhcos <8>
            type: name
          kind: NutanixMachineProviderConfig
          memorySize: 16Gi <9>
          project: <10>
            type: name
            name: <project_name>
          subnets:
          - type: uuid
            uuid: <subnet_uuid>
          systemDiskSize: 120Gi <11>
          userDataSecret:
            name: <user_data_secret> <12>
          vcpuSockets: 4 <13>
          vcpusPerSocket: 1 <14>
ifdef::infra[]
      taints: <15>
      - key: node-role.kubernetes.io/infra
        effect: NoSchedule
endif::infra[]
----
<1>  For `<infrastructure_id>`, specify the infrastructure ID that is based on the cluster ID that you set when you provisioned the cluster.
ifndef::infra[]
<2> Specify the node label to add.
<3> Specify the infrastructure ID, node label, and zone.
endif::infra[]
ifdef::infra[]
<2> Specify the `<infra>` node label.
<3> Specify the infrastructure ID, `<infra>` node label, and zone.
endif::infra[]
<4> Annotations for the cluster autoscaler.
<5> Specifies the boot type that the compute machines use. For more information about boot types, see link:https://portal.nutanix.com/page/documents/kbs/details?targetId=kA07V000000H3K9SAK[Understanding UEFI, Secure Boot, and TPM in the Virtualized Environment]. Valid values are `Legacy`, `SecureBoot`, or `UEFI`. The default is `Legacy`.
+
[NOTE]
====
You must use the `Legacy` boot type in {product-title} {product-version}.
====
<6> Specify one or more Nutanix Prism categories to apply to compute machines. This stanza requires `key` and `value` parameters for a category key-value pair that exists in Prism Central. For more information about categories, see link:https://portal.nutanix.com/page/documents/details?targetId=Prism-Central-Guide-vpc_2022_6:ssp-ssp-categories-manage-pc-c.html[Category management].
<7> Specify a Nutanix Prism Element cluster configuration. In this example, the cluster type is `uuid`, so there is a `uuid` stanza.
<8> Specify the image to use. Use an image from an existing default compute machine set for the cluster.
<9> Specify the amount of memory for the cluster in Gi.
<10> Specify the Nutanix project that you use for your cluster. In this example, the project type is `name`, so there is a `name` stanza.
<11> Specify the size of the system disk in Gi.
<12> Specify the name of the secret in the user data YAML file that is in the `openshift-machine-api` namespace. Use the value that installation program populates in the default compute machine set.
<13> Specify the number of vCPU sockets.
<14> Specify the number of vCPUs per socket.
ifdef::infra[]
<15> Specify a taint to prevent user workloads from being scheduled on infra nodes.
+
[NOTE]
====
After adding the `NoSchedule` taint on the infrastructure node, existing DNS pods running on that node are marked as `misscheduled`. You must either delete or link:https://access.redhat.com/solutions/6592171[add toleration on `misscheduled` DNS pods].
====
endif::infra[]

ifeval::["{context}" == "creating-infrastructure-machinesets"]
:!infra:
endif::[]
ifeval::["{context}" == "cluster-tasks"]
:!infra:
endif::[]
