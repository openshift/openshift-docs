// This module is used in the following assemblies:
// configure/ols-configuring-openshift-lightspeed.adoc

:_mod-docs-content-type: PROCEDURE
[id="ols-creating-lightspeed-custom-resource-file-using-cli_{context}"]
= Creating the Lightspeed custom resource file using the CLI

The Custom Resource (CR) file contains information that the Operator uses to deploy {ols-long}. The specific content of the CR file is unique for each LLM provider. Choose the configuration file that matches your LLM provider.

.Prerequisites

* You are logged in to the {ocp-product-title} web console as a user with the `cluster-admin` role. Alternatively, you are logged in to a user account that has permission to create a cluster-scoped custom resource file.

* You have access to the {ocp-short-name} CLI (oc).

* You have installed the {ols-long} Operator.

.Pocedure

. Create an `OLSConfig` file that contains the YAML content for the LLM provider you use:
+
.Example OpenAI custom resource file
+
[source,yaml, subs="attributes,verbatim"]
----
apiVersion: ols.openshift.io/v1alpha1
kind: OLSConfig
metadata:
  name: cluster
spec:
  llm:
    providers:
      - name: myOpenai
        type: openai
        credentialsSecretRef:
          name: credentials
        url: "https://api.openai.com/v1"
        models:
          - name: gpt-3.5-turbo
  ols:
    defaultModel: gpt-3.5-turbo
    defaultProvider: myOpenai
    logLevel: DEBUG
----
+
.Example Azure OpenAI custom resource file
+
[source,yaml, subs="attributes,verbatim"]
----
apiVersion: ols.openshift.io/v1alpha1
kind: OLSConfig
metadata:
  name: cluster
spec:
  llm:
    providers:
      - credentialsSecretRef:
          name: credentials
        deploymentName: <USE THE NAME OF THE DEPLOYMENT YOU CREATED EARLIER>
        models:
          - name: gpt-35-turbo-16k
        name: myAzure
        type: azure_openai
        url: <USE THE URL YOU RECORDED EARLIER>
  ols:
    defaultModel: gpt-35-turbo-16k
    defaultProvider: myAzure
    logLevel: DEBUG
----
+
.Example WatsonX custom resource file
+
[source,yaml, subs="attributes,verbatim"]
----
apiVersion: ols.openshift.io/v1alpha1
kind: OLSConfig
metadata:
  name: cluster
spec:
  llm:
    providers:
      - name: myWatsonx
        type: watsonx
        credentialsSecretRef:
          name: credentials
        url: <APPROPRIATE URL FROM REGIONAL URLS>
        projectId: <your project ID>
        models:
          - name: ibm/granite-13b-chat-v2
  ols:
    defaultModel: ibm/granite-13b-chat-v2
    defaultProvider: myWatsonx
    logLevel: DEBUG
----

. Run the following command:
+
[source,terminal]
----
$ oc create -f /path/to/config-cr.yaml
----
+
The Operator deploys {ols-long} using the information in YAML configuration file.
