// Module included in the following assemblies:
//
// * logging/cluster-logging-elasticsearch.adoc

[id="cluster-logging-elasticsearch-exposing_{context}"]
= Exposing the log store service as a route

By default, the log store that is deployed with cluster logging is not
accessible from outside the logging cluster. You can enable a route with re-encryption termination
for external access to the log store service for those tools that access its data.

Externally, you can access the log store by creating a reencrypt route, your {product-title} token and the installed
log store CA certificate. Then, access a node that hosts the log store service with a cURL request that contains:

* The `Authorization: Bearer ${token}`
* The Elasticsearch reencrypt route and an link:https://www.elastic.co/guide/en/elasticsearch/reference/current/api-conventions.html[Elasticsearch API request].

Internally, you can access the log store service using the log store cluster IP,
which you can get by using either of the following commands:

[source,terminal]
----
$ oc get service elasticsearch -o jsonpath={.spec.clusterIP} -n openshift-logging
----

.Example output
[source,terminal]
----
172.30.183.229
----

[source,terminal]
----
$ oc get service elasticsearch -n openshift-logging
----

.Example output
[source,terminal]
----
NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
elasticsearch   ClusterIP   172.30.183.229   <none>        9200/TCP   22h
----

You can check the cluster IP address with a command similar to the following:

[source,terminal]
----
$ oc exec elasticsearch-cdm-oplnhinv-1-5746475887-fj2f8 -n openshift-logging -- curl -tlsv1.2 --insecure -H "Authorization: Bearer ${token}" "https://172.30.183.229:9200/_cat/health"
----

.Example output
[source,terminal]
----
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    29  100    29    0     0    108      0 --:--:-- --:--:-- --:--:--   108
----

.Prerequisites

* Cluster logging and Elasticsearch must be installed.

* You must have access to the project in order to be able to access to the logs.

.Procedure

To expose  the log store externally:

. Change to the `openshift-logging` project:
+
[source,terminal]
----
$ oc project openshift-logging
----

. Extract the CA certificate from the log store and write to the *_admin-ca_* file:
+
[source,terminal]
----
$ oc extract secret/elasticsearch --to=. --keys=admin-ca
----
+
.Example output
[source,terminal]
----
admin-ca
----

. Create the route for the log store service as a YAML file:
+
.. Create a YAML file with the following:
+
[source,yaml]
----
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: elasticsearch
  namespace: openshift-logging
spec:
  host:
  to:
    kind: Service
    name: elasticsearch
  tls:
    termination: reencrypt
    destinationCACertificate: | <1>
----
<1> Add the log store CA certifcate or use the command in the next step. You do not have to set the `spec.tls.key`, `spec.tls.certificate`, and `spec.tls.caCertificate` parameters required by some reencrypt routes.

.. Run the following command to add the log store CA certificate to the route YAML you created:
+
[source,terminal]
----
$ cat ./admin-ca | sed -e "s/^/      /" >> <file-name>.yaml
----

.. Create the route:
+
[source,terminal]
----
$ oc create -f <file-name>.yaml
----
+
.Example output
[source,terminal]
----
route.route.openshift.io/elasticsearch created
----
+
//For an example reencrypt route object, see Re-encryption Termination.
//+
//This line ^^ will be linked when the topic is available.

. Check that the Elasticsearch service is exposed:

.. Get the token of this ServiceAccount to be used in the request:
+
[source,terminal]
----
$ token=$(oc whoami -t)
----

.. Set the *elasticsearch* route you created as an environment variable.
+
[source,terminal]
----
$ routeES=`oc get route elasticsearch -o jsonpath={.spec.host}`
----

.. To verify the route was successfully created, run the following command that accesses Elasticsearch through the exposed route:
+
[source,terminal]
----
$ curl -tlsv1.2 --insecure -H "Authorization: Bearer ${token}" "https://${routeES}/.operations.*/_search?size=1" | jq
----
+
The response appears similar to the following:
+
.Example output
[source,terminal]
----
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   944  100   944    0     0     62      0  0:00:15  0:00:15 --:--:--   204
{
  "took": 441,
  "timed_out": false,
  "_shards": {
    "total": 3,
    "successful": 3,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 89157,
    "max_score": 1,
    "hits": [
      {
        "_index": ".operations.2019.03.15",
        "_type": "com.example.viaq.common",
        "_id": "ODdiNWIyYzAtMjg5Ni0TAtNWE3MDY1MjMzNTc3",
        "_score": 1,
        "_source": {
          "_SOURCE_MONOTONIC_TIMESTAMP": "673396",
          "systemd": {
            "t": {
              "BOOT_ID": "246c34ee9cdeecb41a608e94",
              "MACHINE_ID": "e904a0bb5efd3e36badee0c",
              "TRANSPORT": "kernel"
            },
            "u": {
              "SYSLOG_FACILITY": "0",
              "SYSLOG_IDENTIFIER": "kernel"
            }
          },
          "level": "info",
          "message": "acpiphp: Slot [30] registered",
          "hostname": "localhost.localdomain",
          "pipeline_metadata": {
            "collector": {
              "ipaddr4": "10.128.2.12",
              "ipaddr6": "fe80::xx:xxxx:fe4c:5b09",
              "inputname": "fluent-plugin-systemd",
              "name": "fluentd",
              "received_at": "2019-03-15T20:25:06.273017+00:00",
              "version": "1.3.2 1.6.0"
            }
          },
          "@timestamp": "2019-03-15T20:00:13.808226+00:00",
          "viaq_msg_id": "ODdiNWIyYzAtMYTAtNWE3MDY1MjMzNTc3"
        }
      }
    ]
  }
}
----
