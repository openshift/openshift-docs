// Module included in the following assemblies:
//
// * virt/updating/upgrading-virt.adoc

:_mod-docs-content-type: PROCEDURE
[id="virt-preventing-workload-updates-during-control-plane-only-update_{context}"]
= Preventing workload updates during a Control Plane Only update

[role="_abstract"]
When you update from one Extended Update Support (EUS) version to the next, you must manually disable automatic workload updates to prevent {VirtProductName} from migrating or evicting workloads during the update process.

[IMPORTANT]
====
In {product-title} 4.16, the underlying {op-system-first} upgraded to version 9.4 of {op-system-base-full}. To operate correctly, all `virt-launcher` pods in the cluster need to use the same version of {op-system-base}.

After upgrading to {product-title} 4.16 from an earlier version, re-enable workload updates in {VirtProductName} to allow `virt-launcher` pods to update. Before upgrading to the next {product-title} version, verify that all VMIs use up-to-date workloads:

[source,terminal]
----
$ oc get kv kubevirt-kubevirt-hyperconverged -o json -n openshift-cnv | jq .status.outdatedVirtualMachineInstanceWorkloads
----

If the previous command returns a value larger than `0`, list all VMIs with outdated `virt-launcher` pods and start live migration to update them to a new version:

[source,terminal]
----
$ oc get vmi -l kubevirt.io/outdatedLauncherImage --all-namespaces
----

For the list of supported {product-title} releases and the {op-system-base} versions they use, see link:https://access.redhat.com/articles/6907891[{op-system-base} Versions Utilized by {op-system} and {product-title}].
====

.Prerequisites

* You have installed the {oc-first}.

* You are running an EUS version of {product-title} and want to update to the next EUS version. You have not yet updated to the odd-numbered version in between.

* You read "Preparing to perform a Control Plane Only update" and learned the caveats and requirements that pertain to your {product-title} cluster.

* You paused the worker nodes' machine config pools as directed by the {product-title} documentation.

* It is recommended that you use the default *Automatic* approval strategy. If you use the *Manual* approval strategy, you must approve all pending updates in the web console. For more details, refer to the "Manually approving a pending Operator update" section.

.Procedure

. Run the following command and record the `workloadUpdateMethods` configuration:
+
[source,terminal,subs="attributes+"]
----
$ oc get kv kubevirt-kubevirt-hyperconverged \
  -n {CNVNamespace} -o jsonpath='{.spec.workloadUpdateStrategy.workloadUpdateMethods}'
----

. Turn off all workload update methods by running the following command:
+
[source,terminal,subs="attributes+"]
----
$ oc patch hyperconverged kubevirt-hyperconverged -n {CNVNamespace} \
  --type json -p '[{"op":"replace","path":"/spec/workloadUpdateStrategy/workloadUpdateMethods", "value":[]}]'
----
+
Example output:
+
[source,terminal]
----
hyperconverged.hco.kubevirt.io/kubevirt-hyperconverged patched
----

. Ensure that the `HyperConverged` Operator is `Upgradeable` before you continue. Enter the following command and monitor the output:
+
[source,terminal,subs="attributes+"]
----
$ oc get hyperconverged kubevirt-hyperconverged -n {CNVNamespace} -o json | jq ".status.conditions"
----
+
Example output:
+
[%collapsible]
[source,json]
----
[
  {
    "lastTransitionTime": "2022-12-09T16:29:11Z",
    "message": "Reconcile completed successfully",
    "observedGeneration": 3,
    "reason": "ReconcileCompleted",
    "status": "True",
    "type": "ReconcileComplete"
  },
  {
    "lastTransitionTime": "2022-12-09T20:30:10Z",
    "message": "Reconcile completed successfully",
    "observedGeneration": 3,
    "reason": "ReconcileCompleted",
    "status": "True",
    "type": "Available"
  },
  {
    "lastTransitionTime": "2022-12-09T20:30:10Z",
    "message": "Reconcile completed successfully",
    "observedGeneration": 3,
    "reason": "ReconcileCompleted",
    "status": "False",
    "type": "Progressing"
  },
  {
    "lastTransitionTime": "2022-12-09T16:39:11Z",
    "message": "Reconcile completed successfully",
    "observedGeneration": 3,
    "reason": "ReconcileCompleted",
    "status": "False",
    "type": "Degraded"
  },
  {
    "lastTransitionTime": "2022-12-09T20:30:10Z",
    "message": "Reconcile completed successfully",
    "observedGeneration": 3,
    "reason": "ReconcileCompleted",
    "status": "True",
    "type": "Upgradeable" <1>
  }
]
----
<1> The {VirtProductName} Operator has the `Upgradeable` status.

. Manually update your cluster from the source EUS version to the next minor version of {product-title}:
+
[source,terminal]
+
----
$ oc adm upgrade
----
+
Verification:

** Check the current version by running the following command:
+
[source,terminal]
----
$ oc get clusterversion
----
+
[NOTE]
====
Updating {product-title} to the next version is a prerequisite for updating {VirtProductName}. For more details, refer to the "Updating clusters" section of the {product-title} documentation.
====

. Update {VirtProductName}.
* With the default *Automatic* approval strategy, {VirtProductName} automatically updates to the corresponding version after you update {product-title}.
* If you use the *Manual* approval strategy, approve the pending updates by using the web console.

. Monitor the {VirtProductName} update by running the following command:
+
[source,terminal,subs="attributes+"]
----
$ oc get csv -n {CNVNamespace}
----

. Confirm that {VirtProductName} successfully updated to the latest z-stream release of the non-EUS version by running the following command:
+
[source,terminal,subs="attributes+"]
----
$ oc get hyperconverged kubevirt-hyperconverged -n {CNVNamespace} -o json | jq ".status.versions"
----
+
Example output:
+
[source,terminal,subs="attributes+"]
----
[
  {
    "name": "operator",
    "version": "{HCOVersion}"
  }
]
----

. Wait until the `HyperConverged` Operator has the `Upgradeable` status before you perform the next update. Enter the following command and monitor the output:
+
[source,terminal,subs="attributes+"]
----
$ oc get hyperconverged kubevirt-hyperconverged -n {CNVNamespace} -o json | jq ".status.conditions"
----

. Update {product-title} to the target EUS version.

. Confirm that the update succeeded by checking the cluster version:
+
[source,terminal]
----
$ oc get clusterversion
----

. Update {VirtProductName} to the target EUS version.
* With the default *Automatic* approval strategy, {VirtProductName} automatically updates to the corresponding version after you update {product-title}.
* If you use the *Manual* approval strategy, approve the pending updates by using the web console.

. Monitor the {VirtProductName} update by running the following command:
+
[source,terminal,subs="attributes+"]
----
$ oc get csv -n {CNVNamespace}
----
+
The update completes when the `VERSION` field matches the target EUS version and the `PHASE` field reads `Succeeded`.

. Restore the `workloadUpdateMethods` configuration that you recorded from step 1 with the following command:
+
[source,terminal,subs="attributes+"]
----
$ oc patch hyperconverged kubevirt-hyperconverged -n {CNVNamespace} --type json -p \
  "[{\"op\":\"add\",\"path\":\"/spec/workloadUpdateStrategy/workloadUpdateMethods\", \"value\":{WorkloadUpdateMethodConfig}}]"
----
+
Example output:
+
[source,terminal]
----
hyperconverged.hco.kubevirt.io/kubevirt-hyperconverged patched
----
+
Verification:

** Check the status of VM migration by running the following command:
+
[source,terminal]
----
$ oc get vmim -A
----

.Next steps

* Unpause the machine config pools for each compute node.
