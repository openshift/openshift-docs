// Module included in the following assemblies:
//
// * configuring/configuring-log-forwarding.adoc

:_mod-docs-content-type: CONCEPT
[id="cluster-logging-collector-log-forwarding-about_{context}"]
= About forwarding logs to third-party systems

To send logs to specific endpoints inside and outside your {ocp-product-title} cluster, you specify a combination of outputs and pipelines in a `ClusterLogForwarder` custom resource (CR). You can also use inputs to forward the application logs associated with a specific project to an endpoint. Authentication is provided by a Kubernetes `Secret` object.

_pipeline_:: Defines simple routing from one log type to one or more outputs, or which logs you want to send. The log types are one of the following:
+
--
* `application`. Container logs generated by user applications running in the cluster, except infrastructure container applications.

* `infrastructure`. Container logs from pods that run in the `openshift*`, `kube*`, or `default` projects and journal logs sourced from node file system.

* `audit`. Audit logs generated by the node audit system, `auditd`, Kubernetes API server, OpenShift API server, and OVN network.
--
+
You can add labels to outbound log messages by using `key:value` pairs in the pipeline. For example, you might add a label to messages that are forwarded to other data centers or label the logs by type. Labels that are added to objects are also forwarded with the log message.

_input_:: Forwards the application logs associated with a specific project to a pipeline.
+
--
In the pipeline, you define which log types to forward using an `inputRef` parameter and where to forward the logs to using an `outputRef` parameter.
--
+

_Secret_:: A `key:value map` that contains confidential data such as user credentials.

Note the following:

* If you do not define a pipeline for a log type, the logs of the undefined types are dropped. For example, if you specify a pipeline for the `application` and `audit` types, but do not specify a pipeline for the `infrastructure` type, `infrastructure` logs are dropped.

* You can use multiple types of outputs in the `ClusterLogForwarder` custom resource (CR) to send logs to servers that support different protocols.

The following example forwards the audit logs to a secure external Elasticsearch instance.

.Sample log forwarding outputs and pipelines
[source,yaml]
----
kind: ClusterLogForwarder
apiVersion: observability.openshift.io/v1
metadata:
  name: instance
  namespace: openshift-logging
spec:
  serviceAccount:
    name: logging-admin
  outputs:
    - name: external-es
      type: elasticsearch
      elasticsearch:
        url: 'https://example-elasticsearch-secure.com:9200'
        version: 8  # <1>
        index: '{.log_type||"undefined"}'  # <2>
        authentication:
          username:
            key: username
            secretName: es-secret  # <3>
          password:
            key: password
            secretName: es-secret  # <3>
      tls:
        ca:                        # <4>
          key: ca-bundle.crt
          secretName: es-secret
        certificate:
          key: tls.crt
          secretName: es-secret
        key:
          key: tls.key
          secretName: es-secret
  pipelines:
    - name: my-logs
      inputRefs:
        - application
        - infrastructure
      outputRefs:
        - external-es
----
<1> Forwarding to an external Elasticsearch of version 8.x or greater requires the `version` field to be specified.
<2> `index` is set to read the field value `.log_type` and falls back to "unknown" if not found.
<3> Use username and password to authenticate to the server
<4> Enable Mutual Transport Layer Security (mTLS) between collector and elasticsearch. The spec identifies the keys and secret to the respective certificates that they represent.

[discrete]
== Supported Authorization Keys
Common key types are provided here. Some output types support additional specialized keys, documented with the output-specific configuration field. All secret keys are optional. Enable the security features you want by setting the relevant keys. You are responsible for creating and maintaining any additional configurations that external destinations might require, such as keys and secrets, service accounts, port openings, or global proxy configuration. Open Shift Logging will not attempt to verify a mismatch between authorization combinations.

Transport Layer Security (TLS):: Using a TLS URL (`+http://...+` or `+ssl://...+`) without a secret enables basic TLS server-side authentication. Additional TLS features are enabled by including a secret and setting the following optional fields:

* `passphrase`: (string) Passphrase to decode an encoded TLS private key. Requires `tls.key`.
* `ca-bundle.crt`: (string) File name of a customer CA for server authentication.

Username and Password::
* `username`: (string) Authentication user name. Requires `password`.
* `password`: (string) Authentication password. Requires `username`.

Simple Authentication Security Layer (SASL)::
* `sasl.enable` (boolean) Explicitly enable or disable SASL.
If missing, SASL is automatically enabled when any of the other `sasl.` keys are set.
* `sasl.mechanisms`: (array) List of allowed SASL mechanism names.
If missing or empty, the system defaults are used.
* `sasl.allow-insecure`: (boolean) Allow mechanisms that send clear-text passwords. Defaults to false.

== Creating a Secret

You can create a secret in the directory that contains your certificate and key files by using the following command:

[source,terminal]
----
$ oc create secret generic -n <namespace> <secret_name> \
  --from-file=ca-bundle.crt=<your_bundle_file> \
  --from-literal=username=<your_username> \
  --from-literal=password=<your_password>
----

[NOTE]
====
Generic or opaque secrets are recommended for best results.
====
