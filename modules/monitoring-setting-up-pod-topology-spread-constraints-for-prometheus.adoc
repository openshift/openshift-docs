// Module included in the following assemblies:
//
// * monitoring/configuring-the-monitoring-stack.adoc

:_mod-docs-content-type: PROCEDURE
[id="setting-up-pod-topology-spread-constraints-for-prometheus_{context}"]
= Setting up pod topology spread constraints for Prometheus

For core {product-title} platform monitoring, you can set up pod topology spread constraints for Prometheus to fine tune how pod replicas are scheduled to nodes across zones.
Doing so helps ensure that Prometheus pods are highly available and run more efficiently, because workloads are spread across nodes in different data centers or hierarchical infrastructure zones.

You configure pod topology spread constraints for Prometheus in the `cluster-monitoring-config` config map.

.Prerequisites

* You have access to the cluster as a user with the `cluster-admin` cluster role.
* You have created the `cluster-monitoring-config` `ConfigMap` object.
* You have installed the OpenShift CLI (`oc`).

.Procedure

. Edit the `cluster-monitoring-config` `ConfigMap` object in the `openshift-monitoring` namespace:
+
[source,terminal]
----
$ oc -n openshift-monitoring edit configmap cluster-monitoring-config
----

. Add  values for the following settings under `data/config.yaml/prometheusK8s` to configure pod topology spread constraints:
+
[source,yaml]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-monitoring-config
  namespace: openshift-monitoring
data:
  config.yaml: |
    prometheusK8s:
      topologySpreadConstraints:
      - maxSkew: 1 <1>
        topologyKey: monitoring <2>
        whenUnsatisfiable: DoNotSchedule <3>
        labelSelector:
          matchLabels: <4>
            app.kubernetes.io/name: prometheus
----
<1> Specify a numeric value for `maxSkew`, which defines the degree to which pods are allowed to be unevenly distributed.
This field is required, and the value must be greater than zero.
The value specified has a different effect depending on what value you specify for `whenUnsatisfiable`.
<2> Specify a key of node labels for `topologyKey`.
This field is required.
Nodes that have a label with this key and identical values are considered to be in the same topology.
The scheduler will try to put a balanced number of pods into each domain.
<3> Specify a value for `whenUnsatisfiable`.
This field is required.
Available options are `DoNotSchedule` and `ScheduleAnyway`.
Specify `DoNotSchedule` if you want the `maxSkew` value to define the maximum difference allowed between the number of matching pods in the target topology and the global minimum.
Specify `ScheduleAnyway` if you want the scheduler to still schedule the pod but to give higher priority to nodes that might reduce the skew.
<4> Specify a value for `matchLabels`. This value is used to identify the set of matching pods to which to apply the constraints.

. Save the file to apply the changes automatically.
+
[WARNING]
====
When you save changes to the `cluster-monitoring-config` config map, the pods and other resources in the `openshift-monitoring` project might be redeployed.
The running monitoring processes in that project might also restart.
====
