// Module included in the following assemblies:
//
// * logging/cluster-logging-external.adoc

[id="cluster-logging-collector-log-forward-fluentd_{context}"]
= Forwarding logs using the Fluentd forward protocol

You can use the Fluentd *forward* protocol to send a copy of your logs to an external log aggregator configured to accept the protocol instead of, or in addition to, the default Elasticsearch log store. You are responsible for configuring the external log aggregator to receive the logs from {product-title}.

To configure log forwarding using the *forward* protocol, create a `ClusterLogForwarder` Custom Resource (CR) with one or more outputs to the Fluentd servers and pipelines that use those outputs. The Fluentd output can use a TCP (insecure) or TLS (secure TCP) connection.

[NOTE]
====
Alternately, you can use a ConfigMap to forward logs using the *forward* protocols. However, this method is deprecated in {product-title} and will be removed in a future release.  
====

.Procedure

. Create a `ClusterLogForwarder` CR YAML file similar to the following:
+
[source,yaml]
----
apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance <1>
spec:
  outputs:
   - name: fluentd-server-secure <2>
     type: fluentdForward <3>
     url: 'tls://fluentdserver.security.example.com:24224' <4>
     secret: <5>
        name: fluentd-secret
   - name: fluentd-server-inecure
     type: fluentdForward
     url: 'tcp://fluentdserver.home.example.com:24224'
  pipelines:
   - name: forward-to-fluentd-secure <6>
     inputRefs:  <7>
     - application
     - audit
     outputRefs:
     - fluentd-server-secure <8>
     - default <9>
   - name: forward-to-fluentd-insecure <10>
     inputRefs:
     - infrastructure
     outputRefs:
     - fluentd-server-insecure
----
<1> The name of the `ClusterLogForwarder` CR must be `instance`.
<2> Specify a name for the output.
<3> Specify the `fluentdForward` type.
<4> Specify the URL and port of the external Fluentd instance as a valid absolute URL. You can use the `tcp` (insecure) or `tls` (secure TCP) protocol. If the cluster-wide proxy using the CIDR annotation is enabled, the output must be a server name or FQDN, not an IP address.
<5> If using a `tls` prefix, you must specify the name of the secret required by the endpoint for TLS communication. The secret must exist in the `openshift-logging` project and must have keys of: *tls.crt*, *tls.key*, and *ca-bundle.crt* that point to the respective certificates that they represent.
<6> Optional. Specify a name for the pipeline.
<7> Specify which log types should be forwarded using that pipeline: `application,` `infrastructure`, or `audit`.
<8> Specify the output to use  with that pipeline for forwarding the logs.
<9> Optional. Specify the `default` output to forward logs to the internal Elasticsearch instance.
<10> Optional. Configure multiple outputs to forward other log types to other external log aggregators of any supported type.

. Create the CR object:
+
[source,terminal]
----
$ oc create -f <file-name>.yaml
----

The Cluster Logging Operator redeploys the Fluentd Pods. If the Pods do not redeploy, you can delete the Fluentd
Pods to force them to redeploy.

[source,terminal]
----
$ oc delete pod --selector logging-infra=fluentd
----
