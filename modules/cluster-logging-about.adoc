// Module included in the following assemblies:
//
// * virt/logging_events_monitoring/virt-openshift-cluster-monitoring.adoc
// * logging/cluster-logging.adoc
// * serverless/knative_serving/cluster-logging-serverless.adoc

// This module uses conditionalized paragraphs so that the module
// can be re-used in associated products.


[id="cluster-logging-about_{context}"]
= About deploying OpenShift Logging

ifdef::openshift-enterprise,openshift-webscale,openshift-origin[]
{product-title} cluster administrators can deploy OpenShift Logging using 
the {product-title}  web console or CLI to install the Elasticsearch
Operator and Cluster Logging Operator. When the operators are installed, you create
a `ClusterLogging` custom resource (CR) to schedule OpenShift Logging pods and
other resources necessary to support OpenShift Logging. The operators are
responsible for deploying, upgrading, and maintaining OpenShift Logging.
endif::openshift-enterprise,openshift-webscale,openshift-origin[]

ifdef::openshift-dedicated[]
{product-title} administrators can deploy the Cluster Logging Operator and the
Elasticsearch Operator by using the {product-title} web console and can configure logging in the
`openshift-logging` namespace. Configuring logging will deploy Elasticsearch,
Fluentd, and Kibana in the `openshift-logging` namespace. The operators are
responsible for deploying, upgrading, and maintaining OpenShift Logging.
endif::openshift-dedicated[]

The `ClusterLogging` CR defines a complete OpenShift Logging environment that includes all the components
of the logging stack to collect, store and visualize logs.  The Cluster Logging Operator watches the OpenShift Logging
CR and adjusts the logging deployment accordingly.

Administrators and application developers can view the logs of the projects for which they have view access.

