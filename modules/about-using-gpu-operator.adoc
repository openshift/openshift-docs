// Module included in the following assemblies:
//
// * virt/virtual_machines/advanced_vm_management/virt-configuring-virtual-gpus.adoc

:_mod-docs-content-type: PROCEDURE
[id="about-using-nvidia-gpu_{context}"]
= Using the NVIDIA GPU Operator

[role="_abstract"]
You can use the NVIDIA GPU Operator with {VirtProductName} to rapidly provision worker nodes for running GPU-enabled virtual machines (VMs). The NVIDIA GPU Operator manages NVIDIA GPU resources in an {product-title} cluster and automates tasks that are required when preparing nodes for GPU workloads.

Before you can deploy application workloads to a GPU resource, you must install components such as the NVIDIA drivers that enable the compute unified device architecture (CUDA), Kubernetes device plugin, container runtime, and other features, such as automatic node labeling and monitoring. By automating these tasks, you can quickly scale the GPU capacity of your infrastructure. The NVIDIA GPU Operator can especially facilitate provisioning complex artificial intelligence and machine learning (AI/ML) workloads.

.Procedure

. Configure your `ClusterPolicy` manifest to match the following example:
+
----
apiVersion: nvidia.com/v1
kind: ClusterPolicy
metadata:
  name: gpu-cluster-policy
spec:
  daemonsets:
    updateStrategy: RollingUpdate
  dcgm:
    enabled: true
  dcgmExporter: {}
  devicePlugin: {}
  driver:
    enabled: false
    kernelModuleType: auto
  gfd: {}
  mig:
    strategy: single
  migManager:
    enabled: true
  nodeStatusExporter:
    enabled: true
  operator:
    defaultRuntime: crio
    initContainer: {}
    runtimeClass: nvidia
    use_ocp_driver_toolkit: true
  sandboxDevicePlugin:
    enabled: true
  sandboxWorkloads:
    defaultWorkload: vm-vgpu
    enabled: true
  toolkit:
    enabled: true
    installDir: /usr/local/nvidia
  validator:
    plugin:
      env:
      - name: WITH_WORKLOAD
        value: "true"
  vfioManager:
    enabled: true
  vgpuDeviceManager:
    config:
      default: default
      name: vgpu-devices-config
    enabled: true
  vgpuManager:
    enabled: true
    image: <vgpu_image_name>
    repository: <vgpu_container_registry>
    version: <nvidia_vgpu_manager_version>
----
+
* `spec.drive.enabled` is set to `false`. This is not required for VMs.
* `spec.sandboxDevicePlugin.enabled` is set to `true`.
* `spec.vfioManager.enabled` is set to `true`.
* `spec.vgpuDeviceManager.enabled` is set to `true` to allow the NVIDIA GPU Operator to configure mediated devices.
* `spec.vgpuManager.enabled` is set to `true`. This is required if you want to use vGPUs with VMs.
* `spec.vgpuManager.repository` is set to your registry value.
* `spec.vgpuManager.version` is set to the version of the vGPU driver you have downloaded from the NVIDIA website and used to build the image.

. Use the NVIDIA GPU Operator to configure mediated devices. For more information see link:https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/openshift-virtualization.html[NVIDIA GPU Operator with OpenShift Virtualization].
