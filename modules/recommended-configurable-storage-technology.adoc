// Module included in the following assemblies:
//
// * storage/optimizing-storage.adoc
// * post_installation_configuration/storage-configuration.adoc

[id="recommended-configurable-storage-technology_{context}"]
= Recommended configurable storage technology

The following table summarizes the recommended and configurable storage technologies for the given {product-title} cluster application.

.Recommended and configurable storage technology
[options="header,footer"]
|===
|Storage type |ROX^1^|RWX^2^|Registry|Scaled registry|Metrics^3^|Logging|Apps

| Block
| Yes^4^
| No
| Configurable
| Not configurable
| Recommended
| Recommended
| Recommended

| File
| Yes^4^
| Yes
| Configurable
| Configurable
| Configurable^5^
| Configurable^6^
| Recommended

| Object
| Yes
| Yes
| Recommended
| Recommended
| Not configurable
| Not configurable
| Not configurable^7^

8+a|
^1^ `ReadOnlyMany`

^2^ `ReadWriteMany`

^3^ Prometheus is the underlying technology used for metrics.

^4^ This does not apply to physical disk, VM physical disk, VMDK, loopback over NFS, AWS EBS, and Azure Disk.

^5^ For metrics, using file storage with the `ReadWriteMany` (RWX) access mode is unreliable. If you use file storage, do not configure the RWX access mode on any persistent volume claims (PVCs) that are configured for use with metrics.

^6^ For logging, using any shared storage would be an anti-pattern. One volume per elasticsearch is required.

^7^ Object storage is not consumed through {product-title}'s PVs or PVCs. Apps must integrate with the object storage REST API.

|===

[NOTE]
====
A scaled registry is an {product-title} registry where two or more pod replicas are running.
====

== Specific application storage recommendations

[IMPORTANT]
====
Testing shows issues with using the NFS server on {op-system-base-full} as storage backend for core services. This includes the OpenShift Container Registry and Quay, Prometheus for monitoring storage, and Elasticsearch for logging storage. Therefore, using {op-system-base} NFS to back PVs used by core services is not recommended.

Other NFS implementations on the marketplace might not have these issues. Contact the individual NFS implementation vendor for more information on any testing that was possibly completed against these {product-title} core components.
====

=== Registry

In a non-scaled/high-availability (HA) {product-title} registry cluster deployment:

* The storage technology does not have to support RWX access mode.
* The storage technology must ensure read-after-write consistency.
* The preferred storage technology is object storage followed by block storage.
* File storage is not recommended for {product-title} registry cluster deployment with production workloads.

=== Scaled registry

In a scaled/HA {product-title} registry cluster deployment:

* The storage technology must support RWX access mode.
* The storage technology must ensure read-after-write consistency.
* The preferred storage technology is object storage.
* Amazon Simple Storage Service (Amazon S3), Google Cloud Storage (GCS), Microsoft Azure Blob Storage, and OpenStack Swift are supported.
* Object storage should be S3 or Swift compliant.
* For non-cloud platforms, such as vSphere and bare metal installations, the only configurable technology is file storage.
* Block storage is not configurable.

=== Metrics

In an {product-title} hosted metrics cluster deployment:

* The preferred storage technology is block storage.
* Object storage is not configurable.

[IMPORTANT]
====
It is not recommended to use file storage for a hosted metrics cluster deployment with production workloads.
====

=== Logging

In an {product-title} hosted logging cluster deployment:

* The preferred storage technology is block storage.
* Object storage is not configurable.

=== Applications

Application use cases vary from application to application, as described in the following examples:

* Storage technologies that support dynamic PV provisioning have low mount time latencies, and are not tied to nodes to support a healthy cluster.
* Application developers are responsible for knowing and understanding the storage requirements for their application, and how it works with the provided storage to ensure that issues do not occur when an application scales or interacts with the storage layer.

== Other specific application storage recommendations

[IMPORTANT]
====
It is not recommended to use RAID configurations on `Write` intensive workloads, such as `etcd`. If you are running `etcd` with a RAID configuration, you might be at risk of encountering performance issues with your workloads.
====

* {rh-openstack-first} Cinder: {rh-openstack} Cinder tends to be adept in ROX access mode use cases.
* Databases: Databases (RDBMSs, NoSQL DBs, etc.) tend to perform best with dedicated block storage.
* The etcd database must have enough storage and adequate performance capacity to enable a large cluster. Information about monitoring and benchmarking tools to establish ample storage and a high-performance environment is described in _Recommended etcd practices_.
