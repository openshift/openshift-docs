// Module included in the following assemblies:
//
// * installing/installing_bare_metal/installing-bare-metal.adoc
// * installing/installing_bare_metal/installing-restricted-networks-bare-metal.adoc
// * installing/installing_vmc/installing-restricted-networks-vmc-user-infra.adoc
// * installing/installing_vmc/installing-vmc-user-infra.adoc
// * installing/installing_vmc/installing-vmc-network-customizations-user-infra.adoc
// * installing/installing_vsphere/installing-restricted-networks-vsphere.adoc
// * installing/installing_vsphere/installing-vsphere.adoc
// * installing/installing_vsphere/installing-vsphere-network-customizations.adoc
// * installing/installing_ibm_z/installing-ibm-z.adoc

ifeval::["{context}" == "installing-restricted-networks-vsphere"]
:restricted:
endif::[]
ifeval::["{context}" == "installing-restricted-networks-vmc-user-infra"]
:restricted:
endif::[]
ifeval::["{context}" == "installing-restricted-networks-bare-metal"]
:restricted:
endif::[]
ifeval::["{context}" == "installing-ibm-z"]
:ibm-z:
endif::[]
ifeval::["{context}" == "installing-restricted-networks-ibm-z"]
:ibm-z:
:restricted:
endif::[]
ifeval::["{context}" == "installing-ibm-power"]
:ibm-power:
endif::[]
ifeval::["{context}" == "installing-restricted-networks-ibm-power"]
:ibm-power:
:restricted:
endif::[]
[id="installation-complete-user-infra_{context}"]
= Completing installation on user-provisioned infrastructure

After you complete the Operator configuration, you can finish installing the
cluster on infrastructure that you provide.

.Prerequisites

* Your control plane has initialized.
* You have completed the initial Operator configuration.

.Procedure

. Confirm that all the cluster components are online with the following command:
+
[source,terminal]
----
$ watch -n5 oc get clusteroperators
----
+
.Example output
[source,terminal]
----
NAME                                       VERSION AVAILABLE   PROGRESSING   DEGRADED   SINCE
authentication                             4.8.0   True        False         False      3h56m
baremetal                                  4.8.0   True        False         False      29h
cloud-credential                           4.8.0   True        False         False      29h
cluster-autoscaler                         4.8.0   True        False         False      29h
config-operator                            4.8.0   True        False         False      6h39m
console                                    4.8.0   True        False         False      3h59m
csi-snapshot-controller                    4.8.0   True        False         False      4h12m
dns                                        4.8.0   True        False         False      4h15m
etcd                                       4.8.0   True        False         False      29h
image-registry                             4.8.0   True        False         False      3h59m
ingress                                    4.8.0   True        False         False      4h30m
insights                                   4.8.0   True        False         False      29h
kube-apiserver                             4.8.0   True        False         False      29h
kube-controller-manager                    4.8.0   True        False         False      29h
kube-scheduler                             4.8.0   True        False         False      29h
kube-storage-version-migrator              4.8.0   True        False         False      4h2m
machine-api                                4.8.0   True        False         False      29h
machine-approver                           4.8.0   True        False         False      6h34m
machine-config                             4.8.0   True        False         False      3h56m
marketplace                                4.8.0   True        False         False      4h2m
monitoring                                 4.8.0   True        False         False      6h31m
network                                    4.8.0   True        False         False      29h
node-tuning                                4.8.0   True        False         False      4h30m
openshift-apiserver                        4.8.0   True        False         False      3h56m
openshift-controller-manager               4.8.0   True        False         False      4h36m
openshift-samples                          4.8.0   True        False         False      4h30m
operator-lifecycle-manager                 4.8.0   True        False         False      29h
operator-lifecycle-manager-catalog         4.8.0   True        False         False      29h
operator-lifecycle-manager-packageserver   4.8.0   True        False         False      3h59m
service-ca                                 4.8.0   True        False         False      29h
storage                                    4.8.0   True        False         False      4h30m
----
+
Alternatively, the following command notifies you when all of the clusters are available. It also retrieves and displays credentials:
+
[source,terminal]
----
$ ./openshift-install --dir=<installation_directory> wait-for install-complete <1>
----
<1> For `<installation_directory>`, specify the path to the directory that you
stored the installation files in.
+
.Example output
[source,terminal]
----
INFO Waiting up to 30m0s for the cluster to initialize...
----
+
The command succeeds when the Cluster Version Operator finishes deploying the
{product-title} cluster from Kubernetes API server.
+
[IMPORTANT]
====
The Ignition config files that the installation program generates contain certificates that expire after 24 hours, which are then renewed at that time. If the cluster is shut down before renewing the certificates and the cluster is later restarted after the 24 hours have elapsed, the cluster automatically recovers the expired certificates. The exception is that you must manually approve the pending `node-bootstrapper` certificate signing requests (CSRs) to recover kubelet certificates. See the documentation for _Recovering from expired control plane certificates_ for more information.
====

. Confirm that the Kubernetes API server is communicating with the pods.
.. To view a list of all pods, use the following command:
+
[source,terminal]
----
$ oc get pods --all-namespaces
----
+
.Example output
[source,terminal]
----
NAMESPACE                         NAME                                            READY   STATUS      RESTARTS   AGE
openshift-apiserver-operator      openshift-apiserver-operator-85cb746d55-zqhs8   1/1     Running     1          9m
openshift-apiserver               apiserver-67b9g                                 1/1     Running     0          3m
openshift-apiserver               apiserver-ljcmx                                 1/1     Running     0          1m
openshift-apiserver               apiserver-z25h4                                 1/1     Running     0          2m
openshift-authentication-operator authentication-operator-69d5d8bf84-vh2n8        1/1     Running     0          5m
...
----

.. View the logs for a pod that is listed in the output of the previous command
by using the following command:
+
[source,terminal]
----
$ oc logs <pod_name> -n <namespace> <1>
----
<1> Specify the pod name and namespace, as shown in the output of the previous
command.
+
If the pod logs display, the Kubernetes API server can communicate with the
cluster machines.

ifndef::ibm-power[]
. For an installation with Fibre Channel Protocol (FCP), additional steps are required to enable multipathing. Do not enable multipathing during installation.
+
See "Enabling multipathing with kernel arguments on RHCOS" in the _Post-installation configuration_ documentation for more information.
endif::ibm-power[]
ifdef::ibm-power[]
. Additional steps are required to enable multipathing. Do not enable multipathing during installation.
+
See "Enabling multipathing with kernel arguments on RHCOS" in the _Post-installation configuration_ documentation for more information.

.. To display a boot list and specify the possible boot devices if the system is booted in normal mode, enter the following command:
+
[source,terminal]
----
$ bootlist -m normal -o
sda
----
.. To update the boot list for normal mode and add alternate device names, enter the following command:
+
[source,terminal]
----
$ bootlist -m normal -o /dev/sdc /dev/sdd /dev/sde
sdc
sdd
sde
----
+
If the original boot disk path is down, the node reboots from the alternate device registered in the normal boot device list.
endif::ibm-power[]
ifdef::ibm-z,ibm-power[]
.. All the worker nodes are restarted. To monitor the process, enter the following command:
+
[source,terminal]
----
$ oc get nodes -w
----
+
[NOTE]
====
If you have additional machine types such as infrastructure nodes, repeat the process for these types.
====
endif::ibm-z,ibm-power[]

ifdef::restricted[]
. Register your cluster on the link:https://cloud.redhat.com/openshift/register[Cluster registration] page.
endif::restricted[]

ifeval::["{context}" == "installing-restricted-networks-vsphere"]
:!restricted:
endif::[]
ifeval::["{context}" == "installing-restricted-networks-vmc-user-infra"]
:!restricted:
endif::[]
ifeval::["{context}" == "installing-restricted-networks-bare-metal"]
:!restricted:
endif::[]
ifdef::openshift-origin[]
:!restricted:
endif::[]
ifeval::["{context}" == "installing-ibm-z"]
:!ibm-z:
endif::[]
ifeval::["{context}" == "installing-restricted-networks-ibm-z"]
:!ibm-z:
:!restricted:
endif::[]
ifeval::["{context}" == "installing-ibm-power"]
:!ibm-power:
endif::[]
ifeval::["{context}" == "installing-restricted-networks-ibm-power"]
:!ibm-power:
:restricted:
endif::[]
