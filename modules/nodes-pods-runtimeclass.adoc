// Module included in the following assemblies:
//
// * storage/understanding-persistent-storage.adoc
//* microshift_storage/understanding-persistent-storage-microshift.adoc
// * nodes/pods/nodes-pods-reduce-timeouts.adoc

[id="nodes-pods-reduce-timeouts-runtime_{context}"]
= Using a runtime class to reduce pod timeouts

// based on https://access.redhat.com/solutions/6221251

You can reduce the pod timeouts that might happen if your cluster storage volume contains many files (~1,000,000 or greater), by using a custom runtime class.  You can configure the custom runtime class to interpret an annotation that signals {product-title} to skip the relabel if the top-level of the volume is found to have the correct label.

One drawback of this approach is that the volume has to be labeled by CRI-O at least once, which could cause the pod timeout you are trying to reduce.

[NOTE]
====
A consequence of this is that the container processes may fail to access sub-paths of the volume if they're relabeled. The SELinux relabeling process labels the top-level of the directory last. As such, assuming another process does not attempt to relabel a file in the volume, the volume should be accessible to the container after the initial relabel.
====

.Procedure

. Create a machine config to add the customized runtime class to CRI-O.

.. Create a YAML file for the machine config:
+
[source,yaml]
----
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfig
metadata:
  labels:
    machineconfiguration.openshift.io/role: worker
  name: 99-worker-selinux-configuration
spec:
  config:
    ignition:
      version: 3.2.0
    storage:
      files:
      - contents:
          source: data:text/plain;charset=utf-8;base64,W2NyaW8ucnVudGltZS5ydW50aW1lcy5zZWxpbnV4XQpydW50aW1lX3BhdGggPSAiL3Vzci9iaW4vcnVuYyIKcnVudGltZV9yb290ID0gIi9ydW4vcnVuYyIKcnVudGltZV90eXBlID0gIm9jaSIKYWxsb3dlZF9hbm5vdGF0aW9ucyA9IFsiaW8ua3ViZXJuZXRlcy5jcmktby5UcnlTa2lwVm9sdW1lU0VMaW51eExhYmVsIl0K
        mode: 0640
        overwrite: true
        path: /etc/crio/crio.conf.d/01-selinux.conf
  osImageURL: ""
----

. Create the object:
+
[source,terminal]
----
$ oc create -f <file-name>.yaml
----

. After the nodes have returned to the `Ready` state, you can verify that the machine config change took effect by viewing the `/etc/crio/crio.conf` file:
+
.. Start a debug session for a configured node:
+
[source,terminal]
----
$ oc debug node/<node_name>
----
+
.. Set `/host` as the root directory within the debug shell:
+
[source,terminal]
----
sh-4.4# chroot /host
----
+
. View the `/etc/crio/crio.conf` file:
+
[source,terminal]
----
sh-4.4# cat /etc/crio/crio.conf
----
+
[source,yaml]
----
...
[crio.runtime.runtimes.selinux]
runtime_path = "/usr/bin/runc"
runtime_root = "/run/runc"
runtime_type = "oci"
allowed_annotations = ["io.kubernetes.cri-o.TrySkipVolumeSELinuxLabel"]
...
----

. Create the RuntimeClass. 
+
[source,yaml]
----
apiVersion: node.k8s.io/v1
kind: RuntimeClass
metadata:
  name: selinux <1>
handler: selinux <2>
----
<1> Specifies the name The name should match that described in the CRI-O config above.
<2> Specifies the `selinux` handler.

. Configure the pod to include the annotation configured in the metadata and the runtime class you created:
+
[source,terminal]
----
apiVersion: v1
kind: Pod
metadata:
  name: sandbox
  annotations:
    io.kubernetes.cri-o.TrySkipVolumeSELinuxLabel: "true"
...
spec:
  runtimeClassName: selinux
...
----
+
When the pod is created, CRI-O runs it with the `selinux` runtime class, which is configured allow the relabeling to be skipped if the volume is already correctly labeled.

Note
It appears that behaviour has changed between OCP 4.10 and OCP 4.11
- When scp_t is set inside the deployment, the pods are not restarted and when you initially want to run. To mitigate this, add the custom scc and then add the service account to this role.
