// Module included in the following assembly:
//
// * release_notes/ocp-4-19-release-notes.adoc

:_mod-docs-content-type: REFERENCE
[id="zstream-4-19-22-bug-fixes_{context}"]
= Fixed issues

[role="_abstract"]
The following issues are fixed with this release:

* Before this update, the Route API validation allowed routes to `spec.paths` containing spaces or "&#35;" characters, which the {product-title} router failed to filter when generating the HAProxy configuration. This led to a significant consequence where users could create routes with invalid paths that prevented HAProxy from starting. With this release, the Route API validation now prohibits the use of space and "&#35;" characters in `spec.path` values, ensuring that users can no longer create routes with these characters. (link:https://issues.redhat.com/browse/OCPBUGS-61662[OCPBUGS-61662])

* Before this release, resizing or cloning small {gcp-first} Hyperdisk volumes would fail due to an Input/Output Operations Per Second (IOPS) validation error from the {gcp-first} API. This occurred because the container storage interface (CSI) driver did not automatically adjust the provisioned IOPS to meet the minimum requirements of the new volume size. With this release, the driver has been updated to correctly calculate and provide the required IOPS during volume expansion operations. Users can now successfully resize and clone these smaller {gcp-first} Hyperdisk volumes. (link:https://issues.redhat.com/browse/OCPBUGS-62116[OCPBUGS-62116])

* Before this update, rounding errors occurred when the Vertical Pod Autoscaler (VPA) Recommender loaded histograms from checkpoints following a restart. This caused the VPA Recommender to produce invalid memory recommendations with a value of 0, which could lead to pods receiving insufficient resources and failing to perform correctly. With this release, the logic for loading histogram data has been corrected to eliminate these rounding errors. As a result, the VPA Recommender now consistently provides accurate memory recommendations even after a restart, ensuring the stability and proper scaling of managed workloads. (link:https://issues.redhat.com/browse/OCPBUGS-63455[OCPBUGS-63455])

* Before this update, when a `MachineDeployment`  was in the process of upgrading its machines and the Cluster Autoscaler was also scaling the `MachineDeployment`, it was possible for the Cluster Autoscaler to remove new machines by scaling down the `MachineDeployment` for idle nodes. With this release, new functionality has been implemented so that scale down does not occur when a `MachineDeployment` is in the process of upgrading its machines. (link:https://issues.redhat.com/browse/OCPBUGS-63603[OCPBUGS-63603])

* Before this update, a Cluster Ingress Operator pod could restart with existing `IngressController` resources in `Available` or `Degraded` status causing the `ingress_controller_conditions` metric to disappear from the Operator's `/metrics` endpoint. As a result, users were unable to monitor the `IngressController` status following a pod restart. With this release, the `IngressControllerConditions` metric is now set during every reconciliation cycle, regardless of whether an Ingress controller status update occurred, ensuring reliable and continuous monitoring of the `IngressController` health. (link:https://issues.redhat.com/browse/OCPBUGS-65723[OCPBUGS-65723])

* Before this release, any unrelated changes to a `netpol` resource triggered a full reconcile of the object, including deleting and re-adding rules. With this release, a `netpol` object fully reconciles when required. Otherwise, it is skipped. (link:https://issues.redhat.com/browse/OCPBUGS-65956[OCPBUGS-65956])

* Before this update, `AdminNetworkPolicy`, `AdminPolicyBasedRouteListers`, `EgressFirewall`, `EgressQoS`, and `NetworkQoS` objects were retaining `managedFields` status entries for nodes that had been deleted, leading to buildup of stale data in etcd for large clusters with frequent node churn. With this release, the cleanup logic is fixed for all the aforementioned resource types. (link:https://issues.redhat.com/browse/OCPBUGS-66139[OCPBUGS-66139])

* Before this update, when opening a terminal to a running pod, the session was disconnected whenever the annotations of the pod changed. With this release, the terminal session no longer disconnects when this metadata is changed. (link:https://issues.redhat.com/browse/OCPBUGS-66179[OCPBUGS-66179])

* Before this update, the filtering mechanism was not handling the scenario where a range was actually a specific version, which resulted in the system mirroring more Operator versions than requested by the customer. With this release, we have fixed the logic to ignore a range when only one version is required, ensuring that only the specific requested version is mirrored. (link:https://issues.redhat.com/browse/OCPBUGS-66410[OCPBUGS-66410])

* Before this update, a bug prevented the `ValidatingAdmissionPolicy` resource from applying to certain {product-title} API resources, such as `BuildConfig` and `DeploymentConfig`. This meant that custom admission policies were not enforced on these specific resources, potentially allowing configurations that did not meet organizational standards to be created or updated. With this release, the validation logic has been corrected to ensure that the`ValidatingAdmissionPolicy` resource now correctly identifies and applies to all intended {product-title} resources. As a result, users can consistently enforce policies across their entire cluster, including the `BuildConfig` and `DeploymentConfig` resources. (link:https://issues.redhat.com/browse/OCPBUGS-66920[OCPBUGS-66920])

* Before this update, changes in {image-mode-os-lower} increased space usage on the rendezvous node's ephemeral temporary file system to approximately 9.4GB during cluster bootstrapping. Because the ephemeral temporary file system is capped at 50% of available RAM, installation would fail on hosts with less than 19GiB of memory due to insufficient space for container images. With this release, the additional data has been moved to a separate temporary file system. As a result, any rendezvous host meeting the minimum RAM requirement for a control plane node (16GB) now has sufficient capacity to successfully bootstrap a cluster. (link:https://issues.redhat.com/browse/OCPBUGS-66999[OCPBUGS-66999])

* Before this update, users could set `prometheus`, `prometheus_replica`, or `cluster` as Prometheus external labels to the `cluster-monitoring-config` and `user-workload-monitoring-config` config maps. This was not recommended and could cause issues with the cluster. With this release, when you run `oc adm upgrade`, `Upgradeable` is `False` if reserved Prometheus `externalLabels` are used, and the upgrade is blocked. (link:https://issues.redhat.com/browse/OCPBUGS-67003[OCPBUGS-67003])

* Before this update, the deployment agent was unable to find a valid IP address when the Ironic API was running on a non-standard port because the reachability test only used the hostname. This limitation resulted in a `LookupAgentIPError`, preventing successful connections and halting the deployment process in environments with custom port configurations. With this release, the reachability test has been updated to use the full API URL, including the specific port number, instead of relying solely on the hostname. As a result, the agent can now consistently identify the correct IP address and connect to Ironic APIs on any port, ensuring smoother deployments and eliminating the previous lookup errors. (link:https://issues.redhat.com/browse/OCPBUGS-67304[OCPBUGS-67304])

* Before this update, {product-title} 4.16 and later versions failed to respect the timeout `http-keep-alive` setting due to a known upstream High HAProxy bug, preventing users from effectively managing connection persistence. This lack of control resulted in inconsistent connection behaviors, where long-lived sessions might be terminated unexpectedly or held open longer than normal. With this release, the `HTTPKeepAliveTimeout` tuning option has been integrated into the `IngressController` API, providing a formal way for customers to configure and enforce this specific timeout. As a result, cluster administrators now possess the granular control necessary to align connection persistence with specific application needs. (link:https://issues.redhat.com/browse/OCPBUGS-68378[OCPBUGS-68378])

* Before this update, the *Operand* details page would incorrectly show information using only half of the screen's display area in the OpenShift web console. With this release, the *Operand* details take up the full page width as expected.  (link:https://issues.redhat.com/browse/OCPBUGS-69677[OCPBUGS-69677])

* Before this update, `iptables-alerter` pods experienced high CPU usage in some clusters due to an issue in the 4.18.20 upgrade. As a consequence, high CPU usage impacted `iptables-alerter pods`, causing performance degradation. With this release, `iptables-alerter` CPU usage has been reduced by optimizing code in version 4.18.21. As a result, high CPU usage for `iptables-alerter` pods has been resolved, improving cluster performance. (link:https://issues.redhat.com/browse/OCPBUGS-70328[OCPBUGS-70328])

* Before this update, when service endpoints were deleted and re-created in {product-title} clusters using OVN-Kubernetes networking and the service port differed from the endpoint port, stale User Datagram Protocol (UDP) connection tracking (conntrack) entries could remain on worker nodes. This occurred because the `conntrack` cleanup logic incorrectly used the endpoint port, which is the target port on the pod, instead of the externally-facing service port that clients connect to when attempting to delete stale entries. With this release, when service endpoints are deleted or updated, the cleanup process correctly uses the service port to match and remove stale `conntrack` entries. This change ensures that network connectivity continues to work reliably across endpoint lifecycle events.  (link:https://issues.redhat.com/browse/OCPBUGS-70345[OCPBUGS-70345])

