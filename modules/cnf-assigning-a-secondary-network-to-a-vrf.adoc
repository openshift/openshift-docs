// Module included in the following assemblies:
//
// networking/multiple_networks/assigning-a-secondary-network-to-a-vrf.adoc

:_mod-docs-content-type: PROCEDURE
[id="cnf-creating-an-additional-network-attachment-with-the-cni-vrf-plug-in_{context}"]
= Creating a secondary network attachment with the CNI VRF plugin

The Cluster Network Operator (CNO) manages secondary network definitions. When you specify a secondary network to create, the CNO creates the `NetworkAttachmentDefinition` custom resource (CR) automatically.

[NOTE]
====
Do not edit the `NetworkAttachmentDefinition` CRs that the Cluster Network Operator manages. Doing so might disrupt network traffic on your secondary network.
====

To create a secondary network attachment with the CNI VRF plugin, perform the following procedure.

.Prerequisites

* Install the {product-title} CLI (oc).
* Log in to the OpenShift cluster as a user with cluster-admin privileges.

.Procedure

. Create the `Network` custom resource (CR) for the additional network attachment and insert the `rawCNIConfig` configuration for the secondary network, as in the following example CR. Save the YAML as the file `additional-network-attachment.yaml`.
+
[source,yaml]
----
apiVersion: operator.openshift.io/v1
kind: Network
metadata:
  name: cluster
spec:
  additionalNetworks:
    - name: test-network-1
      namespace: additional-network-1
      type: Raw
      rawCNIConfig: '{
        "cniVersion": "0.3.1",
        "name": "macvlan-vrf",
        "plugins": [  <1>
        {
          "type": "macvlan", 
          "master": "eth1",
          "ipam": {
              "type": "static",
              "addresses": [
              {
                  "address": "191.168.1.23/24"
              }
              ]
          }
        },
        {
          "type": "vrf", <2>
          "vrfname": "vrf-1",  <3>
          "table": 1001   <4>
        }]
      }'
----
<1> `plugins` must be a list. The first item in the list must be the secondary network underpinning the VRF network. The second item in the list is the VRF plugin configuration.
<2> `type` must be set to `vrf`.
<3> `vrfname` is the name of the VRF that the interface is assigned to. If it does not exist in the pod, it is created.
<4> Optional. `table` is the routing table ID. By default, the `tableid` parameter is used. If it is not specified, the CNI assigns a free routing table ID to the VRF.
+
[NOTE]
====
VRF functions correctly only when the resource is of type `netdevice`.
====

. Create the `Network` resource:
+
[source,terminal]
----
$ oc create -f additional-network-attachment.yaml
----

. Confirm that the CNO created the `NetworkAttachmentDefinition` CR by running the following command. Replace `<namespace>` with the namespace that you specified when configuring the network attachment, for example, `additional-network-1`. The expected output shows the name of the NAD CR and the creation age in minutes.
+
[source,terminal]
----
$ oc get network-attachment-definitions -n <namespace>
----
+
[NOTE]
====
There might be a delay before the CNO creates the CR.
====

.Verification

. Create a pod and assign it to the secondary network with the VRF instance:

.. Create a YAML file that defines the `Pod` resource:
+
.Example `pod-additional-net.yaml` file
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
 name: pod-additional-net
 annotations:
   k8s.v1.cni.cncf.io/networks: '[
       {
               "name": "test-network-1" <1>
       }
 ]'
spec:
 containers:
 - name: example-pod-1
   command: ["/bin/bash", "-c", "sleep 9000000"]
   image: centos:8
----
<1> Specify the name of the secondary network with the VRF instance.

.. Create the `Pod` resource by running the following command. The expected output shows the name of the `Pod` resource and the creation age in minutes.
+
[source,terminal]
----
$ oc create -f pod-additional-net.yaml
----

. Verify that the pod network attachment is connected to the VRF secondary network. Start a remote session with the pod and run the following command. The expected output shows the name of the VRF interface and its unique ID in the routing table.
+
[source,terminal]
----
$ ip vrf show
----

. Confirm that the VRF interface is the controller for the secondary interface:
+
[source,terminal]
----
$ ip link
----
+
.Example output
[source,terminal]
----
5: net1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master red state UP mode
----
