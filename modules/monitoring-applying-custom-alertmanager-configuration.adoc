// Module included in the following assemblies:
//
// * monitoring/managing-alerts.adoc

[id="applying-custom-alertmanager-configuration_{context}"]
= Applying a custom Alertmanager configuration

You can overwrite the default Alertmanager configuration by editing the `alertmanager-main` secret inside the `openshift-monitoring` project.

.Prerequisites

* You have access to the cluster as a user with the `cluster-admin` role.

.Procedure

To change the Alertmanager configuration from the CLI:

. Print the currently active Alertmanager configuration into file `alertmanager.yaml`:
+
[source,terminal]
----
$ oc -n openshift-monitoring get secret alertmanager-main --template='{{ index .data "alertmanager.yaml" }}' | base64 -d > alertmanager.yaml
----
+
. Edit the configuration in `alertmanager.yaml`:
+
[source,yaml]
----
global:
  resolve_timeout: 5m
route:
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 12h
  receiver: default
  routes:
  - match:
      alertname: Watchdog
    repeat_interval: 5m
    receiver: watchdog
  - match:
      service: <your_service> <1>
    routes:
    - match:
        <your_matching_rules> <2>
      receiver: <receiver> <3>
receivers:
- name: default
- name: watchdog
- name: <receiver>
  <receiver_configuration>
----
<1> `service` specifies the service that fires the alerts.
<2> `<your_matching_rules>` specifies the target alerts.
<3> `receiver` specifies the receiver to use for the alert.
+
The following Alertmanager configuration example configures PagerDuty as an alert receiver:
+
[source,yaml,subs=quotes]
----
global:
  resolve_timeout: 5m
route:
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 12h
  receiver: default
  routes:
  - match:
      alertname: Watchdog
    repeat_interval: 5m
    receiver: watchdog
  *- match:
      service: example-app
    routes:
    - match:
        severity: critical
      receiver: team-frontend-page*
receivers:
- name: default
- name: watchdog
*- name: team-frontend-page
  pagerduty_configs:
  - service_key: "_your-key_"*
----
+
With this configuration, alerts of `critical` severity that are fired by the `example-app` service are sent using the `team-frontend-page` receiver. Typically these types of alerts would be paged to an individual or a critical response team.
+
. Apply the new configuration in the file:
+
[source,terminal]
----
$ oc -n openshift-monitoring create secret generic alertmanager-main --from-file=alertmanager.yaml --dry-run -o=yaml |  oc -n openshift-monitoring replace secret --filename=-
----

To change the Alertmanager configuration from the {product-title} web console:

. Navigate to the *Administration* -> *Cluster Settings* -> *Global Configuration* -> *Alertmanager* -> *YAML* page of the web console.

. Modify the YAML configuration file.

. Select *Save*.

.Additional resources

* See link:https://www.pagerduty.com/[the PagerDuty official site] for more information on PagerDuty
* See link:https://www.pagerduty.com/docs/guides/prometheus-integration-guide/[the PagerDuty Prometheus Integration Guide] to learn how to retrieve the `service_key`
* See link:https://prometheus.io/docs/alerting/configuration/[Alertmanager configuration] for configuring alerting through different alert receivers
