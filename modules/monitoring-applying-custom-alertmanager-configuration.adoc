// Module included in the following assemblies:
//
// * monitoring/cluster-monitoring/configuring-the-monitoring-stack.adoc

[id="applying-custom-alertmanager-configuration_{context}"]
= Applying custom Alertmanager configuration

You can overwrite the default Alertmanager configuration by editing the `alertmanager-main` secret inside the `openshift-monitoring` namespace.

.Prerequisites

* An installed `jq` tool for processing JSON data

.Procedure

. Print the currently active Alertmanager configuration into file `alertmanager.yaml`:
+
----
$ oc -n openshift-monitoring get secret alertmanager-main --template='{{ index .data "alertmanager.yaml" }}' |base64 -d > alertmanager.yaml
----
+
. Change the configuration in file `alertmanager.yaml` to your new configuration:
+
[source,yaml]
----
data:
 config.yaml: |
  global:
    resolve_timeout: 5m
  route:
    group_wait: 30s
    group_interval: 5m
    repeat_interval: 12h
    receiver: default
    routes:
    - match:
        alertname: Watchdog
      repeat_interval: 5m
      receiver: watchdog
    - match:
        service: _your service_ <1>
      routes:
      - match:
          _your matching rules_ <2>
        receiver: _receiver_ <3>
  receivers:
  - name: default
  - name: watchdog
  - name: _receiver_
    _receiver configuration_
----
<1> `service` specifies the service that fires the alerts.
<2> `<your matching rules>` specify the target alerts.
<3> `receiver` specifies the receiver to use for the alert.
+
For example, this listing configures PagerDuty for notifications:
+
[source,yaml,subs=quotes]
----
data:
 config.yaml: |
  global:
    resolve_timeout: 5m
  route:
    group_wait: 30s
    group_interval: 5m
    repeat_interval: 12h
    receiver: default
    routes:
    - match:
        alertname: Watchdog
      repeat_interval: 5m
      receiver: watchdog
    *- match:
        service: example-app
      routes:
      - match:
          severity: critical
        receiver: team-frontend-page*
  receivers:
  - name: default
  - name: watchdog
  *- name: team-frontend-page
    pagerduty_configs:
    - service_key: "_your-key_"*
----
+
With this configuration, alerts of `critical` severity fired by the `example-app` service are sent using the `team-frontend-page` receiver, which means that these alerts are paged to a chosen person.
+
. Apply the new configuration in the file:
+
----
$ oc -n openshift-monitoring create secret generic alertmanager-main --from-literal=alertmanager.yaml="$(< alertmanager.yaml)" --dry-run -o=yaml | oc -n openshift-monitoring replace secret --filename=-
----

.Additional resources

* See link:https://www.pagerduty.com/[the PagerDuty official site] for more information on PagerDuty.
* See link:https://www.pagerduty.com/docs/guides/prometheus-integration-guide/[the PagerDuty Prometheus Integration Guide] to learn how to retrieve the `service_key`.
* See link:https://prometheus.io/docs/alerting/configuration/[Alertmanager configuration] for configuring alerting through different alert receivers.
