// Module included in the following assemblies:
//
// * microshift_networking/microshift-networking.adoc

:_content-type: PROCEDURE
[id="microshift-deploying-a-load-balancer_{context}"]
= Deploying a load balancer for a workload

{product-title} offers a built-in implementation of network load balancers. The following example procedure uses the node IP address as the external IP address for the `LoadBalancer` service configuration file.

.Prerequisites

* The {oc-first} is installed.
* You have access to the cluster as a user with the cluster administration role.
* You installed a cluster on an infrastructure configured with the OVN-Kubernetes network plugin.
* The `KUBECONFIG` environment variable is set.

.Procedure

. Verify that your pods are running by running the following command:
+
[source,terminal]
----
$ oc get pods -A
----

. Create the example namespace by running the following commands:
+
[source,terminal]
----
$ NAMESPACE=nginx-lb-test
----
+
[source,terminal]
----
$ oc create ns $NAMESPACE
----

. The following example deploys three replicas of the test `nginx` application in your namespace:
+
[source,terminal]
----
$ oc apply -n $NAMESPACE -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx
data:
  headers.conf: |
    add_header X-Server-IP  \$server_addr always;
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - image: quay.io/packit/nginx-unprivileged
        imagePullPolicy: Always
        name: nginx
        ports:
        - containerPort: 8080
        volumeMounts:
        - name: nginx-configs
          subPath: headers.conf
          mountPath: /etc/nginx/conf.d/headers.conf
        securityContext:
          allowPrivilegeEscalation: false
          seccompProfile:
            type: RuntimeDefault
          capabilities:
            drop: ["ALL"]
          runAsNonRoot: true
      volumes:
        - name: nginx-configs
          configMap:
            name: nginx
            items:
              - key: headers.conf
                path: headers.conf
EOF
----

. You can verify that the three sample replicas started successfully by running the following command:
+
[source,terminal]
----
$ oc get pods -n $NAMESPACE
----

. Create a `LoadBalancer` service for the `nginx` test application with the following sample commands:
+
[source,terminal]
----
$ oc create -n $NAMESPACE -f - <<EOF
apiVersion: v1
kind: Service
metadata:
  name: nginx
spec:
  ports:
  - port: 81
    targetPort: 8080
  selector:
    app: nginx
  type: LoadBalancer
EOF
----
+
[NOTE]
====
You must ensure that the `port` parameter is a host port that is not occupied by other `LoadBalancer` services or {product-title} components.
====

. Verify that the service file exists, that the external IP address is properly assigned, and that the external IP is identical to the node IP by running the following command:
+
[source,terminal]
----
$ oc get svc -n $NAMESPACE
----
+
.Example output
[source,terminal]
----
NAME    TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)        AGE
nginx   LoadBalancer   10.43.183.104   192.168.1.241   81:32434/TCP   2m
----

.Verification

* The following command forms five connections to the example `nginx` application using the external IP address of the `LoadBalancer` service configuration. The result of the command is a list of those server IP addresses. Verify that the load balancer sends requests to all the running applications with the following command:
+
[source,terminal]
----
EXTERNAL_IP=192.168.1.241
seq 5 | xargs -Iz curl -s -I http://$EXTERNAL_IP:81 | grep X-Server-IP
----
+
The output of the previous command contains different IP addresses if the load balancer is successfully distributing the traffic to the applications, for example:
+
.Example output
[source,terminal]
----
X-Server-IP: 10.42.0.41
X-Server-IP: 10.42.0.41
X-Server-IP: 10.42.0.43
X-Server-IP: 10.42.0.41
X-Server-IP: 10.42.0.43
----