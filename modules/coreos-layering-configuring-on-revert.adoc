// Module included in the following assemblies:
//
// * machine_configuration/coreos-layering.adoc

:_mod-docs-content-type: PROCEDURE
[id="coreos-layering-configuring-on-revert_{context}"]
= Reverting an on-cluster custom layered image

If you applied an on-cluster layered image to a node in a custom machine config pool (MCP), you can remove the custom layered image from the node and revert to the base image. 

To revert the node, remove the node from the custom MCP by removing the custom machine config pool label from the node. After you remove the label, the Machine Config Operator (MCO) reboots the node with the cluster base {op-system-first} image, overriding the custom layered image.

[IMPORTANT]
====
Before you remove the label, make sure the node is associated with another MCP.
====

.Prerequisites

* You have opted-in to {image-mode-os-on-caps} by creating a `MachineOSConfig` object.
* You have applied a `MachineOSConfig` object to a node in a custom machine config pool.

.Procedure

* Remove the label from the node by using the following command:
+
[source,terminal]
----
$ oc label node/<node_name> node-role.kubernetes.io/<mcp_name>-
----
+
When you save the changes, the MCO drains, cordons, and reboots the nodes. After the reboot, the node uses the cluster base {op-system-first} image.

.Verification

* Verify that the custom layered image is removed by performing any of the following checks:

** Check that the worker machine config pool is updating with the previous machine config:
+
[source,terminal]
----
$ oc get mcp
----
+
.Sample output
[source,terminal]
----
NAME      CONFIG                                              UPDATED   UPDATING   DEGRADED   MACHINECOUNT   READYMACHINECOUNT   UPDATEDMACHINECOUNT   DEGRADEDMACHINECOUNT   AGE
layered   rendered-layered-e8c8bc1de69777325003e80bc0c04b82   True      False      False      0              0                   0                     0                      4h20m <1>
master    rendered-master-50d7bc27ee8b9ca2250383f0647ade7f    True      False      False      3              3                   3                     0                      5h39m
worker    rendered-worker-e8c8bc1de69777325003e80bc0c04b82    True      False      False      3              3                   3                     0                      5h39m <2>
----
<1> The custom machine config pool no longer has any nodes.
<2> When the `UPDATING` field is `True`, the machine config pool is updating with the previous machine config. When the field becomes `False`, the worker machine config pool has rolled out to the previous machine config.

** Check the nodes to see that scheduling on the nodes is disabled. This indicates that the change is being applied:
+
[source,terminal]
----
$ oc get nodes
----
+
.Example output
[source,terminal]
----
NAME                                         STATUS                     ROLES                  AGE   VERSION
ip-10-0-148-79.us-west-1.compute.internal    Ready                      worker                 32m   v1.32.3
ip-10-0-155-125.us-west-1.compute.internal   Ready,SchedulingDisabled   worker                 35m   v1.32.3
ip-10-0-170-47.us-west-1.compute.internal    Ready                      control-plane,master   42m   v1.32.3
ip-10-0-174-77.us-west-1.compute.internal    Ready                      control-plane,master   42m   v1.32.3
ip-10-0-211-49.us-west-1.compute.internal    Ready                      control-plane,master   42m   v1.32.3
ip-10-0-218-151.us-west-1.compute.internal   Ready                      worker                 31m   v1.32.3
----

** When the node is back in the `Ready` state, check that the node is using the base image:
+
. Open an `oc debug` session to the node. For example:
+
[source,terminal]
----
$ oc debug node/ip-10-0-155-125.us-west-1.compute.internal
----
+
. Set `/host` as the root directory within the debug shell:
+
[source,terminal]
----
sh-4.4# chroot /host
----

. Run the `rpm-ostree status` command to view that the base image is in use:
+
[source,terminal]
----
sh-4.4# rpm-ostree status
----
+
.Example output
+
----
State: idle
Deployments:
* ostree-unverified-registry:registry.build05.ci.openshift.org/ci-ln-qd0hmqk/stable@sha256:a8bd32573f787f6d1c23e1d669abbefd1e31339826d06e750c0ca632ad6c414f
                   Digest: sha256:a8bd32573f787f6d1c23e1d669abbefd1e31339826d06e750c0ca632ad6c414f
                  Version: 419.96.202501202201-0 (2025-01-20T22:06:13Z)
----
