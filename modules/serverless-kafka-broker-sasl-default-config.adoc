// Module is included in the following assemblies:
//
// * serverless/admin_guide/serverless-kafka-admin.adoc

:_content-type: PROCEDURE
[id="serverless-kafka-broker-sasl-default-config_{context}"]
= Configuring SASL authentication for Kafka brokers

As a cluster administrator, you can set up _Simple Authentication and Security Layer_ (SASL) authentication for Kafka brokers by modifying the `KnativeKafka` custom resource (CR).

.Prerequisites

* You have cluster administrator permissions on {product-title}.
* The {ServerlessOperatorName}, Knative Eventing, and the `KnativeKafka` CR are installed on your {product-title} cluster.
* You have created a project or have access to a project with the appropriate roles and permissions to create applications and other workloads in {product-title}.
* You have a username and password for a Kafka cluster.
* You have chosen the SASL mechanism to use, for example `PLAIN`, `SCRAM-SHA-256`, or `SCRAM-SHA-512`.
* If TLS is enabled, you also need the `ca.crt` certificate file for the Kafka cluster.

[NOTE]
====
It is recommended to enable TLS in addition to SASL.
====

.Procedure

. Create the certificate files as a secret in the `knative-eventing` namespace:
+
[source,terminal]
----
$ oc create secret -n knative-eventing generic <secret_name> \
  --from-literal=protocol=SASL_SSL \
  --from-literal=sasl.mechanism=<sasl_mechanism> \
  --from-file=ca.crt=caroot.pem \
  --from-literal=password="SecretPassword" \
  --from-literal=user="my-sasl-user"
----
+
[IMPORTANT]
====
Use the key names `ca.crt`, `password`, and `sasl.mechanism`. Do not change them.
====

. Edit the `KnativeKafka` CR and add a reference to your secret in the `broker` spec:
+
[source,yaml]
----
apiVersion: operator.serverless.openshift.io/v1alpha1
kind: KnativeKafka
metadata:
  namespace: knative-eventing
  name: knative-kafka
spec:
  broker:
    enabled: true
    defaultConfig:
      authSecretName: <secret_name>
...
----
