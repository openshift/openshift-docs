// Module included in the following assemblies:
//
// * logging/efk-logging.adoc

[id='efk-logging-about_{context}']
= About EFK logging in {product-title}

As an {product-title} cluster administrator, you can deploy the Elasticsearch, Fluentd, and Kibana (EFK) stack to
aggregate logs for a range of {product-title} services. 

Application developers can view the logs of the projects for which they have view access. The EFK stack
aggregates logs from hosts and applications, whether coming from multiple
containers or even deleted pods.

The EFK stack aggregates logs from nodes and applications
running inside your {product-title} cluster. Once deployed it uses
link:http://www.fluentd.org/architecture[Fluentd] to aggregate event logs from
all nodes, projects, and pods into
link:https://www.elastic.co/products/elasticsearch[Elasticsearch (ES)]. It also
provides a centralized
link:https://www.elastic.co/guide/en/kibana/current/introduction.html[Kibana]
web UI where users and administrators can create rich visualizations and
dashboards with the aggregated data.

{product-title} cluster administrators can deploy cluster logging by creating a subscription from the Operator Hub Community Operators.  
Creating the subscription in the 'openshift-operators' namespace deploys the Cluster Logging operator, the Elasticsearch operator, 
and the other resources necessary to support the deployment of the sub-system.  The operators are responsible for deploying, upgrading, and maintaining cluster logging.

You can configure cluster logging by modifying the Custom Resource deployed in the **openshift-logging** namespace.  The *_../hack/cr.yaml_* resource
defines a complete cluster logging deployment that includes all the subcomponents
of the logging stack to collect, store and visualize logs.  The Cluster Logging operator
watches the `ClusterLogging` Custom Resources and adjusts the logging deployment accordingly.

