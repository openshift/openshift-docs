// This module is included in the following assemblies:
// * create/remote-pipelines-tasks-resolvers.adoc

// // *openshift_pipelines/remote-pipelines-tasks-resolvers.adoc
:_mod-docs-content-type: REFERENCE
[id="resolver-stepactions-ref_{context}"]
= Step action definitions provided with {pipelines-shortname}

{pipelines-shortname} provides standard `StepAction` definitions that you can use in your tasks. Use the cluster resolver to reference these definitions.


[discrete]
[id="op-stepaction-git-clone_{context}"]
== git-clone

The `git-clone` step action uses Git to initialize and clone a remote repository on a workspace. You can use this step action to define a task that clones a repository at the start of a pipeline that builds or otherwise processes this source code.


.Example usage of the `git-clone` step action in a task
[source,yaml,subs="attributes+"]
----
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: clone-repo-anon
spec:
# ...
  steps:
  - name: clone-repo-step
    ref:
      resolver: cluster
      params:
      - name: name
        value: git-clone
      - name: namespace
        value: openshift-pipelines
      - name: kind
        value: stepaction
    params:
    - name: URL
      value: $(params.url)
    - name: OUTPUT_PATH
      value: $(workspaces.output.path)
----

.Supported parameters for the `git-clone` step action
[cols="1,2,1,1",options="header"]
|===
| Parameter | Description | Type | Default value
|`OUTPUT_PATH` | A directory for the fetched Git repository. Cloned repo data is placed in the root of the directory or in the relative path defined by the `SUBDIRECTORY` parameter |`string` |
|`SSH_DIRECTORY_PATH` |A `.ssh` directory with the private key, `known_hosts`, `config`, and other files as necessary. If you provide this directory, the task uses it for authentication to the Git repository. Bind the workspace providing this directory to a `Secret` resource for secure storage of authentication information. |`string` |
|`BASIC_AUTH_PATH` |A directory containing a `.gitconfig` and `.git-credentials` files. If you provide this directgory, the task uses it for authentication to the Git repository. Use a `SSH_DIRECTORY_PATH` directory for authentication instead of `BASIC_AUTH_PATH` whenever possible. Bind the workspace providing this directory to a `Secret` resource for secure storage of authentication information. |`string` |
|`SSL_CA_DIRECTORY_PATH` |A workspace containing CA certificates. If you provide this workspace, Git uses these certificates to verify the peer when interacting with remote repositories using HTTPS. |`string` |
|`CRT_FILENAME` |Certificate authority (CA) bundle filename in the `ssl-ca-directory` workspace. |`string` |`ca-bundle.crt`
|`HTTP_PROXY` |HTTP proxy server (non-TLS requests). |`string` |
|`HTTPS_PROXY` |HTTPS proxy server (TLS requests). |`string` |
|`NO_PROXY` |Opt out of proxying HTTP/HTTPS requests. |`string` |
|`SUBDIRECTORY` |Relative path in the `output` workspace where the task places the Git repository. |`string` |
|`USER_HOME` |Absolute path to the Git user home directory in the pod. |`string` |`/home/git`
|`DELETE_EXISTING` |Delete the contents of the default workspace, if they exist, before running the Git operations. |`string` |`true`
|`VERBOSE` |Log the executed commands. |`string` |`false`
|`SSL_VERIFY` |The global `http.sslVerify` value. Do not set this parameter to to `false` unless you trust the remote repository. |`string` |`true`
|`URL` |Git repository URL. |`string` |
|`REVISION` |The revision to check out, for example, a branch or tag. |`string` |`main`
|`REFSPEC` |The `refspec` string for the repository that the task fetches before checking out the revision. |`string` |
|`SUBMODULES` |Initialize and fetch Git submodules. |`string` |`true`
|`DEPTH` |Number of commits to fetch, a "shallow clone" is a single commit. |`string` |`1`
|`SPARSE_CHECKOUT_DIRECTORIES` |List of directory patterns, separated by commas, for performing a  "sparse checkout". |`string` |
|===

.Results that the `git-clone` step action returns
[cols="1,1,2",options="header"]
|===
| Result | Type | Description
|`COMMIT` |`string` |The SHA digest of the commit that is at the HEAD of the current branch in the cloned Git repository.
|`URL` |`string` |The URL of the repository that was cloned.
|`COMMITTER_DATE` |`string` |The epoch timestamp of the commit that is at the HEAD of the current branch in the cloned Git repository.
|===


[discrete]
[id="op-stepaction-cache-{context}"]
== cache-upload and cache-fetch

:FeatureName: Using the `cache-upload` and `cache-fetch` step actions
include::snippets/technology-preview.adoc[]

Use the `cache-upload` and `cache-fetch` step actions to preserve the cache directory where a build process keeps its dependencies, storing it in an Amazon Simple Storage Service (S3) bucket, Google Cloud Services (GCS) bucket, or an Open Container Initiative (OCI) repository.

When you use the `cache-upload` step action, the step action calculates a hash based on certain files in your build. You must provide a regular expression to select these files. The `cache-upload` step action stores an image that contains the content of your cache directory, indexed with the hash.

When you use the `cache-fetch` step action, the step action calculates the same hash. Then it checks whether a cached image for this hash is already available. If the image is available, the step action populates your cache directory with the cached content. If the image is not available, the directory remains as it was.

After using the `cache-fetch` step action, you can run the build process. If the cache is successfully fetched, it includes the dependencies that the build process downloaded previously. If the cache was not fetched, the build process downloads dependencies through its normal procedure.

The result of `cache-fetch` indicates whether a cached image was fetched. The subsequent `cache-upload` step action can use the result and skip uploading a new cache image if the cache for the current hash was already available.

The following example task retrieves the source from a repository, fetches the cache (if available), runs a Maven build, and then, if the cache was not fetched, uploads the new cached image of the build directory.

.Example usage of the `cache-fetch` and `cache-upload` step actions in a task

[source,yaml]
----
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: java-demo-task
spec:
  workspaces:
  - name: source
  params:
  - name: repo_url
    type: string
    default: https://github.com/sample-organization/sample-java-project.git
  - name: revision
    type: string
    default: main
  - name: registry
    type: string
    default: image-registry.openshift-image-registry.svc:5000/sample-project/mvn-cache
  - name: image
    type: string
    default: openjdk:latest
  - name: buildCommand
    type: string
    default: "maven -Dmaven.repo.local=${LOCAL_CACHE_REPO} install"
  - name: cachePatterns
    type: array
    default: ["**pom.xml"]
  - name: force-cache-upload
    type: string
    default: "false"
  steps:
   - name: create-repo
     image: $(params.image)
     script: |
       mkdir -p $(workspaces.source.path)/repo
       chmod 777 $(workspaces.source.path)/repo
   - name: fetch-repo
     ref:
       resolver: cluster
       params:
       - name: name
         value: git-clone
       - name: namespace
         value: openshift-pipelines
       - name: kind
         value: stepaction
     params:
       - name: OUTPUT_PATH
         value: $(workspaces.source.path)/repo
       - name: URL
         value: $(params.repo_url)
       - name: REVISION
         value: $(params.revision)
   - name: cache-fetch
     ref:
       resolver: cluster
       params:
       - name: name
         value: cache-fetch
       - name: namespace
         value: openshift-pipelines
       - name: kind
         value: stepaction
     params:
     - name: PATTERNS
       value: $(params.cachePatterns)
     - name: SOURCE
       value: oci://$(params.registry):{{hash}}
     - name: CACHE_PATH
       value: $(workspaces.source.path)/cache
     - name: WORKING_DIR
       value: $(workspaces.source.path)/repo
   - name: run-build
     image: $(params.image)
     workingDir: $(workspaces.source.path)/repo
     env:
       - name: LOCAL_CACHE_REPO
         value: $(workspaces.source.path)/cache/repo
     script: |
       set -x
       $(params.buildCommand)
       echo "Cache size is $(du -sh $(workspaces.source.path)/cache)"
   - name: cache-upload
     ref:
       resolver: cluster
       params:
       - name: name
         value: cache-upload
       - name: namespace
         value: openshift-pipelines
       - name: kind
         value: stepaction
     params:
       - name: PATTERNS
         value: $(params.cachePatterns)
       - name: TARGET
         value: oci://$(params.registry):{{hash}}
       - name: CACHE_PATH
         value: $(workspaces.source.path)/cache
       - name: WORKING_DIR
         value: $(workspaces.source.path)/repo
       - name: FORCE_CACHE_UPLOAD
         value: $(params.force-cache-upload)
----

.Supported parameters for the `cache-fetch` step action
[cols="1,2,1,1",options="header"]
|===
| Parameter | Description | Type | Default value
|`PATTERNS` |Regular expression for selecting files to compute the hash. For example, for a Go project, you can use `go.mod` files to compute the cache, and then the value of this parameter is `pass:[**]/go.sum` (where `pass:[**]` accounts for subdirectories of any depth). | `array` |
|`SOURCE` |Source URI for fetching the cache; use `{{hash}}` to specify the cache hash. The supported types are `oci` (example: `oci://quay.io/example-user/go-cache:{{hash}}`) and `s3` (example: `s3://example-bucket/{{hash}}`) | `string` |
|`CACHE_PATH` |Path for extracting the cache content. Normally this path is in a workspace. | `string` |
|`WORKING_DIR` |Path where the files for calculating the hash are located. | `string` |
|`INSECURE` |If `"true"`, use insecure mode for fetching the cache. | `string` |`"false"`
|`GOOGLE_APPLICATION_CREDENTIALS` |The path where Google credentials are located. Ignored if empty. | `string` |
|`AWS_CONFIG_FILE` |Path to the AWS configuration file. Ignored if empty. | `string` |
|`AWS_SHARED_CREDENTIALS_FILE` |Path to the AWS credentials file. Ignored if empty. | `string` |
|`BLOB_QUERY_PARAMS` |Blob query parameters for configuring S3, GCS, or Azure. Use these optional parameters for additional features such as S3 acceleration, FIPS, or path-style addressing. | `string` |
|===

.Results that the `cache-fetch` step action returns
[cols="1,1,2",options="header"]
|===
| Result | Type | Description
|`fetched` |`string` |`"true"` if the step has fetched the cache or `"false"` if the step has not fetched the cache.
|===


.Supported parameters for the `cache-upload` step action
[cols="1,2,1,1",options="header"]
|===
| Parameter | Description | Type | Default value
|`PATTERNS` |Regular expression for selecting files to compute the hash. For example, for a Go project, you can use `go.mod` files to compute the cache, and then the value of this parameter is `pass:[**]/go.sum` (where `pass:[**]` accounts for subdirectories of any depth). | `array` |
|`TARGET` |Target URI for uploading the cache; use `{{hash}}` to specify the cache hash. The supported types are `oci` (example: `oci://quay.io/example-user/go-cache:{{hash}}`) and `s3` (example: `s3://example-bucket/{{hash}}`) | `string` |
|`CACHE_PATH` |Path for cache content, which the step packs into the image. Normally this path is in a workspace. | `string` |
|`WORKING_DIR` |Path where the files for calculating the hash are located. | `string` |
|`INSECURE` |If `"true"`, use insecure mode for uploading the cache. | `string` |`"false"`
|`FETCHED` |If `"true"`, the cache for this hash was already fetched. | `string` |`"false"`
|`FORCE_CACHE_UPLOAD` |If `"true"`, the step uploads the cache even if it was fetched previously. | `string` |`"false"`
|`GOOGLE_APPLICATION_CREDENTIALS` |The path where Google credentials are located. Ignored if empty. | `string` |
|`AWS_CONFIG_FILE` |Path to the AWS configuration file. Ignored if empty. | `string` |
|`AWS_SHARED_CREDENTIALS_FILE` |Path to the AWS credentials file. Ignored if empty. | `string` |
|`BLOB_QUERY_PARAMS` |Blob query parameters for configuring S3, GCS, or Azure. Use these optional parameters for additional features such as S3 acceleration, FIPS, or path-style addressing. | `string` |
|===

The `cache-upload` step action returns no results.
