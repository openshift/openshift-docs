[id="ipi-install-troubleshooting-post-install-pod-errors_{context}"]

= Post install Pod errors

Use the following procedure to troubleshoot `metal3` Pod errors during deployment.

.Procedure

. Retrieve the status for the `openshift-machine-api`:
+
[source,bash]
----
[kni@provisioner ~]$ oc get all -n openshift-machine-api
----
+
----
NAME                         READY   STATUS
pod/metal3-6c6cc7c56c-lj4lr  0/8     Init:CreateContainerConfigError
----
+
A `CreateContainerConfigError` occurs if there is no `ConfigMap`.
+
----
  Warning  Failed     <invalid> (x7 over 32s)  kubelet, master-1.<cluster-name>.example.com  Error: configmap "metal3-config" not found
----
+
Ensure the `metal3-config.yaml` file has a `ConfigMap` section. If there is no `metal3-config.yaml`, create one in the subsequent steps.

. Create the `metal3-config.yaml` file:
+
[source,yaml]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: metal3-config
  namespace: openshift-machine-api
data:
  cache_url: rhcos-43.81.202001142154.0-qemu.x86_64.qcow2.gz
  deploy_kernel_url: http://172.22.0.1:6180/images/ironic-python-agent.kernel
  deploy_ramdisk_url: http://172.22.0.1:6180/images/ironic-python-agent.initramfs
  dhcp_range: 172.22.0.10,172.22.0.100
  http_port: "6180"
  ironic_endpoint: http://172.22.0.1:6385/v1/
  ironic_inspector_endpoint: http://172.22.0.3:5050/v1/
  provisioning_interface: eno1
  provisioning_ip: 172.22.0.1/24
  rhcos_image_url: <URL-which-has-qcow-image>
----
+
*Note*: Change the `rhcos_image_url` to the appropriate URL for the
deployment environment.

. Place the `metal3-config.yaml` file in the `clusterconfigs/ocp/openshift` directory:
+
[source,bash]
----
[kni@provisioner ~]$ cp metal3-config.yaml clusterconfigs/ocp/openshift directory/99_metal3-config.yaml
----

. Re-run the installation.
+
[source,bash]
----
[kni@provisioner ~]$ /usr/local/bin/openshift-baremetal-install --dir /path/to/createcluster --log-level debug create cluster
----

. Export the `kubeconfig` file:
+
[source,bash]
----
[kni@provisioner ~]$ export KUBECONFIG=clusterconfigs/ocp/auth/kubeconfig
----


. Verify that all {product-title} nodes are up and running:
+
[source,bash]
----
[kni@provisioner ~]$ oc get nodes
----
+
----
NAME                                      STATUS   ROLES   AGE     VERSION
openshift-master-0.openshift.example.com  Ready    master  30h     v1.16.2
openshift-master-1.openshift.example.com  Ready    master  30h     v1.16.2
openshift-master-2.openshift.example.com  Ready    master  30h     v1.16.2
openshift-worker-0.openshift.example.com  Ready    worker  3m27s   v1.16.2
openshift-worker-1.openshift.example.com  Ready    worker  3m27s   v1.16.2
openshift-worker-2.openshift.example.com  Ready    worker  3m27s   v1.16.2
----

. If the installation fails again, review the `.openshift-install.log` files and proceed to the subsequent steps.

. Check if any of the {product-title} nodes are in a `NotReady` state:
+
[source,bash]
----
[kni@provisioner~]$ oc get nodes
----
+
----
NAME                                      STATUS   ROLES   AGE     VERSION
openshift-master-0.openshift.example.com  NotReady master  30h     v1.16.2
openshift-master-1.openshift.example.com  Ready    master  30h     v1.16.2
openshift-master-2.openshift.example.com  Ready    master  30h     v1.16.2
openshift-worker-0.openshift.example.com  Ready    worker  3m27s   v1.16.2
openshift-worker-1.openshift.example.com  Ready    worker  3m27s   v1.16.2
openshift-worker-2.openshift.example.com  Ready    worker  3m27s   v1.16.2

----

. Ensure the `kubelet` service is running on each Control Plane (master) node. For example:
+
[source,bash]
----
[kni@provisioner~]$ ssh core@openshift-master-x
----
+
[source,bash]
----
[core@openshift-master-x ~]$ sudo systemctl status kubelet
----
+
[NOTE]
====
Replace `master-x` with the appropriate hostname and node number.
====
+
----
● kubelet.service - Kubernetes Kubelet
   Loaded: loaded (/etc/systemd/system/kubelet.service; enabled; vendor preset: enabled)
  Drop-In: /etc/systemd/system/kubelet.service.d
           └─10-default-env.conf, 20-nodenet.conf
   Active: inactive (dead) since Tue 2020-03-10 16:05:14 UTC; 33s ago
 Main PID: 2358 (code=exited, status=0/SUCCESS)
      CPU: 3min 34.752s
----

. Start the `kubelet` service as needed:
+
[source,bash]
----
[core@openshift-master-x ~]$ sudo systemctl start kubelet
----
+
[source,bash]
----
[core@openshift-master-x ~]$ sudo systemctl status kubelet
----
+
----
● kubelet.service - Kubernetes Kubelet
   Loaded: loaded (/etc/systemd/system/kubelet.service; enabled; vendor preset: enabled)
  Drop-In: /etc/systemd/system/kubelet.service.d
           └─10-default-env.conf, 20-nodenet.conf
   Active: active (running) since Tue 2020-03-10 16:07:27 UTC; 4s ago
----

. Check the status of the nodes:
+
[source,bash]
----
[kni@provisioner~]$ oc get nodes
----
+
----
NAME                                      STATUS   ROLES   AGE     VERSION
openshift-master-0.openshift.example.com  Ready    master  30h     v1.16.2
openshift-master-1.openshift.example.com  Ready    master  30h     v1.16.2
openshift-master-2.openshift.example.com  Ready    master  30h     v1.16.2
openshift-worker-0.openshift.example.com  Ready    worker  3m27s   v1.16.2
openshift-worker-1.openshift.example.com  Ready    worker  3m27s   v1.16.2
openshift-worker-2.openshift.example.com  Ready    worker  3m27s   v1.16.2
----
