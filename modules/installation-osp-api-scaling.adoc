// Module included in the following assemblies:
//
// * networking/load-balancing-openstack.adoc

:_mod-docs-content-type: PROCEDURE
[id="installation-osp-api-scaling_{context}"]
= Scaling clusters by using Octavia

If you want to use multiple API load balancers, or if your cluster does not use Kuryr, create an Octavia load balancer and then configure your cluster to use it.

.Prerequisites

* Octavia is available on your {rh-openstack-first} deployment.

.Procedure

. From a command line, create an Octavia load balancer that uses the Amphora driver:
+
[source,terminal]
----
$ openstack loadbalancer create --name API_OCP_CLUSTER --vip-subnet-id <id_of_worker_vms_subnet>
----
+
You can use a name of your choice instead of `API_OCP_CLUSTER`.

. After the load balancer becomes active, create listeners:
+
[source,terminal]
----
$ openstack loadbalancer listener create --name API_OCP_CLUSTER_6443 --protocol HTTPS--protocol-port 6443 API_OCP_CLUSTER
----
+
[NOTE]
====
To view the status of the load balancer, enter `openstack loadbalancer list`.
====

. Create a pool that uses the round robin algorithm and has session persistence enabled:
+
[source,terminal]
----
$ openstack loadbalancer pool create --name API_OCP_CLUSTER_pool_6443 --lb-algorithm ROUND_ROBIN --session-persistence type=<source_IP_address> --listener API_OCP_CLUSTER_6443 --protocol HTTPS
----

. To ensure that control plane machines are available, create a health monitor:
+
[source,terminal]
----
$ openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type TCP API_OCP_CLUSTER_pool_6443
----

. Add the control plane machines as members of the load balancer pool:
+
[source,terminal]
----
$ for SERVER in $(MASTER-0-IP MASTER-1-IP MASTER-2-IP)
do
  openstack loadbalancer member create --address $SERVER  --protocol-port 6443 API_OCP_CLUSTER_pool_6443
done
----

. Optional: To reuse the cluster API floating IP address, unset it:
+
[source,terminal]
----
$ openstack floating ip unset $API_FIP
----

. Add either the unset `API_FIP` or a new address to the created load balancer VIP:
+
[source,terminal]
----
$ openstack floating ip set  --port $(openstack loadbalancer show -c <vip_port_id> -f value API_OCP_CLUSTER) $API_FIP
----

Your cluster now uses Octavia for load balancing.

[NOTE]
====
If Kuryr uses the Octavia Amphora driver, all traffic is routed through a single Amphora virtual machine (VM).

You can repeat this procedure to create additional load balancers, which can alleviate the bottleneck.
====
