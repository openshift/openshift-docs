// Module included in the following assemblies:
//
// * networking/hardware_networks/configuring-sriov-device.adoc

:_mod-docs-content-type: PROCEDURE
[id="nw-sriov-configure-exclude-topology-manager_{context}"]
= Excluding the SR-IOV network topology for NUMA-aware scheduling

To exclude advertising the SR-IOV network resource's Non-Uniform Memory Access (NUMA) node to the Topology Manager, you can configure the `excludeTopology` specification in the `SriovNetworkNodePolicy` custom resource. Use this configuration for more flexible SR-IOV network deployments during NUMA-aware pod scheduling.

.Prerequisites

* You have installed the OpenShift CLI (`oc`).
* You have configured the CPU Manager policy to `static`. For more information about CPU Manager, see the _Additional resources_ section.
* You have configured the Topology Manager policy to `single-numa-node`.
* You have installed the SR-IOV Network Operator.

.Procedure

. Create the `SriovNetworkNodePolicy` CR:

.. Save the following YAML in the `sriov-network-node-policy.yaml` file, replacing values in the YAML to match your environment:
+
[source,yaml]
----
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetworkNodePolicy
metadata:
  name: <policy_name>
  namespace: openshift-sriov-network-operator
spec:
  resourceName: sriovnuma0 <1>
  nodeSelector:
    kubernetes.io/hostname: <node_name>
  numVfs: <number_of_Vfs>
  nicSelector: <2>
    vendor: "<vendor_ID>"
    deviceID: "<device_ID>"
  deviceType: netdevice
  excludeTopology: true <3>
----
<1> The resource name of the SR-IOV network device plugin. This YAML uses a sample `resourceName` value.
<2> Identify the device for the Operator to configure by using the network interface controller (NIC selector).
<3> To exclude advertising the NUMA node for the SR-IOV network resource to the Topology Manager, set the value to `true`. The default value is `false`.
+
[NOTE]
====
If many `SriovNetworkNodePolicy` resources target the same SR-IOV network resource, the `SriovNetworkNodePolicy` resources must have the same value as the `excludeTopology` specification. Otherwise, the conflicting policy is rejected.
====
+
.. Create the `SriovNetworkNodePolicy` resource by running the following command. Successful output lists the name of the `SriovNetworkNodePolicy` resource and the `created` status.
+
[source,terminal]
----
$ oc create -f sriov-network-node-policy.yaml
----

. Create the `SriovNetwork` CR:
+
.. Save the following YAML in the `sriov-network.yaml` file, replacing values in the YAML to match your environment:
+
[source,yaml]
----
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetwork
metadata:
  name: sriov-numa-0-network <1>
  namespace: openshift-sriov-network-operator
spec:
  resourceName: sriovnuma0 <2>
  networkNamespace: <namespace> <3>
  ipam: |- <4>
    {
      "type": "<ipam_type>",
    }
----
<1> Replace `sriov-numa-0-network` with the name for the SR-IOV network resource.
<2> Specify the resource name for the `SriovNetworkNodePolicy` CR from the previous step. This YAML uses a sample `resourceName` value.
<3> Enter the namespace for your SR-IOV network resource.
<4> Enter the IP address management configuration for the SR-IOV network.
+
.. Create the `SriovNetwork` resource by running the following command. Successful output lists the name of the `SriovNetwork` resource and the `created` status.
+
[source,terminal]
----
$ oc create -f sriov-network.yaml
----

. Create a pod and assign the SR-IOV network resource from the previous step:
+
.. Save the following YAML in the `sriov-network-pod.yaml` file, replacing values in the YAML to match your environment:
+
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: <pod_name>
  annotations:
    k8s.v1.cni.cncf.io/networks: |-
      [
        {
          "name": "sriov-numa-0-network", <1>
        }
      ]
spec:
  containers:
  - name: <container_name>
    image: <image>
    imagePullPolicy: IfNotPresent
    command: ["sleep", "infinity"]
----
<1> This is the name of the `SriovNetwork` resource that uses the `SriovNetworkNodePolicy` resource.
+
.. Create the `Pod` resource by running the following command. The expected output shows the name of the `Pod` resource and the `created` status.
+
[source,terminal]
----
$ oc create -f sriov-network-pod.yaml
----

.Verification

. Verify the status of the pod by running the following command, replacing `<pod_name>` with the name of the pod:
+
[source,terminal]
----
$ oc get pod <pod_name>
----
+
.Example output
[source,terminal]
----
NAME                                     READY   STATUS    RESTARTS   AGE
test-deployment-sriov-76cbbf4756-k9v72   1/1     Running   0          45h
----

. Open a debug session with the target pod to verify that the SR-IOV network resources are deployed to a different node than the memory and CPU resources.
+
.. Open a debug session with the pod by running the following command, replacing <pod_name> with the target pod name.
+
[source,terminal]
----
$ oc debug pod/<pod_name>
----
+
..  Set `/host` as the root directory within the debug shell. The debug pod mounts the root file system from the host in `/host` within the pod. By changing the root directory to `/host`, you can run binaries from the host file system:
+
[source,terminal]
----
$ chroot /host
----
+
.. View information about the CPU allocation by running the following commands:
+
[source,terminal]
----
$ lscpu | grep NUMA
----
+

.Example output
[source,terminal]
----
NUMA node(s):                    2
NUMA node0 CPU(s):     0,2,4,6,8,10,12,14,16,18,...
NUMA node1 CPU(s):     1,3,5,7,9,11,13,15,17,19,...
----
+
[source,terminal]
----
$ cat /proc/self/status | grep Cpus
----
+
.Example output
[source,terminal]
----
Cpus_allowed:	ffff
Cpus_allowed_list:	1,3,5,7
----
+
The expected output shows the CPUs (1, 3, 5, and 7) that get allocated to a `NUMA` node, such as `NUMA node1`. The SR-IOV network resource can use the NIC from another `NUMA` node, such as `NUMA node0`. Note that the `ffff` hexadecimal value represents the CPU cores that run a process.  
+
[source,terminal]
----
$ cat  /sys/class/net/net1/device/numa_node
----
+
Expected output shows the number for the `NUMA` node, such as `0`.
+
[NOTE]
====
If you set the `excludeTopology` specification to `True`, the required resources might exist in the same NUMA node.
====
