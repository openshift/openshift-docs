// Module included in the following assemblies:
//
// * serverless/develop/serverless-event-sinks.adoc

:_content-type: PROCEDURE
[id="serverless-creating-a-kafka-event-sink_{context}"]

= Creating a Kafka event sink

As a developer, you can create an event sink to receive events from a particular source and send them to a Kafka topic. 

.Prerequisites
* You have installed the Red Hat OpenShift Serverless operator, with Knative Serving, Knative Eventing, and Knative Kafka APIs, from the Operator Hub.

* You have created a Kafka topic in your Kafka environment.

.Procedure
. In the *Developer* perspective, navigate to the *+Add* view.
. Click *Event Sink* in the *Eventing catalog*.
. Search for `KafkaSink` in the catalog items and click it.
. Click *Create Event Sink*.
. In the form view, type the URL of the bootstrap server, which is a combination of host name and port. 
+
image::create-event-sink.png[]

. Type the name of the topic to send event data.
. Type the name of the event sink.
. Click *Create*. 

.Verification
. In the *Developer* perspective, navigate to the *Topology* view.
. Click the created event sink to view its details in the right panel.
