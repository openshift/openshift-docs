// Module included in the following assemblies:
//
// * osd_install_access_delete_cluster/creating-a-gcp-cluster.adoc
// * osd_install_access_delete_cluster/creating-an-aws-cluster.adoc

ifeval::["{context}" == "osd-creating-a-cluster-on-aws"]
:osd-on-aws:
endif::[]
ifeval::["{context}" == "osd-creating-a-cluster-on-gcp"]
:osd-on-gcp:
endif::[]

:_mod-docs-content-type: PROCEDURE
ifdef::osd-on-aws[]
[id="osd-create-aws-cluster-ccs_{context}"]
= Creating a cluster on AWS with CCS
endif::osd-on-aws[]
ifdef::osd-on-gcp[]
[id="osd-create-gcp-cluster-ccs_{context}"]
= Creating a cluster on GCP with CCS
endif::osd-on-gcp[]

By using the Customer Cloud Subscription (CCS) billing model, you can create an {product-title} cluster in an existing
ifdef::osd-on-aws[]
{AWS}
endif::osd-on-aws[]
ifdef::osd-on-gcp[]
{GCP}
endif::osd-on-gcp[]
account that you own.

You must meet several prerequisites if you use the CCS model to deploy and manage {product-title} into your
ifdef::osd-on-aws[]
AWS
endif::osd-on-aws[]
ifdef::osd-on-gcp[]
GCP
endif::osd-on-gcp[]
account.

.Prerequisites

ifdef::osd-on-aws[]
* You have configured your AWS account for use with {product-title}.
* You have not deployed any services in your AWS account.
* You have configured the AWS account quotas and limits that are required to support the desired cluster size.
* You have an `osdCcsAdmin` AWS Identity and Access Management (IAM) user with the `AdministratorAccess` policy attached.
* You have set up a service control policy (SCP) in your AWS organization. For more information, see _Minimum required service control policy (SCP)_.
* Consider having *Business Support* or higher from AWS.
* If you are configuring a cluster-wide proxy, you have verified that the proxy is accessible from the VPC that the cluster is being installed into. The proxy must also be accessible from the private subnets of the VPC.
endif::osd-on-aws[]
ifdef::osd-on-gcp[]
* You have configured your GCP account for use with {product-title}.
* You have configured the GCP account quotas and limits that are required to support the desired cluster size.
* You have created a GCP project.
+
[NOTE]
====
The project name must be 10 characters or less.
====
* You have enabled the Google Cloud Resource Manager API in your GCP project. For more information about enabling APIs for your project, see link:https://cloud.google.com/endpoints/docs/openapi/enable-api[the Google Cloud documentation].
* You have an IAM service account in GCP called `osd-ccs-admin` with the following roles attached:
  ** Compute Admin
  ** DNS Administrator
  ** Security Admin
  ** Service Account Admin
  ** Service Account Key Admin
  ** Service Account User
  ** Organization Policy Viewer
  ** Service Management Administrator
  ** Service Usage Admin
  ** Storage Admin
* You have created a key for your `osd-ccs-admin` GCP service account and exported it to a file named `osServiceAccount.json`.
+
[NOTE]
====
For more information about creating a key for your GCP service account and exporting it to a JSON file,  see link:https://cloud.google.com/iam/docs/creating-managing-service-account-keys#creating_service_account_keys[Creating service account keys] in the Google Cloud documentation.
====
* Consider having *Production Support* or higher from GCP.
* To prevent potential conflicts, consider having no other resources provisioned in the project prior to installing {product-title}.
* If you are configuring a cluster-wide proxy, you have verified that the proxy is accessible from the VPC that the cluster is being installed into.
endif::osd-on-gcp[]

.Procedure

. Log in to {cluster-manager-url} and click *Create cluster*.

. On the *Create an OpenShift cluster* page, select *Create cluster* in the *Red Hat OpenShift Dedicated* row.

. Under *Billing model*, configure the subscription type and infrastructure type:
.. Select a subscription type. For information about {product-title} subscription options, see link:https://access.redhat.com/documentation/en-us/openshift_cluster_manager/2022/html-single/managing_clusters/index#subscribing-osd-cluster_assembly-cluster-subscriptions[Managing OpenShift Dedicated cluster subscriptions] in the {cluster-manager} documentation.
+
[NOTE]
====
The subscription types that are available to you depend on your {product-title} subscriptions and resource quotas. For more information, contact your sales representative or Red Hat support.
====
+
.. Select the *Customer Cloud Subscription* infrastructure type to deploy {product-title} in an existing cloud provider account that you own.
.. Click *Next*.

ifdef::osd-on-aws[]
. Select *Run on Amazon Web Services*.
endif::osd-on-aws[]
ifdef::osd-on-gcp[]
. Select *Run on Google Cloud Platform*.
endif::osd-on-gcp[]

. After selecting your cloud provider, review and complete the listed *Prerequisites*. Select the checkbox to acknowledge that you have read and completed all of the prerequisites.

ifdef::osd-on-aws[]
. Provide your AWS account details:
.. Enter your *AWS account ID*.
.. Enter your *AWS access key ID* and *AWS secret access key* for your AWS IAM user account.
+
[NOTE]
====
Revoking these credentials in AWS results in a loss of access to any cluster created with these credentials.
====
.. Optional: You can select *Bypass AWS service control policy (SCP) checks* to disable the SCP checks.
+
[NOTE]
====
Some AWS SCPs can cause the installation to fail, even if you have the required permissions. Disabling the SCP checks allows an installation to proceed. The SCP is still enforced even if the checks are bypassed.
====
endif::osd-on-aws[]
ifdef::osd-on-gcp[]
. Provide your GCP service account private key in JSON format. You can either click *Browse* to locate and attach a JSON file or add the details in the *Service account JSON* field.
endif::osd-on-gcp[]

. Click *Next* to validate your cloud provider account and go to the *Cluster details* page.

. On the *Cluster details* page, provide a name for your cluster and specify the cluster details:
.. Add a *Cluster name*.
.. Select a cluster version from the *Version* drop-down menu.
.. Select a cloud provider region from the *Region* drop-down menu.
.. Select a *Single zone* or *Multi-zone* configuration.
.. Leave *Enable user workload monitoring* selected to monitor your own projects in isolation from Red Hat Site Reliability Engineer (SRE) platform metrics. This option is enabled by default.
ifdef::osd-on-gcp[]
. Optional: Expand *Advanced Encryption* to make changes to encryption settings.

.. Select *Use Custom KMS keys* to use custom KMS keys. If you prefer not to use custom KMS keys, leave the default setting *Use default KMS Keys*.
+
[IMPORTANT]
====
To use custom KMS keys, the IAM service account `osd-ccs-admin` must be granted the *Cloud KMS CryptoKey Encrypter/Decrypter* role. For more information about granting roles on a resource, see link:https://cloud.google.com/kms/docs/iam#granting_roles_on_a_resource[Granting roles on a resource].
====
+
With *Use Custom KMS keys* selected:

... Select a key ring location from the *Key ring location* drop-down menu.
... Select a key ring from the *Key ring* drop-down menu.
... Select a key name from the *Key name* drop-down menu.
... Provide the *KMS Service Account*.
+
endif::osd-on-gcp[]
.. Optional: Select *Enable additional etcd encryption* if you require etcd key value encryption. With this option, the etcd key values are encrypted, but not the keys. This option is in addition to the control plane storage encryption that encrypts the etcd volumes in {product-title} clusters by default.
+
[NOTE]
====
By enabling etcd encryption for the key values in etcd, you will incur a performance overhead of approximately 20%. The overhead is a result of introducing this second layer of encryption, in addition to the default control plane storage encryption that encrypts the etcd volumes. Consider enabling etcd encryption only if you specifically require it for your use case.
====
+
ifdef::osd-on-gcp[]
.. Optional: Select *Enable FIPS cryptography* if you require your cluster to be FIPS validated.
endif::osd-on-gcp[]
ifdef::osd-on-aws[]
.. Optional: Select *Encrypt persistent volumes with customer keys* if you want to provide your own
AWS Key Management Service (KMS) key Amazon Resource Name (ARN).
// ifdef::osd-on-gcp[]
// encryption keys through the Google Cloud Key Management Service.
// endif::osd-on-gcp[]
The key is used for encrypting all control plane, infrastructure, worker node root volumes, and persistent volumes in your cluster.
+
[IMPORTANT]
====
Only persistent volumes (PVs) created from the default storage class are encrypted with this specific key.

PVs created by using any other storage class are still encrypted, but the PVs are not encrypted with this key unless the storage class is specifically configured to use this key.
====
endif::osd-on-aws[]
.. Click *Next*.

. On the *Default machine pool* page, select a *Compute node instance type* and a *Compute node count*. The number and types of nodes that are available depend on your {product-title} subscription. If you are using multiple availability zones, the compute node count is per zone.
+
[NOTE]
====
After your cluster is created, you can change the number of compute nodes in your cluster, but you cannot change the compute node instance type in a machine pool. The number and types of nodes available to you depend on your {product-title} subscription.
====

ifdef::osd-on-aws[]
. Choose your preference for the Instance Metadata Service (IMDS) type, either using both IMDSv1 and IMDSv2 types or requiring your EC2 instances to use only IMDSv2. You can access instance metadata from a running instance in two ways:
+
* Instance Metadata Service Version 1 (IMDSv1) - a request/response method
* Instance Metadata Service Version 2 (IMDSv2) - a session-oriented method
+
[IMPORTANT]
====
The Instance Metadata Service settings cannot be changed after your cluster is created.
====
+
[NOTE]
====
IMDSv2 uses session-oriented requests. With session-oriented requests, you create a session token that defines the session duration, which can range from a minimum of one second to a maximum of six hours. During the specified duration, you can use the same session token for subsequent requests. After the specified duration expires, you must create a new session token to use for future requests.
====
+
For more information regarding IMDS, see link:https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html[Instance metadata and user data] in the AWS documentation.
endif::osd-on-aws[]

. Optional: Expand *Edit node labels* to add labels to your nodes. Click *Add label* to add more node labels and select *Next*.

. On the *Network configuration* page, select *Public* or *Private* to use either public or private API endpoints and application routes for your cluster.
+
[IMPORTANT]
====
If you are using private API endpoints, you cannot access your cluster until you update the network settings in your cloud provider account.
====

ifdef::osd-on-aws[]
. Optional: To install the cluster in an existing AWS Virtual Private Cloud (VPC):
.. Select *Install into an existing VPC*.
.. If you are installing into an existing VPC and opted to use private API endpoints, you can select *Use a PrivateLink*. This option enables connections to the cluster by Red Hat Site Reliability Engineering (SRE) using only AWS PrivateLink endpoints.
+
[NOTE]
====
The *Use a PrivateLink* option cannot be changed after a cluster is created.
====
+
.. If you are installing into an existing VPC and you want to enable an HTTP or HTTPS proxy for your cluster, select *Configure a cluster-wide proxy*.
endif::osd-on-aws[]

ifdef::osd-on-gcp[]
. Optional: To install the cluster in an existing GCP Virtual Private Cloud (VPC):
.. Select *Install into an existing VPC*.
.. If you are installing into an existing VPC and you want to enable an HTTP or HTTPS proxy for your cluster, select *Configure a cluster-wide proxy*.
endif::osd-on-gcp[]
+
. Click *Next*.

ifdef::osd-on-gcp[]
. Optional: To install the cluster into a GCP Shared VPC:
+
[IMPORTANT]
====

To install a cluster into a Shared VPC, you must use {product-title} version 4.13.15 or above. Additionally, the VPC owner of the host project must enable a project as a host project in their Google Cloud console. For more information, see link:https://cloud.google.com/vpc/docs/provisioning-shared-vpc#set-up-shared-vpc[Enable a host project].
====

.. Select *Install into GCP Shared VPC*.
.. Specify the *Host project ID*. If the specified host project ID is incorrect, cluster creation fails.
+
[IMPORTANT]
====
Once you complete the steps within the cluster configuration wizard and click *Create Cluster*, the cluster will go into the "Installation Waiting" state. At this point, you must contact the VPC owner of the host project, who must assign the dynamically-generated service account the following roles: *Computer Network Administrator*, *Compute Security Administrator*, and *DNS Administrator*.
The VPC owner of the host project has 30 days to grant the listed permissions before the cluster creation fails.
For information about Shared VPC permissions, see link:https://cloud.google.com/vpc/docs/provisioning-shared-vpc#migs-service-accounts[Provision Shared VPC].
====
endif::osd-on-gcp[]
+
. If you opted to install the cluster in an existing
ifdef::osd-on-aws[]
AWS
endif::osd-on-aws[]
ifdef::osd-on-gcp[]
GCP
endif::osd-on-gcp[]
VPC, provide your *Virtual Private Cloud (VPC) subnet settings* and select *Next*.
You must have created the Cloud network address translation (NAT) and a Cloud router. See the additional resources for information about Cloud NATs and Google VPCs.
ifdef::osd-on-aws[]
+
[NOTE]
====
You must ensure that your VPC is configured with a public and a private subnet for each availability zone that you want the cluster installed into. If you opted to use PrivateLink, only private subnets are required.
====
endif::osd-on-aws[]
ifdef::osd-on-gcp[]
+
[NOTE]
====
If you are installing a cluster into a Shared VPC, the VPC name and subnets are shared from the host project.
====
endif::osd-on-gcp[]
. If you opted to configure a cluster-wide proxy, provide your proxy configuration details on the *Cluster-wide proxy* page:
+
--
.. Enter a value in at least one of the following fields:
** Specify a valid *HTTP proxy URL*.
** Specify a valid *HTTPS proxy URL*.
** In the *Additional trust bundle* field, provide a PEM encoded X.509 certificate bundle. The bundle is added to the trusted certificate store for the cluster nodes. An additional trust bundle file is required unless the identity certificate for the proxy is signed by an authority from the {op-system-first} trust bundle.
+
If you use an MITM transparent proxy network that does not require additional proxy configuration but requires additional certificate authorities (CAs), you must provide the MITM CA certificate.
+
[NOTE]
====
If you upload an additional trust bundle file without specifying an HTTP or HTTPS proxy URL, the bundle is set on the cluster but is not configured to be used with the proxy.
====
.. Click *Next*.
--
+
For more information about configuring a proxy with {product-title}, see _Configuring a cluster-wide proxy_.

. In the *CIDR ranges* dialog, configure custom classless inter-domain routing (CIDR) ranges or use the defaults that are provided.
+
[NOTE]
====
If you are installing into a VPC, the *Machine CIDR* range must match the VPC subnets.
====
+
[IMPORTANT]
====
CIDR configurations cannot be changed later. Confirm your selections with your network administrator before proceeding.
====

. On the *Cluster update strategy* page, configure your update preferences:
.. Choose a cluster update method:
** Select *Individual updates* if you want to schedule each update individually. This is the default option.
** Select *Recurring updates* to update your cluster on your preferred day and start time, when updates are available.
+
[NOTE]
====
You can review the end-of-life dates in the update life cycle documentation for {product-title}. For more information, see _{product-title} update life cycle_.
====
+
.. Provide administrator approval based on your cluster update method:
** Individual updates: If you select an update version that requires approval, provide an administrator’s acknowledgment and click *Approve and continue*.
** Recurring updates: If you selected recurring updates for your cluster, provide an administrator’s acknowledgment and click *Approve and continue*. {cluster-manager} does not start scheduled y-stream updates for minor versions without receiving an administrator’s acknowledgment.
+
For information about administrator acknowledgment, see xref:./../upgrading/osd-upgrading-cluster-prepare.adoc#upgrade-49-acknowledgement_osd-updating-cluster-prepare[Administrator acknowledgment when upgrading to OpenShift 4.9].
.. If you opted for recurring updates, select a preferred day of the week and upgrade start time in UTC from the drop-down menus.
.. Optional: You can set a grace period for *Node draining* during cluster upgrades. A *1 hour* grace period is set by default.
.. Click *Next*.
+
[NOTE]
====
In the event of critical security concerns that significantly impact the security or stability of a cluster, Red Hat Site Reliability Engineering (SRE) might schedule automatic updates to the latest z-stream version that is not impacted. The updates are applied within 48 hours after customer notifications are provided. For a description of the critical impact security rating, see link:https://access.redhat.com/security/updates/classification[Understanding Red Hat security ratings].
====

. Review the summary of your selections and click *Create cluster* to start the cluster installation. The installation takes approximately 30-40 minutes to complete.
+
ifdef::osd-on-gcp[]
[NOTE]
====
If you delete a cluster that was installed into a GCP Shared VPC, inform the VPC owner of the host project to remove the IAM policy roles granted to the service account that was referenced during cluster creation.
====
endif::osd-on-gcp[]

.Verification

* You can monitor the progress of the installation in the *Overview* page for your cluster. You can view the installation logs on the same page. Your cluster is ready when the *Status* in the *Details* section of the page is listed as *Ready*.

ifeval::["{context}" == "osd-creating-a-cluster-on-aws"]
:!osd-on-aws:
endif::[]
ifeval::["{context}" == "osd-creating-a-cluster-on-gcp"]
:!osd-on-gcp:
endif::[]
