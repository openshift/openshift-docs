// Module included in the following assemblies:

// * networking/network_observability/installing-operators.adoc

:_content-type: PROCEDURE
[id="network-observability-operator-installation_{context}"]
= Installing the Network Observability Operator
You can install the Network Observability Operator using the {product-title} web console Operator Hub. When you install the Operator,  it provides the `FlowCollector` custom resource definition (CRD). You can set specifications in the web console when you create the  `FlowCollector`.

.Prerequisites

* Installed Loki. It is recommended to install Loki using the link:https://catalog.redhat.com/software/containers/openshift-logging/loki-rhel8-operator/622b46bcae289285d6fcda39[Loki Operator version 5.6].

[NOTE]
====
This documentation assumes that your `LokiStack` instance name is `loki`. Using a different name requires additional configuration.
====

.Procedure

. In the {product-title} web console, click *Operators* -> *OperatorHub*.
//In the Operator Hub on the test console Julian provided perms for, its NetObserv Operator, with a capital O.
. Choose  *Network Observability Operator* from the list of available Operators in the *OperatorHub*, and click *Install*.
. Select the checkbox `Enable Operator recommended cluster monitoring on this Namespace`.
. Navigate to *Operators* -> *Installed Operators*. Under Provided APIs for Network Observability, select the *Flow Collector* link.
.. Navigate to the *Flow Collector* tab, and click *Create FlowCollector*. Make the following selections in the form view:
+
* *spec.agent.ebpf.Sampling* : Specify a sampling size for flows. Lower sampling sizes will have higher impact on resource utilization. For more information, see the `FlowCollector` API reference, under spec.agent.ebpf.
* *spec.deploymentModel*: If you are using Kafka, verify Kafka is selected.
* *spec.exporters*: If you are using Kafka, you can optionally send network flows to Kafka, so that they can be consumed by any processor or storage that supports Kafka input, such as Splunk, Elasticsearch, or Fluentd. To do this, set the following specifications:
** Set the *type* to `KAFKA`.
** Set the *address* as `kafka-cluster-kafka-bootstrap.netobserv`.
** Set the *topic* as `netobserv-flows-export`. The Operator exports all flows to the configured Kafka topic.
** Set the following *tls* specifications:
*** *certFile*: `service-ca.crt`, *name*: `kafka-gateway-ca-bundle`, and *type*: `configmap`.
+
You can also configure this option at a later time by directly editing the YAML. For more information, see _Export enriched network flow data_.
* *loki.url*: Since authentication is specified separately, this URL needs to be updated to `https://loki-gateway-http.netobserv.svc:8080/api/logs/v1/network`. The first part of the URL, "loki", should match the name of your LokiStack.
* *loki.statusUrl*: Set this to `https://loki-query-frontend-http.netobserv.svc:3100/`. The first part of the URL, "loki", should match the name of your LokiStack.
* *loki.authToken*: Select the `FORWARD` value.
* *tls.enable*: Verify that the box is checked so it is enabled.
* *statusTls*: The `enable` value is false by default.
+
For the first part of the certificate reference names: `loki-gateway-ca-bundle`, `loki-ca-bundle`, and `loki-query-frontend-http`,`loki`, should match the name of your `LokiStack`.
.. Click *Create*.

.Verification

To confirm this was successful, when you navigate to *Observe* you should see *Network Traffic* listed in the options.

In the absence of *Application Traffic* within the {product-title} cluster, default filters might show that there are "No results", which results in no visual flow. Beside the filter selections, select *Clear all filters* to see the flow.

[IMPORTANT]
====
If you installed Loki using the Loki Operator, it is advised not to use `querierUrl`, as it can break the console access to Loki. If you installed Loki using another type of Loki installation, this does not apply.
====

