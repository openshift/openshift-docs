// Module included in the following assemblies:
//
// * nodes/nodes-containers-projected-volumes.adoc

[id="nodes-containers-projected-volumes-about_{context}"]
= Understanding projected volumes

Projected volumes can map any combination of these volume sources into a single directory, allowing the user to:

* automatically populate a single volume with the keys from multiple secrets, config maps, and with downward API information,
so that I can synthesize a single directory with various sources of information;
* populate a single volume with the keys from multiple secrets, config maps, and with downward API information,
explicitly specifying paths for each item, so that I can have full control over the contents of that volume.

The following general scenarios show how you can use projected volumes.

*Config map, secrets, Downward API.*::
Projected volumes allow you to deploy containers with configuration data that includes passwords.
An application using these resources could be deploying {rh-openstack-first} on Kubernetes. The configuration data might have to be assembled differently depending on if the services are going to be used for production or for testing. If a pod is labeled with production or testing, the downward API selector `metadata.labels` can be used to produce the correct {rh-openstack} configs.

*Config map + secrets.*::
Projected volumes allow you to deploy containers involving configuration data and passwords.
For example, you might execute a config map with some sensitive encrypted tasks that are decrypted using a vault password file.

*ConfigMap + Downward API.*::
Projected volumes allow you to generate a config including the pod name (available via the `metadata.name` selector). This application can then pass the pod name along with requests to easily determine the source without using IP tracking.

*Secrets + Downward API.*::
Projected volumes allow you to use a secret as a public key to encrypt the namespace of the pod (available via the `metadata.namespace` selector).
This example allows the Operator to use the application to deliver the namespace information securely without using an encrypted transport.

[id="projected-volumes-examples_{context}"]
== Example Pod specs

The following are examples of `Pod` specs for creating projected volumes.

.Pod with a secret, a Downward API, and a config map

[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: volume-test
spec:
  containers:
  - name: container-test
    image: busybox
    volumeMounts: <1>
    - name: all-in-one
      mountPath: "/projected-volume"<2>
      readOnly: true <3>
  volumes: <4>
  - name: all-in-one <5>
    projected:
      defaultMode: 0400 <6>
      sources:
      - secret:
          name: mysecret <7>
          items:
            - key: username
              path: my-group/my-username <8>
      - downwardAPI: <9>
          items:
            - path: "labels"
              fieldRef:
                fieldPath: metadata.labels
            - path: "cpu_limit"
              resourceFieldRef:
                containerName: container-test
                resource: limits.cpu
      - configMap: <10>
          name: myconfigmap
          items:
            - key: config
              path: my-group/my-config
              mode: 0777 <11>
----

<1> Add a `volumeMounts` section for each container that needs the secret.
<2> Specify a path to an unused directory where the secret will appear.
<3> Set `readOnly` to `true`.
<4> Add a `volumes` block to list each projected volume source.
<5> Specify any name for the volume.
<6> Set the execute permission on the files.
<7> Add a secret. Enter the name of the secret object. Each secret you want to use must be listed.
<8> Specify the path to the secrets file under the `mountPath`. Here, the secrets file is in *_/projected-volume/my-group/my-username_*.
<9> Add a Downward API source.
<10> Add a ConfigMap source.
<11> Set the mode for the specific projection

[NOTE]
====
If there are multiple containers in the pod, each container needs a `volumeMounts` section, but only one `volumes` section is needed.
====


.Pod with multiple secrets with a non-default permission mode set

[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: volume-test
spec:
  containers:
  - name: container-test
    image: busybox
    volumeMounts:
    - name: all-in-one
      mountPath: "/projected-volume"
      readOnly: true
  volumes:
  - name: all-in-one
    projected:
      defaultMode: 0755
      sources:
      - secret:
          name: mysecret
          items:
            - key: username
              path: my-group/my-username
      - secret:
          name: mysecret2
          items:
            - key: password
              path: my-group/my-password
              mode: 511
----

[NOTE]
====
The `defaultMode` can only be specified at the projected level and not for each
volume source. However, as illustrated above, you can explicitly set the `mode`
for each individual projection.
====

[id="projected-volumes-pathing_{context}"]
== Pathing Considerations

*Collisions Between Keys when Configured Paths are Identical*:: If you configure any keys with the same path, the pod spec will not be accepted as valid.
In the following example, the specified path for `mysecret` and `myconfigmap` are the same:
+
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: volume-test
spec:
  containers:
  - name: container-test
    image: busybox
    volumeMounts:
    - name: all-in-one
      mountPath: "/projected-volume"
      readOnly: true
  volumes:
  - name: all-in-one
    projected:
      sources:
      - secret:
          name: mysecret
          items:
            - key: username
              path: my-group/data
      - configMap:
          name: myconfigmap
          items:
            - key: config
              path: my-group/data
----

Consider the following situations related to the volume file paths.

*Collisions Between Keys without Configured Paths*:: The only run-time validation that can occur is when all the paths are known at pod creation, similar to the above scenario. Otherwise, when a conflict occurs the most recent specified resource will overwrite anything preceding it
(this is true for resources that are updated after pod creation as well).

*Collisions when One Path is Explicit and the Other is Automatically Projected*:: In the event that there is a collision due to a user specified path matching data that is automatically projected,
the latter resource will overwrite anything preceding it as before.

[id="file-permission-handling-for-windows-pods_{context}"]
== File permission handling for Windows pods

When the `RunAsUser` permission is set in the security context of a Linux-based pod, the projected files have the correct permissions set, including container user ownership. However, this is not the case for Windows pods. When the Windows equivalent `RunAsUsername` permission is set, the kubelet is prevented from setting correct ownership on the files in the projected volume. This is due to differences in the way user accounts are managed in Windows. Windows stores and manages local user and group accounts in a database file called Security Account Manager (SAM). This database is not shared between the Windows container host and the running containers.

[NOTE]
====
{product-title} applies the `RunAsUser` security context to all pods irrespective of its operating system. This means Windows pods automatically have the `RunAsUser` permission applied to its security context.
====

This problem can get exacerbated when used in conjunction with a hostPath volume where best practices are not followed. For example, giving a pod access to the `C:\var\lib\kubelet\pods\` folder results in that pod being able to access service account tokens from other pods.

By default, the projected files will have the following ownership, as shown for an example Windows projected volume file:

[source,posh]
----
Path   : Microsoft.PowerShell.Core\FileSystem::C:\var\run\secrets\kubernetes.io\serviceaccount\..2021_08_31_22_22_18.318230061\ca.crt
Owner  : BUILTIN\Administrators
Group  : NT AUTHORITY\SYSTEM
Access : NT AUTHORITY\SYSTEM Allow  FullControl
         BUILTIN\Administrators Allow  FullControl
         BUILTIN\Users Allow  ReadAndExecute, Synchronize
Audit  :
Sddl   : O:BAG:SYD:AI(A;ID;FA;;;SY)(A;ID;FA;;;BA)(A;ID;0x1200a9;;;BU)
----

This indicates all administrator users, like someone with the `ContainerAdministrator` role, have read, write, and execute access, while non-administrator users have read and execute access.

Creating a Windows pod with the `RunAsUser` and `RunAsUsername` permissions in its security context with a projected volume results in the pod being stuck in the `ContainerCreating` phase. To handle this scenario, {product-title} forces the file permission handling in projected service account volumes set in the security context of the pod to not be honored for projected volumes on Windows. (link:https://bugzilla.redhat.com/show_bug.cgi?id=1971745[BZ#1971745]). Note that this behavior for Windows pods is how file permission handling used to work for all pod types prior to {product-title} 4.7.
