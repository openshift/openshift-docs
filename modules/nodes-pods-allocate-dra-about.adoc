// Module included in the following assemblies:
//
// * nodes/nodes-pods-allocate-dra.adoc

:_mod-docs-content-type: CONCEPT
[id="nodes-pods-allocate-dra-about_{context}"]
= About GPU attributes

// Taken from https://issues.redhat.com/browse/OCPSTRAT-1756
[role="_abstract"]
You can use {attribute-based-full} to enable pods to be scheduled on nodes that have specific graphics processing units (GPU). These attributes are advertised to the cluster by using a Dynamic Resource Allocation (DRA) driver, a third-party application that runs on each node in your cluster. 

The DRA driver manages and exposes specialized resources within your cluster by interacting with the underlying hardware and advertising it to the {product-title} control plane. You must install a DRA driver in your cluster. Installation of the DRA driver is beyond the scope of this documentation. Some DRA device drivers can also slice GPU memory, making it available to multiple workloads.

The DRA driver advertises several GPU device attributes that {product-title} can use for precise GPU selection, including the following attributes:

Product Name::
Pods can request an exact GPU model based on performance requirements or compatibility with applications. This ensures that workloads leverage the best-suited hardware for their tasks.

GPU Memory Capacity::
Pods can request GPUs with a minimum or maximum memory capacity, such as 8 GB, 16 GB, or 40 GB. This is helpful with memory-intensive workloads such as large AI model training or data processing. This attribute enables applications to allocate GPUs that meet memory needs without overcommitting or underutilizing resources.

Compute Capability::
Pods can request GPUs based on the compute capabilities of the GPU, such as the CUDA versions supported. Pods can target GPUs that are compatible with the applicationâ€™s framework and leverage optimized processing capabilities.

Power and Thermal Profiles:: 
Pods can request GPUs based on power usage or thermal characteristics, enabling power-sensitive or temperature-sensitive applications to operate efficiently. This is particularly useful in high-density environments where energy or cooling constraints are factors.

Device ID and Vendor ID:: 
Pods can request GPUs based on the GPU's hardware specifics, which allows applications that require specific vendors or device types to make targeted requests.

Driver Version:: 
Pods can request GPUs that run a specific driver version, ensuring compatibility with application dependencies and maximizing GPU feature access.
