// Module is included in the following assemblies:
//
// 
:_mod-docs-content-type: PROCEDURE
[id="installing-logging-operator-cli_{context}"]
= Installing {clo} by using the CLI

Install {clo} on your {product-title} cluster to collect and forward logs to a log store by using the {oc-first}.

.Prerequisites

* You have administrator permissions.
* You installed the {oc-first}.
* You installed and configured {loki-op}.
* You have created the `openshift-logging` namespace.

.Procedure

. Create an `OperatorGroup` object:
+
.Example `OperatorGroup` object
[source,yaml]
----
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: cluster-logging
  namespace: openshift-logging # <1>
spec:
  upgradeStrategy: Default
----
<1> You must specify `openshift-logging` as the namespace.

. Apply the `OperatorGroup` object by running the following command:
+
[source,terminal]
----
$ oc apply -f <filename>.yaml
----

. Create a `Subscription` object for {clo}:
+
.Example `Subscription` object
[source,yaml]
----
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: cluster-logging
  namespace: openshift-logging # <1>
spec:
  channel: stable-6.<y> # <2>
  installPlanApproval: Automatic # <3>
  name: cluster-logging
  source: redhat-operators # <4>
  sourceNamespace: openshift-marketplace
----
<1> You must specify `openshift-logging` as the namespace.
<2> Specify `stable-6.<y>` as the channel.
<3> If the approval strategy in the subscription is set to `Automatic`, the update process initiates as soon as a new operator version is available in the selected channel. If the approval strategy is set to `Manual`, you must manually approve pending updates.
<4> Specify `redhat-operators` as the value. If your {product-title} cluster is installed on a restricted network, also known as a disconnected cluster, specify the name of the `CatalogSource` object that you created when you configured Operator Lifecycle Manager (OLM).

. Apply the `Subscription` object by running the following command:
+
[source,terminal]
----
$ oc apply -f <filename>.yaml
----

. Create a service account to be used by the log collector:
+
[source,terminal]
----
$ oc create sa logging-collector -n openshift-logging
----

. Assign the necessary permissions to the service account for the collector to be able to collect and forward logs. In this example, the collector is provided permissions to collect logs from both infrastructure and application logs.
+
[source,terminal]
----
$ oc adm policy add-cluster-role-to-user logging-collector-logs-writer -z logging-collector -n openshift-logging
$ oc adm policy add-cluster-role-to-user collect-application-logs -z logging-collector -n openshift-logging
$ oc adm policy add-cluster-role-to-user collect-infrastructure-logs -z logging-collector -n openshift-logging
----

. Create a `ClusterLogForwarder` CR:
+
.Example `ClusterLogForwarder` CR
[source,yaml]
----
apiVersion: observability.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging # <1>
spec:
  serviceAccount:
    name: logging-collector # <2>
  outputs:
  - name: lokistack-out
    type: lokiStack # <3>
    lokiStack:
      target: # <4>
        name: logging-loki 
        namespace: openshift-logging
      authentication:
        token:
          from: serviceAccount
    tls:
      ca:
        key: service-ca.crt
        configMapName: openshift-service-ca.crt
  pipelines:
  - name: infra-app-logs
    inputRefs: # <5>
    - application
    - infrastructure
    outputRefs:
    - lokistack-out
----
<1> You must specify the `openshift-logging` namespace.
<2> Specify the name of the service account created before.
<3> Select the `lokiStack` output type to send logs to the `LokiStack` instance.
<4> Point the `ClusterLogForwarder` to the `LokiStack` instance created earlier.
<5> Select the log output types you want to send to the `LokiStack` instance.

. Apply the `ClusterLogForwarder CR` object by running the following command:
+
[source,terminal]
----
$ oc apply -f <filename>.yaml
----

.Verification

. Verify the installation by running the following command:
+
[source,terminal]
----
$ oc get pods -n openshift-logging
----
+
.Example output
[source,terminal]
----
$ oc get pods -n openshift-logging
NAME                                               READY   STATUS    RESTARTS   AGE
cluster-logging-operator-fb7f7cf69-8jsbq           1/1     Running   0          98m
instance-222js                                     2/2     Running   0          18m
instance-g9ddv                                     2/2     Running   0          18m
instance-hfqq8                                     2/2     Running   0          18m
instance-sphwg                                     2/2     Running   0          18m
instance-vv7zn                                     2/2     Running   0          18m
instance-wk5zz                                     2/2     Running   0          18m
logging-loki-compactor-0                           1/1     Running   0          42m
logging-loki-distributor-7d7688bcb9-dvcj8          1/1     Running   0          42m
logging-loki-gateway-5f6c75f879-bl7k9              2/2     Running   0          42m
logging-loki-gateway-5f6c75f879-xhq98              2/2     Running   0          42m
logging-loki-index-gateway-0                       1/1     Running   0          42m
logging-loki-ingester-0                            1/1     Running   0          42m
logging-loki-querier-6b7b56bccc-2v9q4              1/1     Running   0          42m
logging-loki-query-frontend-84fb57c578-gq2f7       1/1     Running   0          42m
----
