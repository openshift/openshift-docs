// Module included in the following assemblies:
//
// * logging/cluster-logging-curator.adoc

[id="configuration-cronjob_{context}"]
= Modifying the Curator configuration

You can configure the Curator cron schedule using the `ClusterLogging` custom resource
created by the Cluster Logging Operator installation.
The Cluster Logging Operator creates a ConfigMap with default configuration options,
which you can further modify.

You can edit or replace this ConfigMap to reconfigure Curator.

[NOTE]
====
Any `.operations` configurations are in the same location as your application logs configurations.
====

.Prerequisite

* Cluster logging must be installed.

.Procedure

. To configure Curator, edit the `curator` ConfigMap in the `openshift-logging` project:
+
----
$ oc edit configmap/curator
----
+
[source,yaml]
----
client:
  hosts:
    - 127.0.0.1 <1>
  port: 9200  <2>
  url_prefix: <3>
  use_ssl: False <4>
  certificate: <5>
  client_cert: <6>
  client_key: <7>
  ssl_no_validate: False <8>
  http_auth: <9>
  timeout: 30  <10>
  master_only: False <11>
----
<1> Specify the hosts where Curator will run.
<2> Specify the port number of the Elasticsearch cluster, by default 9200.
<3> Optionally, specify a url_prefix to the appropriate value, if needed. For example, if you connect to your Elasticsearch cluster through a proxy and need a URL as opposed to http://localhost:9200.
<4> Optionally, specify `True`, 'False` or left empty. If access to your Elasticsearch instance is protected by SSL encryption, set to `True`.
<5> Optionally, specify a file path to your CA certificate, in single quotes, to validate the SSL certificate used by Elasticsearch or leave empty.
<6> Optionally, specify a file path to an SSL client cert file to authenticate to Elasticsearch. The file may contain both an SSL client certificate and an SSL key, in which case client_key is not used. If specifying client_cert, and the file specified does not also contain the key, use client_key to specify the file containing the SSL key. The file must be in PEM format, and the key part, if used, must be an unencrypted key in PEM format as well. Leave empty if not using a SSL client cert.
<7> Optionally, specify an SSL client key file to authenticate to Elasticsearch. If using client_cert and the file specified does not also contain the key, use client_key to specify the file containing the SSL key. The key file must be an unencrypted key in PEM format. Leave empty if not using a SSL client cert.
<8> Set to `True` to disable SSL certificate verification. Setting ssl_no_validate to True will likely result in a warning message that your SSL certificates are not trusted. This is expected behavior.
<9> Optionally, specify authentication credentials, such as `user:pass`, or leave empty.
<10> Optionally, specify the default client connection timeout value, by default 30 seconds.
<11> Optionally, set to `True` to run Curator on the master node only.
+
For more information on these parameters, see the link:https://www.elastic.co/guide/en/elasticsearch/client/curator/5.2/configfile.html[Elastic Search curator documentation].

. Set the minimum acceptable log severity to display.
+
[source,yaml]
----
logging:
  loglevel: INFO <1>
  logfile:
  logformat: default
  blacklist: ['elasticsearch', 'urllib3']
----
+
Specify the log level:
+
* *CRITICAL*. Curator displays only critical messages.
* *ERROR*. Curator displays only  error and critical messages.
* *WARNING*. Curator displays only  error, warning, and critical messages.
* *INFO*. Curator displays only informational, error, warning, and critical messages.
* *DEBUG*. Curator displays only debug messages, in addition to all of the above.
+
The default value is INFO.

[NOTE]
====
Cluster Logging uses the {product-title} custom environment variable `CURATOR_SCRIPT_LOG_LEVEL` in {product-title} wrapper scripts (run.sh and convert.py).
The environment variable takes the same values as `CURATOR_LOG_LEVEL` for script debugging, as needed.
====

