// Module included in the following assemblies:
//
// *deployment/deployment.adoc

:_mod-docs-content-type: CONCEPT
[id="con-about-token-based-rate-limiting_{context}"]
= About token-based rate limiting with TokenRateLimitPolicy

[role="_abstract"]
{product-title} provides the `TokenRateLimitPolicy` custom resource to enforce rate limits based on token consumption rather than the number of requests. This policy extends the Envoy Rate Limit Service (RLS) protocol with automatic token usage extraction. It is particularly useful for protecting Large Language Model (LLM) APIs, where the cost and resource usage correlate more closely with the number of tokens processed.

Unlike the standard `RateLimitPolicy` which counts requests, `TokenRateLimitPolicy` counts tokens by extracting usage metrics in the body of the AI inference API call, allowing for finer-grained control over API usage based on actual workload.

[id="rhcl-token-rate-limiting_{context}"]
== How token rate limiting works

The `TokenRateLimitPolicy` tracks cumulative token usage per client. Before forwarding a request, it checks if the client has already exceeded their limit from previous usage. After the upstream responds, it extracts the actual token cost and updates the client's counter.

The flow is as follows:

. On an incoming request, the gateway evaluates the matching rules and predicates from the `TokenRateLimitPolicy` resources.
. If the request matches, the gateway prepares the necessary rate limit descriptors and monitors the response.
. After receiving the response, the gateway extracts the `usage.total_tokens` field from the JSON response body.
. The gateway then sends a `RateLimitRequest` to Limitador, including the actual token count as a `hits_addend`.
. Limitador tracks the cumulative token usage and responds to the gateway with `OK` or `OVER_LIMIT`.

[id="rhcl-token-rate-limiting-use-case_{context}"]
== Key features and use cases

* Enforces limits based on token usage by extracting the `usage.total_tokens` field from an OpenAI-style inference JSON response body.
* Suitable for consumption-based APIs such as LLMs where the cost is tied to token counts.
* Allows defining different limits based on criteria such as user identity, API endpoints, or HTTP methods.
* Works with `AuthPolicy` to apply specific limits to authenticated users or groups.
* Inherits functionalities from `RateLimitPolicy`, including defining multiple limits with different durations and using Redis for shared counters in multi-cluster environments.

[id="rhcl-token-rate-limiting-authpolicy_{context}"]
== Integrating with AuthPolicy

You can combine `TokenRateLimitPolicy` with `AuthPolicy` to apply token limits based on authenticated user identity.
When an `AuthPolicy` successfully authenticates a request, it injects identity information that is used by the `TokenRateLimitPolicy` to select the appropriate limit.

For example, you can define different token limits for users belonging to 'free-tier' compared to 'premium-tier' groups, identified using claims in a JWT validated by `AuthPolicy`.
