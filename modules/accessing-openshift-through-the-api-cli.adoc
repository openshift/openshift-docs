// Module included in the following assemblies:
//
// <List assemblies here, each on a new line>

// This module can be included from assemblies using the following include statement:
// include::<path>/proc_accessing-openshift-through-the-api-cli.adoc[leveloffset=+1]

// The file name and the ID are based on the module title. For example:
// * file name: proc_doing-procedure-a.adoc
// * ID: [id='proc_doing-procedure-a_{context}']
// * Title: = Doing procedure A
//
// The ID is used as an anchor for linking to the module. Avoid changing
// it after the module has been published to ensure existing links are not
// broken.
//
// The `context` attribute enables module reuse. Every module's ID includes
// {context}, which ensures that the module has a unique ID even if it is
// reused multiple times in a guide.
//
// Start the title with a verb, such as Creating or Create. See also
// _Wording of headings_ in _The IBM Style Guide_.
[id="accessing-openshift-through-the-api-cli_{context}"]
= Accessing OpenShift through the API-CLI

his section covers how to set up access to an OpenShift cluster on your localhost. The purpose of this is to ensure that you can verify that the cluster is running and to be able to do basic cluster management via the command line.

[discrete]
== Prerequisites

* A running OpenShift Cluster
* Access to the IBM Lab Environment/VPN
** You can contact klpesave@us.ibm.com or johnmuln@us.ibm.com for assistance.
** This is only necessary if your cluster is running in the Poughkeepsie lab environment.
* *Important*: If you plan to deploy new applications and create external routes for them, you will need to add the fqdn of such new routes to the /etc/hosts file of any system that needs to access the deployed app.  This is because there is no wildcard entry for your cluster in your lab-provided DNS.

[discrete]
== Procedure

This section goes over the steps you will need to perform in order to set up API access to your running OpenShift Cluster via the command-line interface (CLI). Many of the following steps expect to be run in a terminal. The host it that terminal should be running on is in *bold*.

. Copy over the kubernetes configuration file so that your CLI can access the provisioned cluster.
*z/VM Instructions*
+
On your *localhost*:
....
$ scp bastion_fqdn_or_ip:kubeconfig ~/.kube/config
....
Copy entry from etc.hosts to /etc/hosts to access web console on your *localhost*.
....
$ scp bastion_fqdn_or_ip:openshift-upi-playbooks/etc.hosts /tmp/etc.hosts
....
+
*zKVM Instructions*
On the *hypervisor*:
....
$ scp 192.168.79.1:ocp4-workdir/auth/kubeconfig kubeconfig
....
+
On your *localhost*:
....
$ scp hypervisor_fqdn_or_ip:kubeconfig ~/.kube/config
....
+
.. Copy entry from etc.hosts to /etc/hosts to access web console on your *localhost*.
....
$ scp hypervisor_fqdn_or_ip:openshift-upi-playbooks/etc.hosts /tmp/etc.hosts
....
+
.. Determine the default public IP address of your hypervisor. This command should print the default public IP when run on the *hypervisor*.
....
$ hostname -I
....
+
.. *IMPORTANT*: Edit the IP address on your localhost to match the IP of your hypervisor obtained in step 2a.
....
$ vi /tmp/etc.hosts
....
+
.. Append the etc.hosts entry to /etc/hosts on your *localhost*.
....
$ cat /tmp/etc.hosts | sudo tee -a /etc/hosts
$ rm /tmp/etc.hosts
....
+
. Verify that you can connect to the cluster using the `oc` command on your *localhost*. The output should print information about the kubernetes API.
....
$ oc status
....
