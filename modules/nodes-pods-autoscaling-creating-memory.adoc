// Module included in the following assemblies:
//
// * nodes/nodes-pods-autoscaling-about.adoc

[id="nodes-pods-autoscaling-creating-memory_{context}"]

= Creating a horizontal pod autoscaler object for memory utilization by using the CLI

Using the {product-title} CLI, you can create a horizontal pod autoscaler (HPA) to automatically scale an existing 
`Deployment`, `DeploymentConfig`, `ReplicaSet`, `ReplicationController`, or `StatefulSet` object. The HPA  
scales the pods associated with that object to maintain the average memory utilization you specify, either a direct value or a percentage 
of requested memory.

[NOTE]
====
It is recommended to use a `Deployment` object or `ReplicaSet` object unless you need a specific feature or behavior provided by other objects.
====

The HPA increases and decreases the number of replicas between the minimum and maximum numbers to maintain
the specified memory utilization across all pods.

For memory utilization, you can specify the minimum and maximum number of pods and the average memory utilization
your pods should target. If you do not specify a minimum, the pods are given default values from the {product-title} server.

.Prerequisites

To use horizontal pod autoscalers, your cluster administrator must have properly configured cluster metrics.
You can use the `oc describe PodMetrics <pod-name>` command to determine if metrics are configured. If metrics are
configured, the output appears similar to the following, with `Cpu` and `Memory` displayed under `Usage`.

[source,terminal]
----
$ oc describe PodMetrics openshift-kube-scheduler-ip-10-0-129-223.compute.internal -n openshift-kube-scheduler
----

.Example output
[source,text,options="nowrap"]
----
Name:         openshift-kube-scheduler-ip-10-0-129-223.compute.internal
Namespace:    openshift-kube-scheduler
Labels:       <none>
Annotations:  <none>
API Version:  metrics.k8s.io/v1beta1
Containers:
  Name:  wait-for-host-port
  Usage:
    Cpu:     0
    Memory:  0
  Name:      scheduler
  Usage:
    Cpu:     8m
    Memory:  45440Ki
Kind:        PodMetrics
Metadata:
  Creation Timestamp:  2020-02-14T22:21:14Z
  Self Link:           /apis/metrics.k8s.io/v1beta1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ip-10-0-129-223.compute.internal
Timestamp:             2020-02-14T22:21:14Z
Window:                5m0s
Events:                <none>
----

.Procedure

To create a horizontal pod autoscaler for memory utilization:

. Create a YAML file for one of the following:

** To scale for a specific memory value, create a `HorizontalPodAutoscaler` object similar to the following for an existing object:
+
[source,yaml,options="nowrap"]
----
apiVersion: autoscaling/v2beta2 <1>
kind: HorizontalPodAutoscaler
metadata:
  name: hpa-resource-metrics-memory <2>
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: v1 <3>
    kind: Deployment <4>
    name: example <5>
  minReplicas: 1 <6>
  maxReplicas: 10 <7>
  metrics: <8>
  - type: Resource
    resource:
      name: memory <9>
      target:
        type: AverageValue <10>
        averageValue: 500Mi <11>
  behavior: <12>
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Pods
        value: 4
        periodSeconds: 60
      - type: Percent
        value: 10
        periodSeconds: 60
      selectPolicy: Max
----
<1> Use the `autoscaling/v2beta2` API.
<2> Specify a name for this horizontal pod autoscaler object.
<3> Specify the API version of the object to scale:
* For a `Deployment`, `ReplicaSet`, or `Statefulset` object, use `apps/v1`.
* For a `ReplicationController`, use `v1`.
* For a `DeploymentConfig`, use `apps.openshift.io/v1`.
<4> Specify the type of object. The object must be a `Deployment`, `DeploymentConfig`, 
`ReplicaSet`, `ReplicationController`, or `StatefulSet`.
<5> Specify the name of the object to scale. The object must exist.
<6> Specify the minimum number of replicas when scaling down.
<7> Specify the maximum number of replicas when scaling up.
<8> Use the `metrics` parameter for memory utilization.
<9> Specify `memory` for memory utilization.
<10> Set the type to `AverageValue`.
<11> Specify `averageValue` and a specific memory value.
<12> Optional: Specify a scaling policy to control the rate of scaling up or down.

** To scale for a percentage, create a `HorizontalPodAutoscaler` object similar to the following for an existing object:
+
[source,yaml,options="nowrap"]
----
apiVersion: autoscaling/v2beta2 <1>
kind: HorizontalPodAutoscaler
metadata:
  name: memory-autoscale <2>
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: apps.openshift.io/v1 <3>
    kind: Deployment <4>
    name: example <5>
  minReplicas: 1 <6>
  maxReplicas: 10 <7>
  metrics: <8>
  - type: Deployment
    resource:
      name: memory <9>
      target:
        type: Utilization <10>
        averageUtilization: 50 <11>
  behavior: <12>
    scaleUp:
      stabilizationWindowSeconds: 180
      policies:
      - type: Pods
        value: 6
        periodSeconds: 120
      - type: Percent
        value: 10
        periodSeconds: 120
      selectPolicy: Max
----
<1> Use the `autoscaling/v2beta2` API.
<2> Specify a name for this horizontal pod autoscaler object.
<3> Specify the API version of the object to scale:
* For a ReplicationController, use `v1`.
* For a DeploymentConfig, use `apps.openshift.io/v1`.
* For a Deployment, ReplicaSet, Statefulset object, use `apps/v1`.
<4> Specify the type of object. The object must be a `Deployment`, `DeploymentConfig`, 
`ReplicaSet`, `ReplicationController`, or `StatefulSet`.
<5> Specify the name of the object to scale. The object must exist.
<6> Specify the minimum number of replicas when scaling down.
<7> Specify the maximum number of replicas when scaling up.
<8> Use the `metrics` parameter for memory utilization.
<9> Specify `memory` for memory utilization.
<10> Set to `Utilization`.
<11> Specify `averageUtilization` and a target average memory utilization over all the pods,
represented as a percent of requested memory. The target pods must have memory requests configured.
<12> Optional: Specify a scaling policy to control the rate of scaling up or down.

. Create the horizontal pod autoscaler:
+
[source,terminal]
----
$ oc create -f <file-name>.yaml
----
+
For example:
+
[source,terminal]
----
$ oc create -f hpa.yaml
----
+
.Example output
[source,terminal]
----
horizontalpodautoscaler.autoscaling/hpa-resource-metrics-memory created
----

. Verify that the horizontal pod autoscaler was created:
+
[source,terminal]
----
$ oc get hpa hpa-resource-metrics-memory
----
+
.Example output
[source,terminal]
----
NAME                          REFERENCE            TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
hpa-resource-metrics-memory   Deployment/example   2441216/500Mi   1         10        1          20m
----
+
[source,terminal]
----
$ oc describe hpa hpa-resource-metrics-memory
----
+
.Example output
[source,text]
----
Name:                        hpa-resource-metrics-memory
Namespace:                   default
Labels:                      <none>
Annotations:                 <none>
CreationTimestamp:           Wed, 04 Mar 2020 16:31:37 +0530
Reference:                   Deployment/example
Metrics:                     ( current / target )
  resource memory on pods:   2441216 / 500Mi
Min replicas:                1
Max replicas:                10
ReplicationController pods:  1 current / 1 desired
Conditions:
  Type            Status  Reason              Message
  ----            ------  ------              -------
  AbleToScale     True    ReadyForNewScale    recommended size matches current size
  ScalingActive   True    ValidMetricFound    the HPA was able to successfully calculate a replica count from memory resource
  ScalingLimited  False   DesiredWithinRange  the desired count is within the acceptable range
Events:
  Type     Reason                   Age                 From                       Message
  ----     ------                   ----                ----                       -------
  Normal   SuccessfulRescale        6m34s               horizontal-pod-autoscaler  New size: 1; reason: All metrics below target
----
