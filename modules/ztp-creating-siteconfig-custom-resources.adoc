// Module included in the following assemblies:
//
// *scalability_and_performance/ztp-deploying-disconnected.adoc

:_content-type: PROCEDURE
[id="ztp-creating-siteconfig-custom-resources_{context}"]
= Creating custom resources to install a single managed cluster

This procedure tells you how to manually create and deploy a single managed cluster. If you are creating multiple clusters, perhaps hundreds, use the `SiteConfig` method described in
“Creating ZTP custom resources for multiple managed clusters”.

.Prerequisites

* Enable Assisted Installer Service.

* Ensure network connectivity:
** The container within the hub must be able to reach the Baseboard Management Controller (BMC) address of the target bare-metal host.

** The managed cluster must be able to resolve and reach the hub’s API `hostname` and `{asterisk}.app` hostname.
Example of the hub’s API and `{asterisk}.app` hostname:
+
[source,terminal]
----
console-openshift-console.apps.hub-cluster.internal.domain.com
api.hub-cluster.internal.domain.com
----

** The hub must be able to resolve and reach the API and `{asterisk}.app` hostname of the managed cluster.
Here is an example of the managed cluster’s API and `{asterisk}.app` hostname:
+
[source,terminal]
----
console-openshift-console.apps.sno-managed-cluster-1.internal.domain.com
api.sno-managed-cluster-1.internal.domain.com
----

** A DNS Server that is IP reachable from the target bare-metal host.

* A target bare-metal host for the managed cluster with the following hardware minimums:

** 4 CPU or 8 vCPU
** 32 GiB RAM
** 120 GiB Disk for root filesystem

* When working in a disconnected environment, the release image needs to be mirrored. Use this command to mirror the release image:
+
[source,terminal]
----
oc adm release mirror -a <pull_secret.json>
--from=quay.io/openshift-release-dev/ocp-release:{{ mirror_version_spoke_release }}
--to={{ provisioner_cluster_registry }}/ocp4 --to-release-image={{
provisioner_cluster_registry }}/ocp4:{{ mirror_version_spoke_release }}
----

* You mirrored the ISO and `rootfs` used to generate the spoke cluster ISO to an HTTP server and configured the settings to pull images from there.
+
The images must match the version of the `ClusterImageSet`. To deploy a 4.10.0 version, the `rootfs` and ISO need to be set at 4.10.0.


.Procedure

. Create a `ClusterImageSet` for each specific cluster version that needs to be deployed. A `ClusterImageSet` has the following format:
+
[source,yaml]
----
apiVersion: hive.openshift.io/v1
kind: ClusterImageSet
metadata:
  name: openshift-4.10.0-rc.0 <1>
spec:
   releaseImage: quay.io/openshift-release-dev/ocp-release:4.10.0-x86_64 <2>
----
<1> The descriptive version that you want to deploy.
<2> Specifies the `releaseImage` to deploy and determines the OS Image version. The discovery ISO is based on an OS image version as the `releaseImage`, or latest if the exact version is unavailable.

. Create the `Namespace` definition for the managed cluster:
+
[source,yaml]
----
apiVersion: v1
kind: Namespace
metadata:
     name: <cluster_name> <1>
     labels:
        name: <cluster_name> <1>
----
<1>  The name of the managed cluster to provision.

. Create the `BMC Secret` custom resource:
+
[source,yaml]
----
apiVersion: v1
data:
  password: <bmc_password> <1>
  username: <bmc_username> <2>
kind: Secret
metadata:
  name: <cluster_name>-bmc-secret
  namespace: <cluster_name>
type: Opaque
----
<1> The password to the target bare-metal host. Must be base-64 encoded.
<2> The username to the target bare-metal host. Must be base-64 encoded.

. Create the `Image Pull Secret` custom resource:
+
[source,yaml]
----
apiVersion: v1
data:
  .dockerconfigjson: <pull_secret> <1>
kind: Secret
metadata:
  name: assisted-deployment-pull-secret
  namespace: <cluster_name>
type: kubernetes.io/dockerconfigjson
----
<1> The {product-title} pull secret. Must be base-64 encoded.

. Create the `AgentClusterInstall` custom resource:
+
[source,yaml]
----
apiVersion: extensions.hive.openshift.io/v1beta1
kind: AgentClusterInstall
metadata:
  # Only include the annotation if using OVN, otherwise omit the annotation
  annotations:
    agent-install.openshift.io/install-config-overrides: '{"networking":{"networkType":"OVNKubernetes"}}'
  name: <cluster_name>
  namespace: <cluster_name>
spec:
  clusterDeploymentRef:
    name: <cluster_name>
  imageSetRef:
    name: <cluster_image_set> <1>
  networking:
    clusterNetwork:
    - cidr: <cluster_network_cidr> <2>
      hostPrefix: 23
    machineNetwork:
    - cidr: <machine_network_cidr> <3>
    serviceNetwork:
    - <service_network_cidr> <4>
  provisionRequirements:
    controlPlaneAgents: 1
    workerAgents: 0
  sshPublicKey: <public_key> <5>
----
+
<1> The name of the ClusterImageSet custom resource used to install {product-title} on the bare-metal host.
<2> A block of IPv4 or IPv6 addresses in CIDR notation used for communication among cluster nodes.
<3> A block of IPv4 or IPv6 addresses in CIDR notation used for the target bare-metal host external communication. Also used to determine the API and Ingress VIP addresses when provisioning DU single node clusters.
<4> A block of IPv4 or IPv6 addresses in CIDR notation used for cluster services internal communication.
<5> Entered as plain text. You can use the public key to SSH into the node after it has finished installing.
+
[NOTE]
====
If you want to configure a static IP for the managed cluster at this point, see the procedure in this document for configuring static IP addresses for managed clusters.
====


. Create the `ClusterDeployment` custom resource:
+
[source,yaml]
----
apiVersion: hive.openshift.io/v1
kind: ClusterDeployment
metadata:
  name: <cluster_name>
  namespace: <cluster_name>
spec:
  baseDomain: <base_domain> <1>
  clusterInstallRef:
    group: extensions.hive.openshift.io
    kind: AgentClusterInstall
    name: <cluster_name>
    version: v1beta1
  clusterName: <cluster_name>
  platform:
    agentBareMetal:
      agentSelector:
        matchLabels:
          cluster-name: <cluster_name>
  pullSecretRef:
    name: assisted-deployment-pull-secret
----
+
<1> The managed cluster’s base domain.

. Create the `KlusterletAddonConfig` custom resource:
+
[source,yaml]
----
apiVersion: agent.open-cluster-management.io/v1
kind: KlusterletAddonConfig
metadata:
  name: <cluster_name>
  namespace: <cluster_name>
spec:
  clusterName: <cluster_name>
  clusterNamespace: <cluster_name>
  clusterLabels:
    cloud: auto-detect
    vendor: auto-detect
  applicationManager:
    enabled: true
  certPolicyController:
    enabled: false
  iamPolicyController:
    enabled: false
  policyController:
    enabled: true
  searchCollector:
    enabled: false <1>
----
+
<1> Set to `true` to enable KlusterletAddonConfig or `false` to disable the KlusterletAddonConfig. Keep `searchCollector` disabled.

. Create the `ManagedCluster` custom resource:
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1
kind: ManagedCluster
metadata:
  name: <cluster_name>
spec:
  hubAcceptsClient: true
----

. Create the `InfraEnv` custom resource:
+
[source,yaml]
----
apiVersion: agent-install.openshift.io/v1beta1
kind: InfraEnv
metadata:
  name: <cluster_name>
  namespace: <cluster_name>
spec:
  clusterRef:
    name: <cluster_name>
    namespace: <cluster_name>
  sshAuthorizedKey: <public_key> <1>
  agentLabels: <2>
    location: "<label-name>"
  pullSecretRef:
    name: assisted-deployment-pull-secret
----
<1> Entered as plain text. You can use the public key to SSH into the target bare-metal host when it boots from the ISO.
<2> Sets a label to match. The labels apply when the agents boot.

. Create the `BareMetalHost` custom resource:
+
[source,yaml]
----
apiVersion: metal3.io/v1alpha1
kind: BareMetalHost
metadata:
  name: <cluster_name>
  namespace: <cluster_name>
  annotations:
    inspect.metal3.io: disabled
  labels:
    infraenvs.agent-install.openshift.io: "<cluster_name>"
spec:
  bootMode: "UEFI"
  bmc:
    address: <bmc_address> <1>
    disableCertificateVerification: true
    credentialsName: <cluster_name>-bmc-secret
  bootMACAddress: <mac_address> <2>
  automatedCleaningMode: disabled
  online: true
----
<1> The baseboard management console address of the installation ISO on the target bare-metal host.
<2> The MAC address of the target bare-metal host.
+
Optionally, you can add `bmac.agent-install.openshift.io/hostname: <host-name>` as an annotation to set the managed cluster’s hostname. If you don't add the annotation, the hostname will default to either a hostname from the DHCP server or local host.

. After you have created the custom resources, push the entire directory of generated custom resources to the Git repository you created for storing the custom resources.

.Next step

To provision additional clusters, repeat this procedure for each cluster.
