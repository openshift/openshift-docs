// Module included in the following assemblies:

// * networking/network_observability/configuring-operators.adoc

:_mod-docs-content-type: PROCEDURE
[id="network-observability-flowcollector-kafka-config_{context}"]
= Configuring the FlowCollector resource with Kafka

[role="_abstract"]
Configure the `FlowCollector` resource to use Kafka for high-throughput and low-latency data feeds.

A Kafka instance needs to be running, and a Kafka topic dedicated to {product-title} Network Observability must be created in that instance. For more information, see link:https://access.redhat.com/documentation/en-us/red_hat_amq/7.7/html/using_amq_streams_on_openshift/using-the-topic-operator-str[Kafka documentation with AMQ Streams].

.Prerequisites
* Kafka is installed. Red Hat supports Kafka with AMQ Streams Operator.

.Procedure
. In the web console, navigate to *Ecosystem* -> *Installed Operators*.

. Under the *Provided APIs* heading for the Network Observability Operator, select *Flow Collector*.

. Select the cluster and then click the *YAML* tab.

. Modify the `FlowCollector` resource for {product-title} Network Observability Operator to use Kafka, as shown in the following sample YAML:
+
.Sample Kafka configuration in `FlowCollector` resource
[source, yaml]
----
apiVersion: flows.netobserv.io/v1beta2
kind: FlowCollector
metadata:
  name: cluster
spec:
  deploymentModel: Kafka                                    <1>
  kafka:
    address: "kafka-cluster-kafka-bootstrap.netobserv"      <2>
    topic: network-flows                                    <3>
    tls:
      enable: false                                         <4>
----
<1> Set `spec.deploymentModel` to `Kafka` instead of `Direct` to enable the Kafka deployment model.
<2> `spec.kafka.address` refers to the Kafka bootstrap server address. You can specify a port if needed, for instance `kafka-cluster-kafka-bootstrap.netobserv:9093` for using TLS on port 9093.
<3> `spec.kafka.topic` should match the name of a topic created in Kafka.
<4> `spec.kafka.tls` can be used to encrypt all communications to and from Kafka with TLS or mTLS. When enabled, the Kafka CA certificate must be available as a ConfigMap or a Secret, both in the namespace where the `flowlogs-pipeline` processor component is deployed (default: `netobserv`) and where the eBPF agents are deployed (default: `netobserv-privileged`). It must be referenced with `spec.kafka.tls.caCert`. When using mTLS, client secrets must be available in these namespaces as well (they can be generated for instance using the AMQ Streams User Operator) and referenced with `spec.kafka.tls.userCert`.
