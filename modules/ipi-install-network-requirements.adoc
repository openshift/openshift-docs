// Module included in the following assemblies:
//
// * installing/installing_bare_metal_ipi/ipi-install-prerequisites.adoc

[id='network-requirements_{context}']
= Network requirements

Installer-provisioned installation of {product-title} involves several network requirements by default. First, installer-provisioned installation involves a non-routable `provisioning` network for provisioning the operating system on each bare metal node and a routable `baremetal` network. Since installer-provisioned installation deploys `ironic-dnsmasq`, the networks should have no other DHCP servers running on the same broadcast domain. Network administrators must reserve IP addresses for each node in the {product-title} cluster.

.Network Time Protocol (NTP)

It is recommended that each {product-title} node in the cluster have access to a Network Time Protocol (NTP) server that is discoverable using DHCP. While installation without an NTP server is possible, asynchronous server clocks can cause errors. Using an NTP server can prevent this issue.

.Configuring NICs

{product-title} deploys with two networks:

- `provisioning`: The `provisioning` network is an *optional* non-routable network used for provisioning the underlying operating system on each node that is a part of the {product-title} cluster. When deploying using the `provisioning` network, the first NIC on each node, such as `eth0` or `eno1`,
*must* interface with the `provisioning` network.

- `baremetal`: The `baremetal` network is a routable network. When deploying using the `provisioning` network, the second NIC on each node, such as `eth1` or `eno2`, *must* interface with the `baremetal` network. When deploying without a `provisioning` network, you can use any NIC on each node to interface with the `baremetal` network.

[IMPORTANT]
====
Each NIC should be on a separate VLAN corresponding to the appropriate network.
====

.Configuring the DNS server

Clients access the {product-title} cluster nodes over the `baremetal` network.
A network administrator must configure a subdomain or subzone where the canonical name extension is the cluster name.

----
<cluster-name>.<domain-name>
----

For example:

----
test-cluster.example.com
----

ifdef::upstream[]
For assistance in configuring the DNS server, check xref:ipi-install-upstream-appendix[Appendix] section for:

- xref:creating-dns-records-on-a-dns-server-option1_{context}[Creating DNS Records with Bind (Option 1)]
- xref:creating-dns-records-using-dnsmasq-option2_{context}[Creating DNS Records with dnsmasq (Option 2)]

endif::[]

.Reserving IP addresses for nodes with the DHCP server

For the `baremetal` network, a network administrator must reserve a number of IP addresses, including:

ifeval::[{release} > 4.5]
. Two virtual IP addresses.
endif::[]
ifeval::[{release} <= 4.5]
. Three virtual IP addresses
endif::[]
+
- One IP address for the API endpoint
- One IP address for the wildcard Ingress endpoint
ifeval::[{release} <= 4.5]
- One IP address for the name server
endif::[]

. One IP address for the provisioner node.
. One IP address for each control plane (master) node.
. One IP address for each worker node, if applicable.

The following table provides an exemplary embodiment of fully-qualified domain names. The API and Nameserver addresses begin with canonical name extensions. The hostnames of the control plane and worker nodes are exemplary, so you can use any host naming convention you prefer. 

[width="100%", cols="3,5e,2e", frame="topbot",options="header"]
|=====
| Usage | Hostname | IP
| API | api.<cluster-name>.<domain> | <ip>
| Ingress LB (apps) |  *.apps.<cluster-name>.<domain>  | <ip>
ifeval::[{release} <= 4.5]
| Nameserver | ns1.<cluster-name>.<domain> | <ip>
endif::[]
| Provisioner node | provisioner.<cluster-name>.<domain> | <ip>
| Master-0 | openshift-master-0.<cluster-name>.<domain> | <ip>
| Master-1 | openshift-master-1.<cluster-name>-.<domain> | <ip>
| Master-2 | openshift-master-2.<cluster-name>.<domain> | <ip>
| Worker-0 | openshift-worker-0.<cluster-name>.<domain> | <ip>
| Worker-1 | openshift-worker-1.<cluster-name>.<domain> | <ip>
| Worker-n | openshift-worker-n.<cluster-name>.<domain> | <ip>
|=====

ifdef::upstream[]
For assistance in configuring the DHCP server, check xref:ipi-install-upstream-appendix[Appendix] section for:

- xref:creating-dhcp-reservations-option1_{context}[Creating DHCP reservations with dhcpd (Option 1)]
- xref:creating-dhcp-reservations-using-dnsmasq-option2_{context}[Creating DHCP reservations with dnsmasq (Option 2)]
endif::[]

.Additional requirements with no provisioning network

All installer-provisioned installations require a `baremetal` network. The `baremetal` network is a routable network used for external network access to the outside world. In addition to the IP address supplied to the {product-title} cluster node, installations without a `provisioning` network require the following:

- Setting an available IP address from the `baremetal` network to the `bootstrapProvisioningIP` configuration setting within the `install-config.yaml` configuration file.

- Setting an available IP address from the `baremetal` network to the `provisioningHostIP` configuration setting within the `install-config.yaml` configuration file.

- Deploying the {product-title} cluster using RedFish Virtual Media/iDRAC Virtual Media.

[NOTE]
====
Configuring additional IP addresses for `bootstrapProvisioningIP` and `provisioningHostIP` is not required when using a `provisioning` network.
====

.Port access for the out-of-band management IP address

The out-of-band management IP address is on a separate network from the node. To ensure that the out-of-band management can communicate with the `baremetal` node during installation, the out-of-band management IP address address must be granted access to the TCP 6180 port.