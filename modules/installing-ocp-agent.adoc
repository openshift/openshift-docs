// Module included in the following assemblies:
//
// * installing-with-agent/installing-with-agent.adoc

:_content-type: PROCEDURE
[id="installing-ocp-agent_{context}"]
= Installing {product-title} with the Agent-based Installer

The following procedure deploys a single-node {product-title} in a disconnected environment. You can use this procedure as a basis and modify according to your requirements.

.Procedure

. Navigate to the link:https://mirror.openshift.com/pub/openshift-v4/x86_64/clients/ocp/latest [OpenShift mirror site] and download the latest version of the tarball that matches your operating system.

. Extract the binary by running the following command:
+
[source,terminal]
----
$ tar xvf <file> -C ~/.local/bin
----
+
The file contains the Agent-based Installer.

. Install `nmstate` dependency by running the following command:
+
[source,terminal]
----
$ sudo dnf install /usr/bin/nmstatectl -y
----

. Place the `openshift-install` binary in a directory that is on your PATH.

. Create a directory to store the cluster manifests by running the following command:
+
[source,terminal]
----
$ mkdir ~/<directory_name>
----

+
[NOTE]
====
This is the preferred method for the Agent-based installation. Using ZTP manifests is optional.
====

. Create the `install-config.yaml` file:
+
[source,yaml]
----
cat << EOF > ./cluster-manifests/install-config.yaml
apiVersion: v1
baseDomain: test.example.com
compute:
- architecture: amd64
  hyperthreading: Enabled
  name: worker
  replicas: 0
controlPlane:
  architecture: amd64
  hyperthreading: Enabled
  name: master
  replicas: 1
metadata:
  name: sno-cluster <1>
networking:
  clusterNetwork:
  - cidr: 10.128.0.0/14
    hostPrefix: 23
  machineNetwork:
  - cidr: 192.168.111.0/16
  networkType: OpenShiftSDN
  serviceNetwork:
  - 172.30.0.0/16
platform:
  none: {}
pullSecret: '<pull_secret>' <2>
sshKey: |
  '<ssh_pub_key>' <3>
  EOF
----
+
<1> Required.
<2> Enter your pull secret.
<3> Enter your ssh public key.

+
[NOTE]
====
If you set the platform to `vSphere` or `baremetal`, you can configure IP address endpoints for cluster nodes in three ways:

* IPv4
* IPv6
* IPv4 and IPv6 in parallel (dual-stack)

.Example of dual-stack networking
[source,yaml]
----
networking:
  clusterNetwork:
    - cidr: 172.21.0.0/16
      hostPrefix: 23
    - cidr: fd02::/48
      hostPrefix: 64
  machineNetwork:
    - cidr: 192.168.11.0/16
    - cidr: 2001:DB8::/32
  serviceNetwork:
    - 172.22.0.0/16
    - fd03::/112
  networkType: OVNKubernetes
platform:
  baremetal:
    apiVIPs:
    - 192.168.11.3
    - 2001:DB8::4
    ingressVIPs:
    - 192.168.11.4
    - 2001:DB8::5
----
====

. Create the `agent-config.yaml` file:
+
[source,yaml]
----
  cat > agent-config.yaml << EOF
  apiVersion: v1alpha1
  kind: AgentConfig
  metadata:
    name: sno-cluster
  rendezvousIP: 192.168.111.80 <1>
  hosts: <2>
    - hostname: master-0 <3>
      interfaces:
        - name: eno1
          macAddress: 00:ef:44:21:e6:a5
      rootDeviceHints: <4>
        deviceName: /dev/sdb
      networkConfig: <5>
        interfaces:
          - name: eno1
            type: ethernet
            state: up
            mac-address: 00:ef:44:21:e6:a5
            ipv4:
              enabled: true
              address:
                - ip: 192.168.111.80
                  prefix-length: 23
              dhcp: false
        dns-resolver:
          config:
            server:
              - 192.168.111.1
        routes:
          config:
            - destination: 0.0.0.0/0
              next-hop-address: 192.168.111.2
              next-hop-interface: eno1
              table-id: 254
  EOF
----
+
<1> This IP address is used to determine which node performs the bootstrapping process as well as running the `assisted-service` component.
You must provide the IP address when you do not specify the node's IP addresses in the `networkConfig` parameter. If this address is not provided, one IP address is selected from the provided nodes's `networkConfig`.
<2> The number of hosts defined must match the total number of hosts defined in the `install-config.yaml` file, which is the sum of the values of the `compute.replicas` and `controlPlane.replicas` parameters. When 3 master nodes and 0 worker nodes are defined in the `install-config.yaml` file,
the number of hosts defined is 3. When 3 master nodes and 2 worker nodes are defined in the `install-config.yaml` file, the number of hosts defined is 5.
<3> The optional `hostname` parameter overrides the hostname obtained from either the Dynamic Host Configuration Protocol (DHCP) or a reverse DNS lookup. Each host must have a unique hostname supplied by one of these methods.
<4> The `rootDeviceHints` parameter enables provisioning of the Red Hat Enterprise Linux CoreOS (RHCOS) image to a particular device. It examines the devices in the order it discovers them, and compares the discovered values with the hint values. It uses the first discovered device that matches the hint value.
<5> Set this optional parameter to configure the network interface of a host in NMState format.

+
. Create the Agent image by running the following command:
+
[NOTE]
====
Ensure that the image is created in the same path as the **auth** folder. You can verify this with the following command:

[source,terminal]
----
$ ls
agent.iso  auth
----
====
+
[source,terminal]
----
$ openshift-install agent create image
----
+
NOTE: Red Hat Enterprise Linux CoreOS (RHCOS) supports multipathing on the primary disk, allowing stronger resilience to hardware failure to achieve higher host availability. Multipathing is enabled by default in the `agent.iso` image, with a default `/etc/multipath.conf` configuration.

. Optional: To know when the bootstrap host (which is the rendezvous host) reboots, run the following command:

+
[source,terminal]
----
$ ./openshift-install --dir <manifests_directory> wait-for bootstrap-complete \ <1>
    --log-level=info <2>
----
<1> For `<manifests_directory>`, specify the path to the directory that you stored the manifest files in.
<2> To view different installation details, specify `warn`, `debug`, or `error` instead of `info`.

+
.Example output
[source,terminal]
----
INFO Waiting up to 30m0s for the Kubernetes API at https://api.test.example.com:6443...
INFO API v1.25.0 up
INFO Waiting up to 30m0s for bootstrapping to complete...
INFO It is now safe to remove the bootstrap resources
----
+
The command succeeds when the Kubernetes API server signals that it has been bootstrapped on the control plane machines.

. Boot the `agent.iso` image on the bare metal machines. You can run the image on any Linux distribution.

. To track the progress and verify sucessful installation, run the following command:
+
[source,terminal]
----
$ openshift-install agent wait-for install-complete
----
+
.Example output
[source,terminal]
----
...................................................................
...................................................................
INFO Cluster is installed
INFO Install complete!
INFO To access the cluster as the system:admin user when using 'oc', run
INFO     export KUBECONFIG=/home/core/installer/auth/kubeconfig
INFO Access the OpenShift web-console here: https://console-openshift-console.apps.sno-cluster.test.example.com
----


[NOTE]
====
If you are using the optional method of ZTP manifests, you can configure IP address endpoints for cluster nodes through the `AgentClusterInstall.yaml` file in three ways:

* IPv4
* IPv6
* IPv4 and IPv6 in parallel (dual-stack)

.Example of dual-stack networking
[source,yaml]
----
apiVIP: 192.168.11.3
ingressVIP: 192.168.11.4
clusterDeploymentRef:
  name: mycluster
imageSetRef:
  name: openshift-4.12
networking:
  clusterNetwork:
  - cidr: 172.21.0.0/16
    hostPrefix: 23
  - cidr: fd02::/48
    hostPrefix: 64
  machineNetwork:
  - cidr: 192.168.11.0/16
  - cidr: 2001:DB8::/32
  serviceNetwork:
  - 172.22.0.0/16
  - fd03::/112
  networkType: OVNKubernetes
----
====
