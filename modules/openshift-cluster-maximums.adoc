// Module included in the following assemblies:
//
// * scalability_and_performance/planning-your-environment-according-to-object-maximums.adoc

[id="cluster-maximums_{context}"]
= {product-title} tested cluster maximums

The values in the following table were tested independently of each other and represent the maximum for that particular resource type. It might not be valid to consider these maximums in combinations. Appropriate capacity planning and testing should be performed for large environments. Other objects are created during the test runs, but are not close to the tested maximums. For example, when testing namespaces per cluster, deployments per namespace, or number of nodes, thousands of pods, services, deployments, secrets, config maps, and builds are created, but are not close to the cluster maximums.

[options="header",cols="5*"]
|===
| Maximum type |4.1 and 4.2 tested maximum |4.3 tested maximum |4.4 tested maximum |4.5 through 4.9 tested maximum

| Number of nodes
| 2,000
| 2,000
| 250
| 500

| Number of pods ^[1]^
| 150,000
| 150,000
| 62,500
| 62,500

| Number of pods per node
| 250
| 500
| 500
| 500

| Number of pods per core
| There is no default value.
| There is no default value.
| There is no default value.
| There is no default value.

| Number of namespaces ^[2]^
| 10,000
| 10,000
| 10,000
| 10,000

| Number of builds
| 10,000 (Default pod RAM 512 Mi) - Pipeline Strategy
| 10,000 (Default pod RAM 512 Mi) - Source-to-Image (S2I) build strategy
| 10,000 (Default pod RAM 512 Mi) - Source-to-Image (S2I) build strategy
| 10,000 (Default pod RAM 512 Mi) - Source-to-Image (S2I) build strategy

| Number of pods per namespace ^[3]^
| 25,000
| 25,000
| 25,000
| 25,000

| Number of services ^[4]^
| 10,000
| 10,000
| 10,000
| 10,000

| Number of services per namespace
| 5,000
| 5,000
| 5,000
| 5,000

| Number of back ends per service
| 5,000
| 5,000
| 5,000
| 5,000

| Number of deployments per namespace ^[3]^
| 2,000
| 2,000
| 2,000
| 2,000

|===
[.small]
--
1. The pod count displayed here is the number of test pods. The actual number of pods depends on the application's memory, CPU, and storage requirements.
2. When there are a large number of active projects, etcd might suffer from poor performance if the keyspace grows excessively large and exceeds the space quota. Periodic maintenance of etcd, including defragmentaion, is highly recommended to free etcd storage.
3. There are a number of control loops in the system that must iterate over all objects in a given namespace as a reaction to some changes in state. Having a large number of objects of a given type in a single namespace can make those loops expensive and slow down processing given state changes. The limit assumes that the system has enough CPU, memory, and disk to satisfy the application requirements.
4. Each service port and each service back end has a corresponding entry in iptables. The number of back ends of a given service impact the size of the endpoints objects, which impacts the size of data that is being sent all over the system.
--

In {product-title} {product-version}, half of a CPU core (500 millicore) is reserved by the system compared to {product-title} 3.11 and previous versions.
