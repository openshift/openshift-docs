// Module included in the following assemblies:
//
// * release_notes/ocp-4-18-release-notes.adoc

:_mod-docs-content-type: REFERENCE
= Fixed issues

[role="_abstract"]

You can ensure your environment remains stable by reviewing these fixed issues to verify resolved bugs.

The following issues are fixed for this release:

* Before this update, when service endpoints were deleted and recreated in {product-title} clusters using OVN-Kubernetes networking and the service port differed from the endpoint port, stale User Datagram Protocol (UDP) connection tracking (conntrack) entries could remain on worker nodes. This occurred because the `conntrack` cleanup logic incorrectly used the endpoint port, which is the target port on the pod, instead of the externally-facing service port that clients connect to when attempting to delete stale entries. With this release, the cleanup process uses the service port when deleting or updating service endpoints. This change ensures that stale conntrack entries are correctly matched and removed. Network connectivity now remains reliable during service endpoint lifecycle changes. (link:https://issues.redhat.com/browse/OCPBUGS-70346[OCPBUGS-70346])

* Before this update, a runtime error prevented an egress IP address from being created in an {product-title} cluster on {azure-first}. With this release, a code fix resolves the runtime error. As a result, an egress IP address can be created in an {product-title}t cluster on {azure-short}. (link:https://issues.redhat.com/browse/OCPBUGS-73750[OCPBUGS-73750])

* Before this update, iptables-alerter pods experienced high CPU usage in some clusters due to an issue in the 4.18.20 upgrade. As a consequence, high CPU usage impacted iptables-alerter pods, causing performance degradation. With this release, iptables-alerter CPU usage has been reduced by optimizing code in version 4.18.21. As a result, high CPU usage for iptables-alerter pods has been resolved, improving cluster performance. (link:https://issues.redhat.com/browse/OCPBUGS-73767[OCPBUGS-73767])

* Before this update, {aws-first} APIs returned inconsistent results regarding the existence of a `Machine`. The safeguards designed to handle this inconsistency checked the stored instance ID in the incorrect location. As a consequence, during {aws-short} API instability, virtual machines (VMs) leaked and attempted to join the cluster indefinitely. With this release, the system uses the correct provider ID for consistency checks. If an instance does not appear within 20 seconds, the machine status changes to `Failed` to prevent instance leaks. (link:https://issues.redhat.com/browse/OCPBUGS-73789[OCPBUGS-73789])

* Before this update, the catalog sync triggered high I/O on masters where etcd ran. As a consequence, an etcd leader election was triggered. The triggered election reset TTL counters on keys and prevented etcd events from being cleared. With this release, the default catalog polling interval is increased from ten minutes to four hours. As a result, the load on catalog sources is reduced. (link:https://issues.redhat.com/browse/OCPBUGS-73833[OCPBUGS-73833])
