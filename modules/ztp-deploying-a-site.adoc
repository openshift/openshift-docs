// Module included in the following assemblies:
//
// *scalability_and_performance/ztp-support-for-deployment-of-multi-node-clusters.adoc

:_content-type: PROCEDURE
[id="ztp-deploying-a-site_{context}"]
= Deploying a site

Use the following procedure to prepare the hub cluster for site deployment and initiate
zero touch provisioning (ZTP) by pushing custom resources (CRs) to your Git repository.

.Procedure

. Create the required secrets for the site. These resources must be in a namespace with a name
matching the cluster name. In `out/argocd/example/siteconfig/example-sno.yaml` the cluster name
and namespace is `example-sno`.
+
Create the namespace for the cluster using the following commands:
+
[source,terminal]
----
$ export CLUSTERS=example-sno
----
+
[source,terminal]
----
$ oc create namespace $CLUSTERNS
----

. Create a pull secret for the cluster. The pull secret must contain all of the credentials necessary
for installing OpenShift and all required Operators. In all of the example SiteConfigs, the
pull secret is named `assisted-deployment-pull-secret`, as shown below:
+
[source,terminal]
----
$ oc apply -f - <<EOF
apiVersion: v1
kind: Secret
metadata:
  name: assisted-deployment-pull-secret
  namespace: $CLUSTERNS
type: kubernetes.io/dockerconfigjson
data:
  .dockerconfigjson: $(base64 <pull-secret.json)
EOF
----

. Create a BMC authentication secret for each host you will be deploying:
+
[source,yaml]
----
$ oc apply -f - <<EOF
apiVersion: v1
kind: Secret
metadata:
  name: $(read -p 'Hostname: ' tmp; printf $tmp)-bmc-secret
  namespace: $CLUSTERNS
type: Opaque
data:
  username: $(read -p 'Username: ' tmp; | base64 <<<$tmp)
  password: $(read -s -p 'Password: ' | base64 <<<$tmp)
EOF
----

. Create a SiteConfig CR for your cluster in your local clone of the Git repository:
.. Choose the appropriate example for your CR from the  `out/argocd/example/siteconfig/` folder.
The folder includes example files for single node, three-node, and standard clusters:
+
* `example-sno.yaml`
* `example-3node.yaml`
* `example-standard.yaml`

.. Change the cluster and host details in the example file to match the type of cluster you want.
The following file is a composite of the three files that explains the configuration of each cluster type:
+
[source,yaml]
----
# example-node1-bmh-secret & assisted-deployment-pull-secret need to be created under same namespace example-sno
---
apiVersion: ran.openshift.io/v1
kind: SiteConfig
metadata:
  name: "example-sno"
  namespace: "example-sno"
spec:
  baseDomain: "example.com"
  pullSecretRef:
    name: "assisted-deployment-pull-secret"
  clusterImageSetNameRef: "openshift-4.10" <1>
  sshPublicKey: "ssh-rsa AAAA..."
  clusters:
  - clusterName: "example-sno"
    networkType: "OVNKubernetes"
    clusterLabels: <2>
      # These example cluster labels correspond to the bindingRules in the PolicyGenTemplate examples in ../policygentemplates:
      # ../policygentemplates/common-ranGen.yaml will apply to all clusters with 'common: true'
      common: true
      # ../policygentemplates/group-du-sno-ranGen.yaml will apply to all clusters with 'group-du-sno: ""'
      group-du-sno: ""
      # ../policygentemplates/example-sno-site.yaml will apply to all clusters with 'sites: "example-sno"'
      # Normally this should match or contain the cluster name so it only applies to a single cluster
      sites : "example-sno"
    clusterNetwork:
      - cidr: 1001:1::/48
        hostPrefix: 64
    machineNetwork: <3>
      - cidr: 1111:2222:3333:4444::/64
# For 3-node and standard clusters with static IPs, the API and Ingress IPs must be configured here
apiVIP: 1111:2222:3333:4444::1:1 <4>
ingressVIP: 1111:2222:3333:4444::1:2 <5>

    serviceNetwork:
      - 1001:2::/112
    additionalNTPSources:
      - 1111:2222:3333:4444::2
    nodes:
      - hostName: "example-node1.example.com" <6>
        role: "master"
        bmcAddress: <7>
  "idrac-virtualmedia+https://[1111:2222:3333:4444::bbbb:1]/redfish/v1/Systems/System.Embedded.1"
        bmcCredentialsName:
          name: "example-node1-bmh-secret" <8>
        bootMACAddress: "AA:BB:CC:DD:EE:11"
        bootMode: "UEFI"
        rootDeviceHints:
          hctl: '0:1:0'
        cpuset: "0-1,52-53"
        nodeNetwork: <9>
          interfaces:
            - name: eno1
              macAddress: "AA:BB:CC:DD:EE:11"
          config:
            interfaces:
              - name: eno1
                type: ethernet
                state: up
                macAddress: "AA:BB:CC:DD:EE:11"
                ipv4:
                  enabled: false
                ipv6:
                  enabled: true
                  address:
                  # For SNO sites with static IP addresses, the node-specific, API and Ingress IPs should all be configured on the interface
                  - ip: 1111:2222:3333:4444::aaaa:1
                    prefix-length: 64
                  - ip: 1111:2222:3333:4444::1:1
                    prefix-length: 64
                  - ip: 1111:2222:3333:4444::1:2
                    prefix-length: 64
            dns-resolver:
              config:
                search:
                - example.com
                server:
                - 1111:2222:3333:4444::2
            routes:
              config:
              - destination: ::/0
                next-hop-interface: eno1
                next-hop-address: 1111:2222:3333:4444::1
                table-id: 254
----
<1> `clusterImageSetNameRef` - All cluster types. The value must match an imageset available on the hub cluster. To see the list of supported versions on your hub, run `oc get clusterimagesets`.
<2> `clusterLabels` - All cluster types. These values must correspond to the PolicyGenTemplate labels you will be defining in a later step.
<3> `MachineNetwork` - Single node clusters. The value defines the cluster network sections for a single node deployment.
<4> `apiVIP` - Three-node and standard clusters. The value defines the cluster network sections.
<5> `ingressVIP` - Three-node and standard clusters. The value defines the cluster network sections.
<6> `hostName` - All cluster types. For single node deployments, define one host. For three-node deployments,
define three hosts. For standard deployments, define three hosts with `role: master` and one or more hosts defined with `role: worker`.
<7> `bmcAddress` - All cluster types.
<8> `bmcCredentialsName` - All cluster types.
<9> `nodeNetwork` - All cluster types.

.. You can inspect the default set of extra-manifest MachineConfigs in `out/argocd/extra-manifest`. It
is automatically applied to the cluster as it is installed.
+
Optional: For provisioning additional install-time manifests on the provisioned cluster, create a directory
in your Git repository, for example, `sno-extra-manifest/` and add your custom manifest CRs to this directory.
If your `SiteConfig.yaml` refers to this directory in the `extraManifestPath` field, any CRs in this
referenced directory is appended to the default set of extra manifests.

. Add the `SiteConfig` CR to the `kustomization.yaml` in the `generators` section,
similar to the example shown in `out/argocd/example/siteconfig/kustomization.yaml`.

. Commit your `SiteConfig` and associated `kustomization.yaml` in your Git repository.

. Push your changes to our Git repository and the ArgoCD pipeline will detect the changes and begin the site
deployment. The SiteConfig and PolicyGenTemplate CRs can be pushed simultaneously.
