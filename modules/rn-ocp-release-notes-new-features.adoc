:_mod-docs-content-type: REFERENCE
[id="rn-ocp-release-notes-new-features_{context}"]
= New features and enhancements

This release adds improvements related to the following components and concepts:

[id="ocp-release-notes-api_{context}"]
== API server

////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

[id="ocp-release-notes-auto_{context}"]
== Autoscaling

Network policy support for Autoscaling Operators::
+
The following Operators now have multiple network policies that control network traffic to and from the Operator and operand pods. These policies restrict traffic to only traffic that is explicitly allowed or required.

* Cluster Resource Override Operator
* Cluster Autoscaler
* Vertical Pod Autoscaler
* Horizontal Pod Autoscaler

Applying VPA recommendations without pod re-creation::
+
You can now configure a Vertical Pod Autoscaler Operator (VPA) in the `InPlaceOrRecreate` mode. In this mode, the VPA attempts to apply the recommended updates without re-creating pods. If the VPA is unable to update the pods in place, the VPA falls back to re-creating the pods. For more information, see xref:../nodes/pods/nodes-pods-vertical-autoscaler.adoc#nodes-pods-vertical-autoscaler-modes_nodes-pods-vertical-autoscaler[About the Vertical Pod Autoscaler Operator modes].

Cluster Autoscaler Operator can now cordon nodes before removing the node:: 
+
By default, when the Cluster Autoscaler Operator removes a node, it does not cordon the node when draining the pods from the node. You can configure the Operator to cordon the node before draining and moving the pods. For more information, see xref:../machine_management/applying-autoscaling.adoc#cluster-autoscaler-about_applying-autoscaling[About the cluster autoscaler].

[id="ocp-release-notes-edge-computing_{context}"]
== Edge computing

////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

[id="ocp-release-notes-etcd_{context}"]
== etcd

////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

[id="ocp-release-notes-extensions_{context}"]
== Extensions ({olmv1})

////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

[id="ocp-release-notes-hcp_{context}"]
== Hosted control planes

////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

[id="ocp-release-notes-ibm-power_{context}"]
== IBM Power

////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

[id="ocp-release-notes-ibm-z-linux-one_{context}"]
== IBM Z and IBM LinuxONE

////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

[id="ocp-release-notes-ibm-power-linuxone_{context}"]
== IBM Power, IBM Z, and IBM LinuxOne support matrix

////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

[id="ocp-release-notes-insights-operator_{context}"]
== Insights Operator

////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

[id="ocp-release-notes-install-update_{context}"]
== Installation and update

Configuring {image-mode-os-lower} during installation is now supported::
+
You can now apply a custom layered image to your nodes during {product-title} installation. For more information, see xref:../machine_configuration/mco-coreos-layering.adoc#coreos-layering-install-time_mco-coreos-layering[Applying a custom layered image during OpenShift Container Platform installation].

Installing a cluster on {azure-full} uses Marketplace images by default::
+
As of this update, the {product-title} installation program uses Marketplace images by default when installing a cluster on {azure-short}. This speeds up the installation by removing the need to upload a virtual hard disk to {azure-short} and create an image during installation. This feature is not supported on Azure Stack Hub, or for {azure-short} installations that use Confidential VMs.

Managing your own firewall rules when installing a cluster on {gcp-short} into an existing VPC::
+
As of this update, you can manage your own firewall rules when installing a cluster on {gcp-short} into an existing VPC by enabling the `firewallRulesManagement` parameter in the `install-config.yaml` file. You can limit the permissions that you grant to the installation program by managing your own firewall rules.
+
For more information, see xref:../installing/installing_gcp/installing-gcp-account.adoc#installation-gcp-user-managed-firewall-rules_installing-gcp-account[Managing your own firewall rules].

Throughput customization for {aws-full} gp3 drives::
+
With this update, you can now customize the maximum throughput for gp3 `rootVolume` drives when installing a cluster on {aws-full}. This customization is set by modifying the `compute.platform.aws.rootVolume.throughput` or `controlPlane.platform.aws.rootVolume.throughput` parameters in the `install-config.yaml` file.
+
For more information, see xref:../installing/installing_aws/installation-config-parameters-aws.adoc#installation-configuration-parameters-optional-aws_installation-config-parameters-aws[Optional AWS configuration parameters].

[id="ocp-release-notes-machine-config-operator_{context}"]
== Machine Config Operator

Boot image management for {azure-short} and {vmw-short} clusters promoted to GA:: 
+
Updating boot images has been promoted to GA for {azure-full} and {vmw-full} clusters. For more information, see xref:../machine_configuration/mco-update-boot-images.adoc#mco-update-boot-images[Boot image management].

Configuring {image-mode-os-lower} during installation is now supported::
+
You can now apply a custom layered image to your nodes during {product-title} installation. For more information, see xref:../machine_configuration/mco-coreos-layering.adoc#coreos-layering-install-time_mco-coreos-layering[Applying a custom layered image during OpenShift Container Platform installation].

{image-mode-os-caps} status reporting improvements::
+
The output of the `oc describe machineconfignodes <mcp_name>` now contains an `ImageBuildDegraded` error that indicates if an {image-mode-os-lower} failed. For more information, see xref:../machine_configuration/index.adoc#checking-mco-node-status_machine-config-overview[About node status during updates].

{image-mode-os-caps} status reporting improvements (Technology preview)::
+
The `oc describe machineconfigpool <mcp_name>` output,  as a Technology Preview feature, now includes the following fields that report the status of machine config updates when {image-mode-os-lower} is enabled:
+
* `Spec.ConfigImage.DesiredImage`. This is the desired image for that node.
* `Status.ConfigImage.CurrentImage`. This is the current image on that node.
* `Status.Conditions.ImagePulledFromRegistry`. This reports whether an image is able to pull correctly in an image mode update.

For more information, see xref:../machine_configuration/index.adoc#checking-mco-node-status_machine-config-overview[About node status during updates].

Boot image management for control plane nodes is now supported (Technology Preview)::
+
Updating boot images is now supported as a Technology Preview feature for VMware vSphere clusters. This feature allows you to configure your cluster to update the node boot image whenever you update your cluster. Previously, updating boot images was supported for worker nodes. For more information, see xref:../machine_configuration/mco-update-boot-images.adoc#mco-update-boot-images[Boot image management].

Overriding storage or partition setup (Technology preview)::
+
You can now use a `MachineConfig` object to change the installed disk partition schema, file systems, and RAID configurations for new nodes. Previously, for security reasons, you were blocked from changing these configurations from what was established during the cluster installation. For more information, see "Overriding storage and partition setup".

[id="ocp-release-notes-machine-management_{context}"]
== Machine management

////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

[id="ocp-release-notes-monitoring_{context}"]
== Monitoring

// This should be left for a little while to get users used to the fact that they will find release notes at a new place.
[NOTE]
====
The monitoring stack documentation is now available as a separate documentation set. The {product-version} monitoring release notes are available at link:https://docs.redhat.com/en/documentation/monitoring_stack_for_red_hat_openshift/{product-version}/html-single/release_notes_for_openshift_monitoring[Release notes for OpenShift monitoring].
====

[id="ocp-release-notes-networking_{context}"]
== Networking

Applying unassisted holdover for boundary clocks and time synchronous clocks::
+
{product-title} 4.20 introduced unassisted holdover for boundary clocks and time synchronous clocks as a Technology Preview feature. This feature is now Generally Available (GA).
+
For more information, see xref:../networking/advanced_networking/ptp/configuring-ptp.adoc[Applying unassisted holdover for boundary clocks and time slave clocks].

SR-IOV Operator supports ARM architecture::
+
The Single Root I/O Virtualization (SR-IOV) Operator can now communicate with ARM hardware. You can now complete tasks such as configure network cards that are already plugged into an ARM server and use these cards in your applications. For instructions on how to search for ARM hardware that the SR-IOV Operator supports, see xref:../networking/hardware_networks/about-sriov.adoc[About Single Root I/O Virtualization (SR-IOV) hardware networks].

[id="ocp-release-notes-nodes_{context}"]
== Nodes

Allocating specific GPUs to pods (DRA) is now generally available::
+
Attribute-Based GPU Allocation, which allows pods to request GPUs based on specific device attributes by using a Dynamic Resource Allocation (DRA) driver, is now generally available. For more information, see xref:../nodes/pods/nodes-pods-allocate-dra.adoc#nodes-pods-allocate-dra[Allocating GPUs to Pods].

The default `openshift` cluster image policy is now generally available::
+
The default `openshift` cluster image policy is now generally available and active by default. For more information, see xref:../nodes/nodes-sigstore-using.adoc#nodes-sigstore-using[Manage secure signatures with sigstore].
+
If your {product-title} 4.20 or earlier cluster has a cluster image policy named `openshift`, the upgrade to {product-title} marks the cluster as not updatable (`Upgradeable=False`) because of this default `openshift` cluster image policy. You must remove your `openshift` cluster image policy to clear the `Upgradeable=False` condition and proceed with the update. You can optionally create your own cluster image policy with a different name before removing your `openshift` cluster image policy.

Support for sigstore BYOPKI is now generally available::
+
Support for using a certificate from your own public key infrastructure as a Sigstore root of trust is now generally available. For more information, see xref:../nodes/nodes-sigstore-using.adoc#nodes-sigstore-using[Manage secure signatures with sigstore].

Automatically calculate and apply CPU and memory resources for system components::
+
{product-title} now automatically calculates and reserves a portion of the CPU and memory resources for use by the underlying node and system components. Previously, you needed to enable the feature by creating a `KubeletConfig` custom resource (CR) with the `autoSizingReserved: true` parameter. For clusters updated to {product-title} 4.21, you can enable the feature by deleting the `50-worker-auto-sizing-disabled` machine config. After you delete the machine config, the nodes reboot with the new resource settings. If you manually configured system reserved CPU or memory resources, these settings remain upon update and do not change. For more information on this new feature, see xref:../nodes/nodes/nodes-nodes-resources-configuring.adoc#nodes-nodes-resources-configuring-auto_nodes-nodes-resources-configuring[Automatically allocating resources for nodes].

[id="ocp-release-notes-ocp-cli_{context}"]
== OpenShift CLI (oc)

Signature mirroring enabled by default for oc-mirror v2::
With this update, the oc-mirror v2 plugin mirrors image signatures by default. This enhancement ensures that image integrity is automatically preserved during the mirroring process without requiring additional configuration. If your environment does not require signature validation, you can manually disable this feature by using the `--remove-signatures` command-line flag. For more information, see xref:../disconnected/about-installing-oc-mirror-v2.adoc#oc-mirror-signature-mirroring_about-installing-oc-mirror-v2[Disabling signature mirroring for oc-mirror plugin v2].
////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

[id="ocp-release-notes-operator-development_{context}"]
== Operator development

////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

Bare Metal Operator has read-only root filesystem by default::
+
As of this update, the Bare Metal Operator has the `readOnlyRootFilesystem` security context setting enabled to meet common hardening recommendations.

[id="ocp-release-notes-operator-lifecycle_{context}"]
== Operator lifecycle

////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

[id="ocp-release-notes-post-install-configuration_{context}"]
== Postinstallation configuration

////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

[id="ocp-release-notes-rhcos_{context}"]
== Red Hat Enterprise Linux CoreOS (RHCOS)

////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

[id="ocp-release-notes-scale-and-perform_{context}"]
== Scalability and performance

Pod-level IRQ affinity introduces housekeeping mode::
+
For latency-sensitive workloads, you can now configure the `irq-load-balancing.crio.io` pod annotation to use `housekeeping` mode. This mode enables a subset of pinned CPUs to handle system interrupts while isolating the remaining pinned CPUs for latency-sensitive workloads. This reduces the overall CPU footprint by eliminating the need for dedicated housekeeping CPUs for IRQ handling. When you configure `housekeeping` mode, the first pinned CPU and its thread siblings handle interrupts for the system.
+
For more information, see xref:../scalability_and_performance/cnf-provisioning-low-latency-workloads.adoc#cnf-disabling-interrupt-processing-for-individual-pods_cnf-provisioning-low-latency[Configuring interrupt processing for individual pods].

[id="ocp-release-notes-storage_{context}"]
== Storage

Volume Attributes Classes is generally available::
+
Volume Attributes Classes provide a way for administrators to describe "classes" of storage they offer. Different classes might correspond to different quality-of-service levels. Volume Attributes Classes was introduced in {product-title} 4.19, and is now generally available in 4.21.
+
Volume Attributes Classes is available only with AWS Elastic Block Storage (EBS) and Google Cloud Platform (GCP) persistent disk (PD) Container Storage Interface (CSI).
+
You can apply a Volume Attributes Classes to a persistent volume claim (PVC). If a new Volume Attributes Class becomes available in the cluster, you can update the PVC with the new Volume Attributes Classes if needed.
+
Volume Attributes Classes have parameters that describe volumes belonging to them. If a parameter is omitted, the default is used at volume provisioning. If a user applies the PVC with a different Volume Attributes Class with omitted parameters, the default value of the parameters might be used depending on the CSI driver implementation. For more information, see the related CSI driver documentation.
+
For more information, see xref:../storage/understanding-persistent-storage.adoc#storage-persistent-storage-pvc-volumeattributesclass_understanding-persistent-storage[Volume Attributes Classes]. 

Azure File CSI supporting snapshots feature is generally available::
+
A snapshot represents the state of the storage volume in a cluster at a particular point in time. Volume snapshots can be used to provision a new volume.
+
{product-title} 4.17 introduced volume snapshot support for the Microsoft Azure File Container Storage Interface (CSI) Driver Operator as a Technology Preview feature. In 4.21, this feature is generally available. Also, Azure File snapshots now supports Network File System (NFS) in addition to Server Message Block (SMB).
+
For more information, see xref:../storage/container_storage_interface/persistent-storage-csi.adoc#csi-drivers-supported_persistent-storage-csi[CSI drivers supported by OpenShift Container Platform] and xref:../storage/container_storage_interface/persistent-storage-csi-snapshots.adoc[CSI volume snapshots].

Azure File CSI supporting volume cloning feature is generally available::
+
Volume cloning duplicates an existing persistent volume (PV) to help protect against data loss in {product-title}. You can also use a volume clone just as you would use any standard volume.
+
{product-title} 4.16 introduced volume cloning for the Microsoft Azure File Container Storage Interface (CSI) Driver Operator as a Technology Preview feature. In 4.21, this feature is generally available. Also, Azure File cloning now supports Network File System (NFS) in addition to Server Message Block (SMB).
+
For more information, see xref:../storage/container_storage_interface/persistent-storage-csi-azure-file.adoc[Azure File CSI Driver Operator] and xref:../storage/container_storage_interface/persistent-storage-csi-cloning.adoc[CSI volume cloning].

oVirt CSI Driver Operator is removed from {product-title} 4.21::
+
Red Hat Virtualization (RHV) as a host platform for {product-title} was deprecated in version 4.14 and is no longer supported. In {product-title} 4.21, the oVirt CSI Driver Operator is removed.

CIFS/SMB CSI Driver Operator supports IBM Power::
+
In {product-title} 4.21, the CIFS/SMB CSI Driver Operator supports IBM Power (ppc64le).
+
For more information, see xref:../storage/container_storage_interface/persistent-storage-csi-smb-cifs.adoc[CIFS/SMB CSI Driver Operator].

Introduction of new field to track the status of volume resize attempts::
+
{product-title} 4.19 introduced resizing recovery that stops the expansion controller from indefinitely attempting to expand a volume to an unsupported size request. This feature allows you to recover and provide another smaller resize value for the persistent volume claim (PVC). The new value must be larger than the original volume size.
+
{product-title} 4.21 introduces the `pvc.Status.AllocatedResourceStatus` field, which shows the status of volume resize attempts. If a user changes the size of their PVCs, this new field allows resource quota to be tracked accurately.
+
For more information about resizing volumes, see xref:../storage/expanding-persistent-volumes.adoc[Expanding persistent volumes].
+
For more information about recovering when resizing volumes, see xref:../storage/expanding-persistent-volumes.adoc#expanding-recovering-from-failure_expanding-persistent-volumes[Recovering from failure when expanding volumes].

Mutable CSI node allocatable property (Technical Preview)::
+
This feature allows for dynamically updating the maximum number of storage volumes a node can handle. Without this feature, volume limits are essentially immutable when a node first joins the cluster. If the environment changes—for example, if you attach a new network interface (ENI) that shares a hardware "slot" with your storage—{product-title} does not recognize it has fewer slots available for disks, leading to pods becoming stuck.
+
This feature is only supported on AWS Elastic Block Storage (EBS).
+
Mutable CSI node allocatable property is supported in {product-title} 4.21 as a Technical Preview feature. To enable this feature, you need to enable Feature Gates.
+
For more information about enabling Technical Preview features, see xref:../nodes/clusters/nodes-cluster-enabling-features.adoc[Feature Gates].

Reducing permissions while using the GCP PD CSI Driver Operator is generally available::
+
The default installation allows the Google Cloud Platform (GCP) persistent disk (PD) Container Storage Interface (CSI) Driver to impersonate any service account in the Google Cloud project. You can reduce the scope of permissions granted to the GCP PD CSI Driver service account in your Google Cloud project to only the required node service accounts.
+
For more information about this feature, see xref:../storage/container_storage_interface/persistent-storage-csi-gcp-pd.adoc#persistent-storage-csi-gcp-pd-reduce-permissions_persistent-storage-csi-gcp-pd[Reducing permissions while using the GCP PD CSI Driver Operator].

Volume group snapshots API updated (Technical Preview)::
+
The API for the Container Storage Interface (CSI) volume group snapshot feature is updated from `v1beta1` to `v1beta2`.
+
This feature is supported at the Technical Preview level.
+
For more information, see xref:../storage/container_storage_interface/persistent-storage-csi-group-snapshots.adoc[CSI volume group snapshots].

[id="ocp-release-notes-support-sigstore_{context}"]
== Support for sigstore bring your own PKI (BYOPKI) image validation

////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

[id="ocp-release-notes-web-console_{context}"]
== Web console

////
Instructions: Add entries in the following format:

Item description::
+
Detailed information.
////

