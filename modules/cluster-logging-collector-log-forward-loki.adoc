[id="cluster-logging-collector-log-forward-loki_{context}"]
= Forwarding logs to Loki

You can forward logs to an external Loki logging system in addition to, or instead of, the internal default {product-title} Elasticsearch instance.

To configure log forwarding to Loki, you must create a `ClusterLogForwarder` custom resource (CR) with an output to Loki, and a pipeline that uses the output. The output to Loki can use the HTTP (insecure) or HTTPS (secure HTTP) connection.

.Prerequisites

* You must have a Loki logging system running at the URL you specify with the `url` field in the CR.

.Procedure

. Create or edit a YAML file that defines the `ClusterLogForwarder` CR object:
+
[source,yaml]
----
apiVersion: "logging.openshift.io/v1"
kind: ClusterLogForwarder
metadata:
  name: instance <1>
  namespace: openshift-logging <2>
spec:
  outputs:
   - name: loki-insecure <3>
     type: "loki" <4>
     url: http://loki.insecure.com:9200 <5>
   - name: loki-secure
     type: "loki"
     url: https://loki.secure.com:9200 <6>
     secret:
        name: loki-secret <7>
  pipelines:
   - name: application-logs <8>
     inputRefs: <9>
     - application
     - audit
     outputRefs:
     - loki-secure <10>
     loki:
       tenantKey: kubernetes.namespace_name <11>
       labelKeys: kubernetes.labels.foo   <12>
----
<1> The name of the `ClusterLogForwarder` CR must be `instance`.
<2> The namespace for the `ClusterLogForwarder` CR must be `openshift-logging`.
<3> Specify a name for the output.
<4> Specify the type as `"loki"`.
<5> Specify the URL and port of the Loki system as a valid absolute URL. You can use the `http` (insecure) or `https` (secure HTTP) protocol. If the cluster-wide proxy using the CIDR annotation is enabled, the output must be a server name or FQDN, not an IP Address.
<6> For a secure connection, you can specify an `https` or `http` URL that you authenticate by specifying a `secret`.
<7> For an `https` prefix, specify the name of the secret required by the endpoint for TLS communication. The secret must exist in the `openshift-logging` project, and must have keys of: *tls.crt*, *tls.key*, and *ca-bundle.crt* that point to the respective certificates that they represent. Otherwise, for `http` and `https` prefixes, you can specify a secret that contains a username and password. For more information, see the following "Example: Setting secret that contains a username and password."
<8> Optional: Specify a name for the pipeline.
<9> Specify which log types to forward by using the pipeline: `application,` `infrastructure`, or `audit`.
<10> Specify the name of the output to use when forwarding logs with this pipeline.
<11> Optional: Specify a meta-data key field to generate values for the `TenantID` field in Loki. For example, setting `tenantKey: kubernetes.namespace_name` uses the names of the Kubernetes namespaces as values for tenant IDs in Loki. To see which other log record fields you can specify, see the "Log Record Fields" link in the following "Additional resources" section.
<12> Optional: Specify a list of meta-data field keys to replace the default Loki labels. Loki label names must match the regular expression `[a-zA-Z_:][a-zA-Z0-9_:]*`. Illegal characters in meta-data keys are replaced with `_` to form the label name. For example, the `kubernetes.labels.foo` meta-data key becomes Loki label `kubernetes_labels_foo`. If you do not set `labelKeys`, the default value is: `[log_type, kubernetes.namespace_name, kubernetes.pod_name, kubernetes_host]`. Keep the set of labels small because Loki limits the size and number of labels allowed. See link:https://grafana.com/docs/loki/latest/configuration/#limits_config[Configuring Loki, limits_config]. You can still query based on any log record field using query filters.
+
[NOTE]
====
Because Loki requires log streams to be correctly ordered by timestamp, `labelKeys` always includes the `kubernetes_host` label set, even if you do not specify it. This inclusion ensures that each stream originates from a single host, which prevents timestamps from becoming disordered due to clock differences on different hosts.
====


. Create the CR object:
+
[source,terminal]
----
$ oc create -f <file-name>.yaml
----
