// Module included in the following assemblies:
//
// * updating/updating_a_cluster/update-using-custom-machine-config-pools.adoc

:_mod-docs-content-type: CONCEPT
[id="update-using-custom-machine-config-pools-about_{context}"]
= About performing a canary rollout update

This topic describes the general workflow of this canary rollout update process. The steps to perform each task in the workflow are described in the following sections.

. Create MCPs based on the worker pool. The number of nodes in each MCP depends on a few factors, such as your maintenance window duration for each MCP, and the amount of reserve capacity, meaning extra worker nodes, available in your cluster.
+
[NOTE]
====
You can change the `maxUnavailable` setting in an MCP to specify the percentage or the number of machines that can be updating at any given time. The default is 1.
====

. Add a node selector to the custom MCPs. For each node that you do not want to update simultaneously with the rest of the cluster, add a matching label to the nodes. This label associates the node to the MCP.
+
[NOTE]
====
Do not remove the default worker label from the nodes. The nodes *must* have a role label to function properly in the cluster.
====

. Pause the MCPs you do not want to update as part of the update process.

. Perform the cluster update. The update process updates the MCPs that are not paused, including the control plane nodes.

. Test the applications on the updated nodes to ensure they are working as expected.

. Unpause the remaining MCPs one-by-one and test the applications on those nodes until all worker nodes are updated. Unpausing an MCP starts the update process for the nodes associated with that MCP. You can check the progress of the update from the web console by clicking *Administration* -> *Cluster settings*. Or, use the `oc get machineconfigpools` CLI command.

. Optionally, remove the custom label from updated nodes and delete the custom MCPs.
