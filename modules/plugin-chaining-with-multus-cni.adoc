// Module included in the following assemblies:
//
// networking/multiple_networks/about-chaining.adoc

:_mod-docs-content-type: PROCEDURE
[id="configuring-plugin-chaining-with-multus-cni_{context}"]
= Configuring plugin chaining with the route-override CNI plugin

Plugin chaining allows you to configure multiple CNI plugins to be applied sequentially to the same network interface. This approach is useful when you need to implement complex network configurations, such as routing traffic over different network paths or creating isolated networks for specialized traffic types.

For instance, in a telco environment, you might have the following requirements:

* Session Initiation Protocol (SIP) traffic for instance voice over IP must always be routed over a dedicated SIP network for optimized performance.
* Management traffic must go over a separate management network for administrative purposes.

Consider a telco application where SIP (telephony) traffic must be isolated from other types of traffic for example management or data traffic. This requires two networks:

* SIP Network: Handles all telephony traffic to ensure quality of service (QoS) and low latency.
* Management Network: Handles administrative traffic such as monitoring and configuration.

In this case, you can configure a pod with two interfaces:

* `eth1` for management traffic, routed through the management network.
* `eth2` for SIP traffic, routed through the SIP network.

This example uses plugin chaining with the `route-override` CNI, to attach both interfaces ensuring SIP traffic is only routed through `eth2` while management traffic flows is routed through `eth1`.

.Prerequisites

* Install the OpenShift CLI (`oc`).
* An account with `cluster-admin` privileges.

.Procedure

. Create the `telco-app` namespace by running the following command:
+
[source,terminal]
----
$ oc create namespace telco-app
----

. Create the NetworkAttachmentDefinition for the management network

.. Create a YAML file, such as `management.yaml`, to define a NetworkAttachmentDefinition (NAD) that configures a new interface, `eth1`, with the following configuration:
+
[source,yaml]
----
apiVersion: k8s.cni.cncf.io/v1
kind: NetworkAttachmentDefinition
metadata:
  name: management-net
  namespace: telco-app
spec:
  config: '{
    "cniVersion": "1.0.0",
    "name": "management-net",
    "plugins": [
      {
        "type": "macvlan",
        "master": "br-ex",
        "vlan": 100,
        "mode": "bridge",
        "ipam": {
          "type": "static",
          "addresses": [
            {
              "address": "192.168.100.10/24",
              "gateway": "192.168.100.1"
            }
          ]
        }
      },
      {
        "type": "route-override",
        "table": 100,
        "srcRules": [
          {
            "from": "192.168.100.10/32",
            "table": 100
          }
        ],
        "routes": [
          { "dst": "0.0.0.0/0", "gw": "192.168.100.1" }
        ]
      }
    ]
  }'
----

. Create a chained NAD by running the following command:
+
[source,terminal]
----
$ oc apply -f management.yaml
----

. Create the NetworkAttachmentDefinition for the SIP Network.

.. Create a YAML file, such as `sip.yaml`, to define a NetworkAttachmentDefinition (NAD) that configures a new interface, `eth2`, with the following configuration:
+
[source,yaml]
----
apiVersion: k8s.cni.cncf.io/v1
kind: NetworkAttachmentDefinition
metadata:
  name: sip-net
  namespace: telco-app
spec:
  config: '{
    "cniVersion": "1.0.0",
    "name": "sip-net",
    "plugins": [
      {
        "type": "macvlan",
        "master": "br-ex",
        "vlan": 200,
        "mode": "bridge",
        "ipam": {
          "type": "static",
          "addresses": [
            {
              "address": "192.168.200.10/24",
              "gateway": "192.168.200.1"
            }
          ]
        }
      },
      {
        "type": "route-override",
        "table": 200,
        "srcRules": [
          {
            "from": "192.168.200.10/32",
            "table": 200
          }
        ],
        "routes": [
          { "dst": "0.0.0.0/0", "gw": "192.168.200.1" }
        ]
      }
    ]
  }'
----

. Create the chained NAD by running the following command:
+
[source,terminal]
----
$ oc apply -f sip.yaml
----

.  Attach the NADs to a pod by creating a Pod definition file, such as `pod.yaml`, with the following configuration:
+
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: voip-app-pod
  namespace: telco-app
  labels:
    app: voip-app
  annotations:
    k8s.v1.cni.cncf.io/networks: '[
      { "name": "management-net", "interface": "eth1" },
      { "name": "sip-net", "interface": "eth2" }
    ]'
spec:
  securityContext:
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
  containers:
  - name: voip-container
    image: dougbtv/asterisk:latest    # This can be any VOIP application like Asterisk or FreeSWITCH
    command: ["/bin/bash", "-c", "asterisk -f"]  # Asterisk command to start the server
    ports:
      - containerPort: 5060          # SIP traffic port (UDP)
      - containerPort: 8088          # Management port (HTTP)
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop: ["ALL"]
      runAsUser: 1000
      runAsGroup: 1000
----

. Create the pod by running the following command:
+
[source,terminal]
----
$ oc apply -f pod.yaml
----

.Verification

. Run the following command to list all network interfaces and their assigned IP addresses inside the `voip-app-pod`. This verifies that the pod has multiple network interfaces configured as expected:
+
[source,terminal]
----
$ oc exec -it voip-app-pod -n telco-app -- ip a
----
+
.Example output
[source,terminal]
----
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0@if31: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 8901 qdisc noqueue state UP 
    link/ether 0a:58:0a:83:02:19 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 10.131.2.25/23 brd 10.131.3.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::858:aff:fe83:219/64 scope link 
       valid_lft forever preferred_lft forever
3: eth1@if5: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 9001 qdisc noqueue state UP qlen 1000
    link/ether aa:25:73:ff:a7:00 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 192.168.100.10/24 brd 192.168.100.255 scope global eth1
       valid_lft forever preferred_lft forever
    inet6 fe80::a825:73ff:feff:a700/64 scope link 
       valid_lft forever preferred_lft forever
4: eth2@if5: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 9001 qdisc noqueue state UP qlen 1000
    link/ether aa:a4:6c:4e:e8:97 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 192.168.200.10/24 brd 192.168.200.255 scope global eth2
       valid_lft forever preferred_lft forever
    inet6 fe80::a8a4:6cff:fe4e:e897/64 scope link 
       valid_lft forever preferred_lft forever
----
+
This output show the pod is attached connected to multiple networks, enabling it to interact with different external services or data planes:
* `eth0`: The default interface for the pod, connected to the cluster network.
* `eth1`: management-net, IP: 192.168.100.10
* `eth2`: sip-net, IP: 192.168.200.10

. Run the following command to view the routing table. 
+
[source,terminal]
----
$ oc exec -it telco-app-pod -n telco-app -- ip route
----
+
.Example output
[source,terminal]
----
default via 10.131.0.1 dev eth0 
10.128.0.0/14 via 10.131.0.1 dev eth0 
10.131.0.0/23 dev eth0 proto kernel scope link src 10.131.0.17 
100.64.0.0/16 via 10.131.0.1 dev eth0 
169.254.0.5 via 10.131.0.1 dev eth0 
172.30.0.0/16 via 10.131.0.1 dev eth0 
192.168.100.0/24 dev eth1 proto kernel scope link src 192.168.100.10 
192.168.200.0/24 dev eth2 proto kernel scope link src 192.168.200.10
----
+
This output shows the routing table inside the pod, which includes the default route and routes for the management and SIP networks. 

* SIP Network Traffic (eth2)
** The pod has an interface `eth2` with an IP address `192.168.200.10` on the `192.168.200.0/24` network. Traffic destined for the `192.168.200.0/24` network is routed through `eth2`, as expected for the SIP traffic.

* Management Network Traffic (eth1)
** The pod has an interface `eth1` with an IP address `192.168.100.10` on the `192.168.100.0/24` network. Traffic destined for `192.168.100.0/24` (management traffic) is routed through `eth1`, which meets the requirement for handling administrative traffic.