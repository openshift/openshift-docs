// Module included in the following assemblies:
// Epic CNF-792 (4.8)
// * scalability_and_performance/cnf-create-performance-profiles.adoc

[id="running-the-performance-profile-creator-wrapper-script_{context}"]
= Running the Performance Profile Creator wrapper script

The performance profile wrapper script simplifies the running of the Performance Profile Creator (PPC) tool. It hides the complexities associated with running `podman` and specifying the mapping directories and it enables the creation of the performance profile.

.Prerequisites

* Access to the Performance Addon Operator image.
* Access to the `must-gather` tarball.

.Procedure

. Create a file on your local machine named, for example, `run-perf-profile-creator.sh`:
+
[source,terminal]
----
$ vi run-perf-profile-creator.sh
----

. Paste the following code into the file:
+
[source,bash]
----
#!/bin/bash

readonly CONTAINER_RUNTIME=${CONTAINER_RUNTIME:-podman}
readonly CURRENT_SCRIPT=$(basename "$0")
readonly CMD="${CONTAINER_RUNTIME} run --entrypoint performance-profile-creator"
readonly IMG_EXISTS_CMD="${CONTAINER_RUNTIME} image exists"
readonly IMG_PULL_CMD="${CONTAINER_RUNTIME} image pull"
readonly MUST_GATHER_VOL="/must-gather"

PAO_IMG="registry.redhat.io/openshift4/performance-addon-rhel8-operator:v4.10"
MG_TARBALL=""
DATA_DIR=""

usage() {
  print "Wrapper usage:"
  print "  ${CURRENT_SCRIPT} [-h] [-p image][-t path] -- [performance-profile-creator flags]"
  print ""
  print "Options:"
  print "   -h                 help for ${CURRENT_SCRIPT}"
  print "   -p                 Performance Addon Operator image"
  print "   -t                 path to a must-gather tarball"

  ${IMG_EXISTS_CMD} "${PAO_IMG}" && ${CMD} "${PAO_IMG}" -h
}

function cleanup {
  [ -d "${DATA_DIR}" ] && rm -rf "${DATA_DIR}"
}
trap cleanup EXIT

exit_error() {
  print "error: $*"
  usage
  exit 1
}

print() {
  echo  "$*" >&2
}

check_requirements() {
  ${IMG_EXISTS_CMD} "${PAO_IMG}" || ${IMG_PULL_CMD} "${PAO_IMG}" || \
      exit_error "Performance Addon Operator image not found"

  [ -n "${MG_TARBALL}" ] || exit_error "Must-gather tarball file path is mandatory"
  [ -f "${MG_TARBALL}" ] || exit_error "Must-gather tarball file not found"

  DATA_DIR=$(mktemp -d -t "${CURRENT_SCRIPT}XXXX") || exit_error "Cannot create the data directory"
  tar -zxf "${MG_TARBALL}" --directory "${DATA_DIR}" || exit_error "Cannot decompress the must-gather tarball"
  chmod a+rx "${DATA_DIR}"

  return 0
}

main() {
  while getopts ':hp:t:' OPT; do
    case "${OPT}" in
      h)
        usage
        exit 0
        ;;
      p)
        PAO_IMG="${OPTARG}"
        ;;
      t)
        MG_TARBALL="${OPTARG}"
        ;;
      ?)
        exit_error "invalid argument: ${OPTARG}"
        ;;
    esac
  done
  shift $((OPTIND - 1))

  check_requirements || exit 1

  ${CMD} -v "${DATA_DIR}:${MUST_GATHER_VOL}:z" "${PAO_IMG}" "$@" --must-gather-dir-path "${MUST_GATHER_VOL}"
  echo "" 1>&2
}

main "$@"
----

. Add execute permissions for everyone on this script:
+
[source,terminal]
----
$ chmod a+x run-perf-profile-creator.sh
----

. Optional: Display the `run-perf-profile-creator.sh` command usage:
+
[source,terminal]
----
$ ./run-perf-profile-creator.sh -h
----
+
.Expected output
+
[source,terminal]
----
Wrapper usage:
  run-perf-profile-creator.sh [-h] [-p image][-t path] -- [performance-profile-creator flags]

Options:
   -h                 help for run-perf-profile-creator.sh
   -p                 Performance Addon Operator image <1>
   -t                 path to a must-gather tarball <2>

A tool that automates creation of Performance Profiles

   Usage:
     performance-profile-creator [flags]

   Flags:
         --disable-ht                        Disable Hyperthreading
     -h, --help                              help for performance-profile-creator
         --info string                       Show cluster information; requires --must-gather-dir-path, ignore the other arguments. [Valid values: log, json] (default "log")
         --mcp-name string                   MCP name corresponding to the target machines (required)
         --must-gather-dir-path string       Must gather directory path (default "must-gather")
         --power-consumption-mode string     The power consumption mode.  [Valid values: default, low-latency, ultra-low-latency] (default "default")
         --profile-name string               Name of the performance profile to be created (default "performance")
         --reserved-cpu-count int            Number of reserved CPUs (required)
         --rt-kernel                         Enable Real Time Kernel (required)
         --split-reserved-cpus-across-numa   Split the Reserved CPUs across NUMA nodes
         --topology-manager-policy string    Kubelet Topology Manager Policy of the performance profile to be created. [Valid values: single-numa-node, best-effort, restricted] (default "restricted")
         --user-level-networking             Run with User level Networking(DPDK) enabled
----
+
[NOTE]
====
There two types of arguments:

* Wrapper arguments namely `-h`, `-p` and `-t`
* PPC arguments
====
+
<1> Optional: Specify the Performance Addon Operator image. If not set, the default upstream image is used: `registry.redhat.io/openshift4/performance-addon-rhel8-operator:v4.10`.
<2> `-t` is a required wrapper script argument and specifies the path to a `must-gather` tarball.

. Run the performance profile creator tool in discovery mode:
+
[NOTE]
====
Discovery mode inspects your cluster using the output from `must-gather`. The output produced includes information on:

* The NUMA cell partitioning with the allocated CPU IDs
* Whether hyperthreading is enabled

Using this information you can set appropriate values for some of the arguments supplied to the Performance Profile Creator tool.
====
+
[source,terminal]
----
$ ./run-perf-profile-creator.sh -t /must-gather/must-gather.tar.gz -- --info=log
----
+
[NOTE]
====
The `info` option requires a value which specifies the output format. Possible values are log and JSON. The JSON format is reserved for debugging.
====

. Check the machine config pool:
+
[source,terminal]
----
$ oc get mcp
----
+
.Example output

[source,terminal]
----
NAME         CONFIG                                                 UPDATED   UPDATING   DEGRADED   MACHINECOUNT   READYMACHINECOUNT   UPDATEDMACHINECOUNT   DEGRADEDMACHINECOUNT   AGE
master       rendered-master-acd1358917e9f98cbdb599aea622d78b       True      False      False      3              3                   3                     0                      22h
worker-cnf   rendered-worker-cnf-1d871ac76e1951d32b2fe92369879826   False     True       False      2              1                   1                     0                      22h
----

. Create a performance profile:
+
[source,terminal]
----
$ ./run-perf-profile-creator.sh -t /must-gather/must-gather.tar.gz -- --mcp-name=worker-cnf --reserved-cpu-count=2 --rt-kernel=true > my-performance-profile.yaml
----
+
[NOTE]
====
The Performance Profile Creator arguments are shown in the Performance Profile Creator arguments table. The following arguments are required:

* `reserved-cpu-count`
* `mcp-name`
* `rt-kernel`

The `mcp-name` argument in this example is set to `worker-cnf` based on the output of the command `oc get mcp`. For Single Node OpenShift (SNO) use `--mcp-name=master`.
====

. Review the created YAML file:
+
[source,terminal]
----
$ cat my-performance-profile.yaml
----
.Example output
+
[source,terminal]
----
apiVersion: performance.openshift.io/v2
kind: PerformanceProfile
metadata:
  name: performance
spec:
  cpu:
    isolated: 1-39,41-79
    reserved: 0,40
  nodeSelector:
    node-role.kubernetes.io/worker-cnf: ""
  numa:
    topologyPolicy: restricted
  realTimeKernel:
    enabled: false
----

. Apply the generated profile:
+
[NOTE]
====
Install the Performance Addon Operator before applying the profile. For install instructions, see xref:cnf-performance-addon-operator-for-low-latency-nodes.adoc#installing-the-performance-addon-operator_cnf-master[Installing the Performance Addon Operator].
====

+
[source,terminal]
----
$ oc apply -f my-performance-profile.yaml
----
