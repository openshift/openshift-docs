// Module included in the following assemblies:
//
// * otel/otel-migrating.adoc

:_mod-docs-content-type: PROCEDURE
[id="migrating-to-otel-from-jaeger-without-sidecars_{context}"]
= Migrating from the {JaegerShortName} to the {OTELShortName} without sidecars

You can migrate from the {JaegerShortName} to the {OTELShortName} without sidecar deployment.

.Prerequisites

* The {JaegerName} is used on the cluster.
* The {OTELName} is installed.

.Procedure

. Configure OpenTelemetry Collector deployment.

. Create the project where the OpenTelemetry Collector will be deployed.
+
[source,yaml]
----
apiVersion: project.openshift.io/v1
kind: Project
metadata:
  name: observability
----

. Create a service account for running the OpenTelemetry Collector instance.
+
[source,yaml]
----
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otel-collector-deployment
  namespace: observability
----

. Create a cluster role for setting the required permissions for the processors.
+
[source,yaml]
----
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otel-collector
rules:
  # <1>
  # <2>
- apiGroups: ["", "config.openshift.io"]
  resources: ["pods", "namespaces", "infrastructures", "infrastructures/status"]
  verbs: ["get", "watch", "list"]
----
<1> Permissions for the `pods` and `namespaces` resources are required for the `k8sattributesprocessor`.
<2> Permissions for `infrastructures` and `infrastructures/status` are required for `resourcedetectionprocessor`.

. Create a ClusterRoleBinding to set the permissions for the service account.
+
[source,yaml]
----
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otel-collector
subjects:
- kind: ServiceAccount
  name: otel-collector-deployment
  namespace: observability
roleRef:
  kind: ClusterRole
  name: otel-collector
  apiGroup: rbac.authorization.k8s.io
----

. Create the OpenTelemetry Collector instance.
+
[NOTE]
====
This collector will export traces to a TempoStack instance. You must create your TempoStack instance by using the Red Hat Tempo Operator and place here the correct endpoint.
====
+
[source,yaml]
----
apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: otel
  namespace: observability
spec:
  mode: deployment
  serviceAccount: otel-collector-deployment
  config: |
    receivers:
      jaeger:
        protocols:
          grpc:
          thrift_binary:
          thrift_compact:
          thrift_http:
    processors:
      batch:
      k8sattributes:
      memory_limiter:
        check_interval: 1s
        limit_percentage: 50
        spike_limit_percentage: 30
      resourcedetection:
        detectors: [openshift]
    exporters:
      otlp:
        endpoint: "tempo-example-gateway:8090"
        tls:
          insecure: true
    service:
      pipelines:
        traces:
          receivers: [jaeger]
          processors: [memory_limiter, k8sattributes, resourcedetection, batch]
          exporters: [otlp]
----

. Point your tracing endpoint to the OpenTelemetry Operator.

. If you are exporting your traces directly from your application to Jaeger, change the API endpoint from the Jaeger endpoint to the OpenTelemetry Collector endpoint.
+
.Example of exporting traces by using the `jaegerexporter` with Golang
[source,golang]
----
exp, err := jaeger.New(jaeger.WithCollectorEndpoint(jaeger.WithEndpoint(url))) # <1>
----
<1> The URL points to the OpenTelemetry Collector API endpoint.
