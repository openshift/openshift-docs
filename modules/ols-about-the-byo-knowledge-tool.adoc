// Module included in the following assemblies:
// * lightspeed-docs-main/configure/ols-configuring-openshift-lightspeed.adoc

:_mod-docs-content-type: CONCEPT
[id="about-the-byo-knowledge-tool_{context}"]
= About the BYO Knowledge tool

[role="_abstract"]
The {ols-long} service uses a large language model (LLM) to generate responses to questions. You can enhance the knowledge that is available to the LLM by using the BYO Knowledge tool to create a retrieval-augmented generation (RAG) database. 

When you create a RAG database, you customize the {ols-long} service for your environment. For example, a network administrator can develop a standard operating procedure (SOP) that is used to provision an {ocp-product-title} cluster. Then, the network administrator can use the BYO Knowledge tool to enhance the knowledge available to the LLM by including information from the SOP.

To bring your own knowledge to an LLM, you complete the following steps:

* Create the custom content in Markdown format.
* Use the BYO Knowledge tool to package the content as a container image.
* Push the container image to an image registry, such as `quay.io`.
* Update the `OLSConfig` custom resource file to list the image that you pushed to the image registry.
* Access the {ols-long} virtual assistant and submit a question that is associated with the custom knowledge that you made available to the LLM.
+
[NOTE]
====
When you use the BYO Knowledge tool, the documents that you make available to the LLM are sent to the LLM provider.
====

{ols-long} supports automatic updates of BYO Knowledge images that use floating tags, such as `latest`. If over time a BYO Knowledge image tag points to different underlying images, {ols-long} detects those changes and updates the corresponding BYO Knowledge database accordingly. This feature is built using OpenShift `ImageStream` objects. {ocp-product-title} clusters check for updates to `ImageStream` objects every 15 minutes.