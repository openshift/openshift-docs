[id="secure-protect-connect_{context}"]
= Secure, protect, and connect APIs on OpenShift with {prodname} 
:prodname: Connectivity Link

This guide shows how you can use {prodname} on OpenShift to secure, protect, and connect an API exposed by a Gateway that uses Kubernetes Gateway API. This guide applies to the platform engineer and application developer user roles in {prodname}. 

NOTE: In multicluster environments, you must perform the following steps in each cluster individually, unless specifically excluded.

This guide includes the following sections:

* xref:deploy-prerequisites_{context}[]
* xref:set-up-environment_{context}[]
* xref:set-up-dns-provider_{context}[]
* xref:set-up-tls-issuer_{context}[]
* xref:create-gateway_{context}[]
* xref:platform-engineer-workflow_{context}[]
* xref:app-developer-workflow_{context}[]

NOTE: The steps in chapters 2 to 7 are typically performed by the platform engineer user role. The steps in chapter 8 are typically performed by the application developer user role. 

== {prodname} capabilities in multicluster environments 

You can leverage {prodname} capabilities in single or multiple OpenShift clusters. The following features are designed to work across multiple clusters as well as in a single-cluster environment:

* Multicluster ingress: {prodname} provides multicluster ingress connectivity using DNS to bring traffic to your Gateways by using a strategy defined in a `DNSPolicy`.
* Global rate limiting: {prodname} can enable global rate limiting use cases when configured to use a shared Redis-based store for counters based on limits defined by a `RateLimitPolicy`.
* Global auth: You can configure a {prodname} `AuthPolicy` to leverage external auth providers to ensure that different clusters exposing the same API can authenticate and authorize in the same way.
* Automatic TLS certificate generation: You can configure a `TLSPolicy` to automatically provision TLS certificates based on Gateway listener hosts by using integration with cert-manager and ACME providers such as Let's Encrypt.
* Integration with federated metrics stores:  {prodname} has example dashboards and metrics for visualizing your Gateways and observing traffic hitting those Gateways across multiple clusters.

== {prodname} user role workflows

* *Platform engineer*: This guide shows how platform engineers can deploy Gateways that provide secure communication and are protected and ready for use by application development teams to deploy APIs. 
+
Platform engineers can use {prodname} in clusters in different geographic regions to bring specific traffic to geo-located Gateways. This approach reduces latency, distributes load, and protects and secures with global rate limiting and auth policies.
* *Application developer*: This guide shows how application developers can override the Gateway-level global auth and rate limiting policies to configure application-level auth and rate limiting requirements for specific users.

== Deployment management tooling

The examples in this guide use `kubectl` commands for simplicity. However, working with multiple clusters is complex, and it is best to use a tool such as OpenShift GitOps, based on Argo CD, to manage the deployment of resources to multiple clusters.

[role="_additional-resources"]
.Additional resources

* For more details on {prodname} user persona roles and workflows, see {LinkRHCLIntro}[{NameRHCLIntro}]. 

* For details on how all {prodname} user roles can observe and monitor Gateways when the OpenShift observability stack and user workload monitoring are deployed, see {LinkRHCLObserve}[{NameRHCLObserve}].