// Module included in the following assemblies:
//
// * nodes/nodes-pods-autoscaling-custom.adoc

:_content-type: CONCEPT
[id="nodes-pods-autoscaling-custom-trigger_{context}"]
= Understanding the custom metrics autoscaler triggers

Triggers, also known as scalers, provide the metrics that the Custom Metrics Autoscaler Operator uses to scale your pods. 

[NOTE]
====
The custom metrics autoscaler currently supports only the Prometheus trigger, which can use the installed {product-title} monitoring or an external Prometheus server as the metrics source.  
====

//You can specify a single trigger or multiple triggers. When using multiple triggers, the scaling is based on the greatest value from all the triggers. This section contains examples of the triggers suported for use with {product-title}. 

You use a `ScaledObject` or `ScaledJob` custom resource to configure triggers for specific objects, as described in the sections that follow. 

[id="nodes-pods-autoscaling-custom-trigger-prom_{context}"]
== Understanding the Prometheus trigger

Scale applications based on Prometheus metrics. See _Additional resources_ for information on the configurations required to use the {product-title} monitoring as a source for metrics. 

[NOTE]
====
If Prometheus is taking metrics from the application that the custom metrics autoscaler is scaling, do not set the minimum replicas to `0` in the custom resource. If there are no application pods, the custom metrics autoscaler does not have any metrics to scale on.
====

.Example scaled object with a Prometheus target
[source,yaml,options="nowrap"]
----
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: prom-scaledobject
  namespace: my-namespace
spec:
 ...
  triggers:
  - type: prometheus <1>
    metadata:
      serverAddress: https://thanos-querier.openshift-monitoring.svc.cluster.local:9092 <2>
      namespace: kedatest <3>
      metricName: http_requests_total <4>
      threshold: '5' <5>
      query: sum(rate(http_requests_total{job="test-app"}[1m])) <6>
      authModes: "basic" <7>
----
<1> Specifies Prometheus as the scaler/trigger type.
<2> Specifies the address of the Prometheus server. This example uses  {product-title} monitoring.
<3> Optional: Specifies the namespace of the object you want to scale. This parameter is mandatory if {product-title} monitoring as a source for the metrics.
<4> Specifies the name to identify the metric in the `external.metrics.k8s.io` API. If you are using more than one trigger, all metric names must be unique.
<5> Specifies the value to start scaling for.
<6> Specifies the Prometheus query to use.
<7> Specifies the authentication method to use. Prometheus scalers support bearer authentication, basic authentication, or TLS authentication. You configure the specific authentication parameters in a trigger authentication, as discussed in a following section. As needed, you can also use a secret.

////
[id="nodes-pods-autoscaling-custom-trigger-kafka_{context}"]
== Understanding the Kafka trigger

Scale applications based on an Apache Kafka topic or other services that support Kafka protocol. The custom metrics autoscaler does not scale higher than the number of Kafka partitions, unless you set the `allowIdleConsumers` parameter to `true` in the scaled object or scaled job.

.Example scaled object with a Kafka target
[source,yaml,options="nowrap"]
----
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: kafka-scaledobject
  namespace: my-namespace
spec:
 ...
  triggers:
  - type: kafka <1>
    metadata:
      topic: my-topic <2>
      bootstrapServers: my-cluster-kafka-bootstrap.openshift-operators.svc:9092 <3>
      consumerGroup: my-group <4>
      lagThreshold: '10' <5>
      offsetResetPolicy: 'latest' <6>
      allowIdleConsumers: true <7>
      scaleToZeroOnInvalidOffset: false <8>
      version: 1.0.0 <9>
----
<1> Specifies Kafka as the scaler/trigger type.
<2> Specifies the name of the Kafka topic on which Kafka is processing the offset lag.
<3> Specifies a comma-separated list of Kafka brokers to connect to.
<4> Specifies the name of the Kafka consumer group used for checking the offset on the topic and processing the related lag.
<5> Optional: Specifies the average target value to trigger scaling actions. The default is `5`.
<6> Optional: Specifies the Kafka offset reset policy for the Kafka consumer. The available values are: `latest` and `earliest`. The default is `latest`.
<7> Optional: Specifies whether the number of Kafka replicas can exceed the number of partitions on a topic.  The default is `false`.
     * If `true`, the number of Kafka replicas can exceed the number of partitions on a topic. This allows for idle Kafka consumers.
     * If `false`, the number of Kafka replicas can exceed the number of partitions on a topic.
<8> Specifies how the trigger behaves when a Kafka partition does not have a valid offset. The default is `false`.
     * If `false`, the scaler keeps a single consumer for that partition.
     * If `true`, the consumers is scaled to zero for that partition.
<9> Optional: Specifies the version of your Kafka brokers. The default is `1.0.0`.

[id="nodes-pods-autoscaling-custom-trigger-cpu_{context}"]
== Understanding the CPU trigger

You can scale based on CPU metrics. This trigger uses cluster metrics as the source for metrics.

[NOTE]
====
This trigger cannot be used with the `ScaledJob` custom resource.
====

.Example scaled object with a CPU target
[source,yaml,options="nowrap"]
----
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: cpu-scaledobject
  namespace: my-namespace
spec:

 ...

  triggers:
  - type: cpu <1>
    metricType: Utilization <2>
    metadata:
      value: "60" <3>
----
<1> Specifies CPU as the scaler/trigger type.
<2> Specifies the type of metric to use, either `Utilization` or `AverageValue`.
<3> Specifies the value to trigger scaling actions upon:
* When using `Utilization`, the target value is the average of the resource metrics across all relevant pods, represented as a percentage of the requested value of the resource for the pods.
* When using `AverageValue`, the target value is the average of the metrics across all relevant pods.

[id="nodes-pods-autoscaling-custom-trigger-memory_{context}"]
== Understanding the memory trigger

You can scale based on memory metrics. This trigger uses cluster metrics as the source for metrics.

[NOTE]
====
This trigger cannot be used with the `ScaledJob` custom resource.
====

.Example scaled object with a memory target
[source,yaml,options="nowrap"]
----
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: memory-scaledobject
  namespace: my-namespace
spec:

 ...

  triggers:
  - type: memory <1>
    metricType: Utilization <2>
    metadata:
      value: "60" <3>
----
<1> Specifies memory as the scaler/trigger type.
<2> Specifies the type of metric to use, either `Utilization` or `AverageValue`.
<3> Specifies the value to trigger scaling actions for:
* When using `Utilization`, the target value is the average of the resource metrics across all relevant pods, represented as a percentage of the requested value of the resource for the pods.
* When using `AverageValue`, the target value is the average of the metrics across all relevant pods.
////

