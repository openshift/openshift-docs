// Module included in the following assemblies:
//
// * networking/ovn_kubernetes_network_provider/migrate-from-openshift-sdn.adoc

[id="nw-ovn-kubernetes-migration-about_{context}"]
= Migration to the OVN-Kubernetes network plugin

Migrating to the OVN-Kubernetes network plugin is a manual process that includes some downtime during which your cluster is unreachable. Although a rollback procedure is provided, the migration is intended to be a one-way process.

A migration to the OVN-Kubernetes network plugin is supported on the following platforms:

* Bare metal hardware
* Amazon Web Services (AWS)
* Google Cloud Platform (GCP)
* {ibm-cloud-name}
* Microsoft Azure
* {rh-openstack-first}
* VMware vSphere

[IMPORTANT]
====
Migrating to or from the OVN-Kubernetes network plugin is not supported for managed OpenShift cloud services such as {product-dedicated}, Azure Red Hat OpenShift(ARO), and Red Hat OpenShift Service on AWS (ROSA).

Migrating from OpenShift SDN network plugin to OVN-Kubernetes network plugin is not supported on Nutanix.
====

[id="considerations-migrating-ovn-kubernetes-network-provider_{context}"]
== Considerations for migrating to the OVN-Kubernetes network plugin

If you have more than 150 nodes in your {product-title} cluster, then open a support case for consultation on your migration to the OVN-Kubernetes network plugin.

The subnets assigned to nodes and the IP addresses assigned to individual pods are not preserved during the migration.

While the OVN-Kubernetes network plugin implements many of the capabilities present in the OpenShift SDN network plugin, the configuration is not the same.

* If your cluster uses any of the following OpenShift SDN network plugin capabilities, you must manually configure the same capability in the OVN-Kubernetes network plugin:
+
--
* Namespace isolation
* Egress router pods
--

* If your cluster or surrounding network uses any part of the `100.64.0.0/16` address range, you must choose another unused IP range by specifying the `v4InternalSubnet` spec under the `spec.defaultNetwork.ovnKubernetesConfig` object definition. OVN-Kubernetes uses the IP range `100.64.0.0/16` internally by default.

The following sections highlight the differences in configuration between the aforementioned capabilities in OVN-Kubernetes and OpenShift SDN network plugins.

[discrete]
[id="namespace-isolation_{context}"]
=== Namespace isolation

OVN-Kubernetes supports only the network policy isolation mode.

[IMPORTANT]
====
For a cluster using OpenShift SDN that is configured in either the multitenant or subnet isolation mode, you can still migrate to the OVN-Kubernetes network plugin. Note that after the migration operation, multitenant isolation mode is dropped, so you must manually configure network policies to achieve the same level of project-level isolation for pods and services.
====

[discrete]
[id="egress-ip-addresses_{context}"]
=== Egress IP addresses

OpenShift SDN supports two different Egress IP modes:

* In the _automatically assigned_ approach, an egress IP address range is assigned to a node.
* In the _manually assigned_ approach, a list of one or more egress IP addresses is assigned to a node.

The migration process supports migrating Egress IP configurations that use the automatically assigned mode.

The differences in configuring an egress IP address between OVN-Kubernetes and OpenShift SDN is described in the following table:

.Differences in egress IP address configuration
[cols="1a,1a",options="header"]
|===
|OVN-Kubernetes|OpenShift SDN

|
* Create an `EgressIPs` object
* Add an annotation on a `Node` object

|
* Patch a `NetNamespace` object
* Patch a `HostSubnet` object
|===

For more information on using egress IP addresses in OVN-Kubernetes, see "Configuring an egress IP address".

[discrete]
[id="egress-network-policies_{context}"]
=== Egress network policies

The difference in configuring an egress network policy, also known as an egress firewall, between OVN-Kubernetes and OpenShift SDN is described in the following table:

.Differences in egress network policy configuration
[cols="1a,1a",options="header"]
|===
|OVN-Kubernetes|OpenShift SDN

|
* Create an `EgressFirewall` object in a namespace

|
* Create an `EgressNetworkPolicy` object in a namespace
|===

[NOTE]
====
Because the name of an `EgressFirewall` object can only be set to `default`, after the migration all migrated `EgressNetworkPolicy` objects are named `default`, regardless of what the name was under OpenShift SDN.

If you subsequently rollback to OpenShift SDN, all `EgressNetworkPolicy` objects are named `default` as the prior name is lost.

For more information on using an egress firewall in OVN-Kubernetes, see "Configuring an egress firewall for a project".
====

[discrete]
[id="egress-router-pods_{context}"]
=== Egress router pods

OVN-Kubernetes supports egress router pods in redirect mode. OVN-Kubernetes does not support egress router pods in HTTP proxy mode or DNS proxy mode.

When you deploy an egress router with the Cluster Network Operator, you cannot specify a node selector to control which node is used to host the egress router pod.

[discrete]
[id="multicast_{context}"]
=== Multicast

The difference between enabling multicast traffic on OVN-Kubernetes and OpenShift SDN is described in the following table:

.Differences in multicast configuration
[cols="1a,1a",options="header"]
|===
|OVN-Kubernetes|OpenShift SDN

|
* Add an annotation on a `Namespace` object

|
* Add an annotation on a `NetNamespace` object
|===

For more information on using multicast in OVN-Kubernetes, see "Enabling multicast for a project".

[discrete]
[id="network-policies_{context}"]
=== Network policies

OVN-Kubernetes fully supports the Kubernetes `NetworkPolicy` API in the `networking.k8s.io/v1` API group. No changes are necessary in your network policies when migrating from OpenShift SDN.
