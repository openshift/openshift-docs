// Module included in the following assemblies:
//
// * scalability_and_performance/ztp-factory-install-clusters.adoc
:_content-type: CONCEPT
[id="hub-edge-cluster-architecture_{context}"]
= Hub and edge cluster architecture

After running all workflows in the hub and edge cluster pipelines, the architecture for a compact hub and 3 plus 1 edge cluster may resemble the following:

[NOTE]
====
In the documentation and particularly with reference to the various scripts invoked you might see the term spoke cluster or spoke clusters used. The preferred term to use in relation to ZTPFWs is edge cluster or edge clusters and they effectively mean the same thing.
====

.Compact hub and 3 + 1 edge cluster architecture
image::225_OpenShift_Installing_Clusters_0422_network.png[Hub and edge cluster architecture]

Every blade in the chassis has access to multiple NICs, which are connected to internal switches. Switches and NICs are referred to as networks using the name of the interface. The `eno4` and `eno5` networks are 10gbs networks with enough bandwidth to support the internal and external traffic of the cluster.
The `eno4` network is used as the external network. It will be configured by DHCP to make it easier for the factory to configure and interact with it. This also simplifies the on site customer configuration.
The `eno5` network is the internal network. It is only be accessible from within the blades. This network is configured with static IPs and is expected to be used for the internal traffic of the cluster. The client also connects to this network and uses it to reconfigure the external connection.

[NOTE]
====
The public internet access is initially required when working on the hub and can be disconnected later after everything is synced. The network interface names `eno4` and `eno5` are configurable in the `spokes.yaml` file.
====
