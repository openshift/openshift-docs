// CNF-950 4.7 Deploying the DU infrastructure profile
// Module included in the following assemblies:
//
// *cnf-provisioning-and-deploying-a-distributed-unit.adoc

[id="scalability_and_performance/cnf-deploying-the-du-infrastructure-profile_{context}"]
= Deploying the DU infrastructure profile

[id="cnf-creating-the-performance-addon-operator-and-du-performance-profile_{context}"]
== Creating the Performance Addon Operator and DU performance profile

. Create and apply the performance profile, for example:
+
[source,yaml]
----
cat <<EOF |  oc apply -f -
apiVersion: performance.openshift.io/v1
kind: PerformanceProfile
metadata:
# This profile is for typical lab DELL R640 with 2 x 26 pcores
  name: perf-example
spec:
  additionalKernelArgs:
  - nosmt
  cpu:
    # Temp. workaround for RT kernel bugs that consume too much
    # CPU power: add more isolated cores
    isolated: "1,3,5,7,9-51"  <1>
    reserved: "0,2,4,6,8"     <2>
  hugepages:
    defaultHugepagesSize: 1G
    pages:
    - count: 16   <3>
      size: 1G
      node: 0
  nodeSelector:
    # Pay attention to the node label, create MCP accordingly
    node-role.kubernetes.io/worker-cnf: ""
  numa:
    topologyPolicy: "restricted"
  realTimeKernel:
    # For CU should be false
    enabled: true

EOF
----
<1> Configure this line based upon the customer CPU hardware selected to run the DU.
<2> Configure this line based upon the customer CPU hardware selected to run the DU.
<3> Configure this line based upon the customer memory configuration selected to run the DU.

. Use the following command to verify the changes have been applied to the cluster:
+
[source,terminal]
----
$ oc wait mcp/worker-cnf --for condition="updated"
----

[id="cnf-creating-the-ptp-operator-and-slave-profile_{context}"]
== Creating the PTP Operator and slave profile

. Apply the PTP configuration, for example:
+
[source,yaml]
----
cat <<EOF |  oc apply -f -
apiVersion: ptp.openshift.io/v1
kind: PtpConfig
metadata:
  name: slave
  namespace: openshift-ptp
spec:
  profile:
  - name: "slave"
# The interface name is hardware-specific
    interface: "eno1" <1>
    ptp4lOpts: "-2 -s --summary_interval -4" <2>
    phc2sysOpts: "-a -r -n 24" <3>
    ptp4lConf: |
      [global]
      #
      # Default Data Set
      #
      twoStepFlag 1
      slaveOnly 0
      priority1 128
      priority2 128
      domainNumber 24 <4>
      #utc_offset 37
      clockClass 248
      clockAccuracy 0xFE
      offsetScaledLogVariance 0xFFFF
      free_running 0
      freq_est_interval 1
      dscp_event 0
      dscp_general 0
      dataset_comparison ieee1588
      G.8275.defaultDS.localPriority 128
      #
      # Port Data Set
      #
      logAnnounceInterval -3 <5>
      logSyncInterval -4 <5>
      logMinDelayReqInterval -4 <5>
      logMinPdelayReqInterval -4 <5>
      announceReceiptTimeout 3 <5>
      syncReceiptTimeout 0
      delayAsymmetry 0
      fault_reset_interval 4
      neighborPropDelayThresh 20000000
      masterOnly 0
      G.8275.portDS.localPriority 128
      #
      # Run time options
      #
      assume_two_step 0
      logging_level 6
      path_trace_enabled 0
      follow_up_info 0
      hybrid_e2e 0
      inhibit_multicast_service 0
      net_sync_monitor 0
      tc_spanning_tree 0
      tx_timestamp_timeout 1
      unicast_listen 0
      unicast_master_table 0
      unicast_req_duration 3600
      use_syslog 1
      verbose 0
      summary_interval 0
      kernel_leap 1
      check_fup_sync 0
      #
      # Servo Options
      #
      pi_proportional_const 0.0
      pi_integral_const 0.0
      pi_proportional_scale 0.0
      pi_proportional_exponent -0.3
      pi_proportional_norm_max 0.7
      pi_integral_scale 0.0
      pi_integral_exponent 0.4
      pi_integral_norm_max 0.3
      step_threshold 0.0
      first_step_threshold 0.00002
      max_frequency 900000000
      clock_servo pi
      sanity_freq_limit 200000000
      ntpshm_segment 0
      #
      # Transport options
      #
      transportSpecific 0x0
      ptp_dst_mac 01:1B:19:00:00:00
      p2p_dst_mac 01:80:C2:00:00:0E
      udp_ttl 1
      udp6_scope 0x0E
      uds_address /var/run/ptp4l
      #
      # Default interface options
      #
      clock_type OC
      network_transport UDPv4
      delay_mechanism E2E
      time_stamping hardware
      tsproc_mode filter
      delay_filter moving_median
      delay_filter_length 10
      egressLatency 0
      ingressLatency 0
      boundary_clock_jbod 0
      #
      # Clock description
      #
      productDescription ;;
      revisionData ;;
      manufacturerIdentity 00:00:00
      userDescription ;
      timeSource 0xA0
  recommend:
  - profile: "slave"
    priority: 4
    match:
    - nodeLabel: "ptp/slave"

EOF
----
<1> The interface selected needs to match the Linux interface name.
<2> `-2` configures Ethernet encapsulation of PTP.  `--summary_interval -4` sets the logging interval.
This is currently set to match `logSyncInterval -4`.
<3> `-n 24` must match the `domainNumber 24`.
<4> `domainNumber 24` must match the `-n 24`.
<5> These variables are set to enable the G.8275.1 profile for PTP.

[id="cnf-creating-the-sriov-operator-and-associated-profiles_{context}"]
== Creating the SR-IOV Operator and associated profiles

. Apply the SR-IOV network node policy, for example:
+
[source,yaml]
----
cat <<EOF |  oc apply -f -
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetworkNodePolicy
metadata:
  name: policy-mh-dpdk-site-1-fqdn-worker1
  namespace: openshift-sriov-network-operator
spec:
# This works for Intel based NICs. <1>
# For Mellanox please change to:
#     deviceType: netdevice
#     isRdma: true
  deviceType: vfio-pci
  isRdma: false
  nicSelector:
# The exact physical function name must match the hardware used
    pfNames: ["ens1f1"] <2>
  nodeSelector:
    node-role.kubernetes.io/worker-cnf: ""
    feature.node.kubernetes.io/network-sriov.capable: "true"
  numVfs: 4
  priority: 10
  resourceName: mh_u_site_1_fqdn_worker1

EOF
----
<1> This file works for Intel and must change for Mellanox, as described in
_SR-IOV configuration notes_.
<2> Must be updated with the specific device on the server.

. Create the SR-IOV network, for example:
+
[source,yaml]
----
cat <<EOF | oc apply -f -
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetwork
metadata:
  name: mh-net-u-site-1-fqdn-worker1
  namespace: openshift-sriov-network-operator
spec:
  ipam:  |
    {
    }
  networkNamespace: mh-net-ns-site-1-fqdn-worker1
  resourceName: mh_u_site_1_fqdn_worker1
  vlan: 100  <1>
---
apiVersion: v1
kind: Namespace
metadata:
    name: mh-net-ns-site-1-fqdn-worker1

EOF
----
<1> Modify this line to match the DUâ€™s networking.
