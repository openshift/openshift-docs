////
This module included in the following assemblies:
-distr_tracing_otel/distr-tracing-otel-configuring.adoc
////
:_content-type: REFERENCE
[id="distr-tracing-config-otel-collector_{context}"]
= OpenTelemetry Collector configuration options

The OpenTelemetry Collector consists of three components that access telemetry data:

Receivers:: A receiver, which can be push or pull based, is how data gets into the Collector. Generally, a receiver accepts data in a specified format, translates it into the internal format, and passes it to processors and exporters defined in the applicable pipelines. By default, no receivers are configured. One or more receivers must be configured. Receivers may support one or more data sources.

Processors:: Optional. Processors run through the data between it is received and exported. By default, no processors are enabled. Processors must be enabled for every data source. Not all processors support all data sources. Depending on the data source, multiple processors might be enabled. Note that the order of processors matters.

Exporters:: An exporter, which can be push or pull based, is how you send data to one or more back ends or destinations. By default, no exporters are configured. One or more exporters must be configured. Exporters can support one or more data sources. Exporters might be used with their default settings, but many exporters require configuration to specify at least the destination and security settings.

You can define multiple instances of components in a custom resource YAML file. When configured, these components must be enabled through pipelines defined in the `spec.config.service` section of the YAML file. As a best practice, only enable the components that you need.

.Example of the OpenTelemetry Collector custom resource file
[source,yaml]
----
apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: cluster-collector
  namespace: tracing-system
spec:
  mode: deployment
  ports:
  - name: promexporter
    port: 8889
    protocol: TCP
  config: |
    receivers:
      otlp:
        protocols:
          grpc:
          http:
    processors:
    exporters:
      jaeger:
        endpoint: jaeger-production-collector-headless.tracing-system.svc:14250
        tls:
          ca_file: "/var/run/secrets/kubernetes.io/serviceaccount/service-ca.crt"
      prometheus:
        endpoint: 0.0.0.0:8889
        resource_to_telemetry_conversion:
          enabled: true # by default resource attributes are dropped
    service: <1>
      pipelines:
        traces:
          receivers: [otlp]
          processors: []
          exporters: [jaeger]
        metrics:
          receivers: [otlp]
          processors: []
          exporters: [prometheus]
----
<1> If a component is configured but not defined in the `service` section, the component is not enabled.

.Parameters used by the Operator to define the OpenTelemetry Collector
[options="header"]
[cols="l, a, a, a"]
|===
|Parameter |Description |Values |Default
|receivers:
|A receiver is how data gets into the Collector. By default, no receivers are configured. There must be at least one enabled receiver for a configuration to be considered valid. Receivers are enabled by being added to a pipeline.
|`otlp`, `jaeger`, `zipkin`
|None

|processors:
|Processors run through the data between it is received and exported. By default, no processors are enabled.
|
|None

|exporters:
|An exporter sends data to one or more back ends or destinations. By default, no exporters are configured. There must be at least one enabled exporter for a configuration to be considered valid. Exporters are enabled by being added to a pipeline. Exporters might be used with their default settings, but many require configuration to specify at least the destination and security settings.
|`otlp`, `otlphttp`, `jaeger`, `logging`, `prometheus`
|None

|service:
  pipelines:
|Components are enabled by adding them to a pipeline under `services.pipeline`.
|
|

|service:
  pipelines:
    traces:
      receivers:
|You enable receivers for tracing by adding them under `service.pipelines.traces`.
|
|None

|service:
  pipelines:
    traces:
      processors:
|You enable processors for tracing by adding them under `service.pipelines.traces`.
|
|None

|service:
  pipelines:
    traces:
      exporters:
|You enable exporters for tracing by adding them under `service.pipelines.traces`.
|
|None

|service:
  pipelines:
    metrics:
      receivers:
|You enable receivers for metrics by adding them under `service.pipelines.metrics`.
|
|None

|service:
  pipelines:
    metrics:
      processors:
|You enable processors for metircs by adding them under `service.pipelines.metrics`.
|
|None

|service:
  pipelines:
    metrics:
      exporters:
|You enable exporters for metrics by adding them under `service.pipelines.metrics`.
|
|None
|===

[id="otel-collector-components_{context}"]
== OpenTelemetry Collector components

[id="receivers_{context}"]
=== Receivers

[id="otlp-receiver_{context}"]
==== OTLP Receiver

The OTLP receiver ingests data using the OpenTelemetry protocol (OTLP).

* Support level: link:https://access.redhat.com/support/offerings/techpreview[Technology Preview]
* Supported signals: traces, metrics

.OpenTelemetry Collector custom resource with an enabled OTLP receiver
[source,yaml]
----
  config: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317 <1>
            tls: <2>
              ca_file: ca.pem
              cert_file: cert.pem
              key_file: key.pem
              client_ca_file: client.pem <3>
              reload_interval: 1h <4>
          http:
            endpoint: 0.0.0.0:4318 <5>
            tls: <6>

    service:
      pipelines:
        traces:
          receivers: [otlp]
        metrics:
          receivers: [otlp]
----
<1> The OTLP gRPC endpoint. If omitted, the default `+0.0.0.0:4317+` is used.
<2> The server-side TLS configuration. Defines paths to TLS certificates. If omitted, TLS is disabled.
<3> The path to the TLS certificate at which the server verifies a client certificate. This sets the value of `ClientCAs` and `ClientAuth` to `RequireAndVerifyClientCert` in the `TLSConfig`. For more information, see the link:https://godoc.org/crypto/tls#Config[`Config` of the Golang TLS package].
<4> Specifies the time interval at which the certificate is reloaded. If the value is not set, the certificate is never reloaded.  `reload_interval` accepts a string containing valid units of time such as `ns`, `us` (or `Âµs`), `ms`, `s`, `m`, `h`.
<5> The OTLP HTTP endpoint. The default value is `+0.0.0.0:4318+`.
<6> The server-side TLS configuration. For more information, see `grpc` protocol configuration section.

[id="jaeger-receiver_{context}"]
==== Jaeger Receiver

The Jaeger receiver ingests data in Jaeger formats.

* Support level: link:https://access.redhat.com/support/offerings/techpreview[Technology Preview]
* Supported signals: traces

.OpenTelemetry Collector custom resource with an enabled Jaeger receiver
[source,yaml]
----
  config: |
    receivers:
      jaeger:
        protocols:
          grpc:
            endpoint: 0.0.0.0:14250 <1>
          thrift_http:
            endpoint: 0.0.0.0:14268 <2>
          thrift_compact:
            endpoint: 0.0.0.0:6831 <3>
          thrift_binary:
            endpoint: 0.0.0.0:6832 <4>
          tls: <5>

    service:
      pipelines:
        traces:
          receivers: [jaeger]
----
<1> The Jaeger gRPC endpoint. If omitted, the default `+0.0.0.0:14250+` is used.
<2> The Jaeger Thrift HTTP endpoint. If omitted, the default `+0.0.0.0:14268+` is used.
<3> The Jaeger Thrift Compact endpoint. If omitted, the default `+0.0.0.0:6831+` is used.
<4> The Jaeger Thrift Binary endpoint. If omitted, the default `+0.0.0.0:6832+` is used.
<5> The TLS server side configuration. See the OTLP receiver configuration section for more details.

[id="zipkin-receiver_{context}"]
==== Zipkin Receiver

The Zipkin receiver ingests data in the Zipkin v1 and v2 formats.

* Support level: link:https://access.redhat.com/support/offerings/techpreview[Technology Preview]
* Supported signals: traces

.OpenTelemetry Collector custom resource with enabled Zipkin receiver
[source,yaml]
----
  config: |
    receivers:
      zipkin:
        endpoint: 0.0.0.0:9411 <1>
        tls: <2>

    service:
      pipelines:
        traces:
          receivers: [zipkin]
----
<1> The Zipkin HTTP endpoint. If omitted, the default `+0.0.0.0:9411+` is used.
<2> The TLS server side configuration. See the OTLP receiver configuration section for more details.

[id="processors_{context}"]
=== Processors


[id="batch-processor_{context}"]
==== Batch processor

The batch processor batches the data to reduce the number of outgoing connections needed to transfer the telemetry information.

* Support level: link:https://access.redhat.com/support/offerings/techpreview[Technology Preview]
* Supported signals: traces, metrics

.Example of the OpenTelemetry Collector custom resource when using the batch processor
[source,yaml]
----
  config: |
    processor:
      batch:
        timeout: 5s
        send_batch_max_size: 10000
    service:
      pipelines:
        traces:
          processors: [batch]
        metrics:
          processors: [batch]
----

.Parameters used by the batch processor
[cols="3",options="header"]
|===
|Parameter |Description |Default

| `timeout`
| Sends the batch after a specific time duration, irrespective of its size.
| 200ms

| `send_batch_size`
| Sends the batch of telemetry data after the specified number of spans or metrics.
| 8192

| `send_batch_max_size`
| The maximum allowable size of the batch. Must be equal or greater than `send_batch_size`.
| 0

| `metadata_keys`
| When activated, a batcher instance is created for each unique set of values found in the `client.Metadata`.
| []

| `metadata_cardinality_limit`
| When the `metadata_keys` are populated, this configuration restricts the number of distinct metadata key-value combinations processed throughout the duration of the process.
| 1000
|===

[id="resource-detection-processor_{context}"]
==== Resource Detection processor

The Resource Detection processor is designed to identify host resource details in alignment with OpenTelemetry's resource semantic standards. Using this detected information, it can add or replace the resource values in telemetry data.

* Support level: link:https://access.redhat.com/support/offerings/techpreview[Technology Preview]
* Supported signals: traces, metrics

.{product-title} permissions required for the Resource Detection processor
[source,yaml]
----
kind: ClusterRole
metadata:
  name: otel-collector
rules:
- apiGroups: ["config.openshift.io"]
  resources: ["infrastructures", "infrastructures/status"]
  verbs: ["get", "watch", "list"]
----

.OpenTelemetry Collector using the Resource Detection processor
[source,yaml]
----
  config: |
    processor:
      resourcedetection:
        detectors: [openshift]
        override: true
    service:
      pipelines:
        traces:
          processors: [resourcedetection]
        metrics:
          processors: [resourcedetection]
----

==== Resource processor

The Resource processor applies changes on resource attributes 

* Support level: link:https://access.redhat.com/support/offerings/techpreview[Technology Preview]
* Supported signals: traces, metrics, logs

.OpenTelemetry Collector using the Resource Detection processor
[source,yaml]
----
  config: |
    processor:
      attributes:
      - key: cloud.availability_zone
        value: "zone-1"
        action: upsert
      - key: k8s.cluster.name
        from_attribute: k8s-cluster
        action: insert
      - key: redundant-attribute
        action: delete
----

Attributes represent the actions that will be applied to the resource attributes like delete the attribute, insert the atribute or upsert it.


==== Span Processor


This processor modifies the span name based on its attributes or extract span attributes from the span name. It also could change span status.It can also include or exclude spans.

* Support level: link:https://access.redhat.com/support/offerings/techpreview[Technology Preview]
* Supported signals: traces

For span renaming need to specify with attributes the new name is gonna be created, to do that use `from_attributes` configuration.

.OpenTelemetry Collector using the Span Processor for renaming span
[source,yaml]
----
  config: |
    processor:
      span:
        name:
          from_attributes: [<key1>, <key2>, ...] <1>
          separator: <value> <2>
----
<1> Defined the keys that will conform the new span name
<2> Optionally a separator

Other uses of this processor includes the ability to extract atributes from the span name

.OpenTelemetry Collector using the Span Processor for extracting attributes from span name
[source,yaml]
----
  config: |
    processor:
      # Let's assume input span name is /api/v1/document/12345678/update
      # Applying the following results in output span name /api/v1/document/{documentId}/update
      # and will add a new attribute "documentId"="12345678" to the span.
      span/to_attributes:
        name:
          to_attributes:
            rules:
              - ^\/api\/v1\/document\/(?P<documentId>.*)\/update$ <1>
----
<1> This rule defined how the extraction will be executed, we can define more rules, in this case if the regexp match the name
    a documentID attibute will be created.

The span status can also be modified in the following way

.OpenTelemetry Collector using the Span Processor for status change
[source,yaml]
----
  config: |
    processor:
      span/set_status:
        status:
          code: Error
          description: "some error description"
----


==== Kubernetes Attributes Processor

The Kubernetes attributes processor enables automatic configuration of spans, metrics, and log resource attributes using Kubernetes metadata.

This processor automatically identifies Kubernetes resources, extracts metadata from them, and incorporates this extracted metadata as resource attributes into relevant spans, metrics, and logs. It utilizes the Kubernetes API to discover all pods operating within a cluster, maintaining records of their IP addresses, pod UIDs, and other relevant metadata. 

* Support level: link:https://access.redhat.com/support/offerings/techpreview[Technology Preview]
* Supported signals: logs, metrics, traces

.{product-title} minimum permissions required to make the Kubernetes Attributes Processor work:
[source,yaml]
----
kind: ClusterRole
metadata:
  name: otel-collector
rules:
  - apiGroups: ['']
    resources: ['pods', 'namespaces']
    verbs: ['get', 'watch', 'list']
----

.OpenTelemetry Collector using the Kubernetes Attributes processor
[source,yaml]
----
  config: |
    processors:
         k8sattributes:
             filter:
                 node_from_env_var: KUBE_NODE_NAME
----

=== Resource Detection Processor

The resource detection processor is employed to identify resource details from the host, structured in accordance with OpenTelemetry's resource semantic conventions. It then appends or replaces the resource value within telemetry data with this gathered information.


This processor supports multiple detectors like docker metadata which extract information from the docker daemon, GCP, AWS for extracting information from those enviromnents. A common usage of this processor is whith environment variable detector,  it will read the informatiton from the `OTEL_RESOURCE_ATTRIBUTES` environment variable that should be in the format `<key1>=<value1>,<key2>=<value2>,...`


* Support level: link:https://access.redhat.com/support/offerings/techpreview[Technology Preview]
* Supported signals: logs, metrics, traces


.OpenTelemetry Collector using the Resource Detection Processor with environment variable detector
[source,yaml]
----
  config: |
    processors:
      resourcedetection/env:
        detectors: [env] <1>
        timeout: 2s
        override: false
----
<1> Specify which detector to use, in this case environment detector

=== Filter Processor

The filter processor leverages the OpenTelemetry Transformation Language to establish criteria for deciding when to discard telemetry data. If any of these conditions are satisfied, the telemetry data is discarded, with each condition being combined through a logical OR operation. 

* Support level: link:https://access.redhat.com/support/offerings/techpreview[Technology Preview]
* Supported signals: logs, metrics, traces

.OpenTelemetry Collector custom resource with an enabled OTLP exporter
[source,yaml]
----
config: |
  processors:
    filter/ottl:
      error_mode: ignore <1>
      traces:
        span:
          - 'attributes["container.name"] == "app_container_1"' <2>
          - 'resource.attributes["host.name"] == "localhost"' <3>
----
<1> Define error mode, there are two possible values for this, ignore which  ignores errors returned by conditions and continues on to the next conditionm and propagate which returns the error up the pipeline. This will result in the payload being dropped from the collector.
<2> Filter the spans that have the attribute `container.name == app_container_1`
<3> Filter the spans that have the resource attribute `host.name == localhost`

=== Routing processor

Routes logs, metrics or traces to specific exporters. This processor will either read a header from the incoming HTTP request (gRPC or plain HTTP), or it will read a resource attribute, and direct the trace information to specific exporters based on the value read.

* Support level: link:https://access.redhat.com/support/offerings/techpreview[Technology Preview]
* Supported signals: logs, metrics, traces

.OpenTelemetry Collector custom resource with an enabled OTLP exporter
[source,yaml]
----
config: |
  processors:
    routing:
      from_attribute: X-Tenant <1>
      default_exporters: <2>
      - jaeger
      table: <3>
      - value: acme
        exporters: [jaeger/acme]
  exporters:
    jaeger:
      endpoint: localhost:14250
    jaeger/acme:
      endpoint: localhost:24250
----
<1> Define HTTP header name for lookup value for doing the route.
<2> Default exporter when the attribute value is not present in the tablel
<3> Table that defines which values are gonna be routed to which exporters


Optionally can be set `attribute_source` configuratiion, which defines where to look for the attribute in from_attribute. The allowed values are: context to search the context, which includes HTTP headers or resource to search the resource attributes.

[id="exporters_{context}"]
=== Exporters

[id="otlp-exporter_{context}"]
==== OTLP exporter

The OTLP gRPC exporter exports data using the OpenTelemetry protocol (OTLP).

* Support level: link:https://access.redhat.com/support/offerings/techpreview[Technology Preview]
* Supported signals: traces, metrics

.OpenTelemetry Collector custom resource with an enabled OTLP exporter
[source,yaml]
----
  config: |
    exporters:
      otlp:
        endpoint: tempo-ingester:4317 <1>
        tls: <2>
          ca_file: ca.pem
          cert_file: cert.pem
          key_file: key.pem
          insecure: false <3>
          insecure_skip_verify: false <4>
          reload_interval: 1h <5>
          server_name_override: <name> <6>
        headers: <7>
          X-Scope-OrgID: "dev"
    service:
      pipelines:
        traces:
          exporters: [otlp]
        metrics:
          exporters: [otlp]
----
<1> The OTLP gRPC endpoint. If the `+https://+` scheme is used, then client transport security is enabled and overrides the `insecure` setting in the `tls`.
<2> The client side TLS configuration. Defines paths to TLS certificates.
<3> Disables client transport security when set to `true`. The default value is `false` by default.
<4> Skips verifying the certificate when set to `true`. The default value is `false`.
<5> Specifies the time interval at which the certificate is reloaded. If the value is not set, the certificate is never reloaded. `reload_interval` accepts a string containing valid units of time such as `ns`, `us` (or `Âµs`), `ms`, `s`, `m`, `h`.
<6> Overrides the virtual host name of authority such as the authority header field in requests. You can use this for testing.
<7> Headers are sent for every request performed during an established connection.

[id="otlp-http-exporter_{context}"]
==== OTLP HTTP exporter

The OTLP HTTP exporter exports data using the OpenTelemetry protocol (OTLP).

* Support level: link:https://access.redhat.com/support/offerings/techpreview[Technology Preview]
* Supported signals: traces, metrics

.OpenTelemetry Collector custom resource with an enabled OTLP exporter
[source,yaml]
----
  config: |
    exporters:
      otlphttp:
        endpoint: http://tempo-ingester:4318 <1>
        tls: <2>
        headers: <3>
          X-Scope-OrgID: "dev"

    service:
      pipelines:
        traces:
          exporters: [otlphttp]
        metrics:
          expoters: [otlphttp]
----
<1> The OTLP HTTP endpoint. If the `+https://+` scheme is used, then client transport security is enabled and overrides the `insecure` setting in the `tls`.
<2> The client side TLS configuration. Defines paths to TLS certificates.
<3> Headers are sent in every HTTP request.

[id="jaeger-exporter_{context}"]
==== Jaeger exporter

The Jaeger exporter exports data using the Jaeger proto format through gRPC.

* Support level: link:https://access.redhat.com/support/offerings/techpreview[Technology Preview]
* Supported signals: traces

.OpenTelemetry Collector custom resource with enabled Jaeger exporter
[source,yaml]
----
  config: |
    exporters:
      jaeger:
        endpoint: jaeger-all-in-one:14250 <1>
        tls: <2>
    service:
      pipelines:
        traces:
          exporters: [jaeger]
----
<1> The Jaeger gRPC endpoint.
<2> The client side TLS configuration. Defines paths to TLS certificates.

[id="logging-exporter_{context}"]
==== Logging exporter

The Logging exporter prints data to the standard output.

* Support level: link:https://access.redhat.com/support/offerings/techpreview[Technology Preview]
* Supported signals: traces, metrics

.OpenTelemetry Collector custom resource with an enabled Logging exporter
[source,yaml]
----
  config: |
    exporters:
      logging:
        verbosity: detailed <1>
    service:
      pipelines:
        traces:
          exporters: [logging]
        metrics:
          exporters: [logging]
----
<1> Verbosity of the logging export: `detailed` or `normal` or `basic`. When set to `detailed`, pipeline data is verbosely logged. Defaults to `normal`.

[id="prometheus-exporter_{context}"]
==== Prometheus exporter

The Prometheus exporter exports data using the Prometheus or OpenMetrics formats.

* Support level: link:https://access.redhat.com/support/offerings/techpreview[Technology Preview]
* Supported signals: metrics

.OpenTelemetry Collector custom resource with an enabled Prometheus exporter
[source,yaml]
----
  ports:
  - name: promexporter <1>
    port: 8889
    protocol: TCP
  config: |
    exporters:
      prometheus:
        endpoint: 0.0.0.0:8889 <2>
        tls: <3>
          ca_file: ca.pem
          cert_file: cert.pem
          key_file: key.pem
        namespace: prefix <4>
        const_labels: <5>
          label1: value1
        enable_open_metrics: true <6>
        resource_to_telemetry_conversion: <7>
          enabled: true
        metric_expiration: 180m <8>
    service:
      pipelines:
        metrics:
          exporters: [prometheus]
----
<1> Exposes the Prometheus port from the collector pod and service. You can enable scraping of metrics by Prometheus by using the port name in `ServiceMonitor` or `PodMonitor` custom resource.
<2> The network endpoint where the metrics are exposed.
<3> The server-side TLS configuration. Defines paths to TLS certificates.
<4> If set, exports metrics under the provided value. No default.
<5> Key-value pair labels that are applied for every exported metric. No default.
<6> If `true`, metrics are exported using the OpenMetrics format. Exemplars are only exported in the OpenMetrics format and only for histogram and monotonic sum metrics such as `counter`. Disabled by default.
<7> If `enabled` is `true`, all the resource attributes are converted to metric labels by default. Disabled by default.
<8> Defines how long metrics are exposed without updates. The default is `5m`.

