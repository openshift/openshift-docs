// Module included in the following assemblies:
//
// * logging/cluster-logging-external.adoc

[id="cluster-logging-collector-log-forward-kafka_{context}"]
= Forwarding logs to a Kafka broker

You can forward logs to an external Kafka broker in addition to or instead of the internal instance. 

To configure forwarding logs to an external Elasticsearch instance, create a `ClusterLogForwarder` custom resource (CR) with an output to that instance and a pipeline that uses the output. You can include a specific Kafka topic in the output or use the default. The Kafka output can use a TCP (insecure) or TLS (secure TCP) connection.

.Procedure

. Create a `ClusterLogForwarder` CR YAML file similar to the following:
+
[source,yaml]
----
apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance <1>
spec:
  outputs:
   - name: app <2>
     type: kafka <3>
     url: tls://kafka.example.com:9093/app-topic <4>
     secret:
       name: kafka <5>
   - name: infra
     type: kafka
     url: tls://kafka.example.com:9093/infra-topic
   - name: audit
     type: kafka
     url: tls://kafka.example.com:9093/audit-topic
     secret:
       name: kafka
  pipelines:
   - name: app-topic <6>
     inputRefs: <7>
     - application
     outputRefs: <8>
     - infra 
     - default <9>
   - name: infra-topic
     inputRefs:
     - infrastructure
     outputRefs:
     - infra
   - name: audit-topic
     inputRefs:
     - audit
     outputRefs:
     - audit
----
<1> The name of the `ClusterLogForward` CR must be `instance`.
<2> Specify a name for the output.
<3> Specify the kafka type.
<4> Specify the URL and port of the Kafka broker as a valid absolute URL, optionally with a specific topic. You can use the `tcp` (insecure) or `tls` (secure TCP) protocol. If the cluster-wide proxy using the CIDR annotation is enabled, the output must be a server name or FQDN, not an IP Address.
<5> Optional: If using a `tls` prefix, you must specify the name of the secret required by the endpoint for TLS communication. The secret must exist in the `openshift-logging` project. The secret must exist in the `openshift-logging` project and must have keys of: *tls.crt*, *tls.key*, and *ca-bundler.crt* that point to the respective certificates that they represent.
<6> Optional. Specify a name for the pipeline.
<7> Specify which log types should be forwarded using that pipeline: `application,` `infrastructure`, or `audit`.
<8> Specify the output to use with that pipeline for forwarding the logs.
<9> Optional. Specify the `default` output in pipelines to also forward logs to the internal Elasticsearch instance.

. Create the CR object:
+
[source,terminal]
----
$ oc create -f <file-name>.yaml
----
