// Module included in the following assemblies:
//
// * service-mesh-docs-main/traces/ossm-distr-tracing-assembly.adoc

:_mod-docs-content-type: PROCEDURE
[id="ossm-config-otel_{context}"]
= Configuring {OTELName} with Service Mesh

[role="_abstract"]
You can integrate {SMProductName} with {OTELName} to instrument, generate, collect, and export OpenTelemetry traces, metrics, and logs to analyze and understand the performance and behavior of the software.

.Prerequisites

* You have installed the {TempoOperator}. For more information see, link:https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/distributed_tracing/distr-tracing-tempo-installing#installing-the-tempo-operator_distr-tracing-tempo-installing[Installing the Tempo Operator].
* You have installed the {OTELOperator}. For more information see, link:https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/red_hat_build_of_opentelemetry/install-otel[Installing the Red Hat build of OpenTelemetry].
* You have installed a `TempoStack` which is configured in a `tempo` namespace. For more information see, link:https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/distributed_tracing/distr-tracing-tempo-installing#installing-a-tempostack-instance_distr-tracing-tempo-installing[Installing a TempoStack instance].
* You have created an {istio} instance.
* You have created an {istio} CNI instance.

.Procedure

. Navigate to the {OTELOperator} and install the `OpenTelemetryCollector` resource in the `istio-system` namespace, similar to the following example:
+
[source, yaml]
----
kind: OpenTelemetryCollector
apiVersion: opentelemetry.io/v1beta1
metadata:
  name: otel
  namespace: istio-system
spec:
  observability:
    metrics: {}
  deploymentUpdateStrategy: {}
  config:
    exporters:
      otlp:
        endpoint: 'tempo-sample-distributor.tempo.svc.cluster.local:4317'
        tls:
          insecure: true
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: '0.0.0.0:4317'
          http: {}
    service:
      pipelines:
        traces:
          exporters:
            - otlp
          receivers:
            - otlp
----

. Update the {SMProductName}  {istio} custom resource (CR) to enable tracing and define the {OTELShortName} tracing providers in your `meshConfig`, similar to the following example:
+
[source,yaml]
----
apiVersion: sailoperator.io/v1
kind: Istio
metadata:
#  ...
  name: default
spec:
  namespace: istio-system
#  ...
  values:
    meshConfig:
      enableTracing: true
      extensionProviders:
      - name: otel
        opentelemetry:
          port: 4317
          service: otel-collector.istio-system.svc.cluster.local # <1>
----
<1> The `service` field is the `OpenTelemetry` collector service in the `istio-system` namespace.

. Create an {istio} Telemetry resource to enable tracers defined in `spec.values.meshConfig.ExtensionProviders`, similar to the following example:
+
[source,yaml]
----
apiVersion: telemetry.istio.io/v1
kind: Telemetry
metadata:
  name: otel-demo
  namespace: istio-system
spec:
  tracing:
    - providers:
        - name: otel
      randomSamplingPercentage: 100
----
+
After you verify that you can see traces, lower the `randomSamplingPercentage` value or set it to `default` to reduce the number of requests.
+
[NOTE]
====
You can use a single {istio} Telemetry resource for both the Prometheus metrics provider and a tracing provider by setting `spec.metrics.overrides.disabled` to `false`. This enables the Prometheus metrics provider. This is an optional step and you can skip it if you configured metrics through the OpenShift Cluster Monitoring method described in the previous step.
====

. Create the `bookinfo` namespace by running the following command:
+
[source, terminal]
----
$ oc create ns bookinfo
----

. Depending on the update strategy you are using, enable sidecar injection in the namespace by running the appropriate commands:

.. If you are using the `InPlace` update strategy, run the following command:
+
[source,terminal]
----
$ oc label namespace curl istio-injection=enabled
----

.. If you are using the `RevisionBased` update strategy, run the following commands:

... Display the revision name by running the following command:
+
[source,terminal]
----
$ oc get istiorevisions.sailoperator.io
----
+
.Example output
[source,terminal]
----
NAME      TYPE    READY   STATUS    IN USE   VERSION   AGE
default   Local   True    Healthy   True     v1.24.3   3m33s
----

... Label the namespace with the revision name to enable sidecar injection by running the following command:
+
[source,terminal]
----
$ oc label namespace curl istio.io/rev=default
----

. Deploy the `bookinfo` application in the `bookinfo` namespace by running the following command:
+
[source, terminal]
----
$ oc apply -f https://raw.githubusercontent.com/openshift-service-mesh/istio/release-1.24/samples/bookinfo/platform/kube/bookinfo.yaml -n bookinfo
----

. Generate traffic to the `productpage` pod to generate traces:
+
[source,terminal]
----
$ oc exec -it -n bookinfo deployments/productpage-v1 -c istio-proxy -- curl localhost:9080/productpage
----

. Validate the integration by running the following command to see traces in the UI:
+
[source,terminal]
----
$ oc get routes -n tempo tempo-sample-query-frontend
----
+
[NOTE]
====
The {ocp-short-name} route for Jaeger UI must be created in the Tempo namespace. You can either manually create it for the `tempo-sample-query-frontend` service, or update the `Tempo` custom resource with `.spec.template.queryFrontend.jaegerQuery.ingress.type: route`.
====