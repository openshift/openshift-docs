// Module included in the following assemblies:
//
// * telco_ref_design_specs/ran/telco-ran-ref-du-components.adoc

:_mod-docs-content-type: REFERENCE
[id="telco-ran-sr-iov-operator_{context}"]
= SR-IOV Operator

New in this release::
* With this release, you can use the SR-IOV Network Operator to configure QinQ (802.1ad and 802.1q) tagging. QinQ tagging provides efficient traffic management by enabling the use of both inner and outer VLAN tags. Outer VLAN tagging is hardware accelerated, leading to faster network performance. The update extends beyond the SR-IOV Network Operator itself. You can now configure QinQ on externally managed VFs by setting the outer VLAN tag using `nmstate`. QinQ support varies across different NICs. For a comprehensive list of known limitations for specific NIC models, see _Configuring QinQ support for SR-IOV enabled workloads_ in the _Additional resources_ section.

* With this release, you can configure the SR-IOV Network Operator to drain nodes in parallel during network policy updates, dramatically accelerating the setup process. This translates to significant time savings, especially for large cluster deployments that previously took hours or even days to complete.

Description::
The SR-IOV Operator provisions and configures the SR-IOV CNI and device plugins.
Both `netdevice` (kernel VFs) and `vfio` (DPDK) devices are supported.

Limits and requirements::
* Use {product-title} supported devices
* SR-IOV and IOMMU enablement in BIOS: The SR-IOV Network Operator will automatically enable IOMMU on the kernel command line.
* SR-IOV VFs do not receive link state updates from the PF. If link down detection is needed you must configure this at the protocol level.
* You can apply multi-network policies on `netdevice` drivers types only. Multi-network policies require the `iptables` tool, which cannot manage `vfio` driver types.


Engineering considerations::
* SR-IOV interfaces with the `vfio` driver type are typically used to enable additional secondary networks for applications that require high throughput or low latency.

* Customer variation on the configuration and number of `SriovNetwork` and `SriovNetworkNodePolicy` custom resources (CRs) is expected.

* IOMMU kernel command line settings are applied with a `MachineConfig` CR at install time. This ensures that the `SriovOperator` CR does not cause a reboot of the node when adding them.

* SR-IOV support for draining nodes in parallel is not applicable in a {sno} cluster.

* If you exclude the `SriovOperatorConfig` CR from your deployment, the CR will not be created automatically.

* In scenarios where you pin or restrict workloads to specific nodes, the SR-IOV parallel node drain feature will not result in the rescheduling of pods. In these scenarios, the SR-IOV Operator disables the parallel node drain functionality.

