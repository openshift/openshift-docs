// Module included in the following assemblies:
// * edge_computing/image-based-upgrade/cnf-preparing-for-image-based-upgrade.adoc

:_mod-docs-content-type: PROCEDURE
[id="zp-image-based-upgrade-installing-operators-with-gitops_{context}"]
= Installing {lcao} and the OADP Operator with ZTP GitOps

You need both the {lcao} and the OADP Operator to do an image-based upgrade with ZTP GitOps.

[id="zp-image-based-upgrade-installing-lcao-with-gitops_{context}"]
== Installing the {lcao} with GitOps ZTP

Install the {lcao} with GitOps ZTP to do an image-based upgrade.

.Prerequisites

* Create a directory called `custom-crs` in the `source-crs` directory. The `source-crs` directory must be located in the same location as `kustomization.yaml` file.

.Procedure

. Create the following CRs in the `openshift-lifecycle-agent` namespace and push them to the `source-crs/custom-crs` directory.
+
--
.LcaSubscriptionNS.yaml
[source,yaml]
----
apiVersion: v1
kind: Namespace
metadata:
  name: openshift-lifecycle-agent
  annotations:
    workload.openshift.io/allowed: management
    ran.openshift.io/ztp-deploy-wave: "2"
  labels:
    kubernetes.io/metadata.name: openshift-lifecycle-agent
----

.LcaSubscriptionOperGroup.yaml
[source,yaml]
----
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: lifecycle-agent-operatorgroup
  namespace: openshift-lifecycle-agent
  annotations:
    ran.openshift.io/ztp-deploy-wave: "2"
spec:
  targetNamespaces:
    - openshift-lifecycle-agent
----

.LcaSubscription.yaml
[source,yaml]
----
apiVersion: operators.coreos.com/v1
kind: Subscription
metadata:
  name: lifecycle-agent
  namespace: openshift-lifecycle-agent
  annotations:
    ran.openshift.io/ztp-deploy-wave: "2"
spec:
  channel: "stable"
  name: lifecycle-agent
  source: redhat-operators
  sourceNamespace: openshift-marketplace
  installPlanApproval: Manual
  status:
    state: AtLatestKnown
----

.Example directory structure
[source,terminal]
----
├── kustomization.yaml
├── sno
│   ├── example-cnf.yaml
│   ├── common-ranGen.yaml
│   ├── group-du-sno-ranGen.yaml
│   ├── group-du-sno-validator-ranGen.yaml
│   └── ns.yaml
├── source-crs
│   ├── custom-crs
│   │   ├── LcaSubscriptionNS.yaml
│   │   ├── LcaSubscriptionOperGroup.yaml
│   │   ├── LcaSubscription.yaml
----
--

. Add the CRs to your common `PolicyGenTemplate`.
+
.Example directory structure
[source,yaml]
----
apiVersion: ran.openshift.io/v1
kind: PolicyGenTemplate
metadata:
  name: "example-common-latest"
  namespace: "ztp-common"
spec:
  bindingRules:
    common: "true"
    du-profile: "latest"
  sourceFiles:
    - fileName: custom-crs/LcaSubscriptionNS.yaml
      policyName: "subscriptions-policy"
    - fileName: custom-crs/LcaSubscriptionOperGroup.yaml
      policyName: "subscriptions-policy"
    - fileName: custom-crs/LcaSubscription.yaml
      policyName: "subscriptions-policy"
[...]
----

[id="zp-image-based-upgrade-installing-oadp-with-gitops_{context}"]
== Installing and configuring the OADP Operator with GitOps ZTP

You can install and configure the OADP Operator with GitOps ZTP well before you want to start the upgrade.

.Prerequisites

* Create a directory called `custom-crs` in the `source-crs` directory. The `source-crs` directory must be located in the same location as `kustomization.yaml` file.

.Procedure

. Create the following CRs in the `openshift-adp` namespace and push them to the `source-crs/custom-crs` directory.
+
--
.OadpSubscriptionNS.yaml
[source,yaml]
----
apiVersion: v1
kind: Namespace
metadata:
  name: openshift-adp
  annotations:
    workload.openshift.io/allowed: management
    ran.openshift.io/ztp-deploy-wave: "2"
  labels:
    kubernetes.io/metadata.name: openshift-adp
----

.OadpSubscriptionOperGroup.yaml
[source,yaml]
----
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: redhat-oadp-operator
  namespace: openshift-adp
  annotations:
    ran.openshift.io/ztp-deploy-wave: "2"
spec:
  targetNamespaces:
  - openshift-adp
----

.OadpSubscription.yaml
[source,yaml]
----
apiVersion: operators.coreos.com/v1
kind: Subscription
metadata:
  name: redhat-oadp-operator
  namespace: openshift-adp
  annotations:
    ran.openshift.io/ztp-deploy-wave: "2"
spec:
  channel: stable-1.3
  name: redhat-oadp-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
  installPlanApproval: Manual
status:
  state: AtLatestKnown
----

.OadpOperatorStatus.yaml
[source,yaml]
----
apiVersion: operators.coreos.com/v1
kind: Operator
metadata:
  name: redhat-oadp-operator.openshift-adp
  annotations:
    ran.openshift.io/ztp-deploy-wave: "2"
status:
  components:
    refs:
    - kind: Subscription
      namespace: openshift-adp
      conditions:
      - type: CatalogSourcesUnhealthy
        status: "False"
    - kind: InstallPlan
      namespace: openshift-adp
      conditions:
      - type: Installed
        status: "True"
    - kind: ClusterServiceVersion
      namespace: openshift-adp
      conditions:
      - type: Succeeded
        status: "True"
        reason: InstallSucceeded
----

.Example directory structure
[source,terminal]
----
├── kustomization.yaml
├── sno
│   ├── example-cnf.yaml
│   ├── common-ranGen.yaml
│   ├── group-du-sno-ranGen.yaml
│   ├── group-du-sno-validator-ranGen.yaml
│   └── ns.yaml
├── source-crs
│   ├── custom-crs
│   │   ├── OadpSubscriptionNS.yaml
│   │   ├── OadpSubscriptionOperGroup.yaml
│   │   ├── OadpSubscription.yaml
│   │   ├── OadpOperatorStatus.yaml
----
--

. Add the CRs to your common `PolicyGenTemplate`.
+
.Example directory structure
+
[source,yaml]
----
apiVersion: ran.openshift.io/v1
kind: PolicyGenTemplate
metadata:
  name: "example-common-latest"
  namespace: "ztp-common"
spec:
  bindingRules:
    common: "true"
    du-profile: "latest"
  sourceFiles:
    - fileName: custom-crs/OadpSubscriptionNS.yaml
      policyName: "subscriptions-policy"
    - fileName: custom-crs/OadpSubscriptionOperGroup.yaml
      policyName: "subscriptions-policy"
    - fileName: custom-crs/OadpSubscription.yaml
      policyName: "subscriptions-policy"
    - fileName: custom-crs/OadpOperatorStatus.yaml
      policyName: "subscriptions-policy"
[...]
----

. Create the `DataProtectionApplication` CR and the S3 secret.

.. Create the following CRs in your `source-crs/custom-crs` directory:
+
--
.DataProtectionApplication.yaml
[source,yaml]
----
apiVersion: oadp.openshift.io/v1
kind: DataProtectionApplication
metadata:
  name: dataprotectionapplication
  namespace: openshift-adp
  annotations:
    ran.openshift.io/ztp-deploy-wave: "100"
spec:
  configuration:
    restic:
      enable: false <1>
    velero:
      defaultPlugins:
        - aws
        - openshift
      resourceTimeout: 10m
  backupLocations:
    - velero:
        config:
          profile: "default"
          region: minio
          s3Url: $url
          insecureSkipTLSVerify: "true"
          s3ForcePathStyle: "true"
        provider: aws
        default: true
        credential:
          key: cloud
          name: cloud-credentials
        objectStorage:
          bucket: $bucketName <2>
          prefix: $prefixName <2>
status:
  conditions:
  - reason: Complete
    status: "True"
    type: Reconciled
----
<1> The `spec.configuration.restic.enable` field must be set to `false` for an image-based upgrade because persistent volume contents are retained and reused after the upgrade.
<2> The bucket defines the bucket name that is created in S3 backend. The prefix defines the name of the subdirectory that will be automatically created in the bucket. The combination of bucket and prefix must be unique for each target cluster to avoid interference between them. To ensure a unique storage directory for each target cluster, you can use the {rh-rhacm} hub template function, for example, prefix: {{hub .ManagedClusterName hub}}.

.OadpSecret.yaml
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: cloud-credentials
  namespace: openshift-adp
  annotations:
    ran.openshift.io/ztp-deploy-wave: "100"
type: Opaque
----

.OadpBackupStorageLocationStatus.yaml
[source,yaml]
----
apiVersion: velero.io/v1
kind: BackupStorageLocation
metadata:
  namespace: openshift-adp
  annotations:
    ran.openshift.io/ztp-deploy-wave: "100"
status:
  phase: Available
----

The `OadpBackupStorageLocationStatus.yaml` CR verifies the availability of backup storage locations created by OADP.
--

.. Add the CRs to your site `PolicyGenTemplate` with overrides.
+
[source,yaml]
----
apiVersion: ran.openshift.io/v1
kind: PolicyGenTemplate
metadata:
  name: "example-cnf"
  namespace: "ztp-site"
spec:
  bindingRules:
    sites: "example-cnf"
    du-profile: "latest"
  mcp: "master"
  sourceFiles:
    ...
    - fileName: custom-crs/OadpSecret.yaml
      policyName: "config-policy"
      data:
        cloud: <your_credentials> <1>
    - fileName: custom-crs/DataProtectionApplication.yaml
      policyName: "config-policy"
      spec:
        backupLocations:
          - velero:
              config:
              config:
                region: minio
                s3Url: <your_S3_URL> <2>
                profile: "default"
                insecureSkipTLSVerify: "true"
                s3ForcePathStyle: "true"
              provider: aws
              default: true
              credential:
                key: cloud
                name: cloud-credentials
              objectStorage:
                bucket: <your_bucket_name> <3>
                prefix: <cluster-name> <3>
    - fileName: custom-crs/OadpBackupStorageLocationStatus.yaml
      policyName: "config-policy"
----
<1> Specify your credentials for your S3 storage backend.
<2> Specify the URL for your S3-compatible bucket.
<3> The `bucket` defines the bucket name that is created in S3 backend. The `prefix` defines the name of the subdirectory that will be automatically created in the `bucket`. The combination of `bucket` and `prefix` must be unique for each target cluster to avoid interference between them. To ensure a unique storage directory for each target cluster, you can use the {rh-rhacm} hub template function, for example, `prefix: {{hub .ManagedClusterName hub}}`.