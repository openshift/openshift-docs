// Module included in the following assemblies:
//
// serverless/cluster-logging-serverless.adoc
[id="using-cluster-logging-to-find-logs-for-services-deployed-with-knative-serving_{context}"]
= Using cluster logging to find logs for services deployed with Knative Serving

With OpenShift Cluster Logging, the logs that your applications write to the console are collected in Elasticsearch. The following procedure outlines how to apply these capabilities to applications deployed by using Knative Serving.


.Procedure

. Use the following command to find the URL to Kibana:
+

[source,terminal]
----
$ oc -n cluster-logging get route kibana`
----

. Enter the URL in your browser to open the Kibana UI.

. Ensure the index is set to *.all*. If the index is not set to *.all*, only the OpenShift system logs will be listed.

. Filter the logs by using the Kubernetes namespace your service is deployed in. Add a filter to identify the service itself: `kubernetes.namespace_name:default AND kubernetes.labels.serving_knative_dev\/service:{SERVICE_NAME}`.
+
[NOTE]
====
You can also filter by using `/configuration` or `/revision`.
====

. You can narrow your search by using `kubernetes.container_name:<user-container>` to only display the logs generated by your application. Otherwise, you will see logs from the queue-proxy.
+
[NOTE]
====
Use JSON-based structured logging in your application to allow for the quick filtering of these logs in production environments.
====
