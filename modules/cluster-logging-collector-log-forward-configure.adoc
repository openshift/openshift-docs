// Module included in the following assemblies:
//
// * logging/cluster-logging-external.adoc

[id="cluster-logging-collector-log-forward-configure_{context}"]
= Configuring log forwarding using the Log Forwarding API

To configure the Log Forwarding, edit the Cluster Logging Custom Resource (CR) to add the `clusterlogging.openshift.io/logforwardingtechpreview: enabled` annotation and create a Log Forwarding Custom Resource to specify the outputs, pipelines, and enable log forwarding.

If you enable Log Forwarding, you should define a pipeline all for three source types: `logs.app`, `logs.infra`, and `logs.audit`. The logs from any undefined source type are dropped. For example, if you specify a pipeline for the `logs.app` and `log-audit` types, but do not specify a pipeline for the `logs.infra` type, `logs.infra` logs are dropped.

.Procedure

To configure log forwarding using the API:

. Create a Log Forwarding CR YAML file similar to the following:
+
[source,yaml]
----
apiVersion: "logging.openshift.io/v1alpha1"
kind: "LogForwarding"
metadata:
  name: instance <1>
  namespace: openshift-logging <2>
spec:
  disableDefaultForwarding: true <3>
  outputs: <4>
   - name: elasticsearch
     type: "elasticsearch"
     endpoint: elasticsearch.openshift-logging.svc:9200
     secret:
        name: elasticsearch
   - name: elasticsearch-insecure
     type: "elasticsearch"
     endpoint: elasticsearch-insecure.svc.messaging.cluster.local
     insecure: true
   - name: secureforward-offcluster
     type: "forward"
     endpoint: https://secureforward.offcluster.com:24224
     secret:
        name: secureforward
  pipelines: <5>
   - name: container-logs
     inputSource: logs.app
     outputRefs:
     - elasticsearch
     - secureforward-offcluster
   - name: infra-logs
     inputSource: logs.infra
     outputRefs:
     - elasticsearch-insecure
   - name: audit-logs
     inputSource: logs.audit
     outputRefs:
     - secureforward-offcluster
----
<1> The name of the log forwarding CR must be `instance`.
<2> The namespace for the log forwarding CR must be `openshift-logging`.
<3> Set to `true` disable the default log forwarding behavior. 
<4> Add one or more endpoints:
* Specify the type of output, either `elasticseach` or `forward`.
* Enter a name for the output.
* Enter the endpoint, either the server name, FQDN, or IP address. If the cluster-wide proxy using the CIDR annotation is enabled, the endpoint must be a server name or FQDN, not an IP Address. For the internal {product-title} Elasticsearch instance, specify `elasticsearch.openshift-logging.svc:9200`.
* Optional: Enter the name of the secret required by the endpoint for TLS communication. The secret must exist in the `openshift-logging` project.
* Specify `insecure: true` if the endpoint does not use a secret, resulting in insecure communication.
<5> Add one or more pipelines:
* Enter a name for the pipeline
* Specify the source type: `logs.app`, `logs.infra`, or `logs.audit`.
* Specify the name of one or more outputs configured in the CR.
+
[NOTE]
====
If you set `disableDefaultForwarding: true` you must configure a pipeline and output for all three types of logs, application, infrastructure, and audit. If you do not specify a pipeline and output for a log type, those logs are not stored and will be lost.
====

. Create the CR object:
+
----
$ oc create -f <file-name>.yaml
----

== Example log forwarding custom resources

A typical Log Forwarding configuration would be similar to the following examples.

The following Log Forwarding custom resource sends all logs to a secured external Elasticsearch logstore:

.Sample custom resource to forward to an Elasticsearch logstore

[source,yaml]
----
apiVersion: logging.openshift.io/v1alpha1
kind: LogForwarding
metadata:
  name: instance
  namespace: openshift-logging
spec:
  disableDefaultForwarding: true
  outputs:
    - name: user-created-es
      type: elasticsearch
      endpoint: 'elasticsearch-server.openshift-logging.svc:9200'
      secret:
        name: piplinesecret
  pipelines:
    - name: app-pipeline
      inputSource: logs.app
      outputRefs:
        - user-created-es
    - name: infra-pipeline
      inputSource: logs.infra
      outputRefs:
        - user-created-es
    - name: audit-pipeline
      inputSource: logs.audit
      outputRefs:
        - user-created-es
----

The following Log Forwarding custom resource sends all logs to a secured Fluentd instance using the Fluentd *forward* protocol.

.Sample custom resource to use the *forward* protocol

[source,yaml]
----
apiVersion: logging.openshift.io/v1alpha1
kind: LogForwarding
metadata:
  name: instance
  namespace: openshift-logging
spec:
  disableDefaultForwarding: true
  outputs:
    - name: fluentd-created-by-user
      type: forward
      endpoint: 'fluentdserver.openshift-logging.svc:24224'
      secret:
        name: fluentdserver
  pipelines:
    - name: app-pipeline
      inputType: logs.app
      outputRefs:
        - fluentd-created-by-user
    - name: infra-pipeline
      inputType: logs.infra
      outputRefs:
        - fluentd-created-by-user
    - name: clo-default-audit-pipeline
      inputType: logs.audit
      outputRefs:
        - fluentd-created-by-user
----

////
The following Log Forwarding custom resource sends all logs to the internal {product-title} Elaticsearch instance, which is the default log forwarding method.

.Sample custom resource to use the default log forwarding

[source,yaml]
----
apiVersion: logging.openshift.io/v1alpha1
kind: LogForwarding
metadata:
  name: instance
  namespace: openshift-logging
spec:
  disableDefaultForwarding: false
----

The following Log Forwarding custom resource contains an incorrectly defined source type, `logs.app-logs`. The `status` block shows that the associated pipeline, `app-pipeline`, is dropped resulting in application logs not being stored.

.Sample custom resource with a dropped pipeline

[source,yaml]
----
apiVersion: logging.openshift.io/v1alpha1
kind: LogForwarding
metadata:
  annotations:
    clusterlogging.openshift.io/logforwardingtechpreview: enabled
  creationTimestamp: "2019-11-25T01:22:29Z"
  generation: 1
  name: instance
  namespace: openshift-logging
  resourceVersion: "30213"
  selfLink: /apis/logging.openshift.io/v1alpha1/namespaces/openshift-logging/logforwardings/instance
  uid: 06b40471-8fc1-4f80-8c1e-0117757c67f8
spec:
  outputs:
  - endpoint: fluentdserver1.openshift-logging.svc:24224
    insecure: true
    name: fluentd-created-by-user
    type: forward
  pipelines:
  - inputSource: logs.app-logs
    name: app-pipeline
    outputRefs:
    - fluentd-created-by-user
  - inputSource: logs.infra
    name: infra-pipeline
    outputRefs:
    - fluentd-created-by-user
  - inputSource: logs.audit
    name: audit-pipeline
    outputRefs:
    - fluentd-created-by-user
status:
  lastUpdated: null
  outputs:
  - lastUpdated: "2019-11-25T01:24:55Z"
    name: fluentd-created-by-user
    state: Accepted
  pipelines:
  - conditions:
    - reason: UnrecognizedSourceType
      status: "False"
      typ: SourceType
    lastUpdated: "2019-11-25T01:24:55Z"
    name: app-pipeline
    state: Dropped
  - lastUpdated: "2019-11-25T01:24:55Z"
    name: infra-pipeline
    state: Accepted
  - lastUpdated: "2019-11-25T01:24:55Z"
    name: audit-pipeline
    state: Accepted
  sources:
  - logs.infra
  - logs.audit
----
////
