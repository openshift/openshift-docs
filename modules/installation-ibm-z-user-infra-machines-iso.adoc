// Module included in the following assemblies:
//
// * installing/installing_ibm_z/installing-ibm-z.adoc

[id="installation-user-infra-machines-iso-ibm-z_{context}"]
= Creating {op-system-first} machines

Before you install a cluster on IBM Z infrastructure that you provision, you must install {op-system} on z/VM guest virtual machines for the cluster to use. Complete the following steps to create the machines.

.Prerequisites

* An FTP server running on your provisioning machine that is accessible to the machines you create.

.Procedure

. Log in to Linux on your provisioning machine.

. Download the Red Hat Enterprise Linux CoreOS installation files from the link:https://mirror.openshift.com/pub/openshift-v4/s390x/dependencies/rhcos/4.2/latest/[{op-system} image mirror].
+
[IMPORTANT]
====
The {op-system} images might not change with every release of {product-title}.
You must download images with the highest version that is less than or equal
to the {product-title} version that you install. Use the image versions
that match your {product-title} version if they are available.
====
+
Download the following files:

* The initramfs: `rhcos-<version>-installer-initramfs.img`
* The kernel: `rhcos-<version>-installer-kernel`
* The operating system image for the disk on which you want to install {op-system}. This type can differ by virtual machine:
+
`rhcos-<version>-s390x-metal-dasd.raw.gz` for DASD
+
`rhcos-<version>-s390x-metal-zfcp.raw.gz` for FCP

. Create parameter files. The following parameters are specific for a particular virtual machine:
** For `coreos.inst.install_dev=`, specify `dasda` for a DASD installation, or `sda` for FCP. Note that FCP requires `zfcp.allow_lun_scan=0`.
** For `rd.dasd=`, specifys the DASD where {op-system} is to be installed.
** `rd.zfcp=<adapter>,<wwpn>,<lun>` specifies the FCP disk to install {op-system} on.
** For `ip=`, specify the following seven entries:
... The IP address for the machine.
... An empty string.
... The gateway.
... The netmask.
... The machine host and domain name in the form `hostname.domainname`. Omit this value to let {op-system} decide set it.
... The network interface name. Omit this value to let {op-system} decide set it.
... If you use static IP addresses, an empty string.
** For `coreos.inst.ignition_url=`, specify the Ignition file for the machine role. Use `bootstrap.ign`, `master.ign`, or `worker.ign`.
** All other parameters can stay as they are.
+
Example parameter file, `bootstrap-0.parm`, for the bootstrap machine:
+
----
rd.neednet=1 coreos.inst=yes coreos.inst.install_dev=dasda coreos.inst.image_url=ftp://
cl1.provide.example.com:8080/assets/rhcos-42.80.20191105.0-metal-dasd.raw.gz
coreos.inst.ignition_url=ftp://cl1.provide.example.com:8080/ignition-bootstrap-0
ip=172.18.78.2::172.18.78.1:255.255.255.0:::none nameserver=172.18.78.1
rd.znet=qeth,0.0.bdf0,0.0.bdf1,0.0.bdf2,layer2=1,portno=0 zfcp.allow_lun_scan=0 cio_ignore=all,
!condev rd.dasd=0.0.3490
----

. Transfer the initramfs, kernel, parameter files, and {op-system} images to z/VM, for example with FTP. For details about how to transfer the files with FTP and boot from the virtual reader, see link:https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/installation_guide/sect-installing-zvm-s390[Installing under Z/VM].
. Punch the files to the virtual reader of the z/VM guest virtual machine that is to become your bootstrap node.
+
See link:https://www.ibm.com/support/knowledgecenter/en/SSB27U_7.1.0/com.ibm.zvm.v710.dmsb4/pun.htm[PUNCH] in the IBM Knowledge Center.
+
[TIP]
====
You can use the CP PUNCH command or, if you use Linux, the **vmur** command to transfer files between two z/VM guest virtual machines.
====
+
. Log in to CMS on the bootstrap machine.
. IPL the bootstrap machine from the reader:
+
----
$ ipl c
----
+
See link:https://www.ibm.com/support/knowledgecenter/en/SSB27U_7.1.0/com.ibm.zvm.v710.hcpb7/iplcommd.htm[IPL] in the IBM Knowledge Center.
+
. Repeat this procedure for the other machines in the cluster.
