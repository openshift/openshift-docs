// This is included in the following assemblies:
//
// ipi-install-configuration-files.adoc
[id='configure-network-components-to-run-on-the-control-plane_{context}']

= Configure network components to run on the control plane

Configure networking components to run exclusively on the control plane nodes. By default, {product-title} allows any node in the machine config pool to host the `apiVIP` and `ingressVIP` virtual IP addresses. However, many environments deploy worker nodes in separate subnets from the control plane nodes. Consequently, you must place the `apiVIP` and `ingressVIP` virtual IP addresses exclusively with the control plane nodes.

.Procedure

. Change to the directory storing the `install-config.yaml` file:
+
[source,terminal]
----
$ cd ~/clusterconfigs
----

. Switch to the `manifests` subdirectory:
+
[source,terminal]
----
$ cd manifests
----

. Create a file named `cluster-network-avoid-workers-99-config.yaml`:
+
[source,terminal]
----
$ touch cluster-network-avoid-workers-99-config.yaml
----

. Open the `cluster-network-avoid-workers-99-config.yaml` file in an editor and enter a custom resource (CR) that describes the Operator configuration:
+
[source,yaml]
----
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfig
metadata:
  name: 50-worker-fix-ipi-rwn
  labels:
    machineconfiguration.openshift.io/role: worker
spec:
  config:
    ignition:
      version: 3.2.0
    systemd:
      units:
      - name: nodeip-configuration.service
        enabled: true
        contents: |
          [Unit]
          Description=Writes IP address configuration so that kubelet and crio services select a valid node IP
          Wants=network-online.target
          After=network-online.target ignition-firstboot-complete.service
          Before=kubelet.service crio.service
          [Service]
          Type=oneshot
          ExecStart=/bin/bash -c "exit 0 "
          [Install]
          WantedBy=multi-user.target
    storage:
      files:
        - path: /etc/kubernetes/manifests/keepalived.yaml
          mode: 0644
          contents:
            source: data:,
        - path: /etc/kubernetes/manifests/mdns-publisher.yaml
          mode: 0644
          contents:
            source: data:,
        - path: /etc/kubernetes/manifests/coredns.yaml
          mode: 0644
          contents:
            source: data:,
----
+
This manifest places the `apiVIP` and `ingressVIP` virtual IP addresses on the control plane nodes. Additionally, this manifest deploys the following processes on the control plane nodes only:
+
* `openshift-ingress-operator`
+
* `keepalived`

. Save the `cluster-network-avoid-workers-99-config.yaml` file.

. Create a `manifests/cluster-ingress-default-ingresscontroller.yaml` file:
+
[source,yaml]
----
apiVersion: operator.openshift.io/v1
kind: IngressController
metadata:
  name: default
  namespace: openshift-ingress-operator
spec:
  nodePlacement:
    nodeSelector:
      matchLabels:
        node-role.kubernetes.io/master: ""
----

. Consider backing up the `manifests` directory. The installer deletes the `manifests/` directory when creating the cluster.

. Modify the `cluster-scheduler-02-config.yml` manifest to make the control plane nodes schedulable by setting the `mastersSchedulable` field to `true`. Control plane nodes are not schedulable by default. For example:
+
----
$ sed -i "s;mastersSchedulable: false;mastersSchedulable: true;g" clusterconfigs/manifests/cluster-scheduler-02-config.yml
----
+
[NOTE]
====
If control plane nodes are not schedulable, deploying the cluster will fail.
====

. Before deploying the cluster, ensure that the `api.<cluster-name>.<domain>` domain name is resolvable in the external DNS server. When you configure network components to run exclusively on the control plane, the internal DNS resolution no longer works for worker nodes, which is an expected outcome.
+
[IMPORTANT]
====
Failure to create a DNS record for the `api.<cluster-name>.<domain>` domain name in the external DNS server precludes worker nodes from joining the cluster.
====
