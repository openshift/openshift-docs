// Module included in the following assemblies:
//
// * virt/managing_vms/advanced_vm_management/virt-configuring-virtual-gpus.adoc

:_mod-docs-content-type: PROCEDURE
[id="virt-creating-exposing-mediated-devices_{context}"]
= Creating and exposing mediated devices

As an administrator, you can create mediated devices and expose them to the cluster by editing the `HyperConverged` custom resource (CR). The mediated device values that you supply can vary depending on the particular Graphics Processing Units (GPUs) you are using.

.Prerequisites

* You have installed the {oc-first}.
* You enabled the Input-Output Memory Management Unit (IOMMU) driver.
* If your hardware vendor provides drivers, you installed them on the nodes where you want to create mediated devices.
** If you use NVIDIA cards, you link:https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/openshift-virtualization.html[installed the NVIDIA GRID driver].

[IMPORTANT]
====
Before {VirtProductName} 4.14, the `mediatedDeviceTypes` field was named `mediatedDevicesTypes`. Ensure that you use the correct field name when configuring mediated devices.
====

.Procedure

. Open the `HyperConverged` CR in your default editor by running the following command:
+
[source,terminal,subs="attributes+"]
----
$ oc edit hyperconverged kubevirt-hyperconverged -n {CNVNamespace}
----
+
.Example configuration
[%collapsible]
====
[source,yaml,subs="attributes+"]
----
apiVersion: hco.kubevirt.io/v1
kind: HyperConverged
metadata:
  name: kubevirt-hyperconverged
  namespace: {CNVNamespace}
spec:
  mediatedDevicesConfiguration:
    mediatedDeviceTypes:
    - nvidia-231
    nodeMediatedDeviceTypes:
    - mediatedDeviceTypes:
      - nvidia-233
      nodeSelector:
        kubernetes.io/hostname: node-11.redhat.com
  # ...
----
====

. Identify the name selector and resource name values for the devices that you want to expose to the cluster, as shown in the following example. You can use the same value for both, replacing any spaces in the name with an underscore:
+
[source,terminal]
----
$ oc debug node/node-11.redhat.com
sh-5.1# chroot /host
sh-5.1# cd sys/class/mdev_bus
sh-5.1# ls
0000:4b:00.4
sh-5.1# cd 0000:4b:00.4/mdev_supported_types
sh-5.1# ls
nvidia-742  nvidia-744	nvidia-746  nvidia-748	nvidia-750  nvidia-752
nvidia-743  nvidia-745	nvidia-747  nvidia-749	nvidia-751  nvidia-753
sh-5.1# cd nvidia-745
sh-5.1# ls
available_instances  create  description  device_api  devices  name
sh-5.1# cat name
NVIDIA A2-2Q
----

. As shown in the following example:
.. Create mediated devices by adding them to the `spec.mediatedDevicesConfiguration` stanza.

.. Expose the mediated devices to the cluster by adding the `mdevNameSelector` and `resourceName` values to the `spec.permittedHostDevices.mediatedDevices` stanza of the `HyperConverged` CR:
+
.Example snippet
[source,yaml]
----
spec:
 mediatedDevicesConfiguration:
   mediatedDeviceTypes:
   - nvidia-745
   nodeMediatedDeviceTypes:
   - mediatedDeviceTypes:
     - nvidia-746
     nodeSelector:
       kubernetes.io/hostname: node-11.redhat.com
 permittedHostDevices:
   mediatedDevices:
   - mdevNameSelector: GRID A2-2Q
     resourceName: nvidia.com/GRID_A2-2Q
   - mdevNameSelector: GRID A2-4Q
     resourceName: nvidia.com/GRID_A2-4Q
----
+
where:

<mediatedDeviceTypes>:: Specifies global settings for the cluster and is required.

<nodeMediatedDeviceTypes>:: Specifies global configuration overrides for a specific node or group of nodes and is optional. Must be used with the global `mediatedDeviceTypes` configuration.

<mediatedDeviceTypes>:: Specifies an override to the global `mediatedDeviceTypes` configuration for the specified nodes. Required if you use `nodeMediatedDeviceTypes`.

<nodeSelector>:: Specifies the node selector and must include a `key:value` pair. Required if you use `nodeMediatedDeviceTypes`.

<mdevNameSelector>:: Specifies the mediated devices that map to this value on the host.

<resourceName>:: Specifies the matching resource name that is allocated on the node.

. Save your changes and exit the editor.

.Verification

* Confirm that the virtual GPU is attached to the node by running the following command:
+
[source,terminal]
----
$ oc get node <node_name> -o json \
  | jq '.status.allocatable
    | with_entries(select(.key | startswith("nvidia.com/")))
    | with_entries(select(.value != "0"))'
----
