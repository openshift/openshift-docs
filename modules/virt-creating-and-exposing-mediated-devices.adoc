// Module included in the following assemblies:
//
// * virt/managing_vms/advanced_vm_management/virt-configuring-virtual-gpus.adoc

:_mod-docs-content-type: PROCEDURE
[id="virt-creating-exposing-mediated-devices_{context}"]
= Creating and exposing mediated devices

As an administrator, you can create mediated devices and expose them to the cluster by editing the `HyperConverged` custom resource (CR). The mediated device values that you supply can vary depending on the particular Graphics Processing Units (GPUs) you are using.

.Prerequisites

* You have installed the {oc-first}.
* You have enabled the Input-Output Memory Management Unit (IOMMU) driver.
* If your hardware vendor provides drivers, you have installed them on the nodes where you want to create mediated devices.
** If you use NVIDIA cards, you have link:https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/openshift-virtualization.html[installed the NVIDIA GRID driver].

[IMPORTANT]
====
Before {VirtProductName} 4.14, the `mediatedDeviceTypes` field was named `mediatedDevicesTypes`. Ensure that you use the correct field name when configuring mediated devices.
====

.Procedure

. Open the `HyperConverged` CR in your default editor by running the following command:
+
[source,terminal,subs="attributes+"]
----
$ oc edit hyperconverged kubevirt-hyperconverged -n {CNVNamespace}
----
+
*Example configuration*
[%collapsible]

[source,yaml]
----
apiVersion: hco.kubevirt.io/v1
kind: HyperConverged
metadata:
  name: kubevirt-hyperconverged
  namespace: {CNVNamespace}
spec:
  mediatedDevicesConfiguration:
    mediatedDeviceTypes:
    - nvidia-231
    nodeMediatedDeviceTypes:
    - mediatedDeviceTypes:
      - nvidia-233
      nodeSelector:
        kubernetes.io/hostname: node-11.redhat.com
  # ...
----

 Identify the name selector and resource name values for the devices that you want to expose to the cluster, as shown in the following example. You can use the same value for both, replacing any spaces in the name with an underscore.
+
[source,terminal]
----
$ oc debug node/node-11.redhat.com
sh-5.1# chroot /host
sh-5.1# cd sys/class/mdev_bus
sh-5.1# ls
sh-5.1# cd 0000:4b:00.4/mdev_supported_types
sh-5.1# ls
sh-5.1# cd nvidia-745
sh-5.1# ls
sh-5.1# cat name
----

.Example output
[source,terminal]
----
0000:4b:00.4
nvidia-742 nvidia-744 nvidia-746 nvidia-748 nvidia-750 nvidia-752
nvidia-743 nvidia-745 nvidia-747 nvidia-749 nvidia-751 nvidia-753
available_instances create description device_api devices name
NVIDIA A2-2Q
----

. Create and expose mediated devices by:
.. Adding them to the `spec.mediatedDevicesConfiguration` stanza.
.. Adding the `mdevNameSelector` and `resourceName` values to the `spec.permittedHostDevices.mediatedDevices` stanza of the `HyperConverged` CR.

. Identify the `mdevNameSelector` value by viewing the contents of:
`/sys/bus/pci/devices/<slot>:<bus>:<domain>.<function>/mdev_supported_types/<type>/name`.
+
.Example snippet
[source,yaml]
----
spec:
 mediatedDevicesConfiguration:
   mediatedDeviceTypes:
   - nvidia-745
   nodeMediatedDeviceTypes:
   - mediatedDeviceTypes:
     - nvidia-746
     nodeSelector:
       kubernetes.io/hostname: node-11.redhat.com
 permittedHostDevices:
   mediatedDevices:
   - mdevNameSelector: GRID A2-2Q
     resourceName: nvidia.com/GRID_A2-2Q
   - mdevNameSelector: GRID A2-4Q
     resourceName: nvidia.com/GRID_A2-4Q
----
+
where:

<mediatedDeviceTypes>:: Specifies global settings for the cluster and is required.

<nodeMediatedDeviceTypes>:: Specifies global configuration overrides for a specific node or group of nodes and is optional. Must be used with the global `mediatedDeviceTypes` configuration.

<mediatedDeviceTypes>:: Specifies an override to the global `mediatedDeviceTypes` configuration for the specified nodes. Required if you use `nodeMediatedDeviceTypes`.

<nodeSelector>:: Specifies the node selector and must include a `key:value` pair. Required if you use `nodeMediatedDeviceTypes`.

<mdevNameSelector>:: Specifies the mediated devices that map to this value on the host.

<resourceName>:: Specifies the matching resource name that is allocated on the node.

. Save your changes and exit the editor.

.Verification

* Confirm that the virtual GPU is attached to the node by running the following command:
+
[source,terminal]
----
$ oc get node <node_name> -o json \
  | jq '.status.allocatable' \
  | with_entries(select(.key | startswith("nvidia.com/"))) \
  | with_entries(select(.value != "0"))
----
