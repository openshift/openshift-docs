:_mod-docs-content-type: ASSEMBLY
[id="tempo-troubleshoot"]
= Troubleshooting
include::_attributes/common-attributes.adoc[]
:context: tempo-troubleshoot

toc::[]

There are multiple ways on you can diagnistic and fix common problems with the Tempo stack,
for some of them is very useful to inspect the logs of the different components along with
some useful metrics.

If for some reason you cannot find traces in in tempo there are two possible reasons,
one possibility is that Tempo is not ingesting the traces, in such case we need to review the components
in the ingestion path. The other posibility is an issue with the query path.

== Problems ingesting traces

There are two potential problems with data ingestion into Tempo.
Either the spans are not being sent properly, or they are not being sampled.

Unhealthy ingesters can result from failing due to out-of-memory (OOM) 
issues or scale-down events. If you have unhealthy ingesters, you might see some errors in the logs.

You can check the following metrics to make sure Tempo is reciving traces
    tempo_distributor_spans_received_total
    tempo_ingester_traces_created_total

Both metrics should be greather than zero if Tempo is ingesting. In case one of them is wrong we need
to review a couple of things

If tempo_distributor_spans_received_total is 0 , this means that the distributor is not reciving spans.
check network configuration, protocols and ports of the applications that are trying to send traces to
the distributor.

If tempo_ingester_traces_created_total is 0, means a communcation problem between the ingester 
and the distributor. Inspect both logs to see for errors.

=== Review ingestion limits

In high-volume tracing environments, the default trace limits may not be adequate.
If spans are being refused due to these limits, you will see logs  in te distributor
indicating some limits are passed

You will also see the `tempo_discarded_spans_total` metric incremented.

== Problems quering trace

Once you've confirmed that the data has been successfully ingested into Tempo, it's time to look into potential issues with querying the data.

Check the logs of the `query-frontend`. The `query-frontend` pod runs with two containers (`query-frontend` and `querier`. If you see something similiar to the following errors, it means that there is an error in the query path.

[source,terminal]
----
level=info ts=XXXXXXX caller=frontend.go:63 method=GET traceID=XXXXXXXXX url=/api/traces/XXXXXXXXX duration=xxxx status=500
could not dial 10.X.X.X:3200 connection refused
----

The tempo-querier and tempo-queryfrontend were unable to communicate with each other. Review the logs of both services to determine if either has crashed. Additionally, check your network settings and policies to ensure proper communication between them.


Other useful metrics to review:

- `cortex_query_frontend_connected_clients` exposed by the `query-frontend`. if `cortex_query_frontend_connected_clients`  > 0 is an indication than `queriers` are connected to the `query-frontend`.

