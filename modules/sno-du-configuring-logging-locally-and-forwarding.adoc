// Module included in the following assemblies:
//
// *scalability_and_performance/sno-du-deploying-clusters-on-single-nodes.adoc

:_content-type: PROCEDURE
[id="sno-du-configuring-logging-locally-and-forwarding_{context}"]
= Configuring logging locally and forwarding

To be able to debug a single node distributed unit (DU), logs need to be stored for further
analysis.

.Procedure

* Use the following example to configure logging:
+
[source,yaml]
----
apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name: instance
  namespace: openshift-logging
spec:
  collection:
    logs:
      fluentd: {}
      type: fluentd
  curation:
    type: "curator"
    curator:
      schedule: "30 3 * * *"
    managementState: Managed
---
apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging
spec:
  inputs:
    - infrastructure: {}
    outputs:
      - name: kafka-open
        type: kafka
        url: tcp://10.46.55.190:9092/test    <1>
    pipelines:
      - inputRefs:
          - audit
        name: audit-logs
        outputRefs:
          - kafka-open
      - inputRefs:
          - infrastructure
        name: infrastructure-logs
        outputRefs:
          - kafka-open
----
<1> Specify the destination of the kafka server.
