// Module included in the following assemblies:
//
// *scalability_and_performance/sno-du-deploying-clusters-on-single-nodes.adoc

:_content-type: PROCEDURE
[id="sno-du-configuring-logging-locally-and-forwarding_{context}"]
= Configuring logging locally and forwarding

To be able to debug a single node distributed unit (DU), logs need to be stored for further
analysis.

.Procedure

* Use the following example to configure logging:
+
[source,yaml]
----
apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
    name: instance
    namespace: openshift-logging
spec:
    collection:
        logs:
            fluentd: {}
            type: fluentd

    managementState: Managed
---
apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
    name: instance
    namespace: openshift-logging
spec:
    inputs:
        - infrastructure: {}

          name: infra-logs
    outputs:
        - name: kafka-open
          type: kafka
          url: tcp://10.46.55.190:9092/test    <1>
    pipelines:
        - inputRefs:
            - audit
          name: audit-logs
          outputRefs:
            - kafka-open
        - inputRefs:
            - infrastructure
          name: infrastructure-logs
          outputRefs:
            - kafka-open
----
<1> Specify the destination of the kafka server.
