// Module included in the following assemblies:
//
// * nodes/scheduling/nodes-descheduler.adoc

[id="nodes-descheduler-strategies_{context}"]
= Descheduler strategies

The following descheduler strategies are available:

Low node utilization::
The `LowNodeUtilization` strategy finds nodes that are underutilized and evicts pods, if possible, from other nodes in the hope that recreation of evicted pods will be scheduled on these underutilized nodes.
+
The underutilization of nodes is determined by several configurable threshold parameters: CPU, memory, and number of pods. If a node's usage is below the configured thresholds for all parameters (CPU, memory, and number of pods), then the node is considered to be underutilized.
+
You can also set a target threshold for CPU, memory, and number of pods. If a node's usage is above the configured target thresholds for any of the parameters, then the node's pods might be considered for eviction.
+
Additionally, you can use the `NumberOfNodes` parameter to set the strategy to activate only when the number of underutilized nodes is above the configured value. This can be helpful in large clusters where a few nodes might be underutilized frequently or for a short period of time.

Duplicate pods::
The `RemoveDuplicates` strategy ensures that there is only one pod associated with a replica set, replication controller, deployment, or job running on same node. If there are more, then those duplicate pods are evicted for better spreading of pods in a cluster.
+
This situation could occur after a node failure, when a pod is moved to another node, leading to more than one pod associated with a replica set, replication controller, deployment, or job on that node. After the failed node is ready again, this strategy evicts the duplicate pod.
+
This strategy has an optional parameter, `ExcludeOwnerKinds`, that allows you to specify a list of `Kind` types. If a pod has any of these types listed as an `OwnerRef`, that pod is not considered for eviction.

Violation of inter-pod anti-affinity::
The `RemovePodsViolatingInterPodAntiAffinity` strategy ensures that pods violating inter-pod anti-affinity are removed from nodes.
+
This situation could occur when anti-affinity rules are created for pods that are already running on the same node.

Violation of node affinity::
The `RemovePodsViolatingNodeAffinity` strategy ensures that pods violating node affinity are removed from nodes.
+
This situation could occur if a node no longer satisfies a pod's affinity rule. If another node is available that satisfies the affinity rule, then the pod is evicted.

Violation of node taints::
The `RemovePodsViolatingNodeTaints` strategy ensures that pods violating `NoSchedule` taints on nodes are removed.
+
This situation could occur if a pod is set to tolerate a taint `key=value:NoSchedule` and is running on a tainted node. If the node's taint is updated or removed, the taint is no longer satisfied by the pod's tolerations and the pod is evicted.

Too many restarts::
The `RemovePodsHavingTooManyRestarts` strategy ensures that pods that have been restarted too many times are removed from nodes.
+
This situation could occur if a pod is scheduled on a node that is unable to start it. For example, if the node is having network issues and is unable to mount a networked persistent volume, then the pod should be evicted so that it can be scheduled on another node. Another example is if the pod is crashlooping.
+
This strategy has two configurable parameters: `PodRestartThreshold` and `IncludingInitContainers`. If a pod is restarted more than the configured `PodRestartThreshold` value, then the pod is evicted. You can use the `IncludingInitContainers` parameter to specify whether restarts for Init Containers should be calculated into the `PodRestartThreshold` value.

Pod life time::

The `PodLifeTime` strategy evicts pods that are too old.
+
After a pod reaches the age, in seconds, set by the `MaxPodLifeTimeSeconds` parameter, it is evicted.
