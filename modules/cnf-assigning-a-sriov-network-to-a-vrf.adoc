// Module included in the following assemblies:
//
//networking/hardware_networks/configuring-sriov-device.adoc

[id="cnf-assigning-a-sriov-network-to-a-vrf_{context}"]
= Assigning an SR-IOV network to a VRF

:FeatureName: CNI VRF plug-in
include::technology-preview.adoc[leveloffset=+1]

As a cluster administrator, you can assign an SR-IOV network interface to your VRF domain by using the CNI VRF plug-in.

To do this, add the VRF configuration to the optional `metaPlugins` parameter of the `SriovNetwork` resource.

[NOTE]
====
Applications that use VRFs need to bind to a specific device. The common usage is to use the `SO_BINDTODEVICE` option for a socket. `SO_BINDTODEVICE` binds the socket to a device that is specified in the passed interface name, for example, `eth1`. To use `SO_BINDTODEVICE`, the application must have `CAP_NET_RAW` capabilities.
====

[id="cnf-creating-an-additional-sriov-network-with-vrf-plug-in_{context}"]
== Creating an additional SR-IOV network attachment with the CNI VRF plug-in

The SR-IOV Network Operator manages additional network definitions. When you specify an additional SR-IOV network to create, the SR-IOV Network Operator creates the `NetworkAttachmentDefinition` custom resource (CR) automatically.

[NOTE]
====
Do not edit `NetworkAttachmentDefinition` custom resources that the SR-IOV Network Operator manages. Doing so might disrupt network traffic on your additional network.
====

To create an additional SR-IOV network attachment with the CNI VRF plug-in, perform the following procedure.

.Prerequisites

* Install the {product-title} CLI (oc).
* Log in to the {product-title} cluster as a user with cluster-admin privileges.

.Procedure

. Create the `SriovNetwork` custom resource (CR) for the additional SR-IOV network attachment and insert the `metaPlugins` configuration, as in the following example CR. Save the YAML as the file `sriov-network-attachment.yaml`.
+
[source,yaml]
----
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetwork
metadata:
  name: example-network
  namespace: additional-sriov-network-1
spec:
  ipam: |
    {
      "type": "host-local",
      "subnet": "10.56.217.0/24",
      "rangeStart": "10.56.217.171",
      "rangeEnd": "10.56.217.181",
      "routes": [{
        "dst": "0.0.0.0/0"
      }],
      "gateway": "10.56.217.1"
    }
  vlan: 0
  resourceName: intelnics
  metaPlugins : |
    {
      "type": "vrf", <1>
      "vrfname": "example-vrf-name" <2>
    }
----
<1> `type` must be set to `vrf`.
<2> `vrfname` is the name of the VRF that the interface is assigned to. If it does not exist in the pod, it is created.

. Create the `SriovNetwork` resource:
+
[source,terminal]
----
$ oc create -f sriov-network-attachment.yaml
----

.Verifying that the `NetworkAttachmentDefinition` CR is successfully created

* Confirm that the SR-IOV Network Operator created the `NetworkAttachmentDefinition` CR by running the following command.
+
[source,terminal]
----
$ oc get network-attachment-definitions -n <namespace> <1>
----
<1> Replace `<namespace>` with the namespace that you specified when configuring the network attachment, for example, `additional-sriov-network-1`.
+
.Example output
[source,terminal]
----
NAME                            AGE
additional-sriov-network-1      14m
----
+
[NOTE]
====
There might be a delay before the SR-IOV Network Operator creates the CR.
====

.Verifying that the additional SR-IOV network attachment is successful

To verify that the VRF CNI is correctly configured and the additional SR-IOV network attachment is attached, do the following:

. Create an SR-IOV network that uses the VRF CNI.
. Assign the network to a pod.
. Verify that the pod network attachment is connected to the SR-IOV additional network. Remote shell into the pod and run the following command:
+
[source,terminal]
----
$ ip vrf show
----
+
.Example output
[source,terminal]
----
Name              Table
-----------------------
red                 10
----
. Confirm the VRF interface is master of the secondary interface:
+
[source,terminal]
----
$ ip link
----
+
.Example output
[source,terminal]
----
...
5: net1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master red state UP mode
...
----
