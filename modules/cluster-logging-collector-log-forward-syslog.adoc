// Module included in the following assemblies:
//
// * logging/cluster-logging-external.adoc

[id="cluster-logging-collector-log-forward-syslog_{context}"]
= Forwarding logs using the syslog protocol

You can use the *syslog* link:https://tools.ietf.org/html/rfc3164[RFC3164] or link:https://tools.ietf.org/html/rfc5424[RFC5424] protocol to send a copy of your logs to an external log aggregator configured to accept the protocol instead of, or in addition to, the default Elasticsearch log store. You are responsible for configuring the external log aggregator, such as a syslog server, to receive the logs from {product-title}.

To configure log forwarding using the *syslog* protocol, create a `ClusterLogForwarder` custom resource (CR) with one or more outputs to the syslog servers and pipelines that use those outputs. The syslog output can use a UDP, TCP, or TLS connection.

[NOTE]
====
Alternately, you can use a config map to forward logs using the *syslog* RFC3164 protocols. However, this method is deprecated in {product-title} and will be removed in a future release.
====

.Prerequisites

* You must have a logging server that is configured to receive the logging data using the specified protocol or format.

.Procedure

. Create a `ClusterLogForwarder` CR YAML file similar to the following:
+
[source,yaml]
----
apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance <1>
  namespace: openshift-logging <2>
spec:
  outputs:
   - name: rsyslog-east <3>
     type: syslog <4>
     syslog: <5>
       facility: local0
       rfc: RFC3164
       payloadKey: message
       severity: informational
     url: 'tls://rsyslogserver.east.example.com:514' <6>
     secret: <7>
        name: syslog-secret
   - name: rsyslog-west
     type: syslog
     syslog:
      appName: myapp
      facility: user
      msgID: mymsg
      procID: myproc
      rfc: RFC5424
      severity: debug
     url: 'udp://rsyslogserver.west.example.com:514'
  pipelines:
   - name: syslog-east <8>
     inputRefs: <9>
     - audit
     - application
     outputRefs: <10>
     - rsyslog-east
     - default <11>
     parse: json <12>
     labels:
       secure: "true" <13>
       syslog: "east"
   - name: syslog-west <14>
     inputRefs:
     - infrastructure
     outputRefs:
     - rsyslog-west
     - default
     labels:
       syslog: "west"
----
<1> The name of the `ClusterLogForwarder` CR must be `instance`.
<2> The namespace for the `ClusterLogForwarder` CR must be `openshift-logging`.
<3> Specify a name for the output.
<4> Specify the `syslog` type.
<5> Optional. Specify the syslog parameters, listed below.
<6> Specify the URL and port of the external syslog instance. You can use the `udp` (insecure), `tcp` (insecure) or `tls` (secure TCP) protocol. If the cluster-wide proxy using the CIDR annotation is enabled, the output must be a server name or FQDN, not an IP address.
<7> If using a `tls` prefix, you must specify the name of the secret required by the endpoint for TLS communication. The secret must exist in the `openshift-logging` project and must have keys of: *tls.crt*, *tls.key*, and *ca-bundle.crt* that point to the respective certificates that they represent.
<8> Optional: Specify a name for the pipeline.
<9> Specify which log types should be forwarded using that pipeline: `application,` `infrastructure`, or `audit`.
<10> Specify the output to use  with that pipeline for forwarding the logs.
<11> Optional: Specify the `default` output to forward logs to the internal Elasticsearch instance.
<12> Optional: Forward structured JSON log entries as JSON objects in the `structured` field. The log entry must contain valid structured JSON; otherwise, OpenShift Logging removes the `structured` field and instead sends the log entry to the default index, `app-00000x`.
<13> Optional: String. One or more labels to add to the logs. Quote values like "true" so they are recognized as string values, not as a boolean.
<14> Optional: Configure multiple outputs to forward logs to other external log aggregators of any supported type:
** Optional. A name to describe the pipeline.
** The `inputRefs` is the log type to forward using that pipeline: `application,` `infrastructure`, or `audit`.
** The `outputRefs` is the name of the output to use.
** Optional: String. One or more labels to add to the logs.

. Create the CR object:
+
[source,terminal]
----
$ oc create -f <file-name>.yaml
----

The Red Hat OpenShift Logging Operator redeploys the Fluentd pods. If the pods do not redeploy, you can delete the Fluentd
pods to force them to redeploy.

[source,terminal]
----
$ oc delete pod --selector logging-infra=fluentd
----

[id=cluster-logging-collector-log-forward-examples-syslog-parms]
== Syslog parameters

You can configure the following for the `syslog` outputs. For more information, see the syslog link:https://tools.ietf.org/html/rfc3164[RFC3164] or link:https://tools.ietf.org/html/rfc5424[RFC5424] RFC.

* facility: The link:https://tools.ietf.org/html/rfc5424#section-6.2.1[syslog facility]. The value can be a decimal integer or a case-insensitive keyword:
** `0` or `kern` for kernel messages
** `1` or `user` for user-level messages, the default.
** `2` or `mail` for the mail system
** `3` or `daemon` for system daemons
** `4` or `auth` for security/authentication messages
** `5` or `syslog` for messages generated internally by syslogd
** `6` or `lpr` for the line printer subsystem
** `7` or `news` for the network news subsystem
** `8` or `uucp` for the UUCP subsystem
** `9` or `cron` for the clock daemon
** `10` or `authpriv` for security authentication messages
** `11` or `ftp` for the FTP daemon
** `12` or `ntp` for the NTP subsystem
** `13` or `security` for the syslog audit log
** `14` or `console` for the syslog alert log
** `15` or `solaris-cron` for the scheduling daemon
** `16`–`23` or `local0` – `local7` for locally used facilities
* Optional. `payloadKey`: The record field to use as payload for the syslog message.
+
[NOTE]
====
Configuring the `payloadKey` parameter prevents other parameters from being forwarded to the syslog.
====
+
* rfc: The RFC to be used for sending logs using syslog. The default is RFC5424.
* severity: The link:https://tools.ietf.org/html/rfc5424#section-6.2.1[syslog severity] to set on outgoing syslog records. The value can be a decimal integer or a case-insensitive keyword:
** `0` or `Emergency` for messages indicating the system is unusable
** `1` or `Alert` for messages indicating action must be taken immediately
** `2` or `Critical` for messages indicating critical conditions
** `3` or `Error` for messages indicating error conditions
** `4` or `Warning` for messages indicating warning conditions
** `5` or `Notice` for messages indicating normal but significant conditions
** `6` or `Informational` for messages indicating informational messages
** `7` or `Debug` for messages indicating debug-level messages, the default
* tag: Tag specifies a record field to use as a tag on the syslog message.
* trimPrefix: Remove the specified prefix from the tag.

[id=cluster-logging-collector-log-forward-examples-syslog-5424]
== Additional RFC5424 syslog parameters

The following parameters apply to RFC5424:

* appName: The APP-NAME is a free-text string that identifies the application that sent the log. Must be specified for `RFC5424`.
* msgID: The MSGID is a free-text string that identifies the type of message. Must be specified for `RFC5424`.
* procID: The PROCID is a free-text string. A change in the value indicates a discontinuity in syslog reporting. Must be specified for `RFC5424`.
