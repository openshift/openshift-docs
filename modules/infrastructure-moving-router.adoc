// Module included in the following assemblies:
//
// * machine_management/creating-infrastructure-machinesets.adoc

[id="infrastructure-moving-router_{context}"]
= Moving the router

You can deploy the router pod to a different machine set. By default, the pod is deployed to a worker node.

.Prerequisites

* Configure additional machine sets in your {product-title} cluster.

.Procedure

. View the `IngressController` custom resource for the router Operator:
+
[source,terminal]
----
$ oc get ingresscontroller default -n openshift-ingress-operator -o yaml
----
+
The command output resembles the following text:
+
[source,yaml]
----
apiVersion: operator.openshift.io/v1
kind: IngressController
metadata:
  creationTimestamp: 2019-04-18T12:35:39Z
  finalizers:
  - ingresscontroller.operator.openshift.io/finalizer-ingresscontroller
  generation: 1
  name: default
  namespace: openshift-ingress-operator
  resourceVersion: "11341"
  selfLink: /apis/operator.openshift.io/v1/namespaces/openshift-ingress-operator/ingresscontrollers/default
  uid: 79509e05-61d6-11e9-bc55-02ce4781844a
spec: {}
status:
  availableReplicas: 2
  conditions:
  - lastTransitionTime: 2019-04-18T12:36:15Z
    status: "True"
    type: Available
  domain: apps.<cluster>.example.com
  endpointPublishingStrategy:
    type: LoadBalancerService
  selector: ingresscontroller.operator.openshift.io/deployment-ingresscontroller=default
----

. Edit the `ingresscontroller` resource and change the `nodeSelector` to use the `infra` label:
+
[source,terminal]
----
$ oc edit ingresscontroller default -n openshift-ingress-operator
----
+
Add the `nodeSelector` stanza that references the `infra` label to the `spec` section, as shown:
+
[source,yaml]
----
  spec:
    nodePlacement:
      nodeSelector:
        matchLabels:
          node-role.kubernetes.io/infra: ""
----

. Confirm that the router pod is running on the `infra` node.
.. View the list of router pods and note the node name of the running pod:
+
[source,terminal]
----
$ oc get pod -n openshift-ingress -o wide
----
+
.Example output
[source,terminal]
----
NAME                              READY     STATUS        RESTARTS   AGE       IP           NODE                           NOMINATED NODE   READINESS GATES
router-default-86798b4b5d-bdlvd   1/1      Running       0          28s       10.130.2.4   ip-10-0-217-226.ec2.internal   <none>           <none>
router-default-955d875f4-255g8    0/1      Terminating   0          19h       10.129.2.4   ip-10-0-148-172.ec2.internal   <none>           <none>
----
+
In this example, the running pod is on the `ip-10-0-217-226.ec2.internal` node.

.. View the node status of the running pod:
+
[source,terminal]
----
$ oc get node <node_name> <1>
----
<1> Specify the `<node_name>` that you obtained from the pod list.
+
.Example output
[source,terminal]
----
NAME                          STATUS  ROLES         AGE   VERSION
ip-10-0-217-226.ec2.internal  Ready   infra,worker  17h   v1.19.0
----
+
Because the role list includes `infra`, the pod is running on the correct node.
