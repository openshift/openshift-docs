// Module included in the following assemblies:
//
// * nodes/nodes-pods-autoscaling-about.adoc

:_mod-docs-content-type: PROCEDURE
[id="nodes-pods-autoscaling-creating-cpu_{context}"]
= Creating a horizontal pod autoscaler for CPU utilization by using the CLI

Using the {product-title} CLI, you can create a horizontal pod autoscaler (HPA) to automatically scale an existing `Deployment`, `DeploymentConfig`, `ReplicaSet`, `ReplicationController`, or `StatefulSet` object. The HPA scales the pods associated with that object to maintain the CPU usage you specify.

[NOTE]
====
It is recommended to use a `Deployment` object or `ReplicaSet` object unless you need a specific feature or behavior provided by other objects.
====

The HPA increases and decreases the number of replicas between the minimum and maximum numbers to maintain the specified CPU utilization across all pods.

When autoscaling for CPU utilization, you can use the `oc autoscale` command and specify the minimum and maximum number of pods you want to run at any given time and the average CPU utilization your pods should target. If you do not specify a minimum, the pods are given default values from the {product-title} server.

To autoscale for a specific CPU value, create a `HorizontalPodAutoscaler` object with the target CPU and pod limits.

.Prerequisites

To use horizontal pod autoscalers, your cluster administrator must have properly configured cluster metrics.
You can use the `oc describe PodMetrics <pod-name>` command to determine if metrics are configured. If metrics are
configured, the output appears similar to the following, with `Cpu` and `Memory` displayed under `Usage`.

[source,terminal]
----
$ oc describe PodMetrics openshift-kube-scheduler-ip-10-0-135-131.ec2.internal
----

.Example output
[source,text,options="nowrap"]
----
Name:         openshift-kube-scheduler-ip-10-0-135-131.ec2.internal
Namespace:    openshift-kube-scheduler
Labels:       <none>
Annotations:  <none>
API Version:  metrics.k8s.io/v1beta1
Containers:
  Name:  wait-for-host-port
  Usage:
    Memory:  0
  Name:      scheduler
  Usage:
    Cpu:     8m
    Memory:  45440Ki
Kind:        PodMetrics
Metadata:
  Creation Timestamp:  2019-05-23T18:47:56Z
  Self Link:           /apis/metrics.k8s.io/v1beta1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ip-10-0-135-131.ec2.internal
Timestamp:             2019-05-23T18:47:56Z
Window:                1m0s
Events:                <none>
----

.Procedure

To create a horizontal pod autoscaler for CPU utilization:

. Perform one of the following:

** To scale based on the percent of CPU utilization, create a `HorizontalPodAutoscaler` object for an existing object:
+
[source,terminal]
----
$ oc autoscale <object_type>/<name> \// <1>
  --min <number> \// <2>
  --max <number> \// <3>
  --cpu-percent=<percent> <4>
----
+
<1> Specify the type and name of the object to autoscale. The object must exist and be a `Deployment`, `DeploymentConfig`/`dc`, `ReplicaSet`/`rs`, `ReplicationController`/`rc`, or `StatefulSet`.
<2> Optionally, specify the minimum number of replicas when scaling down.
<3> Specify the maximum number of replicas when scaling up.
<4> Specify the target average CPU utilization over all the pods, represented as a percent of requested CPU. If not specified or negative, a default autoscaling policy is used.
+
For example, the following command shows autoscaling for the `image-registry` `Deployment` object. The initial deployment requires 3 pods. The HPA object increases the minimum to 5. If CPU usage on the pods reaches 75%, the pods will increase to 7:
+
[source,terminal]
----
$ oc autoscale deployment/image-registry --min=5 --max=7 --cpu-percent=75
----

** To scale for a specific CPU value, create a YAML file similar to the following for an existing object:
+
.. Create a YAML file similar to the following:
+
[source,yaml,options="nowrap"]
----
apiVersion: autoscaling/v2 <1>
kind: HorizontalPodAutoscaler
metadata:
  name: cpu-autoscale <2>
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: apps/v1 <3>
    kind: Deployment <4>
    name: example <5>
  minReplicas: 1 <6>
  maxReplicas: 10 <7>
  metrics: <8>
  - type: Resource
    resource:
      name: cpu <9>
      target:
        type: AverageValue <10>
        averageValue: 500m <11>
----
<1> Use the `autoscaling/v2` API.
<2> Specify a name for this horizontal pod autoscaler object.
<3> Specify the API version of the object to scale:
* For a `Deployment`, `ReplicaSet`, `Statefulset` object, use `apps/v1`.
* For a `ReplicationController`, use `v1`.
* For a `DeploymentConfig`, use `apps.openshift.io/v1`.
<4> Specify the type of object. The object must be a `Deployment`, `DeploymentConfig`/`dc`, `ReplicaSet`/`rs`, `ReplicationController`/`rc`, or `StatefulSet`.
<5> Specify the name of the object to scale. The object must exist.
<6> Specify the minimum number of replicas when scaling down.
<7> Specify the maximum number of replicas when scaling up.
<8> Use the `metrics` parameter for memory utilization.
<9> Specify `cpu` for CPU utilization.
<10> Set to `AverageValue`.
<11> Set to `averageValue` with the targeted CPU value.

.. Create the horizontal pod autoscaler:
+
[source,terminal]
----
$ oc create -f <file-name>.yaml
----

. Verify that the horizontal pod autoscaler was created:
+
[source,terminal]
----
$ oc get hpa cpu-autoscale
----
+
.Example output
[source,terminal]
----
NAME            REFERENCE            TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
cpu-autoscale   Deployment/example   173m/500m       1         10        1          20m
----

