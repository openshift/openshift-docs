// Module included in the following assemblies:
//
// * nodes/nodes-pods-autoscaling-about.adoc

[id="nodes-pods-autoscaling-creating-cpu_{context}"]

= Creating a horizontal pod autoscaler for CPU utilization

You can create a horizontal pod autoscaler (HPA) for an existing DeploymentConfig or ReplicationController object
that automatically scales the pods associated with that object in order to maintain the CPU usage you specify.

The HPA increases and decreases the number of replicas between the minimum and maximum numbers to maintain the specified CPU utilization across all pods.

When autoscaling for CPU utilization, you can use the `oc autoscale` command and specify the minimum and maximum number of pods you want to run at any given time and the average CPU utilization your pods should target. If you do not specify a minimum, the pods are given default values from the {product-title} server.
To autoscale for a specific CPU value, create a `HorizontalPodAutoscaler` object with the target CPU and pod limits.

.Prerequisites

In order to use horizontal pod autoscalers, your cluster administrator must have properly configured cluster metrics.
You can use the `oc describe PodMetrics <pod-name>` command to determine if metrics are configured. If metrics are
configured, the output appears similar to the following, with `Cpu` and `Memory` displayed under `Usage`.

[source,terminal]
----
$ oc describe PodMetrics openshift-kube-scheduler-ip-10-0-135-131.ec2.internal
----

.Example output
[source,yaml,options="nowrap"]
----
Name:         openshift-kube-scheduler-ip-10-0-135-131.ec2.internal
Namespace:    openshift-kube-scheduler
Labels:       <none>
Annotations:  <none>
API Version:  metrics.k8s.io/v1beta1
Containers:
  Name:  wait-for-host-port
  Usage:
    Memory:  0
  Name:      scheduler
  Usage:
    Cpu:     8m
    Memory:  45440Ki
Kind:        PodMetrics
Metadata:
  Creation Timestamp:  2019-05-23T18:47:56Z
  Self Link:           /apis/metrics.k8s.io/v1beta1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ip-10-0-135-131.ec2.internal
Timestamp:             2019-05-23T18:47:56Z
Window:                1m0s
Events:                <none>
----

.Procedure

To create a horizontal pod autoscaler for CPU utilization:

. Perform one of the following one of the following:

** To scale based on the percent of CPU utilization, create a `HorizontalPodAutoscaler` object for an existing DeploymentConfig:
+
[source,terminal]
----
$ oc autoscale dc/<dc-name> \// <1>
  --min <number> \// <2>
  --max <number> \// <3>
  --cpu-percent=<percent> <4>
----
+
<1> Specify the name of the DeploymentConfig. The object must exist.
<2> Optionally, specify the minimum number of replicas when scaling down.
<3> Specify the maximum number of replicas when scaling up.
<4> Specify the target average CPU utilization over all the pods, represented as a percent of requested CPU. If not specified or negative, a default autoscaling policy is used.

** To scale based on the percent of CPU utilization, create a `HorizontalPodAutoscaler` object for an existing ReplicationController:
+
[source,terminal]
----
$ oc autoscale rc/<rc-name> <1>
  --min <number> \// <2>
  --max <number> \// <3>
  --cpu-percent=<percent> <4>
----
+
<1> Specify the name of the ReplicationController. The object must exist.
<2> Specify the minimum number of replicas when scaling down.
<3> Specify the maximum number of replicas when scaling up.
<4> Specify the target average CPU utilization over all the pods, represented as a percent of requested CPU. If not specified or negative, a default autoscaling policy is used.

** To scale for a specific CPU value, create a YAML file similar to the following for an existing DeploymentConfig or ReplicationController:
+
.. Create a YAML file similar to the following:
+
[source,yaml,options="nowrap"]
----
apiVersion: autoscaling/v2beta2 <1>
kind: HorizontalPodAutoscaler
metadata:
  name: cpu-autoscale <2>
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: v1 <3>
    kind: ReplicationController <4>
    name: example <5>
  minReplicas: 1 <6>
  maxReplicas: 10 <7>
  metrics: <8>
  - type: Resource
    resource:
      name: cpu <9>
      target:
        type: Utilization <10>
        averageValue: 500m <11>
----
<1> Use the `autoscaling/v2beta2` API.
<2> Specify a name for this horizontal pod autoscaler object.
<3> Specify the API version of the object to scale:
* For a ReplicationController, use `v1`,
* For a DeploymentConfig, use `apps.openshift.io/v1`.
<4> Specify the kind of object to scale, either `ReplicationController` or `DeploymentConfig`.
<5> Specify the name of the object to scale. The object must exist.
<6> Specify the minimum number of replicas when scaling down.
<7> Specify the maximum number of replicas when scaling up.
<8> Use the `metrics` parameter for memory utilization.
<9> Specify `cpu` for CPU utilization.
<10> Set to `Utilization`.
<11> Set the type to `averageValue`.

.. Create the horizontal pod autoscaler:
+
[source,terminal]
----
$ oc create -f <file-name>.yaml
----

. Verify that the horizontal pod autoscaler was created:
+
[source,terminal]
----
$ oc get hpa cpu-autoscale
----
+
.Example output
[source,terminal]
----
NAME            REFERENCE                       TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
cpu-autoscale   ReplicationController/example   173m/500m       1         10        1          20m
----

For example, the following command creates a horizontal pod autoscaler that maintains between 3 and 7 replicas of the pods that are controlled by the `image-registry` DeploymentConfig in order to maintain an average CPU utilization of 75% across all pods.

[source,terminal]
----
$ oc autoscale dc/image-registry --min 3 --max 7 --cpu-percent=75
----

.Example output
[source,terminal]
----
deploymentconfig "image-registry" autoscaled
----

The command creates a horizontal pod autoscaler with the following definition:

[source,terminal]
----
$ oc edit hpa frontend -n openshift-image-registry
----

.Example output
[source,yaml]
----
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  creationTimestamp: "2020-02-21T20:19:28Z"
  name: image-registry
  namespace: default
  resourceVersion: "32452"
  selfLink: /apis/autoscaling/v1/namespaces/default/horizontalpodautoscalers/frontend
  uid: 1a934a22-925d-431e-813a-d00461ad7521
spec:
  maxReplicas: 7
  minReplicas: 3
  scaleTargetRef:
    apiVersion: apps.openshift.io/v1
    kind: DeploymentConfig
    name: image-registry
  targetCPUUtilizationPercentage: 75
status:
  currentReplicas: 5
  desiredReplicas: 0
----

The following example shows autoscaling for the `image-registry` DeploymentConfig. The initial deployment requires 3 pods. The HPA object increased that minimum to 5 and will increase the pods up to 7 if CPU usage on the pods reaches 75%:

. View the current state of the `image-registry` deployment:
+
[source,terminal]
----
$ oc get dc image-registry
----
+
.Example output
[source,terminal]
----
NAME             REVISION   DESIRED   CURRENT   TRIGGERED BY
image-registry   1          3         3         config
----

. Autoscale the `image-registry` DeploymentConfig:
+
[source,terminal]
----
$ oc autoscale dc/image-registry --min=5 --max=7 --cpu-percent=75
----
+
.Example output
[source,terminal]
----
horizontalpodautoscaler.autoscaling/image-registry autoscaled
----

. View the new state of the deployment:
+
[source,terminal]
----
$ oc get dc image-registry
----
+
There are now 5 pods in the deployment:
+
.Example output
[source,terminal]
----
NAME             REVISION   DESIRED   CURRENT   TRIGGERED BY
image-registry   1          5         5         config
----
