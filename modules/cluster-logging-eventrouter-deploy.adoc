// Module included in the following assemblies:
//
// * logging/cluster-logging-eventrouter.adoc

[id="cluster-logging-eventrouter-deploy_{context}"]
= Deploying and configuring the Event Router

Use the following steps to deploy the Event Router into your cluster. You should always deploy the Event Router to the `openshift-logging` project to ensure it collects events from across the cluster.

The following Template object creates the service account, cluster role, and cluster role binding required for the Event Router. The template also configures and deploys the Event Router pod. You can use this template without making changes, or change the Deployment object CPU and memory requests.

.Prerequisites

* You need proper permissions to create service accounts and update cluster role bindings.  For example, you can run the following template with a user that has the *cluster-admin* role.

* Cluster logging must be installed.

.Procedure

. Create a template for the Event Router:
+
[source,yaml]
----
kind: Template
apiVersion: v1
metadata:
  name: eventrouter-template
  annotations:
    description: "A pod forwarding kubernetes events to cluster logging stack."
    tags: "events,EFK,logging,cluster-logging"
objects:
  - kind: ServiceAccount <1>
    apiVersion: v1
    metadata:
      name: eventrouter
      namespace: ${NAMESPACE}
  - kind: ClusterRole <2>
    apiVersion: v1
    metadata:
      name: event-reader
    rules:
    - apiGroups: [""]
      resources: ["events"]
      verbs: ["get", "watch", "list"]
  - kind: ClusterRoleBinding  <3>
    apiVersion: v1
    metadata:
      name: event-reader-binding
    subjects:
    - kind: ServiceAccount
      name: eventrouter
      namespace: ${NAMESPACE}
    roleRef:
      kind: ClusterRole
      name: event-reader
  - kind: ConfigMap <4>
    apiVersion: v1
    metadata:
      name: eventrouter
      namespace: ${NAMESPACE}
    data:
      config.json: |-
        {
          "sink": "stdout"
        }
  - kind: Deployment <5>
    apiVersion: apps/v1
    metadata:
      name: eventrouter
      namespace: ${NAMESPACE}
      labels:
        component: eventrouter
        logging-infra: eventrouter
        provider: openshift
    spec:
      selector:
        matchLabels:
          component: eventrouter
          logging-infra: eventrouter
          provider: openshift
      replicas: 1
      template:
        metadata:
          labels:
            component: eventrouter
            logging-infra: eventrouter
            provider: openshift
          name: eventrouter
        spec:
          serviceAccount: eventrouter
          containers:
            - name: kube-eventrouter
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              resources:
                requests:
                  cpu: ${CPU}
                  memory: ${MEMORY}
              volumeMounts:
              - name: config-volume
                mountPath: /etc/eventrouter
          volumes:
            - name: config-volume
              configMap:
                name: eventrouter
parameters:
  - name: IMAGE
    displayName: Image
    value: "registry.redhat.io/openshift4/ose-logging-eventrouter:latest"
  - name: CPU  <6>
    displayName: CPU
    value: "100m"
  - name: MEMORY <7>
    displayName: Memory
    value: "128Mi"
  - name: NAMESPACE
    displayName: Namespace
    value: "openshift-logging" <8>
----
<1> Creates a Service Account in the `openshift-logging` project for the Event Router.
<2> Creates a ClusterRole to monitor for events in the cluster.
<3> Creates a ClusterRoleBinding to bind the ClusterRole to the ServiceAccount.
<4> Creates a ConfigMap in the `openshift-logging` project to generate the required `config.json` file.
<5> Creates a Deployment in the `openshift-logging` project to generate and configure the Event Router pod.
<6> Specifies the minimum amount of memory to allocate to the Event Router pod. Defaults to `128Mi`.
<7> Specifies the minimum amount of CPU to allocate to the Event Router pod. Defaults to `100m`.
<8> Specifies the `openshift-logging` project to install objects in.

. Use the following command to process and apply the template:
+
[source,terminal]
----
$ oc process -f <templatefile> | oc apply -n openshift-logging -f -
----
+
For example:
+
[source,terminal]
----
$ oc process -f eventrouter.yaml | oc apply -n openshift-logging -f -
----
+
.Example output
[source,terminal]
----
serviceaccount/logging-eventrouter created
clusterrole.authorization.openshift.io/event-reader created
clusterrolebinding.authorization.openshift.io/event-reader-binding created
configmap/logging-eventrouter created
deployment.apps/logging-eventrouter created
----

. Validate that the Event Router installed in the `openshift-logging` project:
+
.. View the new Event Router Pod:
+
[source,terminal]
----
$ oc get pods --selector  component=eventrouter -o name -n openshift-logging
----
+
.Example output
[source,terminal]
----
pod/cluster-logging-eventrouter-d649f97c8-qvv8r
----

.. View the events collected by the Event Router:
+
[source,terminal]
----
$ oc logs <cluster_logging_eventrouter_pod> -n openshift-logging
----
+
For example:
+
[source,terminal]
----
$ oc logs cluster-logging-eventrouter-d649f97c8-qvv8r -n openshift-logging
----
+
.Example output
[source,terminal]
----
{"verb":"ADDED","event":{"metadata":{"name":"openshift-service-catalog-controller-manager-remover.1632d931e88fcd8f","namespace":"openshift-service-catalog-removed","selfLink":"/api/v1/namespaces/openshift-service-catalog-removed/events/openshift-service-catalog-controller-manager-remover.1632d931e88fcd8f","uid":"787d7b26-3d2f-4017-b0b0-420db4ae62c0","resourceVersion":"21399","creationTimestamp":"2020-09-08T15:40:26Z"},"involvedObject":{"kind":"Job","namespace":"openshift-service-catalog-removed","name":"openshift-service-catalog-controller-manager-remover","uid":"fac9f479-4ad5-4a57-8adc-cb25d3d9cf8f","apiVersion":"batch/v1","resourceVersion":"21280"},"reason":"Completed","message":"Job completed","source":{"component":"job-controller"},"firstTimestamp":"2020-09-08T15:40:26Z","lastTimestamp":"2020-09-08T15:40:26Z","count":1,"type":"Normal"}}
----
+
You can also use Kibana to view events by creating an index pattern using the Elasticsearch `infra` index.
