// Module included in the following assemblies:
//
// * installing/installing_aws/installing-aws-user-infra.adoc
// * installing/installing_aws/installing-restricted-networks-aws.adoc

[id="installation-aws-user-infra-requirements_{context}"]
= Required AWS infrastructure components

To install {product-title} on user-provisioned infrastructure in
Amazon Web Services (AWS), you must manually create both the machines and their
supporting infrastructure.

For more information about the integration testing for different platforms,
see the link:https://access.redhat.com/articles/4128421[OpenShift Container Platform 4.x Tested Integrations]
page.

You can use the provided CloudFormation templates to create this infrastructure,
you can manually create the components, or you can reuse existing infrastructure
that meets the cluster requirements. Review the CloudFormation templates
for more details about how the components interrelate.

[id="installation-aws-user-infra-cluster-machines_{context}"]
== Cluster machines

You need `AWS::EC2::Instance` objects for the following machines:

* A bootstrap machine. This machine is required during installation, but you
can remove it after your cluster deploys.
* At least three control plane machines. The control plane machines are not
governed by a MachineSet.
* Compute machines. You must create at least two compute machines, which are also known as worker machines,
during installation. These machines are not governed by a MachineSet.

////
You can also create and control them by using a MachineSet after your
control plane initializes and you can access the cluster API by using the `oc`
command line interface.
////

You can use the following instance types for the cluster machines with the provided CloudFormation templates.


[IMPORTANT]
====
If `m4` instance types are not available in your region, such as with
`eu-west-3`, use `m5` types instead.
====

.Instance types for machines
[cols="2a,2a,2a,2a",options="header"]
|===

|Instance type
|Bootstrap
|Control plane
|Compute

|`i3.large`
|x
|
|

| `m4.large` or `m5.large`
|
|
|x

| `m4.xlarge` or `m5.xlarge`
|
|x
|x

| `m4.2xlarge`
|
|x
|x

| `m4.4xlarge`
|
|x
|x

| `m4.8xlarge`
|
|x
|x

| `m4.10xlarge`
|
|x
|x

| `m4.16xlarge`
|
|x
|x

| `c4.large`
|
|
|x

| `c4.xlarge`
|
|
|x

| `c4.2xlarge`
|
|x
|x

| `c4.4xlarge`
|
|x
|x

| `c4.8xlarge`
|
|x
|x

| `r4.large`
|
|
|x

| `r4.xlarge`
|
|x
|x

| `r4.2xlarge`
|
|x
|x

| `r4.4xlarge`
|
|x
|x

| `r4.8xlarge`
|
|x
|x

| `r4.16xlarge`
|
|x
|x

|===

You might be able to use other instance types that meet the specifications of these instance types.

[id="csr-management-aws_{context}"]
== Certificate signing requests management

Because your cluster has limited access to automatic machine management when you
use infrastructure that you provision, you must provide a mechanism for approving
cluster certificate signing requests (CSRs) after installation. The
`kube-controller-manager` only approves the kubelet client CSRs. The
`machine-approver` cannot guarantee the validity of a serving certificate
that is requested by using kubelet credentials because it cannot confirm that
the correct machine issued the request. You must determine and implement a
method of verifying the validity of the kubelet serving certificate requests
and approving them.

[id="installation-aws-user-infra-other-infrastructure_{context}"]
== Other infrastructure components

* A VPC
* DNS entries
* Load balancers (classic or network) and listeners
* A public and a private Route53 zone
* Security groups
* IAM roles
* S3 buckets

.Required VPC components

You must provide a suitable VPC and subnets that allow communication to your
machines.

[cols="2a,7a,3a,3a",options="header"]
|===

|Component
|AWS type
2+|Description

|VPC
|* `AWS::EC2::VPC`
* `AWS::EC2::VPCEndpoint`
2+|You must provide a public VPC for the cluster to use. The VPC uses an
endpoint that references the route tables for each subnet to improve communication with the registry that is hosted in S3.

|Public subnets
|* `AWS::EC2::Subnet`
* `AWS::EC2::SubnetNetworkAclAssociation`
2+|Your VPC must have public subnets for between 1 and 3 availability zones
and associate them with appropriate Ingress rules.

|Internet gateway
|
* `AWS::EC2::InternetGateway`
* `AWS::EC2::VPCGatewayAttachment`
* `AWS::EC2::RouteTable`
* `AWS::EC2::Route`
* `AWS::EC2::SubnetRouteTableAssociation`
* `AWS::EC2::NatGateway`
* `AWS::EC2::EIP`
2+|You must have a public internet gateway, with public routes, attached to the
VPC. In the provided templates, each public subnet has a NAT gateway with an EIP address. These NAT gateways allow cluster resources, like private subnet instances, to reach the internet and are not required for some restricted network or proxy scenarios.

.7+|Network access control
.7+| * `AWS::EC2::NetworkAcl`
* `AWS::EC2::NetworkAclEntry`
2+|You must allow the VPC to access the following ports:
h|Port
h|Reason

|`80`
|Inbound HTTP traffic

|`443`
|Inbound HTTPS traffic

|`22`
|Inbound SSH traffic

|`1024` - `65535`
|Inbound ephemeral traffic

|`0` - `65535`
|Outbound ephemeral traffic


|Private subnets
|* `AWS::EC2::Subnet`
* `AWS::EC2::RouteTable`
* `AWS::EC2::SubnetRouteTableAssociation`
2+|Your VPC can have private subnets. The provided CloudFormation templates
can create private subnets for between 1 and 3 availability zones.
If you use private subnets, you must provide appropriate routes and tables
for them.

|===


.Required DNS and load balancing components

Your DNS and load balancer configuration needs to use a public hosted zone and
can use a private hosted zone similar to the one that the installation program
uses if it provisions the cluster's infrastructure. You must
create a DNS entry that resolves to your load balancer. An entry for
`api.<cluster_name>.<domain>` must point to the external load balancer, and an
entry for `api-int.<cluster_name>.<domain>` must point to the internal load
balancer.

The cluster also requires load balancers and listeners for port 6443, which are
required for the Kubernetes API and its extensions, and port 22623, which are
required for the Ignition config files for new machines. The targets will be the
master nodes. Port 6443 must be accessible to both clients external to the
cluster and nodes within the cluster. Port 22623 must be accessible to nodes
within the cluster.


[cols="2a,2a,8a",options="header"]
|===

|Component
|AWS type
|Description

|DNS
|`AWS::Route53::HostedZone`
|The hosted zone for your internal DNS.

|etcd record sets
|`AWS::Route53::RecordSet`
|The registration records for etcd for your control plane machines.

|Public load balancer
|`AWS::ElasticLoadBalancingV2::LoadBalancer`
|The load balancer for your public subnets.

|External API server record
|`AWS::Route53::RecordSetGroup`
|Alias records for the external API server.

|External listener
|`AWS::ElasticLoadBalancingV2::Listener`
|A listener on port 6443 for the external load balancer.

|External target group
|`AWS::ElasticLoadBalancingV2::TargetGroup`
|The target group for the external load balancer.

|Private load balancer
|`AWS::ElasticLoadBalancingV2::LoadBalancer`
|The load balancer for your private subnets.

|Internal API server record
|`AWS::Route53::RecordSetGroup`
|Alias records for the internal API server.

|Internal listener
|`AWS::ElasticLoadBalancingV2::Listener`
|A listener on port 22623 for the internal load balancer.

|Internal target group
|`AWS::ElasticLoadBalancingV2::TargetGroup`
|The target group for the Internal load balancer.

|Internal listener
|`AWS::ElasticLoadBalancingV2::Listener`
|A listener on port 6443 for the internal load balancer.

|Internal target group
|`AWS::ElasticLoadBalancingV2::TargetGroup`
|The target group for the internal load balancer.

|===

.Security groups

The control plane and worker machines require access to the following ports:

[cols="2a,2a,2a,2a",options="header"]
|===

|Group
|Type
|IP Protocol
|Port range


.4+|MasterSecurityGroup
.4+|`AWS::EC2::SecurityGroup`
|`icmp`
|`0`

|`tcp`
|`22`

|`tcp`
|`6443`

|`tcp`
|`22623`

.2+|WorkerSecurityGroup
.2+|`AWS::EC2::SecurityGroup`
|`icmp`
|`0`

|`tcp`
|`22`


.2+|BootstrapSecurityGroup
.2+|`AWS::EC2::SecurityGroup`

|`tcp`
|`22`

|`tcp`
|`19531`

|===

.Control plane Ingress

The control plane machines require the following Ingress groups. Each Ingress group is
a `AWS::EC2::SecurityGroupIngress` resource.

[cols="2a,5a,2a,2a",options="header"]
|===

|Ingress group
|Description
|IP protocol
|Port range


|`MasterIngressEtcd`
|etcd
|`tcp`
|`2379`- `2380`

|`MasterIngressVxlan`
|Vxlan packets
|`udp`
|`4789`

|`MasterIngressWorkerVxlan`
|Vxlan packets
|`udp`
|`4789`

|`MasterIngressInternal`
|Internal cluster communication and Kubernetes proxy metrics
|`tcp`
|`9000` - `9999`

|`MasterIngressWorkerInternal`
|Internal cluster communication
|`tcp`
|`9000` - `9999`

|`MasterIngressKube`
|Kubernetes kubelet, scheduler and controller manager
|`tcp`
|`10250` - `10259`

|`MasterIngressWorkerKube`
|Kubernetes kubelet, scheduler and controller manager
|`tcp`
|`10250` - `10259`

|`MasterIngressIngressServices`
|Kubernetes Ingress services
|`tcp`
|`30000` - `32767`

|`MasterIngressWorkerIngressServices`
|Kubernetes Ingress services
|`tcp`
|`30000` - `32767`

|===


.Worker Ingress

The worker machines require the following Ingress groups. Each Ingress group is
a `AWS::EC2::SecurityGroupIngress` resource.

[cols="2a,5a,2a,2a",options="header"]
|===

|Ingress group
|Description
|IP protocol
|Port range


|`WorkerIngressVxlan`
|Vxlan packets
|`udp`
|`4789`

|`WorkerIngressWorkerVxlan`
|Vxlan packets
|`udp`
|`4789`

|`WorkerIngressInternal`
|Internal cluster communication
|`tcp`
|`9000` - `9999`

|`WorkerIngressWorkerInternal`
|Internal cluster communication
|`tcp`
|`9000` - `9999`

|`WorkerIngressKube`
|Kubernetes kubelet, scheduler and controller manager
|`tcp`
|`10250`

|`WorkerIngressWorkerKube`
|Kubernetes kubelet, scheduler and controller manager
|`tcp`
|`10250`

|`WorkerIngressIngressServices`
|Kubernetes Ingress services
|`tcp`
|`30000` - `32767`

|`WorkerIngressWorkerIngressServices`
|Kubernetes Ingress services
|`tcp`
|`30000` - `32767`

|===


.Roles and instance profiles

You must grant the machines permissions in AWS. The provided CloudFormation
templates grant the machines permission the following `AWS::IAM::Role` objects
and provide a `AWS::IAM::InstanceProfile` for each set of roles. If you do
not use the templates, you can grant the machines the following broad permissions
or the following individual permissions.

[cols="2a,2a,2a,2a",options="header"]
|===

|Role
|Effect
|Action
|Resource

.4+|Master
|`Allow`
|`ec2:*`
|`*`

|`Allow`
|`elasticloadbalancing:*`
|`*`

|`Allow`
|`iam:PassRole`
|`*`

|`Allow`
|`s3:GetObject`
|`*`

|Worker
|`Allow`
|`ec2:Describe*`
|`*`


.3+|Bootstrap
|`Allow`
|`ec2:Describe*`
|`*`

|`Allow`
|`ec2:AttachVolume`
|`*`

|`Allow`
|`ec2:DetachVolume`
|`*`

|`Allow`
|`s3:GetObject`
|`*`

|===
