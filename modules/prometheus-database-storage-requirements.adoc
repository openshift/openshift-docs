// Module included in the following assemblies:
//
// * scalability_and_performance/scaling-cluster-monitoring-operator.adoc
// * installing-byoh/installing-existing-hosts.adoc

[id="prometheus-database-storage-requirements_{context}"]
= Prometheus database storage requirements

Red Hat performed various tests for different scale sizes.

.Prometheus Database storage requirements based on number of nodes/pods in the cluster
[options="header"]
|===
|Number of Nodes |Number of Pods |Prometheus storage growth per day |Prometheus storage growth per 15 days |RAM Space (per scale size) |Network (per tsdb chunk)

|50
|1800
|6.3 GB
|94 GB
|6 GB
|16 MB

|100
|3600
|13 GB
|195 GB
|10 GB
|26 MB

|150
|5400
|19 GB
|283 GB
|12 GB
|36 MB

|200
|7200
|25 GB
|375 GB
|14 GB
|46 MB
|===

Approximately 20 percent of the expected size was added as overhead to ensure
that the storage requirements do not exceed the calculated value.

The above calculation is for the default {product-title} Cluster Monitoring
Operator.

[NOTE]
====
CPU utilization has minor impact. The ratio is approximately 1 core out of 40
per 50 nodes and 1800 pods.
====

*Lab environment*

In a previous release, all experiments were performed in an {product-title} on
OpenStack environment:

* Infra nodes (VMs) - 40 cores, 157 GB RAM.
* CNS nodes (VMs) - 16 cores, 62 GB RAM, NVMe drives.

[IMPORTANT]
====
Currently, OpenStack environments are not supported for {product-title} {product-version}.
====

*Recommendations for {product-title}*

* Use at least three infrastructure (infra) nodes.
* Use at least three *openshift-container-storage* nodes with non-volatile memory express (NVMe) drives.
