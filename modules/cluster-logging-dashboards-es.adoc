// Module included in the following assemblies:
//
// * logging/cluster-logging-dashboards.adoc

[id="cluster-logging-dashboards-es_{context}"]
= About the Logging/Elastisearch nodes dashboard  

The *Logging/Elasticsearch nodes* dashboard contains charts that show details about your Elasticsearch instance, many at node-level, for further diagnostics.

Elasticsearch status::  

The {product-title} *Logging/Elasticsearch nodes* dashboard contains the following charts about the status of your Elasticsearch instance.

.Elasticsearch status fields
[options="header"]
|===
|Metric|Description

|Cluster status 
a|The cluster health status during the selected time period. Each time series represents one of possible states: green, yellow or red. A value of `1` indicates the state is active.

* 0 - green
* 1 - yellow
* 2 - red

The cluster health status is: green, yellow or red:  

* A red status indicates that the specific shard is not allocated in the cluster.
* A yellow status indicates that the primary shard is allocated but replicas are not.
* A green status indicates that all shards are allocated. 

|Cluster nodes 
|The total number of Elasticsearch nodes in the cluster.

|Cluster data nodes 
|The number of Elasticsearch data nodes in the cluster.

|Cluster pending tasks 
|The number of cluster state changes that have not been executed and are waiting in a cluster queue. For example: index creation, index deletion, or shard allocation. A growing trend indicates that the cluster is not able to keep up with changes.

|===

Elasticsearch cluster index shard status::

Every Elasticsearch index is a logical group of one or more shards, a basic scalability unit of persisted data. There are two types of index shards: primary shards, and replica shards. When a document is indexed into an index it is stored in one of its primary shards and then it is copied into every replica of that shard. The number of primary shards is specified when the index is created and the number cannot change during index lifetime. The number of replica shards can be changed anytime.

The index shard can be in several states depending on its lifecycle phase or events occurring in the cluster. When the shard is able to serve search and indexing requests, the shard is active. Otherwise the shard is non–active, for example, the shard is initializing, reallocating, unassigned, and so forth.

Index shards consist of a number of smaller internal blocks, called index segments, which are physical representations of the data. An index segment is a relatively small, immutable Lucene index that is created when Lucene commits newly-indexed data. Lucene merges index segments into larger segments in the background to keep the total number of segments low. If the process of merging segments is slower than the speed at which new segments are created, problems can arise over the long term.

When Lucene performs data operations, such as the search operation, Lucene performs the operation against the index segments in the relevant index. For that purpose, each segment contains specific data structures that need to be loaded in the memory and mapped. Index mapping can have a significant impact on the memory used by segment data structures.

The {product-title} *Logging/Elasticsearch nodes* dashboard contains the following charts about the Elasticsearch index shards.

.Elasticsearch cluster shard status charts
[options="header"]

|===
|Metric|Description

|Cluster active shards 
|The number of active primary shards and the total number of shards, including replicas, in the cluster. If the number of shards grows higher, the cluster performance starts degrading.

|Cluster initializing shards 
|The number of non-active shards in the cluster. A cluster will have non–active shards for short periods. A growing number of non–active shards over longer periods is a sign of a problem that needs attention.

|Cluster relocating shards 
|

|Cluster unassigned shards
| 

|Number of segments
|The number of link:https://www.elastic.co/blog/found-elasticsearch-from-the-bottom-up#index-segments[Lucene index segments] and the number of merging index segments. If the merging process is slower than the speed at which new segments are created, problems can occur over the long term.

|Memory used by segments
|The amount of memory used by different data structures in index segments.

|===

Elasticsearch node metrics::

Each Elasticsearch node has a finite amount of resources that can be used to process tasks. When all the resources are used and a new task needs to be processed, the new task must wait until some resources are freed. These tasks are put into an Elasticsearch queue. 

The {product-title} *Logging/Elasticsearch nodes* dashboard contains the following charts about resource usage for a selected node and the number of tasks waiting in the Elasticsearch queue.

.Elasticsearch node metric charts
[options="header"]
|===
|Metric|Description

|ThreadPool tasks
|The number of waiting tasks in individual queues assigned to specific task types. A long–term accumulation of tasks in any queue can indicate node resource shortages or some pathological problem.

|CPU usage 
|The amount of CPU that the selected Elasticsearch node is using as a percentage of the total CPU allocated to the host container.

|Memory usage 
|The amount of memory being used by the selected Elasticsearch node.

|Disk usage 
|The total disk space used by the selected Elasticsearch node by index data and metadata, the persisted copy of cluster state. This chart also displays three additional thresholds watermarks that are used to control index shard allocation on the node. The thresholds are: `lower watermark`, `upper watermark` and `flood stage`.
Reaching one of these thresholds should be avoided. Prometheus alerts you before you hit these thresholds, based on linear predictions of the actual trend.

|Documents indexing rate 
|The rate that documents are indexed on the selected Elasticsearch node.

|Indexing latency 
|The time taken by the selected Elasticsearch node to index the documents. The indexing latency can be affected by many factors, such as JVM Heap memory and overall load. A long-term growing trend indicates a resource capacity shortage in the instance.

|Search rate 
|The rate of number of search requests executed on the selected Elasticsearch node.

|Search latency  
|The time taken by the selected Elasticsearch node for completing a search request. Search latency is also subject to many factors. A long-term growing trend indicates a resource capacity shortage in the instance.

|Documents count (with replicas) 
|The number of documents stored on the selected Elasticsearch node, including documents stored in both the primary shards and replica shards that are allocated on the node.

|Documents deleting rate 
|The rate that Elasticsearch deletes documents from any of the index shards allocated on the selected Elasticsearch node.

|Documents merging rate 
|The rate of that Elasticsearch merges documents in any of index shards allocated on the selected Elasticsearch node.

|===

Elasticsearch node fielddata::

_Fielddata_ is a query–time in–memory data structure for text fields that is built by Elasticsearch and kept in the JVM Heap. Fielddata is built at the index-segment level and because it is an expensive operation to build, this data structure is cached. A fielddata cache can be evicted when the underlying index segment is deleted or merged, or if there is not enough JVM HEAP memory for all the fielddata caches. 

The {product-title} *Logging/Elasticsearch nodes* dashboard contains the following charts about Elasticsearch fielddata.

.Elasticsearch node fielddata charts
[options="header"]
|===
|Metric|Description

|Fielddata memory size 
|The amount of JVM Heap used for the fielddata cache on the selected Elasticsearch node.

|Fielddata evictions 
|The number of fielddata structures that were deleted from the selected Elasticsearch node. 

|===

Elasticsearch node query cache::

If the data stored in the index does not change, search query results are cached in a node-level query cache for resuse by Elasticsearch. 

The {product-title} *Logging/Elasticsearch nodes* dashboard contains the following charts about the Elasticsearch node query cache.

.Elasticsearch node query charts
[options="header"]
|===
|Metric|Description

|Query cache size 
|The total amount of memory used for the query cache for all the shards allocated on the selected Elasticsearch node.

|Query cache evictions 
|The number of query cache evictions on the selected Elasticsearch node.

|Query cache hits 
|The number of query cache hits on the selected Elasticsearch node.

|Query cache misses 
|The number of query cache misses on the selected Elasticsearch node.

|===

Elasticsearch index throttling::

When indexing documents, Elasticsearch stores the documents in index segments, which are physical representations of the data. At the same time, Elasticsearch periodically merges smaller segments into a larger segment as a way to optimize resource use. If the indexing is faster then the ability to merge segments, the merge process gets behind. To prevent this situation, Elasticsearch throttles indexing, typically by reducing the number of threads allocated to indexing down to a single thread. 

The {product-title} *Logging/Elasticsearch nodes* dashboard contains the following charts about the Elasticsearch index throttling.

.Index throttling charts
[options="header"]
|===
|Metric|Description

|Indexing throttling 
|The amount of time that Elasticsearch has been throttling the indexing operations on the selected Elasticsearch node.

|Merging throttling 
|The amount of time the Elasticsearch has been throttling the segment merge operations on the selected Elasticsearch node.

|===

Node JVM Heap statistics::

The {product-title} *Logging/Elasticsearch nodes* dashboard contains the following charts about JVM Heap operations.

.JVM Heap statistic charts
[options="header"]
|===
|Metric|Description

|Heap used 
|The amount of the total allocated JVM Heap space being used on the selected Elasticsearch node.

|GC count 
|The number of garbage collection operations that have been executed on the selected Elasticsearch node, old and young garbage collection.

|GC time 
|The amount of time that the the JVM spent executing garbage collection operations on the selected Elasticsearch node, by old and young garbage collection.

|===
