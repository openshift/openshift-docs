// Module included in the following assemblies:
//
// * logging/cluster-logging-external.adoc

[id="cluster-logging-collector-legacy-fluentd_{context}"]
= Forwarding logs using the legacy Fluentd method

You can use the Fluentd *forward* protocol to send logs to destinations outside of your {product-title} cluster instead of the default Elasticsearch log store by creating a configuration file and ConfigMap. You are responsible for configuring the external log aggregator to receive the logs from {product-title}.

[IMPORTANT]
====
This method for forwarding logs is deprecated in {product-title} and will be removed in a future release.
====

ifdef::openshift-origin[]
The *forward* protocols are provided with the Fluentd image as of v1.4.0.
endif::openshift-origin[]

To send logs using the Fluentd *forward* protocol, create a configuration file called `secure-forward.conf`, that points to an external log aggregator. Then, use that file to create a ConfigMap called called `secure-forward` in the `openshift-logging` namespace, which {product-title} uses when forwarding the logs.

.Sample Fluentd configuration file

[source,yaml]
----
<store>
  @type forward
  <security>
    self_hostname fluentd.example.com
    shared_key "fluent-receiver"
  </security>
  transport tls
  tls_verify_hostname false
  tls_cert_path '/etc/ocp-forward/ca-bundle.crt'
  <buffer>
    @type file
    path '/var/lib/fluentd/secureforwardlegacy'
    queued_chunks_limit_size "1024"
    chunk_limit_size "1m"
    flush_interval "5s"
    flush_at_shutdown "false"
    flush_thread_count "2"
    retry_max_interval "300"
    retry_forever true
    overflow_action "exception"
  </buffer>
  <server>
    host fluent-receiver.example.com
    port 24224
  </server>
</store>
----

.Procedure

To configure {product-title} to forward logs using the legacy Fluentd method:

. Create a configuration file named `secure-forward` and specify parameters similar to the following within the `<store>` stanza:
+
[source,yaml]
----
<store>
  @type forward
  <security>
    self_hostname <common-name> <1>
    shared_key <key> <2>
  </security>
  transport tls <3>
  tls_verify_hostname <value> <4>
  tls_cert_path <path_to_file> <5>
  <buffer> <6>
    @type file
    path '/var/lib/fluentd/secureforwardlegacy'
    queued_chunks_limit_size "#{ENV['BUFFER_QUEUE_LIMIT'] || '1024' }"
    chunk_limit_size "#{ENV['BUFFER_SIZE_LIMIT'] || '1m' }"
    flush_interval "#{ENV['FORWARD_FLUSH_INTERVAL'] || '5s'}"
    flush_at_shutdown "#{ENV['FLUSH_AT_SHUTDOWN'] || 'false'}"
    flush_thread_count "#{ENV['FLUSH_THREAD_COUNT'] || 2}"
    retry_max_interval "#{ENV['FORWARD_RETRY_WAIT'] || '300'}"
    retry_forever true
    overflow_action "#{ENV['BUFFER_QUEUE_FULL_ACTION'] || 'exception'}"
  </buffer>
  <server>
    name <7>
    host <8>
    hostlabel <9>
    port <10>
  </server>
  <server> <11>
    name
    host
  </server>
----
<1> Specify the default value of the auto-generated certificate common name (CN).
<2> Enter the shared key between nodes
<3> Specify `tls` to enable TLS validation.
<4> Set to `true` to verify the server cert hostname. Set to `false` to ignore server cert hostname.
<5> Specify the path to the private CA certificate file as `/etc/ocp-forward/ca_cert.pem`.
<6> Specify the link:https://docs.fluentd.org/configuration/buffer-section[Fluentd buffer parameters] as needed.
<7> Optionally, enter a name for this server.
<8> Specify the host name or IP of the server.
<9> Specify the host label of the server.
<10> Specify the port of the server.
<11> Optionally, add additional servers.
If you specify two or more servers, *forward* uses these server nodes in a round-robin order.
+
To use Mutual TLS (mTLS) authentication, see the link:https://docs.fluentd.org/output/forward#tips-and-tricks[Fluentd documentation] for information about client certificate, key parameters, and other settings.

. Create a ConfigMap named `secure-forward` in the `openshift-logging` namespace from the configuration file:
+
[source,terminal]
----
$ oc create configmap secure-forward --from-file=secure-forward.conf -n openshift-logging
----

The Cluster Logging Operator redeploys the Fluentd pods. If the pods do not redeploy, you can delete the Fluentd
pods to force them to redeploy.

[source,terminal]
----
$ oc delete pod --selector logging-infra=fluentd
----
