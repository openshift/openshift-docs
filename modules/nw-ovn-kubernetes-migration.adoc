// Module included in the following assemblies:
//
// * networking/ovn_kubernetes_network_provider/migrate-from-openshift-sdn.adoc

[id="nw-ovn-kubernetes-migration_{context}"]
= Migrating to the OVN-Kubernetes default CNI network provider

As a cluster administrator, you can change the default Container Network Interface (CNI) network provider for your cluster to OVN-Kubernetes.
During the migration, you must reboot every node in your cluster.

[IMPORTANT]
====
While performing the migration, your cluster is unavailable and workloads might be interrupted.
Perform the migration only when an interruption in service is acceptable.
====

.Prerequisites

* Install the OpenShift Command-line Interface (CLI), commonly known as `oc`.
* Access to the cluster as a user with the `cluster-admin` role.
* A cluster installed on bare metal infrastructure configured with the OpenShift SDN default CNI network provider.
* The cluster is in a known good state, without any errors.

.Procedure

. To backup the configuration for the cluster network, enter the following command:
+
----
$ oc get Network.config.openshift.io cluster -o yaml  > cluster-openshift-sdn.yaml
----

. To enable the migration, set an annotation on the Cluster Network Operator configuration object by entering the following command:
+
----
$ oc annotate Network.operator.openshift.io cluster \
  'networkoperator.openshift.io/network-migration'=""
----

. To change the default CNI network provider, enter the following command:
+
----
$ oc patch Network.config.openshift.io cluster \
  --type='merge' --patch '{ "spec": { "networkType": "OVNKubernetes" } }'
----

. To confirm the migration disabled the OpenShift SDN default CNI network provider and removed all OpenShift SDN Pods, enter the following command. It might take several moments for all the OpenShift SDN Pods to stop.
+
----
$ watch oc get pod -n openshift-sdn
----

. To complete the migration, reboot each node in your cluster. For example, you could use a bash script similar to the following. The script assumes that you can connect to each host by using `ssh` and that you have configured `sudo` to not prompt for a password.
+
[source,bash]
----
#!/bin/bash

for ip in $(oc get nodes  -o jsonpath='{.items[*].status.addresses[?(@.type=="InternalIP")].address}')
do
   echo "reboot node $ip"
   ssh -o StrictHostKeyChecking=no core@$ip sudo shutdown -r -t 3
done
----

. After the nodes in your cluster have rebooted, confirm that the migration succeeded:

.. To confirm that the default CNI network provider is OVN-Kubernetes, enter the following command.  The value of `status.networkType` must be `OVNKubernetes`.
+
----
$ oc get network.config/cluster -o jsonpath='{.status.networkType}{"\n"}'
----

.. To confirm that the cluster nodes are in the `Ready` state, enter the following command:
+
----
$ oc get nodes
----
+
If a node is stuck in the `NotReady` state, reboot the node again.

.. To confirm that your Pods are not in an error state, enter the following command:
+
----
$ oc get pods --all-namespaces -o wide --sort-by='{.spec.nodeName}'
----
+
If Pods on a node are in an error state, reboot that node.

. Complete the following steps only if the migration succeeds and your cluster is in a good state:

.. To remove the migration annotation from the Cluster Network Operator configuration object, enter the following command:
+
----
$ oc annotate Network.operator.openshift.io cluster \
  networkoperator.openshift.io/network-migration-
----

.. To remove the OpenShift SDN network provider namespace, enter the following command:
+
----
$ oc delete namespace openshift-sdn
----
