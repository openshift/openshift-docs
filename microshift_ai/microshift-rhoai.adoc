:_mod-docs-content-type: ASSEMBLY
[id="microshift-rh-openshift-ai"]
include::_attributes/attributes-microshift.adoc[]
= Using {rhoai-full} with {microshift-short}
:context: microshift-rh-openshift-ai

toc::[]

Learn how to serve artificial intelligence and machine learning (AI/ML) models with {ai-first} on your {microshift-short} edge deployments.

:FeatureName: {rhoai-full}
include::snippets/technology-preview.adoc[leveloffset=+1]

include::modules/microshift-rhoai-con.adoc[leveloffset=+1]

include::modules/microshift-rhoai-workflow.adoc[leveloffset=+1]

//additional resources for rhoai-workflow module
[role="_additional-resources"]
.Additional resources

* xref:../microshift_networking/microshift-configuring-routes.adoc#microshift-configuring-routes[Configuring routes]

include::modules/microshift-rhoai-install.adoc[leveloffset=+1]

include::modules/microshift-rhoai-create-ns.adoc[leveloffset=+1]

include::modules/microshift-rhoai-model-package-oci.adoc[leveloffset=+1]

//additional resources for rhoai-oci module
[role="_additional-resources"]
.Additional resources

* link:https://kserve.github.io/website/latest/modelserving/storage/oci/[Serving models with OCI images]

include::modules/microshift-rhoai-serving-ai-models-con.adoc[leveloffset=+1]

include::modules/microshift-rhoai-supported-crds.adoc[leveloffset=+2]

include::modules/microshift-rhoai-supported-mserv-runtimes.adoc[leveloffset=+2]

include::modules/microshift-rhoai-servingruntimes-ex.adoc[leveloffset=+1]

//additional resources for serving runtimes procedure module
[role="_additional-resources"]
.Additional resources

* link:https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/latest/html/serving_models/about-model-serving_about-model-serving#about-model-serving_about-model-serving[About model serving]

* link:https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/latest/html/serving_models/serving-large-models_serving-large-models#servingruntime[Model-serving runtimes]

* link:https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/latest/html/serving_models/serving-large-models_serving-large-models[Serving models on the single-model serving platform]

* link:https://docs.redhat.com/en/documentation/red_hat_openshift_ai_cloud_service/latest/html/serving_models/serving-large-models_serving-large-models#tested-verified-runtimes_serving-large-models[Tested and verified model-serving runtimes]
//the `2-latest` link is not working (2-latest in place of `1`)

* link:https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/latest/html/serving_models/serving-large-models_serving-large-models#adding-a-tested-and-verified-model-serving-runtime-for-the-single-model-serving-platform_serving-large-models[Adding a tested and verified model-serving runtime for the single-model serving platform] ({rhoai-full} documentation)

* link:https://kserve.github.io/website/0.8/modelserving/servingruntimes/[Serving Runtimes] (KServe documentation)

* link:https://kserve.github.io/website/latest/modelserving/data_plane/v1_protocol/[V1 Inference Protocol] (KServe documentation)

* link:https://kserve.github.io/website/latest/modelserving/data_plane/v2_protocol/[Open Inference Protocol (V2)] (KServe documentation)

include::modules/microshift-rhoai-inferenceservice-ex.adoc[leveloffset=+1]

include::modules/microshift-rhoai-export-metrics-otel.adoc[leveloffset=+2]

include::modules/microshift-inferenceservice-more-options.adoc[leveloffset=+2]

include::modules/microshift-rhoai-model-serving-rt-verify.adoc[leveloffset=+1]

//additional resources for inferenceservice modules
.Additional resources

* link:https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/latest/html/serving_models/serving-large-models_serving-large-models#inferenceservice[InferenceService]

include::modules/microshift-rhoai-create-route.adoc[leveloffset=+1]

//additional resources for creating a route
.Additional resources

* xref:../microshift_networking/microshift-configuring-routes.adoc#microshift-configuring-routes[Configuring routes]

include::modules/microshift-rhoai-query-model-con.adoc[leveloffset=+1]

include::modules/microshift-rhoai-verify-model-connected.adoc[leveloffset=+2]

include::modules/microshift-rhoai-get-model-ready-inference.adoc[leveloffset=+2]

include::modules/microshift-rhoai-query-model.adoc[leveloffset=+2]

include::modules/microshift-rhoai-get-model-server-metrics.adoc[leveloffset=+2]

include::modules/microshift-rhoai-override-kserve-config.adoc[leveloffset=+1]
