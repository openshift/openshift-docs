:_content-type: ASSEMBLY
[id="sno-du-enabling-workload-partitioning-on-single-node-openshift"]
= Workload partitioning on single node OpenShift
include::modules/common-attributes.adoc[]
:context: sno-du-enabling-workload-partitioning-on-single-node-openshift

toc::[]

In resource-constrained environments, such as single node production deployments, it is advantageous to reserve most of the CPU resources for your own workloads and configure OpenShift to run on a fixed number of CPUs within the host. A good example of this type of environment is a telecommunication service providers implementation of a Radio Access Network (RAN).

In these environments, management workloads, including the OpenShift control plane, need to be configured to use fewer resources than they might by default in normal clusters.

You can isolate the {product-title} services, cluster management workloads, and infrastructure pods to run on a
reserved set of CPUs. This is useful for resource-constrained environments, such as a single node cluster, where you want to reserve most of the CPU resources for user workloads and configure {product-title} to run on a fixed number of CPUs within the host.

When you use workload partitioning, the CPU resources used by {product-title} for cluster management are
isolated to a partitioned set of CPU resources on a single node cluster with a DU profile applied. This
falls broadly into two categories:

* Isolates cluster management functions to the defined number of CPUs. All cluster management functions operate solely on that `cpuset`.

* Tunes the cluster configuration (with the applied DU profile) so the actual CPU usage fits within the assigned `cpuset`.

The minimum number of reserved CPUs required for the management partition for a single node cluster is
four CPU HTs. Inclusion of Operators or workloads outside of the set of accepted management pods requires
additional CPU HTs.

Workload partitioning isolates the workloads away from the non-management workloads using the normal scheduling
capabilities of Kubernetes to manage the number of pods that can be placed onto those cores, and avoids mixing
cluster management workloads and user workloads.

To fully leverage workload partitioning, you need to install the Performance Addon Operator and apply the
performance profile.

When you use workload partitioning, the CPU resources used by {product-title} for cluster management are isolated to a partitioned set of CPU resources on a single node cluster with a DU profile applied. This falls broadly into two categories:

* Isolates cluster management functions to the defined number of CPUs. All cluster management functions operate solely on that `cpuset`.

* Tunes the cluster configuration (with the applied DU profile) so the actual CPU usage fits within the assigned `cpuset`.

The minimum number of reserved CPUs required for the management partition for a single node cluster is four CPU HTs. Inclusion of Operators or workloads outside of the set of accepted management pods requires additional CPU HTs.

Workload partitioning isolates the workloads away from the non-management workloads using the normal scheduling capabilities of Kubernetes to manage the number of pods that can be placed onto those cores, and avoids mixing cluster management workloads and user workloads.

To fully leverage workload partitioning, you need to install the Performance Addon Operator and apply the performance profile.

The concept of cluster management workloads is flexible and can encompass:

* All {product-title} core components necessary to run the cluster.

* Any add-on Operators necessary to make up the platform as defined by the customer.

* Operators or other components from third-party vendors that the customer deems as management rather than operational.

** Adding management workloads might require additional CPU resources to be added to the partition.

Workload partitioning introduces a new extended resource of `<workload-type>.workload.openshift.io/cores` for each CPU pool, workload-type, defined in the configuration file. Kubelet advertises these new resources. When workload partitioning is enabled, it represents all of the CPU capacity of the host, not just the CPU pool.

include::modules/sno-du-enabling-workload-partitioning.adoc[leveloffset=+1]
