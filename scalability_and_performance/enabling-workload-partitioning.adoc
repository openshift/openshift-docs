:_content-type: ASSEMBLY
[id="enabling-workload-partitioning"]
= Workload partitioning
include::_attributes/common-attributes.adoc[]
:context: enabling-workload-partitioning

toc::[]

In resource-constrained environments, you can use workload partitioning to isolate {product-title} services, cluster management workloads, and infrastructure pods to run on a reserved set of CPUs.

The minimum number of reserved CPUs required for the cluster management is four CPU Hyper-Threads (HTs).
With workload partitioning, you annotate the set of cluster management pods and a set of typical add-on Operators for inclusion in the cluster management workload partition.
These pods operate normally within the minimum size CPU configuration.
Additional Operators or workloads outside of the set of minimum cluster management pods require additional CPUs to be added to the workload partition.

Workload partitioning isolates user workloads from platform workloads using standard Kubernetes scheduling capabilities.

The following changes are required for workload partitioning:

. In the `install-config.yaml` file, add the additional field: `cpuPartitioningMode`.
+
[source,yaml]
----
apiVersion: v1
baseDomain: devcluster.openshift.com
cpuPartitioningMode: AllNodes <1>
compute:
  - architecture: amd64
    hyperthreading: Enabled
    name: worker
    platform: {}
    replicas: 3
controlPlane:
  architecture: amd64  
  hyperthreading: Enabled
  name: master
  platform: {}
  replicas: 3
----
<1> Sets up a cluster for CPU partitioning at install time. The default value is `None`. 
+
[NOTE]
====
Workload partitioning can only be enabled during cluster installation. You cannot disable workload partitioning post-installation.
====

. In the performance profile, specify the `isolated` and `reserved` CPUs. 
+
[source,yaml]
----
apiVersion: performance.openshift.io/v2
kind: PerformanceProfile
metadata:
  name: openshift-node-workload-partitioning-worker
spec:
  cpu:
    isolated: 0,1 <1>
    reserved: "2-3" <2>
  machineConfigPoolSelector:
    pools.operator.machineconfiguration.openshift.io/worker: ""
  nodeSelector:
    node-role.kubernetes.io/worker: ""
----
<1> Sets the isolated CPUs. Ensure all of the Hyper-Threading pairs match.
<2> Specifies the CPU set to pin the workloads and the {product-title} infrastructure pods to. When workload partitioning is enabled, platform containers and platform services such as `systemd`, `CRI-O`, and `Kubelet`  are restricted to these CPUs. All CPUs that are not isolated should be reserved.

Workload partitioning introduces an extended `management.workload.openshift.io/cores` resource type for platform pods.
Kubelet advertises the resources and CPU requests by pods allocated to the pool within the corresponding resource.
When workload partitioning is enabled, the `management.workload.openshift.io/cores` resource allows the scheduler to correctly assign pods based on the `cpushares` capacity of the host, not just the default `cpuset`.

[role="_additional-resources"]
.Additional resources

* For the recommended workload partitioning configuration for {sno} clusters, see xref:../scalability_and_performance/ztp_far_edge/ztp-reference-cluster-configuration-for-vdu.adoc#ztp-sno-du-enabling-workload-partitioning_sno-configure-for-vdu[Workload partitioning].
