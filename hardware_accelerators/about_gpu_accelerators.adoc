:_mod-docs-content-type: ASSEMBLY
[id="about-hardware-accelerators"]
= About hardware accelerators
include::_attributes/common-attributes.adoc[]
:context: gpu-accelerators

toc::[]

[IMPORTANT]
====
Hardware accelerators are a Technology Preview feature only. Technology Preview features are not supported with Red{nbsp}Hat production service level agreements (SLAs) and might not be functionally complete. Red{nbsp}Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.

For more information about the support scope of Red{nbsp}Hat Technology Preview features, see link:https://access.redhat.com/support/offerings/techpreview/[Technology Preview Features Support Scope].
====

GPU accelerators are specialized hardware accelerators that play a key role in the emerging generative artificial intelligence and machine learning (AI/ML) industry. Specifically, hardware accelerators are essential to the training and serving of large language and other foundational models that power this new technology. It allows data scientists, data engineers, ML engineers, and developers to take advantage of the specialized hardware acceleration for data-intensive transformations and model development and serving. Much of that ecosystem is open source with a number of contributing vendors and open source foundations. 

Specialized hardware accelerators provide a rich set of benefits for AI/ML development:

* One platform for all. Allows for collaborative environments for developers, data engineers, data scientists, and DevOps.
* Extended capabilities with Operators. Operators allow for bringing AI/ML capabilities to OpenShift.
* Hybrid-cloud support. On-premise support for model development, delivery, and deployment. 
* Support for AI/ML workloads. Model testing, iteration, integration, promotion, and serving into production as services.

Red{nbsp}Hat provides an optimized platform to enable these specialized hardware accelerators in our RHEL and OpenShift platforms at the Linux (kernel and userspace) and Kubernetes layers. To do this, Red{nbsp}Hat combines the proven capabilities of Red{nbsp}Hat OpenShift AI and Red{nbsp}Hat OpenShift in a single enterprise-ready AI application platform. 

// GRAPHIC HERE

Red{nbsp}Hat OpenShift AI is an open hybrid AI/ML platform built on Red{nbsp}Hat OpenShift that enables enterprises to create and deliver AI-enabled applications securely and at scale across hybrid clouds. It enables data acquisition and preparation, model training and fine-tuning, model serving and model monitoring, and hardware acceleration. 

// Link to RHOAI landing page

GPU accelerators are designed to work within air gapped (disconnected) environments. This is because of customer requirements to maintain a secure environment for development and testing.  

GPU Operators use the operating framework of a Kubernetes cluster to enable the required accelerator resources. A device plugin is also provided that can be deployed manually or as a DaemonSet. This plugin enables the registration of the GPU in the cluster.   

== Supported vendors

Red{nbsp}Hat Openshift supports GPU accelerators provided by the following vendors:

* AMD
* NVIDIA
* Intel

// The topics in this section describe how to install and test the supported GPU accelerators in an OpenShift environment.

== Prerequisites

[role="_additional-resources"]
.Additional resources

* xref:../virt/virtual_machines/advanced_vm_management#virt-configuring-virtual-gpus.adoc[Configuring virtual GPUs]
*

// Modules for each vendor to be included here as they are completed.
// include::modules/amd-gpu-operator.adoc[leveloffset=+1]
// include::modules/nvidia-gpu-operator.adoc[leveloffset=+1]
// include::modules/intel-gpu-operator.adoc[leveloffset=+1]