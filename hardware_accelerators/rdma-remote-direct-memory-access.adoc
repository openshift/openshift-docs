:_mod-docs-content-type: ASSEMBLY
[id="rdma-remote-direct-memory-access"]
= NVIDIA GPUDirect Remote Direct Memory Access (RDMA)
include::_attributes/common-attributes.adoc[]
:context: rdma-remote-direct-memory-access

toc::[]
 
NVIDIA GPUDirect Remote Direct Memory Access (RDMA) allows for the memory in one computer to directly access the memory of another computer without needing access through the operating system. This provides the ability to bypass kernel intervention in the process, freeing up resources and greatly reducing the CPU overhead normally needed to process network communications. This is useful for distributing GPU-accelerated workloads across clusters. And because RDMA is so suited toward high bandwidth and low latency applications, this makes it ideal for big data and machine learning applications.
 
There are currently three configuration methods for NVIDIA GPUDirect RDMA:

Shared device:: This method allows for an NVIDIA GPUDirect RDMA device to be shared among multiple pods on the {product-title} worker node where the device is exposed. 

Host device:: This method provides direct physical Ethernet access on the worker node by 
creating an additional host network on a pod. A plugin allows the network device to be moved from the host network namespace to the network namespace on the pod.

SR-IOV legacy device:: The Single Root IO Virtualization (SR-IOV) method can share a single network device, such as an Ethernet adapter, with multiple pods. SR-IOV segments the device, recognized on the host node as a physical function (PF), into multiple virtual functions (VFs).  The VF is used like any other network device.   

Each of these methods can be used across either the NVIDIA GPUDirect RDMA over Converged Ethernet (RoCE) or Infiniband infrastructures, providing an aggregate total of six methods of configuration.

:FeatureName: Remote Direct Memory Access

include::modules/rdma-prerequisites.adoc[leveloffset=+1]

* Install the xref:../hardware_enablement/psap-node-feature-discovery-operator.adoc#installing-the-node-feature-discovery-operator_node-feature-discovery-operator[Node Feature Discovery Operator].

* Install the xref:../networking/networking_operators/sr-iov-operator/installing-sriov-operator.adoc#installing-sriov-operator[SR-IOV Operator].

* Install the link:https://docs.nvidia.com/networking/display/kubernetes2501/getting-started-openshift.html#network-operator-installation-using-openshift-oc-cli[NVIDIA Network Operator] (NVIDIA documentation). 

* Install the link:https://docs.nvidia.com/datacenter/cloud-native/openshift/24.9.2/install-gpu-ocp.html[NVIDIA GPU Operator] (NVIDIA documentation).

include::modules/rdma-disabling-irdma-kernel-module.adoc[leveloffset=+1]

include::modules/rdma-creating-persistent-naming-rules.adoc[leveloffset=+1]

include::modules/rdma-configuring-the-nfd-operator.adoc[leveloffset=+1]

include::modules/rdma-configuring-the-sriov-operator.adoc[leveloffset=+1]

include::modules/rdma-configuring-the-nvidia-network-operator.adoc[leveloffset=+1]

include::modules/rdma-configuring-the-gpu-operator.adoc[leveloffset=+1]

