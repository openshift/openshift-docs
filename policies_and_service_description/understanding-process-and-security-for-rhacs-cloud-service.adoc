:_content-type: ASSEMBLY
[id="understanding-process-and-security-for-rhacs-cloud-service"]
= Understanding process and security for {product-title-managed-short}
include::modules/common-attributes.adoc[]
:context: process-and-security

toc::[]

[role="_abstract"]
Red Hat Site Reliability Engineers (SREs) maintain {rh-rhacscs-first} using a centralized monitoring and alerting system, audit logs, and a comprehensive set of access controls and audit mechanisms to ensure the security, integrity, and compliance of customer Control Plane instances and associated cloud accounts.


[id="incident-and-operations-management_{context}"]
== Incident and operations management

[id="platform-monitoring_{context}"]
=== Platform monitoring

Red Hat Site Reliability Engineers (SREs) maintain a centralized monitoring and alerting system for all {rh-rhacscs-first} components and SRE services.

Platform audit logs are securely routed to a centralized security information and event monitoring (SIEM) system where they can trigger configured alerts to the SRE team and are also subject to manual review.
Audit logs are retained in the SIEM system for one year. Audit logs for a specific {product-title-managed-short} instance are not deleted at the time the cluster is deleted.

[id="incident-management_{context}"]
=== Incident management

An incident is an event that results in the degradation or failure of one or more Red Hat services.

A customer or a member of Customer Experience and Engagement (CEE) reports an incident through a support case, directly through the central monitoring and alerting system, or directly by a member of the Site Reliability Engineering (SRE) team.

Depending on the impact on the service and the customer, the incident is divided into the following categories of link:https://access.redhat.com/support/offerings/production/sla[severity].
When managing a new incident, Red Hat uses the following general workflow:

. An SRE first responder is made aware of a new incident and begins an initial investigation.
. After the initial investigation, an incident lead is assigned to the incident to coordinate recovery efforts.
. The incident lead manages all communications and coordination around the recovery, including all relevant notifications and support case updates.
. The incident is resolved.

[id="infrastructure-and-data-resiliency_{context}"]
=== Infrastructure and data resiliency

{product-title-short} Cloud instances are deployed in OpenShift Dedicated clusters and managed by Red Hat.
Customer data is stored in an encrypted Relational Database Service (RDS) database that is not accessible via the public Internet.
The only access allowed is audited access by SREs. Red Hat does not commit to a Recovery Point Objective (RPO) or Recovery Time Objective (RTO).

[id="change-management_{context}"]
== Change management

[id="red-hat-initiated-changes_{context}"]
=== Red Hat initiated changes

Red Hat Site Reliability Engineering (SRE) manages the infrastructure, code, and configuration of the Central instance of {rh-rhacscs-first}.
This process ensures that Red Hat can continuously introduce service improvements without negatively impacting customers.

Each proposed change goes through a series of automated checks immediately after check-in. The changes are then deployed to a staging environment where they undergo automated integration testing.

Finally, the changes are deployed to the production environment. Most of the steps are fully automated.A reviewer must approve advancement to each step. The reviewer cannot be the same person who proposed the change.
Some changes are released to production incrementally, using feature flags to control the availability of new features to specific clusters or customers.


[id="patch-management_{context}"]
=== Patch management

{product-title-managed-short} has been patched for bugs and vulnerabilities in regular z-stream upgrades.

[id="release-management_{context}"]
=== Release management

Red Hat automatically upgrades your {product-title-managed-short} Central instance. You can also schedule the upgrade at regular intervals (recurring upgrade) or one time (individual upgrade) through the web console.

Red Hat can force upgrade a cluster to a new z-stream version only if the cluster is affected by a Common Vulnerabilities and Exposures (CVE) with critical impact.


[id="identity-and-access-management_{context}"]
== Identity and access management

[id="sre-access-to-rhacs-cloud-service-clusters-and-accounts_{context}"]
=== SRE access to {product-title-managed-short} clusters and accounts

Red Hat does not have access to data residing on Secured Clusters or to the Secured Clusters themselves.
In addition, by default, Red Hat Site Reliability Engineers (SREs) do not have access to customers centralised instances.

For example, they do not have access to vulnerability reports or customer data.
However, SREs can be given temporary admin access to a Central instance if an issue requires it, such as a customer being locked out of their account.

Red Hat SREs have audited access to cloud service logs, metrics, and debugging information for Central instances.
They also have audited access to anonymized telemetry data, such as the number of API calls made or the number of {product-title-short} resource objects created.

[id="security-and-regulation-compliance_{context}"]
== Security and regulation compliance

[id="securing-access-controls-and-auditing_{context}"]
=== Securing access controls and auditing

{rh-rhacscs-first} has implemented a comprehensive set of access controls and auditing mechanisms to ensure the security and integrity of customer Control plane instances and associated cloud accounts, mitigate the risk of unauthorized access, and ensure compliance with security best practices.

A combination of role-based access control (RBAC) and network controls manages access to customer control plane instances in the {product-title-managed-short}.
Read more about RBAC controls for customer Control plane instances in xref:../operating/manage-user-access/manage-role-based-access-control-3630.adoc#manage-role-based-access-control[Managing RBAC in Red Hat Advanced Cluster Security for Kubernetes].

RBAC controls are also in place for the administration of the Central instances themselves to ensure that only authorized users have the necessary permissions to perform administrative tasks.
In addition to RBAC, network controls are applied to client control plane instances to further secure access.
Central instances are configured to route all network traffic through an egress proxy that helps monitor and control network connections.

Kube NetworkPolicies are also installed to prevent connections between namespaces, providing an additional layer of network security.
In addition, RBAC controls also exist for cloud accounts that host instances.
Credentials for Amazon Web Services (AWS) cloud accounts are stored in a Bitwarden Vault.

The {product-title-short} development team owns the Vault to ensure that only authorized personnel have access to these credentials.
An upcoming release is expected to include the migration of credentials to the AWS parameter Vault, which will further improve the security of access controls for cloud accounts.


[id="ensuring-security-and-privacy-of-customer-sensitive-data_{context}"]
=== Ensuring security and privacy of customer sensitive data

{product-title-managed-short} follows industry-standard practices for storing, isolating, and accessing sensitive customer data, with a focus on role-based access, personnel training, and deauthorization to minimize the risk of unauthorized access and protect the privacy of customer data.

Customer's sensitive data is stored in encrypted volumes from Amazon Web Services (AWS) RDS (Relational Database Service), ensuring that persistent data is protected from unauthorized access.
This is in line with industry best practices for securing data in transit and at rest.

Each tenant in {product-title-managed-short} is allocated its own RDS instance, ensuring that customer data is isolated and segregated between tenants.
This ensures that data belonging to one tenant cannot be accessed or inadvertently leaked to another tenant.

Currently, {product-title-managed-short} developers have access to customer data because they have administrator credentials for the {ocp} cluster and AWS account.
However, backplane access is used to access the customer data, following the principle of least privilege.

This ensures that only authorized personnel with a legitimate need can access customer data, minimizing the risk of unauthorized access.
When employees leave employment or no longer require access to customer data, their access to the Bitwarden Vault where the credentials are stored is immediately blocked to prevent any unauthorized access to customer data.

The {product-title-managed-short} collects usage data from the user interface (UI) to Pendo, an external data processor.
Appropriate security measures and contractual agreements are in place to ensure the protection and confidentiality of customer data processed and stored by third-party processors.


[id="data-encryption_{context}"]
=== Data encryption

[id="encrypting-persistent-customer-data_{context}"]
==== Encrypting persistent customer data

{product-title-managed-short} follows best practices for encrypting persistent customer data, uses industry-recognized encryption mechanisms, securely manages encryption keys, and restricts access to authorized personnel to protect customer data from unauthorized access and maintain data privacy.

The {product-title-managed-short} uses Amazon Web Services (AWS) RDS (Relational Database Service) to store persistent customer data.
The RDS instances are not publicly accessible to ensure that the data is not exposed to unauthorized access from external sources.

In addition, the database (DB) credentials are stored only within the namespace where the Central instance is running, limiting access to authorized users.
Persistent data in {product-title-managed-short} is encrypted using disk encryption through RDS. This ensures that the data is protected even if the physical storage media is compromised.

AWS RDS determines whether the specific ciphers and key lengths used for encryption in {product-title-managed-short} comply with its documentation.
These encryption standards are industry-recognized and continually updated to ensure reliable security measures.

AWS RDS and AWS Key Management Service (KMS) manages encryption keys in the {product-title-managed-short}.
AWS RDS manages encryption of persistent data, while KMS is used for key management, including key creation, rotation, and revocation.
This ensures that encryption keys are properly managed and secured, reducing the risk of unauthorized access to customer data.


[id="encrypting-customer-data-in-transit_{context}"]
==== Encrypting customer data in transit

{product-title-managed-short} employs robust encryption mechanisms to protect data in transit, including the use of TLS (Transport Layer Security) encryption, supported ciphers and key lengths, secure certificate and private key management, and regular certificate rotation.
These measures ensure the confidentiality, integrity, and authenticity of data transmitted between components of the service and provide a high level of data security.

TLS is used to encrypt customer data during transmission between components of the service. This ensures that data is encrypted during transmission over the network and is thus protected against eavesdropping.

The Go runtime used to manage TLS ciphers determines the specific ciphers and key lengths supported for network encryption in {product-title-managed-short}.
These ciphers and key lengths are selected based on industry best practices and are constantly updated to maintain strong security measures.

Certificate and private key management in {product-title-managed-short} is secure.
RDS (Relational Database Service) manages the private keys for the database and ensures their proper storage and protection.
The private keys for Central are stored as Kubernetes secrets and secured in a Bitwarden Vault.

To further improve security, a migration of the secrets to the Amazon Web Services (AWS) parameter store takes place.
The {product-title-managed-short} follows a regular schedule for certificate and private key rotation to ensure the continued security of the service.


[id="data-classification_{context}"]
=== Data classification

Red Hat defines and follows a data classification standard to determine the sensitivity of data and to highlight the inherent risk to the confidentiality and integrity of that data when it is collected, used, transmitted, stored, and processed.
Customer proprietary data is classified at the highest level of sensitivity and handling requirements.


[id="vulnerability-management_{context}"]
=== Vulnerability management

{product-title-managed-short} performs regular vulnerability scans using industry-standard tools. Identified vulnerabilities are tracked to remediation on a schedule based on severity.
Third-party assessors document vulnerability scanning and remediation activities for verification in the course of compliance certification audits.