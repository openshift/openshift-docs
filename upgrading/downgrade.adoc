[[install-config-downgrade]]
= Downgrading a cluster
{product-author}
{product-version}
:icons: font
:experimental:
:toc: macro
:toc-title:
:prewrap!:
:description: Manual steps to revert {product-title} to a previous version following an upgrade.
:keywords: yum
:context: downgrade

toc::[]

After an {product-title}
xref:../upgrading/index.adoc#install-config-upgrading-index[upgrade],
you might need to downgrade your cluster to an earlier
version. You can downgrade from {product-title} version 3.11 to version 3.10.

[IMPORTANT]
====
Downgrading a cluster to version 3.10 is supported for only
xref:../install/index.adoc#planning-installation-types[RPM-based
installations] of {product-title}, and you must take your entire cluster offline
to downgrade.
====

[[downgrade-verifying-backups]]
== Verifying backups

. Ensure that a backup of the *_master-config.yaml_* file,
*_scheduler.json_* file, and the etcd data directory exist on your masters:
+
----
/etc/origin/master/master-config.yaml.<timestamp>
/etc/origin/master/scheduler.json
/var/lib/etcd/openshift-backup-xxxx
----
+ The Ansible playbook that you run during the
xref:../upgrading/index.adoc#install-config-upgrading-index[upgrade process]
creates these files. 

. Locate the copies of the following files that you created when you
xref:automated_upgrades.adoc#preparing-for-an-automated-upgrade[prepared for an upgrade].
+
On node and master hosts:
+
----
/etc/origin/node/node-config.yaml
----
+
On etcd hosts, including masters that have etcd co-located on them:
+
----
/etc/etcd/etcd.conf
----

[[downgrade-shutting-down-the-cluster]]
== Shutting down the cluster

. On all master and node hosts, run:
+
----
# systemctl stop atomic-openshift-node
----

[[downgrade-removing-rpms]]
== Removing RPMs and static pods

. On all masters, nodes, and etcd members (if using a dedicated etcd cluster),
remove the following packages:
+
----
# yum remove atomic-openshift \
   atomic-openshift-excluder-3.11.16-1.git.0.b48b8f8.el7.noarch \
   atomic-openshift-hyperkube-3.11.16-1.git.0.b48b8f8.el7.x86_64 \
   atomic-openshift-node-3.11.16-1.git.0.b48b8f8.el7.x86_64 \
   atomic-openshift-3.11.16-1.git.0.b48b8f8.el7.x86_64 \
   atomic-openshift-docker-excluder-3.11.16-1.git.0.b48b8f8.el7.noarch \
   atomic-openshift-clients-3.11.16-1.git.0.b48b8f8.el7.x86_64 \
   atomic-openshift-master \
   atomic-openshift-sdn-ovs 
----

. Verify the packages were removed successfully:
+
----
# rpm -qa | grep atomic-openshift
----

. On control plane hosts (master and etcd hosts), move the static pod definitions:
+
----
# mkdir /etc/origin/node/pods-backup
# mv /etc/origin/node/pods/* /etc/origin/node/pods-backup/
----

. Reboot each host:
+
----
# systemctl reboot
----


[[downgrade-reinstalling-rpms]]
== Reinstalling RPMs

. Disable the {product-title} 3.11 repositories, and re-enable the 3.10
repositories:
+
----
# subscription-manager repos \
    --disable=rhel-7-server-ose-3.11-rpms \
    --enable=rhel-7-server-ose-3.10-rpms
----

. On each master, install the following packages:
+
----
# yum install atomic-openshift \
    atomic-openshift-node-3.10.51-1.git.0.90663d3.el7.x86_64 \
    atomic-openshift-docker-excluder-3.10.51-1.git.0.90663d3.el7.noarch \
    atomic-openshift-excluder-3.10.51-1.git.0.90663d3.el7.noarch \
    atomic-openshift-clients-3.10.51-1.git.0.90663d3.el7.x86_64 \
    atomic-openshift-hyperkube-3.10.51-1.git.0.90663d3.el7.x86_64 \
    atomic-openshift-3.10.51-1.git.0.90663d3.el7.x86_64 \
    atomic-openshift-master \
    openvswitch \
    atomic-openshift-sdn-ovs \
    tuned-profiles-atomic-openshift-node 
----

. On each node, install the following packages:
+
----
# yum install atomic-openshift \
    atomic-openshift-node-3.10.51-1.git.0.90663d3.el7.x86_64 \
    atomic-openshift-docker-excluder-3.10.51-1.git.0.90663d3.el7.noarch \
    atomic-openshift-excluder-3.10.51-1.git.0.90663d3.el7.noarch \
    atomic-openshift-clients-3.10.51-1.git.0.90663d3.el7.x86_64 \
    atomic-openshift-hyperkube-3.10.51-1.git.0.90663d3.el7.x86_64 \
    atomic-openshift-3.10.51-1.git.0.90663d3.el7.x86_64 \
    openvswitch \
    atomic-openshift-sdn-ovs \
    tuned-profiles-atomic-openshift-node
----

. On each host, verify the packages were installed successfully:
+
----
# rpm -qa | grep atomic-openshift
----

:context: downgrade
include::day_two_guide/topics/proc_restoring-etcd.adoc[leveloffset=+1]

include::day_two_guide/topics/proc_adding-etcd-after-restoring.adoc[leveloffset=+2]

include::day_two_guide/topics/proc_bringing-openshift-online.adoc[leveloffset=+1]

[[verifying-the-downgrade]]
== Verifying the downgrade

 To verify the downgrade:

. Check that all nodes are marked as *Ready*:
+
----
# oc get nodes
NAME                        STATUS                     AGE
master.example.com          Ready,SchedulingDisabled   165d
node1.example.com           Ready                      165d
node2.example.com           Ready                      165d
----

. Verify the successful downgrade of the registry and router, if deployed:

.. Verify you are running the `v3.10` versions of the *docker-registry*
and *router* images:
+
----
# oc get -n default dc/docker-registry -o json | grep \"image\"
    "image": "openshift3/ose-docker-registry:v3.10",
# oc get -n default dc/router -o json | grep \"image\"
    "image": "openshift3/ose-haproxy-router:v3.10",
----

.. Verify that *docker-registry* and *router* pods are running and in ready state:
+
----
# oc get pods -n default

NAME                       READY     STATUS    RESTARTS   AGE
docker-registry-2-b7xbn    1/1       Running   0          18m
router-2-mvq6p             1/1       Running   0          6m
----

. Use the
xref:../admin_guide/diagnostics_tool.adoc#admin-guide-diagnostics-tool[diagnostics tool]
on the master to look for common issues and provide suggestions:
+
----
# oc adm diagnostics
...
[Note] Summary of diagnostics execution:
[Note] Completed with no errors or warnings seen.
----
