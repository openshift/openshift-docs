[[architecture-core-concepts-pods-and-services]]
= Pods and Services
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

[[pods]]

== Pods

{product-title} leverages the Kubernetes concept of a _pod_, which is one or
more xref:containers_and_images.adoc#containers[containers] deployed
together on one host, and the smallest compute unit that can be defined,
deployed, and managed.

Pods are the rough equivalent of a machine instance (physical or virtual) to a
container. Each pod is allocated its own internal IP address, therefore owning its entire
port space, and containers within pods can share their local storage and networking.

Pods have a lifecycle; they are defined, then they are assigned to run on
a node, then they run until their container(s) exit or they are removed
for some other reason. Pods, depending on policy and exit code, may be
removed after exiting, or may be retained in order to enable access to
the logs of their containers.

{product-title} treats pods as largely immutable; changes cannot be made to
a pod definition while it is running. {product-title} implements changes by
terminating an existing pod and recreating it with modified configuration,
base image(s), or both. Pods are also treated as expendable, and do not
maintain state when recreated. Therefore pods should usually be managed by
higher-level xref:deployments.adoc#replication-controllers[controllers],
rather than directly by users.

ifdef::openshift-enterprise,openshift-origin[]
[IMPORTANT]
====
The recommended maximum number of pods per {product-title} node host is 110.
====
endif::[]

Below is an example definition of a pod that provides a long-running
service, which is actually a part of the {product-title} infrastructure: the
integrated container registry. It demonstrates many features of pods, most of
which are discussed in other topics and thus only briefly mentioned here:

.Pod Object Definition (YAML)
====

[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  annotations: { ... }
  labels:                                <1>
    deployment: docker-registry-1
    deploymentconfig: docker-registry
    docker-registry: default
  generateName: docker-registry-1-       <2>
spec:
  containers:                            <3>
  - env:                                 <4>
    - name: OPENSHIFT_CA_DATA
      value: ...
    - name: OPENSHIFT_CERT_DATA
      value: ...
    - name: OPENSHIFT_INSECURE
      value: "false"
    - name: OPENSHIFT_KEY_DATA
      value: ...
    - name: OPENSHIFT_MASTER
      value: https://master.example.com:8443
    image: openshift/origin-docker-registry:v0.6.2 <5>
    imagePullPolicy: IfNotPresent
    name: registry
    ports:                              <6>
    - containerPort: 5000
      protocol: TCP
    resources: {}
    securityContext: { ... }            <7>
    volumeMounts:                       <8>
    - mountPath: /registry
      name: registry-storage
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: default-token-br6yz
      readOnly: true
  dnsPolicy: ClusterFirst
  imagePullSecrets:
  - name: default-dockercfg-at06w
  restartPolicy: Always
  serviceAccount: default               <9>
  volumes:                              <10>
  - emptyDir: {}
    name: registry-storage
  - name: default-token-br6yz
    secret:
      secretName: default-token-br6yz
----

====

<1> Pods can be "tagged" with one or more xref:labels[labels], which can then
be used to select and manage groups of pods in a single operation. The labels
are stored in key/value format in the `*metadata*` hash. One label in this
example is *docker-registry=default*.
<2> Pods must have a unique name within their
xref:projects_and_users.adoc#namespaces[namespace]. A pod definition may specify
the basis of a name with the `*generateName*` attribute, and random characters
will be added automatically to generate a unique name.
<3> `*containers*` specifies an array of container definitions; in this case (as
with most), just one.
<4> Environment variables can be specified to pass necessary values to each
container.
<5> Each container in the pod is instantiated from its own
xref:containers_and_images.adoc#docker-images[Docker-formatted container image].
<6> The container can bind to ports which will be made available on the pod's
IP.
<7> {product-title} defines a
ifndef::openshift-online[]
xref:../additional_concepts/authorization.adoc#security-context-constraints[security
context]
endif::[]
ifdef::openshift-online[]
security context
endif::[]
for containers which specifies whether they are allowed to run as
privileged containers, run as a user of their choice, and more. The default
context is very restrictive but administrators can modify this as needed.
<8> The container specifies where external storage volumes should be mounted
within the container. In this case, there is a volume for storing the registry's
data, and one for access to credentials the registry needs for making requests
against the {product-title} API.
<9> Pods making requests against the {product-title} API is a common enough pattern
that there is a `*serviceAccount*` field for specifying which
xref:../../dev_guide/service_accounts.adoc#dev-guide-service-accounts[service account] user the pod should
authenticate as when making the requests. This enables fine-grained access
control for custom infrastructure components.
<10> The pod defines storage volumes that are available to its container(s) to
use. In this case, it provides an ephemeral volume for the registry storage and
a `*secret*` volume containing the service account credentials.

[NOTE]
====
This pod definition does not include attributes that
are filled by {product-title} automatically after the pod is created and
its lifecycle begins. The
xref:../../rest_api/kubernetes_v1.adoc#rest-api-kubernetes-v1[Kubernetes API documentation]
has complete details of the pod REST API object attributes, and the
link:https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/user-guide/pods.md[Kubernetes pod documentation]
has details about the functionality and purpose of pods.
====

[[services]]

== Services

A Kubernetes link:http://kubernetes.io/docs/user-guide/services[service] serves
as an internal load balancer. It identifies a set of replicated xref:pods[pods]
in order to proxy the connections it receives to them. Backing pods can be added
to or removed from a service arbitrarily while the service remains consistently
available, enabling anything that depends on the service to refer to it at a
consistent address.  The default service clusterIP addresses are from the
{product-title} internal network and they are used to permit pods to access each
other. To permit external access to the service, additional externalIP addresses
that are
ifndef::openshift-online[]
xref:../../dev_guide/getting_traffic_into_cluster.adoc#using-externalIP[external]
endif::[]
ifdef::openshift-online[]
external
endif::[]
to cluster, can be assigned to the service. These externalIP addresses can also be virtual IP addresses that provide
ifdef::openshift-enterprise,openshift-origin[]
xref:../../admin_guide/high_availability.adoc#admin-guide-high-availability[highly available]
endif::[]
ifdef::openshift-dedicated,openshift-online,atomic-registry[]
highly available
endif::[]
access to the service.

Services are assigned an IP address and port pair that, when accessed,
proxy to an appropriate backing pod. A service uses a label selector to find
all the containers running that provide a certain network service on a certain
port.

Like pods, services are REST objects. The following
example shows the definition of a service for the pod defined above:

.Service Object Definition (YAML)
====

[source,yaml]
----
apiVersion: v1
kind: Service
metadata:
  name: docker-registry      <1>
spec:
  selector:                  <2>
    docker-registry: default
  portalIP: 172.30.136.123   <3>
  ports:
  - nodePort: 0
    port: 5000               <4>
    protocol: TCP
    targetPort: 5000         <5>
----

<1> The service name *docker-registry* is also used to construct an
environment variable with the service IP that is inserted into other
pods in the same namespace. The maximum name length is 63 characters.
<2> The label selector identifies all pods with the
*docker-registry=default* label attached as its backing pods.
<3> Virtual IP of the service, allocated automatically at creation from a pool
of internal IPs.
<4> Port the service listens on.
<5> Port on the backing pods to which the service forwards connections.
====

The link:http://kubernetes.io/docs/user-guide/services/[Kubernetes
documentation] has more information on services.

[[service-externalip]]
=== Service externalIPs

In addition to the cluster's internal IP addresses, the user can configure IP addresses that are external to the cluster. The administrator is responsible for ensuring that traffic arrives at a node with this IP.

ifdef::openshift-origin,openshift-enterprise[]
The externalIPs must be selected by the admin from the *ExternalIPNetworkCIDRs*
range configured in
xref:../../admin_guide/tcp_ingress_external_ports.adoc#unique-external-ips-ingress-traffic-configure-cluster[*_master-config.yaml_*]
file. When *_master-config.yaml_* is changed, the master service must be
restarted.
endif::[]

ifdef::openshift-dedicated,openshift-online[]
The externalIPs must be selected by the admin from the *ExternalIPNetworkCIDRs*
range configured in master configuration file.
endif::[]

.Sample ExternalIPNetworkCIDR /etc/origin/master/master-config.yaml
====
----
networkConfig:
  ExternalIPNetworkCIDR: 172.47.0.0/24
----
====

.Service externalIPs Definition (JSON)
====

[source,json]
----
{
    "kind": "Service",
    "apiVersion": "v1",
    "metadata": {
        "name": "my-service"
    },
    "spec": {
        "selector": {
            "app": "MyApp"
        },
        "ports": [
            {
                "name": "http",
                "protocol": "TCP",
                "port": 80,
                "targetPort": 9376
            }
        ],
        "externalIPs" : [
            "80.11.12.10"         <1>
        ]
    }
}
----

<1> List of External IP addresses on which the *port* is exposed. In addition to the internal IP addresses)

====

ifdef::openshift-origin,openshift-enterprise[]
[[service-ingressip]]
=== Service ingressIPs

In non-cloud clusters, externalIP addresses can be automatically assigned from a
pool of addresses. This eliminates the need for the administrator manually
assigning them.

The pool is configured in *_/etc/origin/master/master-config.yaml_* file. After
changing this file, restart the master service.

The `ingressIPNetworkCIDR` is set to `172.29.0.0/16` by default. If the cluster
environment is not already using this private range, use the default range or
set a custom range.

[NOTE]
====
If you are using xref:../../admin_guide/high_availability.adoc#admin-guide-high-availability[high availibility], then this range must be less than 256
addresses.
====

.Sample ingressIPNetworkCIDR /etc/origin/master/master-config.yaml
====
----
networkConfig:
  ingressIPNetworkCIDR: 172.29.0.0/16
----
====

endif::[]

[[service-nodeport]]
=== Service NodePort

Setting the service `type=NodePort` will allocate a port from a flag-configured range (default: 30000-32767), and each node will proxy that port (the same port number on every node) into your service.

ifdef::openshift-origin,openshift-enterprise[]
The selected port will be reported in the service configuration, under  `spec.ports[*].nodePort`.

To specify a custom port just place the port number in the nodePort field. The custom port number must be in the configured range for nodePorts. When '*master-config.yaml*' is changed the master service must be restarted.

.Sample servicesNodePortRange /etc/origin/master/master-config.yaml
====
----
kubernetesMasterConfig:
  servicesNodePortRange: ""
----
====

The service will be visible as both the `<NodeIP>:spec.ports[].nodePort`
and `spec.clusterIp:spec.ports[].port`

[NOTE]
====
Setting a nodePort is a privileged operation.
====

[[service-proxy-mode]]
=== Service Proxy Mode

{product-title} has two different implementations of the service-routing
infrastructure. The default implementation is entirely *iptables*-based, and
uses probabilistic *iptables* rewriting rules to distribute incoming service
connections between the endpoint pods. The older implementation uses a user
space process to accept incoming connections and then proxy traffic between the
client and one of the endpoint pods.

The *iptables*-based implementation is much more efficient, but it requires that
all endpoints are always able to accept connections; the user space
implementation is slower, but can try multiple endpoints in turn until it finds
one that works. If you have good
xref:../../dev_guide/application_health.adoc#dev-guide-application-health[readiness
checks] (or generally reliable nodes and pods), then the *iptables*-based
service proxy is the best choice. Otherwise, you can enable the user space-based
proxy when installing, or after deploying the cluster by editing the node
configuration file.
endif::[]

[[labels]]

== Labels

Labels are used to organize, group, or select API objects.
For example, xref:pods[pods] are "tagged" with labels, and then
xref:services[services] use label selectors to identify the pods they
proxy to. This makes it possible for services to reference groups of
pods, even treating pods with potentially different containers
as related entities.

Most objects can include labels in their metadata. So labels can
be used to group arbitrarily-related objects; for example,
all of the xref:pods[pods], xref:services[services],
xref:deployments.adoc#replication-controllers[replication
controllers], and
xref:deployments.adoc#deployments-and-deployment-configurations[deployment
configurations] of a particular application can be grouped.

Labels are simple key/value pairs, as in the following example:

====

[source,yaml]
----
labels:
  key1: value1
  key2: value2
----

====

Consider:

- A pod consisting of an *nginx* container, with the label
*role=webserver*.
- A pod consisting of an *Apache httpd* container, with the same label
*role=webserver*.

A service or replication controller that is defined to use pods with the
*role=webserver* label treats both of these pods as part of the same group.

The
https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/user-guide/labels.md[Kubernetes
documentation] has more information on labels.

[[endpoints]]

== Endpoints

The servers that back a service are called its endpoints, and are
specified by an object of type *Endpoints* with the same name as the
service. When a service is backed by pods, those pods are normally
specified by a label selector in the service specification, and
{product-title} automatically creates the Endpoints object pointing to
those pods.

In some cases, you may want to create a service but have it be backed
by external hosts rather than by pods in the {product-title} cluster.
In this case, you can leave out the `*selector*` field in the service,
and
xref:../../dev_guide/integrating_external_services.adoc#dev-guide-integrating-external-services[create
the Endpoints object manually].

Note that {product-title} will not let most users manually create an
Endpoints object that points to an IP address in
xref:../../install_config/configuring_sdn.adoc#configuring-the-pod-network-on-masters[the
network blocks reserved for pod and service IPs]. Only
xref:../additional_concepts/authorization.adoc#roles[cluster admins]
or other users with
xref:../additional_concepts/authorization.adoc#evaluating-authorization[permission
to `create` resources under `endpoints/restricted`] can create such
Endpoint objects.
