= Routing
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:

toc::[]

== Overview
Routers provide external DNS mapping and load balancing to
link:kubernetes_model.html#service[services] over protocols that pass
distinguishing information directly to the router. Routers support the following
protocols:

- HTTP
- HTTPS
- WebSockets
- TLS with SNI

NOTE: WebSocket traffic uses the same route conventions and supports the same
TLS termination types as other traffic.

The router uses the service selector to watch the endpoints that support the
service, bypassing its logic and replacing it with the router's own. Routers
subscribe to a configuration and automatically update themselves with any
changes. Router may be containerized or virtual, converting any changes to API
calls to another system, such as *F5*.

Other capabilities exist to load-balance a service within a cluster. These
services are exposed via a configurable link relation between different
services, and ensure a set of services can be available.
link:../../dev_guide/deployments.html[Deployments] can use these services as
local proxies for each host, or reuse the shared routing infrastructure.

As an OpenShift administrator, you can configure routers in your instance. This
allows developers to then set the route types for their projects.

== Route Types
Routes can be either secure or unsecure. Secure routes provide the ability to
use different types of TLS termination to serve certificates to the client.
Routers support link:#edge-termination[edge],
link:#passthrough-termination[passthrough], and
link:#re-encryption-termination[re-encryption] termination.

To create a secure route, specify the TLS termination of the route in a JSON
file.

.An Unsecure Route
====

----
{
    "kind": "Route",
    "apiVersion": "v1beta1",
    "metadata": {
        "name": "route-unsecure"
    },
    "id": "route-unsecure",
    "host": "www.example.com",
    "serviceName": "hello-nginx"
}
----
====

.A Secure Route Using Edge Termination
====

----
{
    "metadata": {
        "name": "route-edge"
    },
    "id": "route-edge",
    "apiVersion": "v1beta1",
    "kind": "Route",
    "host": "www.example.com",
    "serviceName": "hello-nginx",
    "tls": {
        "termination": "edge",
        "certificate": "CERT TEXT OMITTED FOR READABILITY",
        "key": "CERT TEXT OMITTED FOR READABILITY",
        "caCertificate": "CERT TEXT OMITTED FOR READABILITY"
     }
}
----
====

.An Unsecure Route with a Path:
====

----
{
    "kind": "Route",
    "apiVersion": "v1beta1",
    "metadata": {
        "name": "route-unsecure"
    },
    "id": "route-unsecure",
    "host": "www.example.com",
    "path": "/test",
    "serviceName": "hello-nginx"
}
----

====

Unsecure routes are likely faster to set up, as they are the default configuration, but secure routes offer greater security for information to remain private.

== Path Based Routes
Path based routes specify a path component that can be compared against a URL. This implies that the traffic for the route is HTTP based. Routers should match routes based on the most specific path to the least. However, this depends on your implementation. The following table shows example routes and their accessibility:

////
*  For a route with \_www.example.com/test_:
** \_www.example.com/test_ should be accessible
** \_www.example.com_ should not be accessible
*  For routes with \_www.example.com/test_ and \_www.example.com_:
** \_www.example.com/test_ should be accessible
** \_www.example.com_ should be accessible
*  For routes with \_www.example.com_:
** \_www.example.com/test_ should be accessible (matched by the host, not the route)
** \_www.example.com_ should be accessible
////

.Route Availability
[cols="3*", options="header"]
|===
|Route |When Compared to |Accessible

.2+|_www.example.com/test_ |_www.example.com/test_ |Yes

|_www.example.com_ |No

.2+|_www.example.com/test_ and _www.example.com_ |_www.example.com/test_ |Yes

|_www.example.com_ |Yes

.2+|_www.example.com_ |_www.example.com/test_ |Yes (Matched by the host, not the route)

|_www.example.com_ |Yes
|===

== Securing Routes
You can create a secure route to your pods by specifying the TLS termination of
the route and, optionally, providing certificates.

NOTE: Currently, TLS termination in OpenShift Beta relies on SNI for serving
custom certificates. Any non-SNI traffic received on port 443 has TLS
termination with a generic certificate. In the future, the ability to create
custom front ends within the router will allow all traffic to serve custom
certificates.

By default, OpenShift routes are unsecure, but can be set to any of the
following three types of secure TLS termination.

[[edge-termination]]
*Edge Termination*

With edge termination, TLS termination occurs prior to traffic reaching its
destination. TLS certificates are served by the front end of the router.

You can configure edge termination on your route by specifying the following:

.Configuring Edge Termination
====

----
{
    "metadata": {
        "name": "route-edge"
    },
    "id": "route-edge",
    "apiVersion": "v1beta1",
    "kind": "Route",
    "host": "www.example.com",
    "serviceName": "hello-nginx",
    "tls": {
        "termination": "edge", <1>
        "certificate": "CERT TEXT OMITTED FOR READABILITY", <2>
        "key": "CERT TEXT OMITTED FOR READABILITY", <3>
        "caCertificate": "CERT TEXT OMITTED FOR READABILITY" <4>
     }
}
----

<1> Set the `*termination*` field to `edge`.
<2> Set the `*certificate*` field to the contents of the certificate file. See
the link:#special-notes[special notes] below.
<3> Set the `*key*` field to the contents of the key file. See the
link:#special-notes[special notes] below.
<4> Set the `*caCertificate*` field to the contents of the CA certificate file.
See the link:#special-notes[special notes] below.
====

[[passthrough-termination]]
*Passthrough Termination*

With passthrough termination, encrypted traffic is sent straight to the
destination without the router providing TLS termination.

You can configure passthrough termination on your route by specifying the
following:

.Configuring Passthrough Termination
====

----
{
    "metadata": {
        "name": "route-secure"
    },
    "id": "route-secure",
    "apiVersion": "v1beta1",
    "kind": "Route",
    "host": "www.example.com",
    "serviceName": "hello-nginx-secure",
    "tls": { "termination" : "passthrough" } <1>
}
----

<1> Set the `*termination*` field to `passthrough`.
====

The destination, such as an *Nginx*, *Apache*, or another *HAProxy* instance, is
then responsible for serving certificates for the traffic.

[[re-encryption-termination]]
*Re-encryption Termination*

Re-encryption is a type of edge termination where the client encrypts
communication with a certificate, which is then re-encrypted with a different
certificate when the traffic reaches the destination. The router uses health
checks to determine the authenticity of the host.

You can configure re-encryption termination on your route by specifying the
following:

.Configuring Re-encryption Termination
====

----
{
    "metadata": {
        "name": "route-reencrypt"
    },
    "id": "route-reencrypt",
    "apiVersion": "v1beta1",
    "kind": "Route",
    "host": "www.example2.com",
    "serviceName": "hello-nginx-secure",
    "tls": {
        "termination": "reencrypt", <1>
        "certificate": "CERT TEXT OMITTED FOR READABILITY", <2>
        "key": "CERT TEXT OMITTED FOR READABILITY", <3>
        "caCertificate": "CERT TEXT OMITTED FOR READABILITY", <4>
        "destinationCaCertificate": "CERT TEXT OMITTED FOR READABILITY" <5>
     }
}
----

<1> Set the `*termination*` field to `reencrypt`.
<2> Set the `*certificate*` field to the contents of the certificate file. See
the link:#special-notes[special notes] below.
<3> Set the `*key*` field to the contents of the key file. See the
link:#special-notes[special notes] below.
<4> Set the `*caCertificate*` field to the contents of the CA certificate file.
See the link:#special-notes[special notes] below.
<5> Use the `*destinationCaCertificate*` field to validate the secure connection
from the router to the destination, specific to each implementation. See the
link:#special-notes[special notes] below.
====

[[wildcard-certificates]]
*Wildcard Certificates*

Based on the implementation, you may be able to use a default certificate. Default certificates
are useful for implementing a wildcard certificate for the router.  For example, if you have
many routes that end in example.com you may wish to install a router with a wild card
certificate for `*.example.com`.

To provide the default certificate to the router you must specify it in the create command with
the default-cert option. The certificate should be a concatenated file of the key, certificate,
and any CA certificates that are required by the browser. The certificate should be in a
form acceptable by the underlying router implementation. In the case of HAProxy it should be a
PEM based certificate.

****
`osadm router --credentials="$OPENSHIFTCONFIG" --default-cert=/full/path/to/certificate.pem`
****

For HAProxy, if a default certificate is provided, it will load it first. The certificate that
is loaded first will be presented to any route that matches the CN on the certificate and
any route that is secure but does not match any configured certificates. For example, if
the default certificate is for `\*.example.com` and a secure route for `www.foo.com` is created
with no certificates the route will still be written and the router will serve the `*.example.com`
certficiate. This may result in a browser warning for users since the CN on the certificate
does not match the url.

If no default certificate is supplied, the HAProxy router will default to a generic, expired
certificate that is provided in the base image.

[[special-notes]]
*Special Notes About Secure Routes*

Currently, password protected key files are not supported. HAProxy prompts you
for a password upon starting and does not have a way to automate this process.
To remove a passphrase from a keyfile, you can run:

****
`# openssl rsa -in _<passwordProtectedKey.key>_ -out _<new.key>_`
****

When creating a secure route, you must include your certificate files as a
single line of text. Replace the existing line breaks with:

****
`\n`
****

== Routers
A template router provides certain infrastructure information to the underlying
router implementation, such as:

- A wrapper that watches endpoints and routes.
- Endpoint and route data, which is saved into a consumable form.
- Passing the internal state to a configurable template and executing the
template.
- Calling a reload script.

Router plug-ins assume they can bind to host ports 80 and 443. This is to allow
external traffic to route to the host and subsequently through the router.
Routers also assume that networking is configured such that it can access all
pods in the cluster.

At the time of writing, a template router is the single type of router plug-in
available in OpenShift.

[[haproxy-template-router]]
*HAProxy Template Router*

The HAProxy template router implementation is the reference implementation for a
template router plug-in. This uses the `openshift/origin-haproxy-router`
repository to run an HAProxy instance alongside the template router plug-in. To
test routes, an install command is provided.


Check the default router ("router"):

****
$ `osadm router --dry-run`
****

See what the router would look like if created:

****
$ `osadm router -o json`
****

Create a router if it does not exist:

****
$ `osadm router router-west --replicas=2 --credentials="$OPENSHIFTCONFIG"`
****

Use a different router image and see the router configuration:

****
$ `osadm router region-west -o yaml --images=myrepo/somerouter:mytag`
****

NOTE: This command is currently being actively developed. It is intended to simplify the tasks of setting up routers in a new installation.

The following diagram illustrates how data flows from the master through the
plug-in and finally into an HAProxy configuration:

.HAProxy Router Data Flow
image:router_model.png[HAProxy Router Data Flow]
====

*Sticky Sessions*

Implementing sticky sessions is up to the underlying router configuration.  The default HAProxy
template implements sticky sessions using the `balance source` directive which balances based
on the source IP.  In addition, the template router plugin will provide the service name and
namespace to the underlying implementation.  This can be used for more advanced configuration
such as implementing stick-tables that synchronize between a set of peers. For details on the
implementation you may inspect the `haproxy-config.template` located in the `/var/lib/haproxy/conf`
directory of your router container.

////
== Highly-available Routers
You can configure a highly-available router setup by running multiple instances
of the router pod and fronting them with a balancing tier. This can be something
as simple as DNS round robin or as complex as multiple load-balancing layers.


=== DNS Round Robin [[dns-round-robin]]

As a simple example, you can create a zone file for a DNS server, such as BIND,
that maps multiple A records for a single domain name. When clients do a lookup,
they are given one of the many records, in order, as a round robin scheme.

[NOTE]
The procedure below uses wildcard DNS with multiple A records to achieve the
desired round robin. The wildcard could be further distributed into shards with:

====
****
`*._<shard>_`
****
====

.To Configure Simple DNS Round Robin:
. Add a new zone that points to your file:
+
====

----
#### named.conf
    zone "v3.rhcloud.com" IN {
            type master;
            file "v3.rhcloud.com.zone";
    };

----
====

. Define the round robin mappings for the DNS lookup:
+
====

----
#### v3.rhcloud.com.zone
    $ORIGIN v3.rhcloud.com.

    @       IN      SOA     . v3.rhcloud.com. (
                         2009092001         ; Serial
                             604800         ; Refresh
                              86400         ; Retry
                            1206900         ; Expire
                                300 )       ; Negative Cache TTL
            IN      NS      ns1.v3.rhcloud.com.
    ns1     IN      A       127.0.0.1
    *       IN      A       10.245.2.2
            IN      A       10.245.2.3


----
====

. Test the entry. The following example test uses `dig` (available in the
*bind-utils* package) in a *Vagrant* environment to show multiple answers for
the same lookup. Performing multiple pings shows the resolution swapping between
IP addresses:
+
[options="nowrap"]
====

----

$ dig hello-openshift.shard1.v3.rhcloud.com

; <<>> DiG 9.9.4-P2-RedHat-9.9.4-16.P2.fc20 <<>> hello-openshift.shard1.v3.rhcloud.com
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 36389
;; flags: qr aa rd; QUERY: 1, ANSWER: 2, AUTHORITY: 1, ADDITIONAL: 2
;; WARNING: recursion requested but not available

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;hello-openshift.shard1.v3.rhcloud.com. IN A

;; ANSWER SECTION:
hello-openshift.shard1.v3.rhcloud.com. 300 IN A	10.245.2.2
hello-openshift.shard1.v3.rhcloud.com. 300 IN A	10.245.2.3

;; AUTHORITY SECTION:
v3.rhcloud.com.		300	IN	NS	ns1.v3.rhcloud.com.

;; ADDITIONAL SECTION:
ns1.v3.rhcloud.com.	300	IN	A	127.0.0.1

;; Query time: 5 msec
;; SERVER: 10.245.2.3#53(10.245.2.3)
;; WHEN: Wed Nov 19 19:01:32 UTC 2014
;; MSG SIZE  rcvd: 132

$ ping hello-openshift.shard1.v3.rhcloud.com
PING hello-openshift.shard1.v3.rhcloud.com (10.245.2.3) 56(84) bytes of data.
...
^C
--- hello-openshift.shard1.v3.rhcloud.com ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1000ms
rtt min/avg/max/mdev = 0.272/0.573/0.874/0.301 ms

$ ping hello-openshift.shard1.v3.rhcloud.com
[...]
----
====

====

The following steps describe how to setup a highly available router environment with IP failover in a 3-step operation:

=== Step 1: Label the infrastructures nodes for the service (router)
Strictly speaking, this step can be optional as you can run the router instances on any of the nodes in your Kubernetes cluster and use Virtual IP addresses (VIPs) that can "float" within those nodes.

However that said, it is recommended you provision certain infrastructure nodes to run the routers and have VIPs that can "float" amongst these nodes. In a complex and possibly bigger cluster, you probably may be already doing something similar so that nodes may be filtered on constraints or requirements specified (e.g. nodes with SSD drives or higher cpu/memory/disk requirements, etc).

In our example, let us define this label or constraint as router instances servicing traffic in the US west geography "ha-router=geo-us-west".

****
`$ openshift kube label nodes openshift-minion-{5,6,7,8,9} "ha-router=geo-us-west"`
****

=== Step 2: Run the IP service (router) with 2 or more replicas
As described earlier in this document, start the router with atleast 2 replicas on nodes matching the constraints or label we used in step 1. In our example, we are going to run 3 instances.
It is worth noting here that we are running a lesser number of replicas for the router than available nodes. This is so that in the case of node failures, Kubernetes will still be able ensure that we have 3 instances available - until of course the number of available "ha-router=geo-us-west" nodes is below 3.
Additionally, it is worth mentioning here that the router uses the host network (and ports 80 and 443) and hence we are running a lesser number of replicas to ensure a higher service level availability (SLA). If there are no constraints on the service being setup for failover, we could just as well target the service to run on one or more or even all of the labelled nodes.

****
`$ osadm router ha-router-us-west --replicas=3 --labels="ha-router=geo-us-west" --credentials="$OPENSHIFTCONFIG" --create`
****

=== Step 3: Configure IP failover for the service (router)
The final step is to configure the virtual IPs and failover for the nodes labelled in step 1 (with "ha-router=geo-us-west"). Ensure the number of replicas matches the number of nodes that satisfy the constraint or label we used in step 1. Specify the virtual IP address and the port that the IP failover should monitor (port 80 for the router) on those instances.

****
`$ osadm ipfailover ha-router-us-west --replicas=5 --selector="ha-router=geo-us-west" --virtual-ips="10.245.2.101-105" --watch-port=80 --credentials="$OPENSHIFTCONFIG" --create`
****
////

== High Availability
You can link:../../admin_guide/high_availability.html[set up a highly-available router or network service] on your OpenShift cluster using IP failover.
