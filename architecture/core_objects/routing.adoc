= Routing
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:

toc::[]

== Overview
Routers provide external DNS mapping and load balancing to
link:kubernetes_model.html#service[services] over protocols that pass
distinguishing information directly to the router. Routers support the following
protocols:

- HTTP
- HTTPS
- WebSockets
- TLS with SNI

[NOTE]
WebSocket traffic uses the same route conventions and supports the same
TLS termination types as other traffic.

The router uses the service selector to watch the endpoints that support the
service, bypassing its logic and replacing it with the router's own. Routers
subscribe to a configuration and automatically update themselves when the
configuration changes. A router may be containerized or virtual, converting any
changes to API calls to another system, such as *F5*.

Other capabilities exist to load-balance a service within a cluster. These
services are exposed via a configurable link relation between different
services, and ensure a set of services can be available.
link:../../dev_guide/deployments.html[Deployments] can use these services as
local proxies for each host, or reuse the shared routing infrastructure.

An OpenShift administrator can configure routers in an OpenShift instance.
Developers can then set the route types for their projects.

== Route Types
Routes can be either secure or unsecured. Secure routes provide the ability to
use different types of TLS termination to serve certificates to the client.
Routers support link:#edge-termination[edge],
link:#passthrough-termination[passthrough], and
link:#re-encryption-termination[re-encryption] termination.

To create a secure route, specify the TLS termination of the route in a JSON
file.

.An Unsecured Route
====

----
{
  "kind": "Route",
  "apiVersion": "v1",
  "metadata": {
    "name": "hello-route"
  },
  "spec": {
    "host": "hello-openshift.v3.rhcloud.com",
    "to": {
      "kind": "Service",
      "name": "hello-openshift"
    }
  }
}
----
====

.A Secure Route Using Edge Termination
====

----
{
  "kind": "Route",
  "apiVersion": "v1",
  "metadata": {
    "name": "hello-route"
  },
  "spec": {
    "host": "hello-openshift.v3.rhcloud.com",
    "to": {
      "kind": "Service",
      "name": "hello-openshift"
    },
    "tls": {
        "termination": "edge",
        "certificate": "CERT TEXT OMITTED FOR READABILITY",
        "key": "CERT TEXT OMITTED FOR READABILITY",
        "caCertificate": "CERT TEXT OMITTED FOR READABILITY"
     }
  }
}
----
====

.An Unsecured Route with a Path:
====

----
{
  "kind": "Route",
  "apiVersion": "v1",
  "metadata": {
    "name": "hello-route"
  },
  "spec": {
    "host": "hello-openshift.v3.rhcloud.com",
    "path": "/test",
    "to": {
      "kind": "Service",
      "name": "hello-openshift"
    }
  }
}
----

====

Unsecured routes are can be faster to set up, as they are the default
configuration, but secure routes offer greater security for information to
remain private.

== Path-Based Routes
Path-based routes specify a path component that can be compared against a URL,
implying that the traffic for the route is HTTP based. Routers should match
routes based on the most specific path to the least. However, this depends on
your implementation. The following table shows example routes and their
accessibility:

////
*  For a route with \_www.example.com/test_:
** \_www.example.com/test_ should be accessible
** \_www.example.com_ should not be accessible
*  For routes with \_www.example.com/test_ and \_www.example.com_:
** \_www.example.com/test_ should be accessible
** \_www.example.com_ should be accessible
*  For routes with \_www.example.com_:
** \_www.example.com/test_ should be accessible (matched by the host, not the route)
** \_www.example.com_ should be accessible
////

.Route Availability
[cols="3*", options="header"]
|===
|Route |When Compared to |Accessible

.2+|_www.example.com/test_ |_www.example.com/test_ |Yes

|_www.example.com_ |No

.2+|_www.example.com/test_ and _www.example.com_ |_www.example.com/test_ |Yes

|_www.example.com_ |Yes

.2+|_www.example.com_ |_www.example.com/test_ |Yes (Matched by the host, not the route)

|_www.example.com_ |Yes
|===

== Securing Routes
Create a secure route to your pods by specifying the TLS termination of the
route and, optionally, providing certificates.

[NOTE]
Currently, TLS termination in OpenShift Beta relies on SNI for serving
custom certificates. Any non-SNI traffic received on port 443 has TLS
termination with a generic certificate. In the future, the ability to create
custom front ends within the router will allow all traffic to serve custom
certificates.

By default, OpenShift routes are unsecured, but can be set to any of the
following three types of secure TLS termination.

[[edge-termination]]
*Edge Termination*

With edge termination, TLS termination occurs prior to traffic reaching its
destination. TLS certificates are served by the front-end of the router.

You can configure edge termination on your route by specifying the following:

.Configuring Edge Termination
====

----
{
  "kind": "Route",
  "apiVersion": "v1",
  "metadata": {
    "name": "hello-route"
  },
  "spec": {
    "host": "hello-openshift.v3.rhcloud.com",
    "to": {
      "kind": "Service",
      "name": "hello-openshift"
    },
    "tls": {
        "termination": "edge", <1>
        "certificate": "CERT TEXT OMITTED FOR READABILITY", <2>
        "key": "CERT TEXT OMITTED FOR READABILITY", <3>
        "caCertificate": "CERT TEXT OMITTED FOR READABILITY" <4>
     }
  }
}
----

<1> Set the `*termination*` field to `edge`.
<2> Set the `*certificate*` field to the contents of the certificate file. See
the link:#special-notes[special notes] below.
<3> Set the `*key*` field to the contents of the key file. See the
link:#special-notes[special notes] below.
<4> Set the `*caCertificate*` field to the contents of the CA certificate file.
See the link:#special-notes[special notes] below.
====

[[passthrough-termination]]
*Passthrough Termination*

With passthrough termination, encrypted traffic is sent straight to the
destination without the router providing TLS termination.

You can configure passthrough termination on your route by specifying the
following:

.Configuring Passthrough Termination
====

----
{
  "kind": "Route",
  "apiVersion": "v1",
  "metadata": {
    "name": "hello-route"
  },
  "spec": {
    "host": "hello-openshift.v3.rhcloud.com",
    "to": {
      "kind": "Service",
      "name": "hello-openshift"
    },
    "tls": { "termination" : "passthrough" } <1>
  }
}
----

<1> Set the `*termination*` field to `passthrough`.
====

The destination, such as an *Nginx*, *Apache*, or another *HAProxy* instance, is
then responsible for serving certificates for the traffic.

[[re-encryption-termination]]
*Re-encryption Termination*

Re-encryption is a type of edge termination where the client encrypts
communication with a certificate, which is then re-encrypted with a different
certificate when the traffic reaches the destination. The router uses health
checks to determine the authenticity of the host.

You can configure re-encryption termination on your route by specifying the
following:

.Configuring Re-encryption Termination
====

----
{
  "kind": "Route",
  "apiVersion": "v1",
  "metadata": {
    "name": "hello-route"
  },
  "spec": {
    "host": "hello-openshift.v3.rhcloud.com",
    "to": {
      "kind": "Service",
      "name": "hello-openshift"
    },
    "tls": {
        "termination": "reencrypt", <1>
        "certificate": "CERT TEXT OMITTED FOR READABILITY", <2>
        "key": "CERT TEXT OMITTED FOR READABILITY", <3>
        "caCertificate": "CERT TEXT OMITTED FOR READABILITY", <4>
        "destinationCaCertificate": "CERT TEXT OMITTED FOR READABILITY" <5>
     }
  }
}
----

<1> Set the `*termination*` field to `reencrypt`.
<2> Set the `*certificate*` field to the contents of the certificate file. See
the link:#special-notes[special notes] below.
<3> Set the `*key*` field to the contents of the key file. See the
link:#special-notes[special notes] below.
<4> Set the `*caCertificate*` field to the contents of the CA certificate file.
See the link:#special-notes[special notes] below.
<5> Use the `*destinationCaCertificate*` field to validate the secure connection
from the router to the destination, specific to each implementation. See the
link:#special-notes[special notes] below.
====

[[wildcard-certificates]]
*Wildcard Certificates*

Depending on your implementation, you can use a default certificate. Default
certificates are useful for implementing a wildcard certificate for the router.
For example, if you have many routes that end in `example.com` you may wish to
install a router with a wildcard certificate for `*.example.com`.

To provide the default certificate to the router you must specify it in the
create command with the `--default-cert` option. The certificate should be a
concatenated file of the key, certificate, and any CA certificates that are
required by the browser. The certificate must be in a form acceptable by the
underlying router implementation. In the case of HAProxy it should be a
PEM-based certificate.

----
$ oadm router --credentials="$KUBECONFIG" --default-cert=/full/path/to/certificate.pem
----

For HAProxy, if a default certificate is provided, it will be loaded first. The
certificate that is loaded first is presented to any route that matches the CN
on the certificate and any route that is secure but does not match any
configured certificates. For example, if the default certificate is for
`\*.example.com` and a secure route for `www.foo.com` is created with no
certificates the route will still be written and the router will serve the
`*.example.com` certificate. This may result in a browser warning for users
since the CN on the certificate does not match the url. If no default
certificate is supplied, the HAProxy router will default to a generic, expired
certificate that is provided in the base image.

[[special-notes]]
*Special Notes About Secure Routes*

Currently, password protected key files are not supported. HAProxy prompts you
for a password upon starting and does not have a way to automate this process.
To remove a passphrase from a keyfile, run:

----
# openssl rsa -in <passwordProtectedKey.key> -out <new.key>
----

When creating a secure route, include your certificate files as a single line of
text. Replace the existing line breaks with:

----
\n
----

== Routers
A template router provides certain infrastructure information to the underlying
router implementation, such as:

- A wrapper that watches endpoints and routes.
- Endpoint and route data, which is saved into a consumable form.
- Passing the internal state to a configurable template and executing the
template.
- Calling a reload script.

Router plug-ins assume they can bind to host ports 80 and 443 to allow external
traffic to route to the host and subsequently through the router. Routers also
assume that networking is configured such that it can access all pods in the
cluster.

At the time of writing, a template router is the single type of router plug-in
available in OpenShift.

[[haproxy-template-router]]
*HAProxy Template Router*

The HAProxy template router implementation is the reference implementation for a
template router plug-in. This uses the `openshift/origin-haproxy-router`
repository to run an HAProxy instance alongside the template router plug-in. To
test routes, an install command is provided.


To check the default router (named *router*):

----
$ oadm router --dry-run
----

To view what the router would look like if created:

----
$ oadm router -o json
----

To create a router if it does not exist:

----
$ oadm router router-west --replicas=2 --credentials="$KUBECONFIG"
----

To use a different router image and view the router configuration:

----
$ oadm router region-west -o yaml --images=myrepo/somerouter:mytag
----

The following diagram illustrates how data flows from the master through the
plug-in and finally into an HAProxy configuration:

.HAProxy Router Data Flow
image:router_model.png[HAProxy Router Data Flow]

*Sticky Sessions*

Sticky sessions are implemented by the underlying router configuration. The
default
link:https://github.com/openshift/origin/blob/3dc5a6e7416a9a6f2270cc236b26be7abb491ab0/images/router/haproxy/conf/haproxy-config.template[HAProxy
template] in the `/var/lib/haproxy/conf` directory of the router container
configures sticky sessions using the `balance source` directive, which balances
based on the source IP. In addition, the template router plug-in provides the
service name and namespace to the underlying implementation. This can be used
for more advanced configurations, such as implementing stick-tables to
synchronize peers.

////
== Highly-available Routers
You can configure a highly-available router setup by running multiple instances
of the router pod and fronting them with a balancing tier. This can be something
as simple as DNS round robin or as complex as multiple load-balancing layers.


=== DNS Round Robin [[dns-round-robin]]

As a simple example, you can create a zone file for a DNS server, such as BIND,
that maps multiple A records for a single domain name. When clients do a lookup,
they are given one of the many records, in order, as a round robin scheme.

[NOTE]
====
The procedure below uses wildcard DNS with multiple A records to achieve the
desired round robin. The wildcard could be further distributed into shards with:

****
`*._<shard>_`
****
====

.To Configure Simple DNS Round Robin:
. Add a new zone that points to your file:
+
====

----
#### named.conf
    zone "v3.rhcloud.com" IN {
            type master;
            file "v3.rhcloud.com.zone";
    };

----
====

. Define the round robin mappings for the DNS lookup:
+
====

----
#### v3.rhcloud.com.zone
    $ORIGIN v3.rhcloud.com.

    @       IN      SOA     . v3.rhcloud.com. (
                         2009092001         ; Serial
                             604800         ; Refresh
                              86400         ; Retry
                            1206900         ; Expire
                                300 )       ; Negative Cache TTL
            IN      NS      ns1.v3.rhcloud.com.
    ns1     IN      A       127.0.0.1
    *       IN      A       10.245.2.2
            IN      A       10.245.2.3


----
====

. Test the entry. The following example test uses `dig` (available in the
*bind-utils* package) in a *Vagrant* environment to show multiple answers for
the same lookup. Performing multiple pings shows the resolution swapping between
IP addresses:
+
[options="nowrap"]
====

----

$ dig hello-openshift.shard1.v3.rhcloud.com

; <<>> DiG 9.9.4-P2-RedHat-9.9.4-16.P2.fc20 <<>> hello-openshift.shard1.v3.rhcloud.com
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 36389
;; flags: qr aa rd; QUERY: 1, ANSWER: 2, AUTHORITY: 1, ADDITIONAL: 2
;; WARNING: recursion requested but not available

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;hello-openshift.shard1.v3.rhcloud.com. IN A

;; ANSWER SECTION:
hello-openshift.shard1.v3.rhcloud.com. 300 IN A	10.245.2.2
hello-openshift.shard1.v3.rhcloud.com. 300 IN A	10.245.2.3

;; AUTHORITY SECTION:
v3.rhcloud.com.		300	IN	NS	ns1.v3.rhcloud.com.

;; ADDITIONAL SECTION:
ns1.v3.rhcloud.com.	300	IN	A	127.0.0.1

;; Query time: 5 msec
;; SERVER: 10.245.2.3#53(10.245.2.3)
;; WHEN: Wed Nov 19 19:01:32 UTC 2014
;; MSG SIZE  rcvd: 132

$ ping hello-openshift.shard1.v3.rhcloud.com
PING hello-openshift.shard1.v3.rhcloud.com (10.245.2.3) 56(84) bytes of data.
...
^C
--- hello-openshift.shard1.v3.rhcloud.com ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1000ms
rtt min/avg/max/mdev = 0.272/0.573/0.874/0.301 ms

$ ping hello-openshift.shard1.v3.rhcloud.com
[...]
----

====

The following steps describe how to setup a highly available router environment with IP failover in a 3-step operation:

=== Step 1: Label the infrastructures nodes for the service (router)
Strictly speaking, this step can be optional as you can run the router instances on any of the nodes in your Kubernetes cluster and use Virtual IP addresses (VIPs) that can "float" within those nodes.

However that said, it is recommended you provision certain infrastructure nodes to run the routers and have VIPs that can "float" amongst these nodes. In a complex and possibly bigger cluster, you probably may be already doing something similar so that nodes may be filtered on constraints or requirements specified (e.g. nodes with SSD drives or higher cpu/memory/disk requirements, etc).

In our example, let us define this label or constraint as router instances servicing traffic in the US west geography "ha-router=geo-us-west".

****
`$ openshift kube label nodes openshift-minion-{5,6,7,8,9} "ha-router=geo-us-west"`
****

=== Step 2: Run the IP service (router) with 2 or more replicas
As described earlier in this document, start the router with atleast 2 replicas on nodes matching the constraints or label we used in step 1. In our example, we are going to run 3 instances.
It is worth noting here that we are running a lesser number of replicas for the router than available nodes. This is so that in the case of node failures, Kubernetes will still be able ensure that we have 3 instances available - until of course the number of available "ha-router=geo-us-west" nodes is below 3.
Additionally, it is worth mentioning here that the router uses the host network (and ports 80 and 443) and hence we are running a lesser number of replicas to ensure a higher service level availability (SLA). If there are no constraints on the service being setup for failover, we could just as well target the service to run on one or more or even all of the labeled nodes.

****
`$ oadm router ha-router-us-west --replicas=3 --labels="ha-router=geo-us-west" --credentials="$KUBECONFIG" --create`
****

=== Step 3: Configure IP failover for the service (router)
The final step is to configure the virtual IPs and failover for the nodes labeled in step 1 (with "ha-router=geo-us-west"). Ensure the number of replicas matches the number of nodes that satisfy the constraint or label we used in step 1. Specify the virtual IP address and the port that the IP failover should monitor (port 80 for the router) on those instances.

****
`$ oadm ipfailover ha-router-us-west --replicas=5 --selector="ha-router=geo-us-west" --virtual-ips="10.245.2.101-105" --watch-port=80 --credentials="$KUBECONFIG" --create`
****
////

== High Availability
You can link:../../admin_guide/high_availability.html[set up a highly-available router or network service] on your OpenShift cluster using IP failover.
