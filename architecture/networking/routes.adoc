[[architecture-core-concepts-routes]]
= Routes
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

== Overview

An {product-title} route exposes a
xref:../../architecture/core_concepts/pods_and_services.adoc#services[service] at a
host name, like _www.example.com_, so that external clients can reach it by
name.

DNS resolution for a host name is handled separately from routing.
Your administrator may have configured a
ifdef::openshift-online,openshift-dedicated[]
DNS wildcard entry
endif::[]
ifdef::openshift-origin,openshift-enterprise[]
xref:../../install_config/install/prerequisites.adoc#prereq-dns[DNS wildcard entry]
endif::[]
that will resolve to the {product-title} node that is running the
{product-title} router. If you are using a different host name you may
need to modify its DNS records independently to resolve to the node that
is running the router.

Each route consists of a name (limited to 63 characters), a service selector,
and an optional security configuration.

ifdef::openshift-online,openshift-dedicated[]
[NOTE]
====
Wildcard routes are disabled in {product-title}.
====
endif::[]

[[routers]]
include::architecture/topics/routers.adoc[]

[[routes-template-routers]]

include::architecture/topics/template_routers.adoc[]

[[available-router-plug-ins]]

== Available Router Plug-ins

The following router plug-ins are provided and supported in {product-title}.
ifdef::openshift-enterprise,openshift-origin[]
Instructions on deploying these routers are available in
xref:../../install_config/router/index.adoc#install-config-router-overview[Deploying a Router].
endif::[]

[[haproxy-template-router]]

=== HAProxy Template Router

The HAProxy template router implementation is the reference implementation for a
template router plug-in. It uses the
ifdef::openshift-enterprise,openshift-dedicated[]
*openshift3/ose-haproxy-router*
endif::[]
ifdef::openshift-origin[]
*openshift/origin-haproxy-router*
endif::[]
repository to run an HAProxy instance alongside the template router plug-in.

The following diagram illustrates how data flows from the master through the
plug-in and finally into an HAProxy configuration:

.HAProxy Router Data Flow
image::router_model.png[HAProxy Router Data Flow]

[[routes-sticky-sessions]]
=== Sticky Sessions

include::architecture/topics/sticky_sessions.adoc[]

[[env-variables]]
include::architecture/topics/router_environment_variables.adoc[]

[[time-units]]
== Timeouts
`TimeUnits` are represented by a number followed by the unit: `us`
*(microseconds), `ms` (milliseconds, default), `s` (seconds), `m` (minutes), `h`
*(hours), `d` (days).

The regular expression is: [1-9][0-9]*(us\|ms\|s\|m\|h\|d)

[[load-balancing]]
== Load-balancing Strategy

When a route has multiple endpoints, HAProxy distributes requests to the route
among the endpoints based on the selected load-balancing strategy. This applies
when no persistence information is available, such
as on the first request in a session.

The strategy can be one of the following:

- `*roundrobin*`: Each endpoint is used in turn, according to its weight.
This is the smoothest and fairest algorithm when the server's
processing time remains equally distributed.
- `*leastconn*`: The endpoint with the lowest number of connections receives the
request. Round-robin is performed when multiple endpoints have the same lowest
number of connections. Use this algorithm when very long sessions are
expected, such as LDAP, SQL, TSE, or others. Not intended to be used
with protocols that typically use short sessions such as HTTP.
- `*source*`: The source IP address is hashed and divided by the total
weight of the running servers to designate which server will
receive the request. This ensures that the same client IP
address will always reach the same server as long as no
server goes down or up. If the hash result changes due to the
number of running servers changing, many clients will be
directed to different servers. This algorithm is generally
used with passthrough routes.

The `ROUTER_TCP_BALANCE_SCHEME` xref:env-variables[environment variable] sets the default
strategy for passthorugh routes. The `ROUTER_LOAD_BALANCE_ALGORITHM` xref:env-variables[environment
variable] sets the default strategy for the router for the remaining routes.
A xref:route-specific-annotations[route specific annotation],
`*haproxy.router.openshift.io/balance*`, can be used to control specific routes.

[[strict-sni]]
== HAProxy Strict SNI

By default, when a host does not resolve to a route in a HTTPS or TLS SNI
request, the default certificate is returned to the caller as part of the *503*
response. This exposes the default certificate and can pose security concerns
because the wrong certificate is served for a site. The HAProxy `strict-sni`
option to bind suppresses use of the default certificate.

The `ROUTER_STRICT_SNI` environment variable controls bind processing. When set
to `true` or `TRUE`, `strict-sni` is added to the HAProxy bind. The default
setting is `false`.

The option can be set when the router is created or added later.

----
$ oc adm router --strict-sni
----

This sets `ROUTER_STRICT_SNI=true`.

[[ciphers]]
== Router Cipher Suite

Each client (for example, Chrome 30, or Java8) includes a suite of ciphers used
to securely connect with the router. The router must have at least one of the
ciphers for the connection to be complete:

.Router Cipher Profiles
[cols="2,6", options="header"]
|===
|Profile | Oldest compatible client
|modern| Firefox 27, Chrome 30, IE 11 on Windows 7, Edge, Opera 17, Safari 9, Android 5.0, Java 8
|intermediate|Firefox 1, Chrome 1, IE 7, Opera 5, Safari 1, Windows XP IE8, Android 2.3, Java 7
|old|Windows XP IE6, Java 6
|===

See the link:https://wiki.mozilla.org/Security/Server_Side_TLS[Security/Server
Side TLS] reference guide for more information.

The router defaults to the `intermediate` profile. You can select a different
profile using the `--ciphers` option when creating a route, or by changing
the `ROUTER_CIPHERS` environment variable with the values `modern`,
`intermediate`, or `old` for an existing router. Alternatively, a set of ":"
separated ciphers can be provided. The ciphers must be from the set displayed
by:

----
openssl ciphers
----

[[route-hostnames]]

== Route Host Names
In order for services to be exposed externally, an {product-title} route allows
you to associate a service with an externally-reachable host name. This edge
host name is then used to route traffic to the service.

When multiple routes from different namespaces claim the same host,
the oldest route wins and claims it for the namespace. If additional
routes with different path fields are defined in the same namespace,
those paths are added. If multiple routes with the same path are
used, the oldest takes priority.

A consequence of this behavior is that if you have two routes for a host name: an
older one and a newer one. If someone else has a route for the same host name
that they created between when you created the other two routes, then if you
delete your older route, your claim to the host name will no longer be in effect.
The other namespace now claims the host name and your claim is lost.

.A Route with a Specified Host:
====

[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: host-route
spec:
  host: www.example.com  <1>
  to:
    kind: Service
    name: service-name
----
<1> Specifies the externally-reachable host name used to expose a service.
====

.A Route Without a Host:
====

[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: no-route-hostname
spec:
  to:
    kind: Service
    name: service-name
----
====

If a host name is not provided as part of the route definition, then
{product-title} automatically generates one for you. The generated host name
is of the form:

----
<route-name>[-<namespace>].<suffix>
----

The following example shows the {product-title}-generated host name for the
above configuration of a route without a host added to a namespace
*mynamespace*:

.Generated Host Name
====

----
no-route-hostname-mynamespace.router.default.svc.cluster.local <1>
----
<1> The generated host name suffix is the default routing subdomain
*router.default.svc.cluster.local*.
====

A cluster administrator can also
ifdef::openshift-enterprise,openshift-origin[]
xref:../../install_config/router/default_haproxy_router.adoc#customizing-the-default-routing-subdomain[customize
the suffix used as the default routing subdomain]
endif::[]
ifdef::openshift-dedicated[]
customize the suffix used as the default routing subdomain
endif::[]
for their environment.

[[route-types]]
== Route Types
Routes can be either secured or unsecured. Secure routes provide the ability to
use several types of TLS termination to serve certificates to the client.
Routers support xref:edge-termination[edge],
xref:passthrough-termination[passthrough], and
xref:re-encryption-termination[re-encryption] termination.

.Unsecured Route Object YAML Definition
====

[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: route-unsecured
spec:
  host: www.example.com
  to:
    kind: Service
    name: service-name
----

====

Unsecured routes are simplest to configure, as they require no key
or certificates, but secured routes offer security for connections to
remain private.

A secured route is one that specifies the TLS termination of the route.
The available types of termination are xref:secured-routes[described
below].

[[path-based-routes]]
== Path Based Routes
Path based routes specify a path component that can be compared against
a URL (which requires that the traffic for the route be HTTP based) such
that multiple routes can be served using the same host name, each with a
different path. Routers should match routes based on the most specific
path to the least; however, this depends on the router implementation. The
following table shows example routes and their accessibility:

.Route Availability
[cols="3*", options="header"]
|===
|Route |When Compared to |Accessible

.2+|_www.example.com/test_ |_www.example.com/test_ |Yes

|_www.example.com_ |No

.2+|_www.example.com/test_ and _www.example.com_ |_www.example.com/test_ |Yes

|_www.example.com_ |Yes

.2+|_www.example.com_ |_www.example.com/test_ |Yes (Matched by the host, not the route)

|_www.example.com_ |Yes
|===

.An Unsecured Route with a Path:
====

[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: route-unsecured
spec:
  host: www.example.com
  path: "/test"   <1>
  to:
    kind: Service
    name: service-name
----

<1> The path is the only added attribute for a path-based route.
====

[NOTE]
====
Path-based routing is not available when using passthrough TLS, as
the router does not terminate TLS in that case and cannot read the contents
of the request.
====

[[secured-routes]]
== Secured Routes
Secured routes specify the TLS termination of the route and, optionally,
provide a key and certificate(s).

[NOTE]
====
TLS termination in {product-title} relies on
link:https://en.wikipedia.org/wiki/Server_Name_Indication[SNI] for serving
custom certificates. Any non-SNI traffic received on port 443 is handled with
TLS termination and a default certificate (which may not match the requested
host name, resulting in validation errors).
====

Secured routes can use any of the following three types of secure TLS
termination.

[[edge-termination]]
*Edge Termination*

With edge termination, TLS termination occurs at the router, prior to proxying
traffic to its destination. TLS certificates are served by the front end of the
router, so they must be configured into the route, otherwise the
ifdef::openshift-enterprise,openshift-origin[]
xref:../../install_config/router/default_haproxy_router.adoc#using-wildcard-certificates[router's
default certificate]
endif::[]
ifdef::openshift-dedicated[]
router's default certificate
endif::[]
will be used for TLS termination.

.A Secured Route Using Edge Termination
====

[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: route-edge-secured <1>
spec:
  host: www.example.com
  to:
    kind: Service
    name: service-name <1>
  tls:
    termination: edge            <2>
    key: |-                      <3>
      -----BEGIN PRIVATE KEY-----
      [...]
      -----END PRIVATE KEY-----
    certificate: |-              <4>
      -----BEGIN CERTIFICATE-----
      [...]
      -----END CERTIFICATE-----
    caCertificate: |-            <5>
      -----BEGIN CERTIFICATE-----
      [...]
      -----END CERTIFICATE-----
----
<1> The name of the object, which is limited to 63 characters.
<2> The `*termination*` field is `edge` for edge termination.
<3> The `*key*` field is the contents of the PEM format key file.
<4> The `*certificate*` field is the contents of the PEM format certificate file.
<5> An optional CA certificate may be required to establish a certificate chain for validation.
====

Because TLS is terminated at the router, connections from the router to
the endpoints over the internal network are not encrypted.

Edge-terminated routes can specify an `insecureEdgeTerminationPolicy` that
enables traffic on insecure schemes (`HTTP`) to be disabled, allowed or
redirected.
The allowed values for `insecureEdgeTerminationPolicy` are:
  `None` or empty (for disabled), `Allow` or `Redirect`.
The default `insecureEdgeTerminationPolicy` is to disable traffic on the
insecure scheme. A common use case is to allow content to be served via a
secure scheme but serve the assets (example images, stylesheets and
javascript) via the insecure scheme.

.A Secured Route Using Edge Termination Allowing HTTP Traffic
====

[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: route-edge-secured-allow-insecure <1>
spec:
  host: www.example.com
  to:
    kind: Service
    name: service-name <1>
  tls:
    termination:                   edge   <2>
    insecureEdgeTerminationPolicy: Allow  <3>
    [ ... ]
----
<1> The name of the object, which is limited to 63 characters.
<2> The `*termination*` field is `edge` for edge termination.
<3> The insecure policy to allow requests sent on an insecure scheme `HTTP`.
====

.A Secured Route Using Edge Termination Redirecting HTTP Traffic to HTTPS
====

[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: route-edge-secured-redirect-insecure <1>
spec:
  host: www.example.com
  to:
    kind: Service
    name: service-name <1>
  tls:
    termination:                   edge      <2>
    insecureEdgeTerminationPolicy: Redirect  <3>
    [ ... ]
----
<1> The name of the object, which is limited to 63 characters.
<2> The `*termination*` field is `edge` for edge termination.
<3> The insecure policy to redirect requests sent on an insecure scheme `HTTP` to a secure scheme `HTTPS`.
====

[[passthrough-termination]]
*Passthrough Termination*

With passthrough termination, encrypted traffic is sent straight to the
destination without the router providing TLS termination. Therefore no
key or certificate is required.

.A Secured Route Using Passthrough Termination
====
[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: route-passthrough-secured <1>
spec:
  host: www.example.com
  to:
    kind: Service
    name: service-name <1>
  tls:
    termination: passthrough     <2>
----
<1> The name of the object, which is limited to 63 characters.
<2> The `*termination*` field is set to `passthrough`. No other encryption fields are needed.
====

The destination pod is responsible for serving certificates for the
traffic at the endpoint. This is currently the only method that can support
requiring client certificates (also known as two-way authentication).

[NOTE]
====
Passthrough routes can also have an `insecureEdgeTerminationPolicy`. The only
valid values are `None` (or empty, for disabled) or `Redirect`.
====

[[re-encryption-termination]]
*Re-encryption Termination*

Re-encryption is a variation on edge termination where the router terminates
TLS with a certificate, then re-encrypts its connection to the endpoint which
may have a different certificate. Therefore the full path of the connection
is encrypted, even over the internal network. The router uses health
checks to determine the authenticity of the host.


.A Secured Route Using Re-Encrypt Termination
====

[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: route-pt-secured <1>
spec:
  host: www.example.com
  to:
    kind: Service
    name: service-name <1>
  tls:
    termination: reencrypt        <2>
    key: [as in edge termination]
    certificate: [as in edge termination]
    caCertificate: [as in edge termination]
    destinationCACertificate: |-  <3>
      -----BEGIN CERTIFICATE-----
      [...]
      -----END CERTIFICATE-----
----

<1> The name of the object, which is limited to 63 characters.
<2> The `*termination*` field is set to `reencrypt`. Other fields are as in edge
termination.
<3> Required for re-encryption. `*destinationCACertificate*`
specifies a CA certificate to validate the endpoint certificate, securing the
connection from the router to the destination pods. If the service is using a service signing certificate, or the administrator has specified a default CA certificate for the router and the service has a certificate signed by that CA, this field can be omitted.
====

If the `*destinationCACertificate*` field is left empty, the router
automatically leverages the certificate authority that is generated for service
serving certificates, and is injected into every pod as
`/var/run/secrets/kubernetes.io/serviceaccount/service-ca.crt`. This allows new
routes that leverage end-to-end encryption without having to generate a
certificate for the route. This is useful for custom routers or the F5 router,
which might not allow the `destinationCACertificate` unless the administrator
has allowed it.

[NOTE]
====
Re-encrypt routes can have an `insecureEdgeTerminationPolicy` with all of the
same values as edge-terminated routes.
====

[[router-sharding]]
== Router Sharding
include::architecture/topics/router_sharding.adoc[]

[[alternateBackends]]
== Alternate Backends and Weights
include::architecture/topics/alternate_backends_weights.adoc[]

[[route-specific-annotations]]
== Route-specific Annotations

Using xref:env-variables[environment variables], a router can set the default
options for all the routes it exposes. An individual route can override some
of these defaults by providing specific configurations in its annotations.

*Route Annotations*

For all the items outlined in this section, you can set annotations on the
*route definition* for the route to alter its configuration

.Route Annotations
[cols="3*", options="header"]
|===
|Variable | Description | Environment Variable Used as Default
|`*haproxy.router.openshift.io/balance*`| Sets the xref:load-balancing[load-balancing algorithm]. Available options are `source`, `roundrobin`, and `leastconn`. | `ROUTER_TCP_BALANCE_SCHEME` for passthrough routes. Otherwise, use `ROUTER_LOAD_BALANCE_ALGORITHM`.
|`*haproxy.router.openshift.io/disable_cookies*`| Disables the use of cookies to track related connections. If set to `true` or `TRUE`, the balance algorithm is used to choose which back-end serves connections for each incoming HTTP request. |
|`*haproxy.router.openshift.io/cookie_name*`| Specifies an optional cookie to be used for
this route. The name must consist of any combination of upper and lower case letters, digits, "_",
and "-". The default is the hashed internal key name for the route. |
|`*haproxy.router.openshift.io/rate-limit-connections*`| Setting `true` or `TRUE` to enables rate limiting functionality. |
|`*haproxy.router.openshift.io/rate-limit-connections.concurrent-tcp*`| Limits the number of concurrent TCP connections shared by an IP address. |
|`*haproxy.router.openshift.io/rate-limit-connections.rate-http*`| Limits the rate at which an IP address can make HTTP requests. |
|`*haproxy.router.openshift.io/rate-limit-connections.rate-tcp*`| Limits the rate at which an IP address can make TCP connections. |
|`*haproxy.router.openshift.io/timeout*` | Sets a server-side timeout for the route. xref:time-units[(TimeUnits)] | `ROUTER_DEFAULT_SERVER_TIMEOUT`
|`*router.openshift.io/haproxy.health.check.interval*`| Sets the interval for the back-end health checks. xref:time-units[(TimeUnits)] | `ROUTER_BACKEND_CHECK_INTERVAL`
|`*haproxy.router.openshift.io/ip_whitelist*` | Sets a xref:whitelist[whitelist] for the route. |
|`*haproxy.router.openshift.io/hsts_header*` | Sets a Strict-Transport-Security header for the edge terminated or re-encrypt route. |

|===

.A Route Setting Custom Timeout
====
[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  annotations:
    haproxy.router.openshift.io/timeout: 5500ms <1>
[...]
----
<1> Specifies the new timeout with HAProxy supported units (us, ms, s, m, h, d).
If unit not provided, ms is the default.
====

[NOTE]
====
Setting a server-side timeout value for passthrough routes too low can cause
WebSocket connections to timeout frequently on that route.
====

[[whitelist]]
== Route-specific IP Whitelists

You can restrict access to a route to a select set of IP addresses by adding the
`haproxy.router.openshift.io/ip_whitelist` annotation on the route. The
whitelist is a space-separated list of IP addresses and/or CIDRs for the
approved source addresses. Requests from IP addresses that are not in the
whitelist are dropped.

Some examples:

When editing a route, add the following annotation to define the desired
source IP's. Alternatively, use `oc annotate route <name>`.

Allow only one specific IP address:

----
metadata:
  annotations:
    haproxy.router.openshift.io/ip_whitelist: 192.168.1.10
----

Allow several IP addresses:

----
metadata:
  annotations:
    haproxy.router.openshift.io/ip_whitelist: 192.168.1.10 192.168.1.11 192.168.1.12
----

Allow an IP CIDR network:

----
metadata:
  annotations:
    haproxy.router.openshift.io/ip_whitelist: 192.168.1.0/24
----

Allow mixed IP addresses and IP CIDR networks:

----
metadata:
  annotations:
    haproxy.router.openshift.io/ip_whitelist: 180.5.61.153 192.168.1.0/24 10.0.0.0/8
----

ifdef::openshift-enterprise,openshift-origin[]
[[wildcard-subdomain-route-policy]]
== Creating Routes Specifying a Wildcard Subdomain Policy

A wildcard policy allows a user to define a route that covers all hosts within a
domain (when the router is configured to allow it). A route can specify a
wildcard policy as part of its configuration using the `wildcardPolicy` field.
Any routers run with a policy allowing wildcard routes will expose the route
appropriately based on the wildcard policy.

xref:../../install_config/router/default_haproxy_router.adoc#using-wildcard-routes[Learn how to configure HAProxy routers to allow wildcard routes].


.A Route Specifying a Subdomain WildcardPolicy
====
[source,yaml]
----
apiVersion: v1
kind: Route
spec:
  host: wildcard.example.com  <1>
  wildcardPolicy: Subdomain   <2>
  to:
    kind: Service
    name: service-name
----
<1> Specifies the externally reachable host name used to expose a service.
<2> Specifies that the externally reachable host name should allow all hosts
    in the subdomain `example.com`. `*.example.com` is the subdomain for host
    name `wildcard.example.com` to reach the exposed service.
====
endif::[]

[[route-status-field]]
== Route Status

The `route status` field is only set by routers. If changes are made to a route
so that a router no longer serves a specific route, the status becomes stale.
The routers do not clear the `route status` field. To remove the stale entries
in the route status, use the
link:https://github.com/openshift/origin/blob/master/images/router/clear-route-status.sh[clear-route-status
script].


[[architecture-core-concepts-routes-deny-allow]]
== Denying or Allowing Certain Domains in Routes

A router can be configured to deny or allow a specific subset of domains from
the host names in a route using the `ROUTER_DENIED_DOMAINS` and
`ROUTER_ALLOWED_DOMAINS` environment variables.

[cols="2"]
|===

|`ROUTER_DENIED_DOMAINS` | Domains listed are not allowed in any indicated routes.
|`ROUTER_ALLOWED_DOMAINS` | Only the domains listed are allowed in any indicated routes.

|===

The domains in the list of denied domains take precedence over the list of
allowed domains. Meaning {product-title} first checks the deny list (if
applicable), and if the host name is not in the list of denied domains, it then
checks the list of allowed domains. However, the list of allowed domains is more
restrictive, and ensures that the router only admits routes with hosts that
belong to that list.

For example, to deny the `[{asterisk}.]open.header.test`, `[{asterisk}.]openshift.org` and
`[{asterisk}.]block.it` routes for the `myrouter` route:

----
$ oc adm router myrouter ...
$ oc set env dc/myrouter ROUTER_DENIED_DOMAINS="open.header.test, openshift.org, block.it"
----

This means that `myrouter` will admit the following based on the route's name:

----
$ oc expose service/<name> --hostname="foo.header.test"
$ oc expose service/<name> --hostname="www.allow.it"
$ oc expose service/<name> --hostname="www.openshift.test"
----

However, `myrouter` will deny the following:

----
$ oc expose service/<name> --hostname="open.header.test"
$ oc expose service/<name> --hostname="www.open.header.test"
$ oc expose service/<name> --hostname="block.it"
$ oc expose service/<name> --hostname="franco.baresi.block.it"
$ oc expose service/<name> --hostname="openshift.org"
$ oc expose service/<name> --hostname="api.openshift.org"
----

Alternatively, to block any routes where the host name is _not_ set to `[{asterisk}.]stickshift.org` or `[{asterisk}.]kates.net`:

----
$ oc adm router myrouter ...
$ oc set env dc/myrouter ROUTER_ALLOWED_DOMAINS="stickshift.org, kates.net"
----

This means that the `myrouter` router will admit:

----
$ oc expose service/<name> --hostname="stickshift.org"
$ oc expose service/<name> --hostname="www.stickshift.org"
$ oc expose service/<name> --hostname="kates.net"
$ oc expose service/<name> --hostname="api.kates.net"
$ oc expose service/<name> --hostname="erno.r.kube.kates.net"
----

However, `myrouter` will deny the following:

----
$ oc expose service/<name> --hostname="www.open.header.test"
$ oc expose service/<name> --hostname="drive.ottomatic.org"
$ oc expose service/<name> --hostname="www.wayless.com"
$ oc expose service/<name> --hostname="www.deny.it"
----

To implement both scenarios, run:

----
$ oc adm router adrouter ...
$ oc env dc/adrouter ROUTER_ALLOWED_DOMAINS="openshift.org, kates.net" \
    ROUTER_DENIED_DOMAINS="ops.openshift.org, metrics.kates.net"
----

This will allow any routes where the host name is set to `[{asterisk}.]openshift.org` or
`[{asterisk}.]kates.net`, and not allow any routes where the host name is set to
`[{asterisk}.]ops.openshift.org` or `[{asterisk}.]metrics.kates.net`.

Therefore, the following will be denied:

----
$ oc expose service/<name> --hostname="www.open.header.test"
$ oc expose service/<name> --hostname="ops.openshift.org"
$ oc expose service/<name> --hostname="log.ops.openshift.org"
$ oc expose service/<name> --hostname="www.block.it"
$ oc expose service/<name> --hostname="metrics.kates.net"
$ oc expose service/<name> --hostname="int.metrics.kates.net"
----

However, the following will be allowed:

----
$ oc expose service/<name> --hostname="openshift.org"
$ oc expose service/<name> --hostname="api.openshift.org"
$ oc expose service/<name> --hostname="m.api.openshift.org"
$ oc expose service/<name> --hostname="kates.net"
$ oc expose service/<name> --hostname="api.kates.net"
----


== Support for Kubernetes ingress objects in OpenShift

In an effort to support the Kubernetes method of managing external access to services
in a cluster an ingress to route controller has been created. This controller watches
ingress objects and attempts to create one or more routes to satisfy the conditions of
the ingress object. For example

----
kind: Ingress
apiVersion: extensions/v1beta1
metadata:
  name: test
spec:
  rules:
  - host: test.com
     http:
       paths:
       - path: /test
         backend:
           serviceName: test-1
           servicePort: 80
----

would generate

----
kind: Route
apiVersion: route.openshift.io/v1
metadata:
  name: test-a34th
  ownerReferences:
  - apiVersion: extensions/v1beta1
     kind: Ingress
     name: test
     controller: true
spec:
  host: test.com
  path: /test
  to:
    name: test-1
  port:
     targetPort: 80
----

The ingress to route controller is responsible for keeping the ingress object and the generated 
route objects in sync, including giving generated routes permissions on the secrets associated with
the ingress object. Hostname claims are made by the generated route objects. 

[NOTE]
====
In order for a route to be created an ingress object needs to have a host, service, and path. 
The resulting route objects created have an autogenerated name with the name of the ingress object 
as a prefix. 
====
