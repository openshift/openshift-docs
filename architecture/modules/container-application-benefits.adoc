// Module included in the following assemblies:
//
// * architecture/introduction-openshift-architecture.adoc

[id="benefits-containerized-applications_{context}"]
= The benefits of containerized applications

Containerized applications offer many advantages over traditional deployment methods. Where applications were once expected to be installed on operating systems that included all their dependencies, containers let an application carry their dependencies with them. As a result:

* Conflicting applications can run on the same systems. Because each container carries its own dependent software and manages its own interfaces (networking, filesystems and so on), there is no problem with applications competing for those assets.
* Linux inside. Containers are really like small Linux operating systems without a kernel. Their filesystem, networking, cgroups, process tables, and other namespaces are separate from the host Linux system, but is able to integrate with the hosts seamlessly when necessary. Being based on Linux allows containers to leverage all the advantages that come with the open source development model of rapid innovation.
* Host operating system configuration can become more generic. Another side effect of dependencies being inside each container is that the operating systems that run them don’t have to each be configured specially. When your data center needs more capacity, you can just spin up another host system.
* Scaling is much simpler. OpenShift offers a simple, standard way of scaling any containerized service. For example, if you build applications as a set of microservices, rather than large, monolithic applications, individual microservices can be scaled up and scaled down individually as needed. You don’t have to scale up an entire, huge application, if only one service is in particular demand. 
* Rolling upgrades. Deploying rolling upgrades between major releases lets you continuously improve your applications without downtime, when compatibility with the current release can be maintained.
* Canary deployment. If you have a new version of a container available, you can simply start it up along side of the containers that are currently running. If the container runs without incident, you can simply add more new containers and spin down the old ones. 

While container images and the containers that run from them have become the primary building blocks for modern application development, to run them at scale requires a reliable and flexible distribution system. Kubernetes has become the defacto standard for orchestrating containers.