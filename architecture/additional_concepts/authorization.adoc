[[architecture-additional-concepts-authorization]]
= Authorization
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

== Overview

Role-based Access Control (RBAC) objects determine whether a user is allowed to
perform a given xref:action[action] within a project.

ifdef::openshift-enterprise,openshift-origin[]
This allows platform
administrators to use the xref:cluster-and-local-rbac[cluster roles and
bindings] to control who has various access levels to the {product-title}
platform itself and all projects.
endif::openshift-enterprise,openshift-origin[]

It allows developers to use
ifdef::openshift-online[]
local roles and bindings
endif::openshift-online[]
ifdef::openshift-enterprise,openshift-origin,openshift-dedicated[]
xref:cluster-and-local-rbac[local roles and bindings]
endif::openshift-enterprise,openshift-origin,openshift-dedicated[]
to control who has access
to their xref:../core_concepts/projects_and_users.adoc#projects[projects]. Note
that authorization is a separate step from
xref:authentication.adoc#architecture-additional-concepts-authentication[authentication],
which is more about determining the identity of who is taking the action.

Authorization is managed using:

[cols="1,7"]
|===

|[[rules-def]]*Rules* |Sets of permitted xref:action[verbs] on a set of
xref:../core_concepts/index.adoc#architecture-core-concepts-index[objects]. For example, whether something can
`create` pods.

|[[roles-def]]*Roles* |Collections of rules.
xref:authentication.adoc#users-and-groups[Users and groups] can be associated
with, or _bound_ to, multiple
ifdef::openshift-online[]
roles at the same time.
endif::openshift-online[]
ifdef::openshift-enterprise,openshift-origin,openshift-dedicated[]
xref:roles[roles] at the same time.
endif::openshift-enterprise,openshift-origin,openshift-dedicated[]

|[[bindings]]*Bindings* |Associations between users and/or groups with a
ifdef::openshift-online[]
role.
endif::openshift-online[]
ifdef::openshift-enterprise,openshift-origin,openshift-dedicated[]
xref:roles[role].
endif::openshift-enterprise,openshift-origin,openshift-dedicated[]


|===

ifdef::openshift-enterprise,openshift-origin[]
Cluster administrators can visualize rules, roles, and bindings
xref:../../admin_guide/manage_rbac.adoc#viewing-roles-and-bindings[using
the CLI].

For example, consider the following excerpt that shows the rule sets
for the *admin* and *basic-user* xref:roles[default cluster roles]:

[options="nowrap"]
----
$ oc describe clusterrole.rbac admin basic-user
----

----
Name:		admin
Labels:		<none>
Annotations:	openshift.io/description=A user that has edit rights within the project and can change the project's membership.
		rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources							Non-Resource URLs	Resource Names	Verbs
  ---------							-----------------	--------------	-----
  appliedclusterresourcequotas					[]			[]		[get list watch]
  appliedclusterresourcequotas.quota.openshift.io		[]			[]		[get list watch]
  bindings							[]			[]		[get list watch]
  buildconfigs							[]			[]		[create delete deletecollection get list patch update watch]
  buildconfigs.build.openshift.io				[]			[]		[create delete deletecollection get list patch update watch]
  buildconfigs/instantiate					[]			[]		[create]
  buildconfigs.build.openshift.io/instantiate			[]			[]		[create]
  buildconfigs/instantiatebinary				[]			[]		[create]
  buildconfigs.build.openshift.io/instantiatebinary		[]			[]		[create]
  buildconfigs/webhooks						[]			[]		[create delete deletecollection get list patch update watch]
  buildconfigs.build.openshift.io/webhooks			[]			[]		[create delete deletecollection get list patch update watch]
  buildlogs							[]			[]		[create delete deletecollection get list patch update watch]
  buildlogs.build.openshift.io					[]			[]		[create delete deletecollection get list patch update watch]
  builds							[]			[]		[create delete deletecollection get list patch update watch]
  builds.build.openshift.io					[]			[]		[create delete deletecollection get list patch update watch]
  builds/clone							[]			[]		[create]
  builds.build.openshift.io/clone				[]			[]		[create]
  builds/details						[]			[]		[update]
  builds.build.openshift.io/details				[]			[]		[update]
  builds/log							[]			[]		[get list watch]
  builds.build.openshift.io/log					[]			[]		[get list watch]
  configmaps							[]			[]		[create delete deletecollection get list patch update watch]
  cronjobs.batch						[]			[]		[create delete deletecollection get list patch update watch]
  daemonsets.extensions						[]			[]		[get list watch]
  deploymentconfigrollbacks					[]			[]		[create]
  deploymentconfigrollbacks.apps.openshift.io			[]			[]		[create]
  deploymentconfigs						[]			[]		[create delete deletecollection get list patch update watch]
  deploymentconfigs.apps.openshift.io				[]			[]		[create delete deletecollection get list patch update watch]
  deploymentconfigs/instantiate					[]			[]		[create]
  deploymentconfigs.apps.openshift.io/instantiate		[]			[]		[create]
  deploymentconfigs/log						[]			[]		[get list watch]
  deploymentconfigs.apps.openshift.io/log			[]			[]		[get list watch]
  deploymentconfigs/rollback					[]			[]		[create]
  deploymentconfigs.apps.openshift.io/rollback			[]			[]		[create]
  deploymentconfigs/scale					[]			[]		[create delete deletecollection get list patch update watch]
  deploymentconfigs.apps.openshift.io/scale			[]			[]		[create delete deletecollection get list patch update watch]
  deploymentconfigs/status					[]			[]		[get list watch]
  deploymentconfigs.apps.openshift.io/status			[]			[]		[get list watch]
  deployments.apps						[]			[]		[create delete deletecollection get list patch update watch]
  deployments.extensions					[]			[]		[create delete deletecollection get list patch update watch]
  deployments.extensions/rollback				[]			[]		[create delete deletecollection get list patch update watch]
  deployments.apps/scale					[]			[]		[create delete deletecollection get list patch update watch]
  deployments.extensions/scale					[]			[]		[create delete deletecollection get list patch update watch]
  deployments.apps/status					[]			[]		[create delete deletecollection get list patch update watch]
  endpoints							[]			[]		[create delete deletecollection get list patch update watch]
  events							[]			[]		[get list watch]
  horizontalpodautoscalers.autoscaling				[]			[]		[create delete deletecollection get list patch update watch]
  horizontalpodautoscalers.extensions				[]			[]		[create delete deletecollection get list patch update watch]
  imagestreamimages						[]			[]		[create delete deletecollection get list patch update watch]
  imagestreamimages.image.openshift.io				[]			[]		[create delete deletecollection get list patch update watch]
  imagestreamimports						[]			[]		[create]
  imagestreamimports.image.openshift.io				[]			[]		[create]
  imagestreammappings						[]			[]		[create delete deletecollection get list patch update watch]
  imagestreammappings.image.openshift.io			[]			[]		[create delete deletecollection get list patch update watch]
  imagestreams							[]			[]		[create delete deletecollection get list patch update watch]
  imagestreams.image.openshift.io				[]			[]		[create delete deletecollection get list patch update watch]
  imagestreams/layers						[]			[]		[get update]
  imagestreams.image.openshift.io/layers			[]			[]		[get update]
  imagestreams/secrets						[]			[]		[create delete deletecollection get list patch update watch]
  imagestreams.image.openshift.io/secrets			[]			[]		[create delete deletecollection get list patch update watch]
  imagestreams/status						[]			[]		[get list watch]
  imagestreams.image.openshift.io/status			[]			[]		[get list watch]
  imagestreamtags						[]			[]		[create delete deletecollection get list patch update watch]
  imagestreamtags.image.openshift.io				[]			[]		[create delete deletecollection get list patch update watch]
  jenkins.build.openshift.io					[]			[]		[admin edit view]
  jobs.batch							[]			[]		[create delete deletecollection get list patch update watch]
  limitranges							[]			[]		[get list watch]
  localresourceaccessreviews					[]			[]		[create]
  localresourceaccessreviews.authorization.openshift.io		[]			[]		[create]
  localsubjectaccessreviews					[]			[]		[create]
  localsubjectaccessreviews.authorization.k8s.io		[]			[]		[create]
  localsubjectaccessreviews.authorization.openshift.io		[]			[]		[create]
  namespaces							[]			[]		[get list watch]
  namespaces/status						[]			[]		[get list watch]
  networkpolicies.extensions					[]			[]		[create delete deletecollection get list patch update watch]
  persistentvolumeclaims					[]			[]		[create delete deletecollection get list patch update watch]
  pods								[]			[]		[create delete deletecollection get list patch update watch]
  pods/attach							[]			[]		[create delete deletecollection get list patch update watch]
  pods/exec							[]			[]		[create delete deletecollection get list patch update watch]
  pods/log							[]			[]		[get list watch]
  pods/portforward						[]			[]		[create delete deletecollection get list patch update watch]
  pods/proxy							[]			[]		[create delete deletecollection get list patch update watch]
  pods/status							[]			[]		[get list watch]
  podsecuritypolicyreviews					[]			[]		[create]
  podsecuritypolicyreviews.security.openshift.io		[]			[]		[create]
  podsecuritypolicyselfsubjectreviews				[]			[]		[create]
  podsecuritypolicyselfsubjectreviews.security.openshift.io	[]			[]		[create]
  podsecuritypolicysubjectreviews				[]			[]		[create]
  podsecuritypolicysubjectreviews.security.openshift.io		[]			[]		[create]
  processedtemplates						[]			[]		[create delete deletecollection get list patch update watch]
  processedtemplates.template.openshift.io			[]			[]		[create delete deletecollection get list patch update watch]
  projects							[]			[]		[delete get patch update]
  projects.project.openshift.io					[]			[]		[delete get patch update]
  replicasets.extensions					[]			[]		[create delete deletecollection get list patch update watch]
  replicasets.extensions/scale					[]			[]		[create delete deletecollection get list patch update watch]
  replicationcontrollers					[]			[]		[create delete deletecollection get list patch update watch]
  replicationcontrollers/scale					[]			[]		[create delete deletecollection get list patch update watch]
  replicationcontrollers.extensions/scale			[]			[]		[create delete deletecollection get list patch update watch]
  replicationcontrollers/status					[]			[]		[get list watch]
  resourceaccessreviews						[]			[]		[create]
  resourceaccessreviews.authorization.openshift.io		[]			[]		[create]
  resourcequotas						[]			[]		[get list watch]
  resourcequotas/status						[]			[]		[get list watch]
  resourcequotausages						[]			[]		[get list watch]
  rolebindingrestrictions					[]			[]		[get list watch]
  rolebindingrestrictions.authorization.openshift.io		[]			[]		[get list watch]
  rolebindings							[]			[]		[create delete deletecollection get list patch update watch]
  rolebindings.authorization.openshift.io			[]			[]		[create delete deletecollection get list patch update watch]
  rolebindings.rbac.authorization.k8s.io			[]			[]		[create delete deletecollection get list patch update watch]
  roles								[]			[]		[create delete deletecollection get list patch update watch]
  roles.authorization.openshift.io				[]			[]		[create delete deletecollection get list patch update watch]
  roles.rbac.authorization.k8s.io				[]			[]		[create delete deletecollection get list patch update watch]
  routes							[]			[]		[create delete deletecollection get list patch update watch]
  routes.route.openshift.io					[]			[]		[create delete deletecollection get list patch update watch]
  routes/custom-host						[]			[]		[create]
  routes.route.openshift.io/custom-host				[]			[]		[create]
  routes/status							[]			[]		[get list watch update]
  routes.route.openshift.io/status				[]			[]		[get list watch update]
  scheduledjobs.batch						[]			[]		[create delete deletecollection get list patch update watch]
  secrets							[]			[]		[create delete deletecollection get list patch update watch]
  serviceaccounts						[]			[]		[create delete deletecollection get list patch update watch impersonate]
  services							[]			[]		[create delete deletecollection get list patch update watch]
  services/proxy						[]			[]		[create delete deletecollection get list patch update watch]
  statefulsets.apps						[]			[]		[create delete deletecollection get list patch update watch]
  subjectaccessreviews						[]			[]		[create]
  subjectaccessreviews.authorization.openshift.io		[]			[]		[create]
  subjectrulesreviews						[]			[]		[create]
  subjectrulesreviews.authorization.openshift.io		[]			[]		[create]
  templateconfigs						[]			[]		[create delete deletecollection get list patch update watch]
  templateconfigs.template.openshift.io				[]			[]		[create delete deletecollection get list patch update watch]
  templateinstances						[]			[]		[create delete deletecollection get list patch update watch]
  templateinstances.template.openshift.io			[]			[]		[create delete deletecollection get list patch update watch]
  templates							[]			[]		[create delete deletecollection get list patch update watch]
  templates.template.openshift.io				[]			[]		[create delete deletecollection get list patch update watch]


Name:		basic-user
Labels:		<none>
Annotations:	openshift.io/description=A user that can get basic information about projects.
		rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources						Non-Resource URLs	Resource Names	Verbs
  ---------						-----------------	--------------	-----
  clusterroles						[]			[]		[get list]
  clusterroles.authorization.openshift.io		[]			[]		[get list]
  clusterroles.rbac.authorization.k8s.io		[]			[]		[get list watch]
  projectrequests					[]			[]		[list]
  projectrequests.project.openshift.io			[]			[]		[list]
  projects						[]			[]		[list watch]
  projects.project.openshift.io				[]			[]		[list watch]
  selfsubjectaccessreviews.authorization.k8s.io		[]			[]		[create]
  selfsubjectrulesreviews				[]			[]		[create]
  selfsubjectrulesreviews.authorization.openshift.io	[]			[]		[create]
  storageclasses.storage.k8s.io				[]			[]		[get list]
  users							[]			[~]		[get]
  users.user.openshift.io				[]			[~]		[get]
----

The following excerpt from viewing local role bindings shows the above roles bound
to various users and groups:

[options="nowrap"]
----
oc describe rolebinding.rbac admin basic-user -n alice-project
----

----
Name:		admin
Labels:		<none>
Annotations:	<none>
Role:
  Kind:	ClusterRole
  Name:	admin
Subjects:
  Kind	Name		Namespace
  ----	----		---------
  User	system:admin
  User	alice


Name:		basic-user
Labels:		<none>
Annotations:	<none>
Role:
  Kind:	ClusterRole
  Name:	basic-user
Subjects:
  Kind	Name	Namespace
  ----	----	---------
  User	joe
  Group	devel
----
endif::openshift-enterprise,openshift-origin[]

The relationships between cluster roles, local roles, cluster role bindings,
local role bindings, users, groups and service accounts are illustrated below.

image::rbac.png[{product-title} RBAC]

[[evaluating-authorization]]

== Evaluating Authorization

Several factors are combined to make the decision when {product-title} evaluates
authorization:

[cols="1,7"]
|===

|[[identity]]*Identity* |In the context of authorization, both the user name and
list of groups the user belongs to.

|[[action]]*Action* a|The action being performed. In most cases, this consists of:

[horizontal]
Project:: The xref:../core_concepts/projects_and_users.adoc#projects[project]
being accessed.
Verb:: Can be `get`, `list`, `create`, `update`, `delete`, `deletecollection` or `watch`.
Resource Name:: The API endpoint being accessed.

|*Bindings* |The full list of xref:bindings[bindings].

|===

{product-title} evaluates authorizations using the following steps:

. The identity and the project-scoped action is used to find all bindings that
apply to the user or their groups.
. Bindings are used to locate all the roles that apply.
. Roles are used to find all the rules that apply.
. The action is checked against each rule to find a match.
. If no matching rule is found, the action is then denied by default.
ifdef::openshift-origin,openshift-enterprise,openshift-dedicated[]
[[cluster-and-local-rbac]]

== Cluster and Local RBAC
There are two levels of RBAC roles and bindings that control authorization:

[cols="1,4"]
|===

|*Cluster RBAC* |xref:roles[Roles] and bindings that are applicable across
all projects. Roles that exist cluster-wide are considered _cluster
roles_. Cluster role bindings can only reference cluster roles.

|*Local RBAC* |xref:roles[Roles] and bindings that are scoped to a given
project. Roles that exist only in a project are considered _local roles_.
Local role bindings can reference both cluster and local roles.

|===

This two-level hierarchy allows re-usability over multiple projects through the
cluster roles while allowing customization inside of individual projects
through local roles.

During evaluation, both the cluster role bindings and the local role bindings are used.
For example:

. Cluster-wide "allow" rules are checked.
. Locally-bound "allow" rules are checked.
. Deny by default.


[[roles]]

== Cluster Roles and Local Roles
Roles are collections of policy xref:rules-def[rules], which are sets of
permitted verbs that can be performed on a set of resources. {product-title}
includes a set of default cluster roles that can be bound to users and groups
xref:cluster-and-local-rbac[cluster wide] or xref:cluster-and-local-rbac[locally].


[cols="1,4",options="header"]
|===

|Default Cluster Role |Description

|*admin* |A project manager. If used in a
xref:cluster-and-local-rbac[local binding], an *admin* user will have
rights to view any resource in the project and modify any resource in the
project except for quota.

|*basic-user* |A user that can get basic information about projects and users.

|*cluster-admin* |A super-user that can perform any action in any project. When
bound to a user with a xref:cluster-and-local-rbac[local binding], they have
xref:../../admin_guide/manage_rbac.adoc#cluster-and-local-role-bindings[full control]
over quota and every action on every resource in the project.

|*cluster-status* |A user that can get basic cluster status information.

|*edit* |A user that can modify most objects in a project, but does not have the
power to view or modify roles or bindings.

|*self-provisioner* |A user that can create their own projects.

|*view* |A user who cannot make any modifications, but can see most objects in a
project. They cannot view or modify roles or bindings.

|===
endif::openshift-origin,openshift-enterprise,openshift-dedicated[]

ifdef::openshift-origin,openshift-enterprise,openshift-dedicated[]
TIP: Remember that xref:authentication.adoc#users-and-groups[users
and groups] can be associated with, or _bound_ to, multiple roles at the same
time.

Project administrators can visualize roles, including a matrix of the
verbs and resources each are associated using the CLI to
endif::openshift-origin,openshift-enterprise,openshift-dedicated[]
ifdef::openshift-enterprise,openshift-origin[]
xref:../../admin_guide/manage_rbac.adoc#viewing-local-bindings[view
local bindings].
endif::openshift-enterprise,openshift-origin[]
ifdef::openshift-dedicated[]
view local bindings.
endif::openshift-dedicated[]

ifdef::openshift-origin,openshift-enterprise,openshift-dedicated[]
[IMPORTANT]
====
The cluster role bound to the project administrator is limited in a project via a
xref:../../admin_guide/manage_rbac.adoc#cluster-and-local-role-bindings[local binding].
It is not bound
xref:../../admin_guide/manage_rbac.adoc#cluster-and-local-role-bindings[cluster-wide]
like the cluster roles granted to the *cluster-admin* or *system:admin*.

Cluster roles are xref:roles[roles] defined at the cluster level, but can be bound either at
the cluster level or at the project level.
====
endif::openshift-origin,openshift-enterprise,openshift-dedicated[]
ifdef::openshift-enterprise,openshift-origin[]
xref:../../admin_guide/manage_rbac.adoc#creating-local-role[Learn
how to create a local role for a project].
endif::[]

ifdef::openshift-enterprise,openshift-origin[]
[[updating-cluster-roles]]

=== Updating Cluster Roles

After any xref:../../upgrading/index.adoc#install-config-upgrading-index[{product-title} cluster
upgrade], the default roles are updated and automatically reconciled when the
server is started. During reconciliation, any permissions that are missing from
the default roles are added. If you added more permissions to the role, they are
not removed.

If you customized the default roles and configured them to prevent automatic
role reconciliation, you must
xref:../../admin_guide/manage_rbac.adoc#updating-policy-definitions[manually update policy definitions]
when you upgrade {product-title}.

[[applying-custom-roles-and-permissions]]

=== Applying Custom Roles and Permissions

To add or update custom roles and permissions, it is strongly recommended to use
the following command:

----
# oc auth reconcile -f FILE
----

This command ensures that new permissions are applied properly in a way that
will not break other clients. This is done internally by computing logical
covers operations between rule sets, which is something you cannot do via a
JSON merge on RBAC resources.

endif::[]
ifdef::openshift-origin,openshift-enterprise,openshift-dedicated[]

ifdef::openshift-enterprise,openshift-origin[]
[[cluster-role-aggregation]]

=== Cluster Role Aggregation
The default admin, edit, and view cluster roles support 
link:https://kubernetes.io/docs/admin/authorization/rbac/#aggregated-clusterroles[cluster role 
aggregation], where the cluster rules for each role are dynamically updated as
new rules are created. This feature is relevant only if you extend the 
Kubernetes API by
xref:../../admin_guide/custom_resource_definitions.adoc#admin-guide-custom-resources[creating custom resources].

xref:../../admin_guide/custom_resource_definitions.adoc#creating-cluster-roles-for-the-custom-resource-definition[Learn how to use cluster role aggregation].
endif::openshift-enterprise,openshift-origin[]

[[security-context-constraints]]

== Security Context Constraints
In addition to the xref:architecture-additional-concepts-authorization[RBAC resources] that control what a user
can do, {product-title} provides _security context constraints_ (SCC) that control the
actions that a xref:../core_concepts/pods_and_services.adoc#pods[pod] can
perform and what it has the ability to access. Administrators can
xref:../../admin_guide/manage_scc.adoc#admin-guide-manage-scc[manage SCCs] using the CLI.
SCCs are also very useful for
xref:../../install_config/persistent_storage/pod_security_context.adoc#install-config-persistent-storage-pod-security-context[managing
access to persistent storage].

SCCs are objects that define a set of conditions that a pod must run with in
order to be accepted into the system. They allow an administrator to control the
following:
endif::[]

ifdef::openshift-enterprise,openshift-origin[]
. Running of
xref:../../install/prerequisites.adoc#security-warning[privileged
containers].
endif::[]
ifdef::openshift-dedicated[]
. Running of privileged containers.
endif::[]
ifdef::openshift-origin,openshift-enterprise,openshift-dedicated[]

. Capabilities a container can request to be added.
. Use of host directories as volumes.
. The SELinux context of the container.
. The user ID.
. The use of host namespaces and networking.
. Allocating an `*FSGroup*` that owns the pod's volumes
. Configuring allowable supplemental groups
. Requiring the use of a read only root file system
. Controlling the usage of volume types
. Configuring allowable seccomp profiles

Seven SCCs are added to the cluster by default, and are viewable by cluster
administrators using the CLI:

----
$ oc get scc
NAME               PRIV      CAPS      SELINUX     RUNASUSER          FSGROUP     SUPGROUP    PRIORITY   READONLYROOTFS   VOLUMES
anyuid             false     []        MustRunAs   RunAsAny           RunAsAny    RunAsAny    10         false            [configMap downwardAPI emptyDir persistentVolumeClaim secret]
hostaccess         false     []        MustRunAs   MustRunAsRange     MustRunAs   RunAsAny    <none>     false            [configMap downwardAPI emptyDir hostPath persistentVolumeClaim secret]
hostmount-anyuid   false     []        MustRunAs   RunAsAny           RunAsAny    RunAsAny    <none>     false            [configMap downwardAPI emptyDir hostPath nfs persistentVolumeClaim secret]
hostnetwork        false     []        MustRunAs   MustRunAsRange     MustRunAs   MustRunAs   <none>     false            [configMap downwardAPI emptyDir persistentVolumeClaim secret]
nonroot            false     []        MustRunAs   MustRunAsNonRoot   RunAsAny    RunAsAny    <none>     false            [configMap downwardAPI emptyDir persistentVolumeClaim secret]
privileged         true      [*]       RunAsAny    RunAsAny           RunAsAny    RunAsAny    <none>     false            [*]
restricted         false     []        MustRunAs   MustRunAsRange     MustRunAs   RunAsAny    <none>     false            [configMap downwardAPI emptyDir persistentVolumeClaim secret]
----

ifdef::openshift-origin,openshift-enterprise[]
[IMPORTANT]
====
Do not modify the default SCCs. Customizing the default SCCs can lead to issues
when {product-title} is upgraded. Instead,
xref:../../admin_guide/manage_scc.adoc#creating-new-security-context-constraints[create
new SCCs].
====
endif::openshift-origin,openshift-enterprise[]

ifdef::openshift-dedicated[]
[IMPORTANT]
====
Do not modify the default SCCs. Customizing the default SCCs can lead to issues
when {product-title} is upgraded.
====
endif::openshift-dedicated[]


The definition for each SCC is also viewable by cluster administrators using the
CLI. For example, for the privileged SCC:

----
# oc export scc/privileged
allowHostDirVolumePlugin: true
allowHostIPC: true
allowHostNetwork: true
allowHostPID: true
allowHostPorts: true
allowPrivilegedContainer: true
allowedCapabilities: <1>
- '*'
apiVersion: v1
defaultAddCapabilities: [] <2>
fsGroup: <3>
  type: RunAsAny
groups: <4>
- system:cluster-admins
- system:nodes
kind: SecurityContextConstraints
metadata:
  annotations:
    kubernetes.io/description: 'privileged allows access to all privileged and host
      features and the ability to run as any user, any group, any fsGroup, and with
      any SELinux context.  WARNING: this is the most relaxed SCC and should be used
      only for cluster administration. Grant with caution.'
  creationTimestamp: null
  name: privileged
priority: null
readOnlyRootFilesystem: false
requiredDropCapabilities: [] <5>
runAsUser: <6>
  type: RunAsAny
seLinuxContext: <7>
  type: RunAsAny
seccompProfiles:
- '*'
supplementalGroups: <8>
  type: RunAsAny
users: <9>
- system:serviceaccount:default:registry
- system:serviceaccount:default:router
- system:serviceaccount:openshift-infra:build-controller
volumes:
- '*'
----

<1> A list of capabilities that can be requested by a pod. An empty list means
that none of capabilities can be requested while the special symbol `***`
allows any capabilities.
<2> A list of additional capabilities that will be added to any pod.
<3> The `FSGroup` strategy which dictates the allowable values for the
Security Context.
<4> The groups that have access to this SCC.
<5> A list of capabilities that will be dropped from a pod.
<6> The run as user strategy type which dictates the allowable values for the
Security Context.
<7> The SELinux context strategy type which dictates the allowable values for
the Security Context.
<8> The supplemental groups strategy which dictates the allowable supplemental
groups for the Security Context.
<9> The users who have access to this SCC.

The `users` and `groups` fields on the SCC control which SCCs can be used.
By default, cluster administrators, nodes, and the build controller are granted
access to the privileged SCC. All authenticated users are granted access to the
restricted SCC.

Docker has a
link:https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities[default
list of capabilities] that are allowed for each container of a pod. The
containers use the capabilities from this default list, but pod manifest authors
can alter it by requesting additional capabilities or dropping some of
defaulting. The `allowedCapabilities`, `defaultAddCapabilities`, and
`requiredDropCapabilities` fields are used to control such requests from the
pods, and to dictate which capabilities can be requested, which ones must be
added to each container, and which ones must be forbidden.

The privileged SCC:

- allows privileged pods.
- allows host directories to be mounted as volumes.
- allows a pod to run as any user.
- allows a pod to run with any MCS label.
- allows a pod to use the host's IPC namespace.
- allows a pod to use the host's PID namespace.
- allows a pod to use any FSGroup.
- allows a pod to use any supplemental group.
- allows a pod to use any seccomp profiles.
- allows a pod to request any capabilities.

The restricted SCC:

- ensures pods cannot run as privileged.
- ensures pods cannot use host directory volumes.
- requires that a pod run as a user in a pre-allocated range of UIDs.
- requires that a pod run with a pre-allocated MCS label.
- allows a pod to use any FSGroup.
- allows a pod to use any supplemental group.

[NOTE]
====
For more information about each SCC, see the *kubernetes.io/description*
annotation available on the SCC.
====

SCCs are comprised of settings and strategies that control the security features
a pod has access to. These settings fall into three categories:

[cols="1,4"]
|===

|*Controlled by a boolean*
|Fields of this type default to the most restrictive value. For example,
`AllowPrivilegedContainer` is always set to *false* if unspecified.

|*Controlled by an allowable set*
|Fields of this type are checked against the set to ensure their value is
allowed.

|*Controlled by a strategy*
a|Items that have a strategy to generate a value provide:

- A mechanism to generate the value, and
- A mechanism to ensure that a specified value falls into the set of allowable
values.

|===

[[authorization-SCC-strategies]]
=== SCC Strategies

[[authorization-RunAsUser]]
==== RunAsUser

. *MustRunAs* - Requires a `runAsUser` to be configured. Uses the configured
`runAsUser` as the default. Validates against the configured `runAsUser`.
. *MustRunAsRange* - Requires minimum and maximum values to be defined if not
using pre-allocated values. Uses the minimum as the default. Validates against
the entire allowable range.
. *MustRunAsNonRoot* - Requires that the pod be submitted with a non-zero
`runAsUser` or have the `USER` directive defined in the image. No default
provided.
. *RunAsAny* - No default provided. Allows any `runAsUser` to be specified.

[[authorization-SELinuxContext]]
==== SELinuxContext

. *MustRunAs* - Requires `seLinuxOptions` to be configured if not using
pre-allocated values. Uses `seLinuxOptions` as the default. Validates against
`*seLinuxOptions*`.
. *RunAsAny* - No default provided. Allows any `seLinuxOptions` to be
specified.

[[authorization-SupplementalGroups]]
==== SupplementalGroups

. *MustRunAs* - Requires at least one range to be specified if not using
pre-allocated values. Uses the minimum value of the first range as the default.
Validates against all ranges.
. *RunAsAny* - No default provided. Allows any `supplementalGroups` to be
specified.

[[authorization-FSGroup]]
==== FSGroup

. *MustRunAs* - Requires at least one range to be specified if not using
pre-allocated values. Uses the minimum value of the first range as the default.
Validates against the first ID in the first range.
. *RunAsAny* - No default provided. Allows any `fsGroup` ID to be specified.

[[authorization-controlling-volumes]]
=== Controlling Volumes

The usage of specific volume types can be controlled by setting the `volumes`
field of the SCC. The allowable values of this field correspond to the volume
sources that are defined when creating a volume:

* link:https://kubernetes.io/docs/concepts/storage/volumes/#azurefilevolume[*azureFile*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#azurediskvolume[*azureDisk*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#flocker[*flocker*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#flexvolume[*flexVolume*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#hostpath[*hostPath*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#emptydir[*emptyDir*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#gcepersistentdisk[*gcePersistentDisk*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#awselasticblockstore[*awsElasticBlockStore*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#gitrepo[*gitRepo*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#secret[*secret*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#nfs[*nfs*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#iscsi[*iscsi*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#glusterfs[*glusterfs*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#persistentvolumeclaim[*persistentVolumeClaim*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#rbd[*rbd*]
* *cinder*
* link:https://kubernetes.io/docs/concepts/storage/volumes/#cephfs[*cephFS*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#downwardapi[*downwardAPI*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#fc-fibre-channel[*fc*]
* *configMap*
* link:https://kubernetes.io/docs/concepts/storage/volumes/#vspherevolume[*vsphereVolume*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#quobyte[*quobyte*]
* *photonPersistentDisk*
* link:https://kubernetes.io/docs/concepts/storage/volumes/#projected[*projected*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#portworxvolume[*portworxVolume*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#scaleio[*scaleIO*]
* link:https://kubernetes.io/docs/concepts/storage/volumes/#storageos[*storageos*]
* *** (a special value to allow the use of all volume types)
* *none* (a special value to disallow the use of all volumes types. Exist only for backwards compatibility)

The recommended minimum set of allowed volumes for new SCCs are *configMap*,
*downwardAPI*, *emptyDir*, *persistentVolumeClaim*, *secret*, and *projected*.

[NOTE]
====
The list of allowable volume types is not exhaustive because new types are
added with each release of {product-title}.
====

[NOTE]
====
For backwards compatibility, the usage of `allowHostDirVolumePlugin` overrides
settings in the `volumes` field.  For example, if `allowHostDirVolumePlugin`
is set to false but allowed in the `volumes` field, then the `hostPath`
value will be removed from `volumes`.
====

[[authorization-allowed-flex-volumes]]
=== Restricting Access to FlexVolumes

{product-title} provides additional control of FlexVolumes based on their
driver. When SCC allows the usage of FlexVolumes, pods can request any
FlexVolumes. However, when the cluster administrator specifies driver names in
the `AllowedFlexVolumes` field, pods must only use FlexVolumes with these
drivers.

.Example of Limiting Access to Only Two FlexVolumes
[source,yaml]
----
volumes:
- flexVolume
allowedFlexVolumes:
- driver: example/lvm
- driver: example/cifs
----

[[authorization-seccomp]]
=== Seccomp

*SeccompProfiles* lists the allowed profiles that can be set for the pod or
container's seccomp annotations. An unset (nil) or empty value means that no
profiles are specified by the pod or container. Use the wildcard `*` to allow
all profiles. When used to generate a value for a pod, the first non-wildcard
profile is used as the default.

ifdef::openshift-enterprise,openshift-origin[]
Refer to the xref:../../admin_guide/seccomp.adoc#admin-guide-seccomp[seccomp documentation] for more information
about configuring and using custom profiles.
endif::openshift-enterprise,openshift-origin[]

[[admission]]

=== Admission
_Admission control_ with SCCs allows for control over the creation of resources
based on the capabilities granted to a user.

In terms of the SCCs, this means that an admission controller can inspect the
user information made available in the context to retrieve an appropriate set of
SCCs. Doing so ensures the pod is authorized to make requests about its
operating environment or to generate a set of constraints to apply to the pod.

The set of SCCs that admission uses to authorize a pod are determined by the
user identity and groups that the user belongs to. Additionally, if the pod
specifies a service account, the set of allowable SCCs includes any constraints
accessible to the service account.

Admission uses the following approach to create the final security context for
the pod:

. Retrieve all SCCs available for use.
. Generate field values for security context settings that were not specified
on the request.
. Validate the final settings against the available constraints.

If a matching set of constraints is found, then the pod is accepted. If the
request cannot be matched to an SCC, the pod is rejected.

A pod must validate every field against the SCC. The following are examples for
just two of the fields that must be validated:

[NOTE]
====
These examples are in the context of a strategy using the preallocated values.
====

*A FSGroup SCC Strategy of MustRunAs*

If the pod defines a `fsGroup` ID, then that ID must equal the default
`fsGroup` ID. Otherwise, the pod is not validated by that SCC and the next SCC
is evaluated.

If the `SecurityContextConstraints.fsGroup` field has value *RunAsAny*
and the pod specification omits the `Pod.spec.securityContext.fsGroup`,
then this field is considered valid. Note that it is possible that during
validation, other SCC settings will reject other pod fields and thus cause the
pod to fail.

*A SupplementalGroups SCC Strategy of MustRunAs*

If the pod specification defines one or more `supplementalGroups` IDs, then
the pod's IDs must equal one of the IDs in the namespace's
*openshift.io/sa.scc.supplemental-groups* annotation. Otherwise, the pod is not
validated by that SCC and the next SCC is evaluated.

If the `SecurityContextConstraints.supplementalGroups` field has value *RunAsAny*
and the pod specification omits the `Pod.spec.securityContext.supplementalGroups`,
then this field is considered valid. Note that it is possible that during
validation, other SCC settings will reject other pod fields and thus cause the
pod to fail.

[[scc-prioritization]]
==== SCC Prioritization

SCCs have a priority field that affects the ordering when attempting to
validate a request by the admission controller.  A higher priority
SCC is moved to the front of the set when sorting.  When the complete set
of available SCCs are determined they are ordered by:

. Highest priority first, nil is considered a 0 priority
. If priorities are equal, the SCCs will be sorted from most restrictive to least restrictive
. If both priorities and restrictions are equal the SCCs will be sorted by name

By default, the anyuid SCC granted to cluster administrators is given priority
in their SCC set.  This allows cluster administrators to run pods as any
user by without specifying a `RunAsUser` on the pod's `SecurityContext`.  The
administrator may still specify a `RunAsUser` if they wish.

[[understanding-pre-allocated-values-and-security-context-constraints]]
==== Understanding Pre-allocated Values and Security Context Constraints

The admission controller is aware of certain conditions in the security context
constraints that trigger it to look up pre-allocated values from a namespace and
populate the security context constraint before processing the pod. Each SCC
strategy is evaluated independently of other strategies, with the pre-allocated
values (where allowed) for each policy aggregated with pod specification values
to make the final values for the various IDs defined in the running pod.

The following SCCs cause the admission controller to look for pre-allocated
values when no ranges are defined in the pod specification:

. A `RunAsUser` strategy of *MustRunAsRange* with no minimum or maximum set.
Admission looks for the *openshift.io/sa.scc.uid-range* annotation to populate
range fields.
. An `SELinuxContext` strategy of *MustRunAs* with no level set. Admission
looks for the *openshift.io/sa.scc.mcs* annotation to populate the level.
. A `FSGroup` strategy of *MustRunAs*. Admission looks for the
*openshift.io/sa.scc.supplemental-groups* annotation.
. A `SupplementalGroups` strategy of *MustRunAs*. Admission looks for the
*openshift.io/sa.scc.supplemental-groups* annotation.

During the generation phase, the security context provider will default any
values that are not specifically set in the pod. Defaulting is based on the
strategy being used:

. `RunAsAny` and `MustRunAsNonRoot` strategies do not provide default
values. Thus, if the pod needs a field defined (for example, a group ID), this
field must be defined inside the pod specification.
. `MustRunAs` (single value) strategies provide a default value which is
always used. As an example, for group IDs: even if the pod specification defines
its own ID value, the namespace's default field will also appear in the pod's
groups.
. `MustRunAsRange` and `MustRunAs` (range-based) strategies provide the
minimum value of the range. As with a single value `MustRunAs` strategy, the
namespace's default value will appear in the running pod. If a range-based
strategy is configurable with multiple ranges, it will provide the minimum value
of the first configured range.

[NOTE]
====
`FSGroup` and `SupplementalGroups` strategies fall back to the
*openshift.io/sa.scc.uid-range* annotation if the
*openshift.io/sa.scc.supplemental-groups* annotation does not exist on the
namespace. If neither exist, the SCC will fail to create.
====

[NOTE]
====
By default, the annotation-based `FSGroup` strategy configures itself with a
single range based on the minimum value for the annotation. For example, if your
annotation reads *1/3*, the `FSGroup` strategy will configure itself with a
minimum and maximum of *1*. If you want to allow more groups to be accepted for
the `FSGroup` field, you can configure a custom SCC that does not use the
annotation.
====

[NOTE]
====
The *openshift.io/sa.scc.supplemental-groups* annotation accepts a comma
delimited list of blocks in the format of `<start>/<length` or `<start>-<end>`.
The *openshift.io/sa.scc.uid-range* annotation accepts only a single block.
====
endif::[]

ifdef::openshift-online[]
[[authorization-online-collaboration]]
== Collaboration

In {product-title} Pro, you can grant roles (like *view* or *edit*) to other
users or groups for your projects.

See xref:../../dev_guide/projects.adoc#project-collaboration-in-online-pro[Project
Collaboration in {product-title} Pro] for information on adding and removing
collaborators.

In {product-title} Starter, collaboration is not available.
endif::openshift-online[]
