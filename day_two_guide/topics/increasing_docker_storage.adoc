////
Increasing Docker Storage

Module included in the following assemblies:

* day_two_guide/docker_tasks.adoc
////

Increasing the amount of storage available ensures continued deployment without
any outages. To do so, a free partition must be made available that contains an
appropriate amount of free capacity.

[[evacuating-a-node]]
== Evacuating the node

[discrete]
*Procedure*

//tag::evacuating-a-node[]
. From a master instance, or as a cluster administrator, allow the evacuation of
any pod from the node and disable scheduling of other pods on that node:
+
----
$ NODE=ose-app-node01.example.com
$ oc adm manage-node ${NODE} --schedulable=false
NAME                          STATUS                     AGE       VERSION
ose-app-node01.example.com   Ready,SchedulingDisabled   20m       v1.6.1+5115d708d7

$ oc adm drain ${NODE} --ignore-daemonsets
node "ose-app-node01.example.com" already cordoned
pod "perl-1-build" evicted
pod "perl-1-3lnsh" evicted
pod "perl-1-9jzd8" evicted
node "ose-app-node01.example.com" drained
----
+
[NOTE]
====
If there are containers running with local volumes that will not migrate, run
the following command: `oc adm drain ${NODE} --ignore-daemonsets
--delete-local-data`.
====

. List the pods on the node to verify that they have been removed:
+
----
$ oc adm manage-node ${NODE} --list-pods

Listing matched pods on node: ose-app-node01.example.com

NAME      READY     STATUS    RESTARTS   AGE
----

. Repeat the previous two steps for each node.

For more information on evacuating and draining pods or nodes, see
xref:../day_two_guide/host_level_tasks.adoc#day-two-guide-node-maintenance[Node maintenance].
//end::evacuating-a-node[]

== Increasing storage

You can increase Docker storage in two ways: attaching a new disk, or extending
the existing disk.

*Increasing storage with a new disk*

[discrete]
=== Prerequisites

- A new disk must be available to the existing instance that requires more storage. In the following steps, the original disk is labeled `/dev/xvdb`, and the new disk is labeled `/dev/xvdd`, as shown in the *_/etc/sysconfig/docker-storage-setup_* file:
+
----
# vi /etc/sysconfig/docker-storage-setup
DEVS="/dev/xvdb /dev/xvdd"
----
+
[NOTE]
====
The process may differ depending on the underlying {product-title}
infrastructure.
====

[discrete]
=== Procedure

. Stop the `docker` and `atomic-openshift-node` services:
+
----
# systemctl stop docker atomic-openshift-node
----

. Run the `docker-storage-setup` command to extend the volume groups and logical
volumes associated with container storage:
+
----
# docker-storage-setup
INFO: Volume group backing root filesystem could not be determined
INFO: Device /dev/xvdb is already partitioned and is part of volume group docker_vol
INFO: Device node /dev/xvdd1 exists.
  Physical volume "/dev/xvdd1" successfully created.
  Volume group "docker_vol" successfully extended
----

. Start the Docker services:
+
----
# systemctl start docker
# vgs
  VG         #PV #LV #SN Attr   VSize  VFree
  docker_vol   2   1   0 wz--n- 64.99g <55.00g
----

. A benefit in adding a disk compared to creating a new volume group and
re-running `docker-storage-setup` is that the images that were used on the
system still exist after the new storage has been added:
+
----
# docker images
REPOSITORY                                              TAG                 IMAGE ID            CREATED             SIZE
docker-registry.default.svc:5000/tet/perl               latest              8b0b0106fb5e        13 minutes ago      627.4 MB
registry.access.redhat.com/rhscl/perl-524-rhel7         <none>              912b01ac7570        6 days ago          559.5 MB
registry.access.redhat.com/openshift3/ose-deployer      v3.6.173.0.21       89fd398a337d        5 weeks ago         970.2 MB
registry.access.redhat.com/openshift3/ose-sti-builder   v3.6.173.0.21       99ab8895d88a        5 weeks ago         970.2 MB
registry.access.redhat.com/openshift3/ose-pod           v3.6.173.0.21       63accd48a0d7        5 weeks ago         208.6 MB
----

. With the increase in storage capacity, enable the node to be schedulable in
order to accept new incoming pods. 
+
As a cluster administrator, run the following from a master instance:
+
----
$ oc adm manage-node ${NODE} --schedulable=true

ose-master01.example.com   Ready,SchedulingDisabled   24m       v1.6.1+5115d708d7
ose-master02.example.com   Ready,SchedulingDisabled   24m       v1.6.1+5115d708d7
ose-master03.example.com   Ready,SchedulingDisabled   24m       v1.6.1+5115d708d7
ose-infra-node01.example.com   Ready                      24m       v1.6.1+5115d708d7
ose-infra-node02.example.com   Ready                      24m       v1.6.1+5115d708d7
ose-infra-node03.example.com   Ready                      24m       v1.6.1+5115d708d7
ose-app-node01.example.com   Ready                      24m       v1.6.1+5115d708d7
ose-app-node02.example.com   Ready                      24m       v1.6.1+5115d708d7
----

*Increasing storage with a new disk*

. Evacuate the node xref:evacuating-a-node[following the previous steps].

. Stop the `docker` and `atomic-openshift-node` services:
+
----
# systemctl stop docker atomic-openshift-node
----

. Resize the existing disk as desired. This can can depend on your environment:
+
* If you are using LVM (Logical Volume Manager):
+
** link:https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/logical_volume_manager_administration/lv#LV_remove[Remove the logical volume]:
+
----
# lvremove /dev/docker_vg/docker/lv
----
+
** link:https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/logical_volume_manager_administration/vg_admin#VG_remove[Remove the Docker volume group]:
+
----
# vgremove docker_vg
----
+
** link:https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/logical_volume_manager_administration/physvol_admin#PV_remove[Remove the physical volume]:
+
----
# pvremove /dev/<my_previous_disk_device>
----
+
* If you are using a cloud provider, you can detach the disk,
destroy the disk, then create a new bigger disk, and attach it to the instance.
+
* For a non-cloud environment, the disk and file system can be resized. See the
following solution for more information:
+
** https://access.redhat.com/solutions/199573

. Verify that the *_/etc/sysconfig/container-storage-setup_* file is correctly
configured for the new disk by checking the device name, size, etc.

. Run `docker-storage-setup` to reconfigure the new disk:
+
----
# docker-storage-setup
INFO: Volume group backing root filesystem could not be determined
INFO: Device /dev/xvdb is already partitioned and is part of volume group docker_vol
INFO: Device node /dev/xvdd1 exists.
  Physical volume "/dev/xvdd1" successfully created.
  Volume group "docker_vol" successfully extended
----

. Start the Docker services:
+
----
# systemctl start docker
# vgs
  VG         #PV #LV #SN Attr   VSize  VFree
  docker_vol   2   1   0 wz--n- 64.99g <55.00g
----

. Start the `atomic-openshift-node` service:
+
----
# systemctl start atomic-openshift-node
----

= Changing the storage backend

With the advancements of services and file systems, changes in a storage backend
may be necessary to take advantage of new features. The following steps provide
an example of changing a device mapper backend to an `overlay2` storage backend.
`overlay2` offers increased speed and density over traditional device mapper.

== Evacuating the node

. From a master instance, or as a cluster administrator, allow the evacuation of
any pod from the node and disable scheduling of other pods on that node:
+
----
$ NODE=ose-app-node01.example.com
$ oc adm manage-node ${NODE} --schedulable=false
NAME                          STATUS                     AGE       VERSION
ose-app-node01.example.com   Ready,SchedulingDisabled   20m       v1.6.1+5115d708d7

$ oc adm drain ${NODE} --ignore-daemonsets
node "ose-app-node01.example.com" already cordoned
pod "perl-1-build" evicted
pod "perl-1-3lnsh" evicted
pod "perl-1-9jzd8" evicted
node "ose-app-node01.example.com" drained
----
+
[NOTE]
====
If there are containers running with local volumes that will not migrate, run
the following command: `oc adm drain ${NODE} --ignore-daemonsets
--delete-local-data`
====

. List the pods on the node to verify that they have been removed:
+
----
$ oc adm manage-node ${NODE} --list-pods

Listing matched pods on node: ose-app-node01.example.com

NAME      READY     STATUS    RESTARTS   AGE
----
+
For more information on evacuating and draining pods or nodes, see
xref:../day_two_guide/host_level_tasks.adoc#day-two-guide-node-maintenance[Node maintenance].

. With no containers currently running on the instance, stop the `docker` and
`atomic-openshift-node service` services:
+
----
# systemctl stop docker atomic-openshift-node
----

. Verify the name of the volume group, logical volume name, and physical volume
name:
+
----
# vgs
  VG         #PV #LV #SN Attr   VSize   VFree
  docker_vol   1   1   0 wz--n- <25.00g 15.00g

# lvs
LV       VG         Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
 dockerlv docker_vol -wi-ao---- <10.00g

# lvremove /dev/docker_vol/docker-pool  -y
# vgremove docker_vol -y
# pvs
  PV         VG         Fmt  Attr PSize   PFree
  /dev/xvdb1 docker_vol lvm2 a--  <25.00g 15.00g

# pvremove /dev/xvdb1 -y
# rm -Rf /var/lib/docker/*
# rm -f /etc/sysconfig/docker-storage
----

. Modify the `docker-storage-setup` file to specify the `STORAGE_DRIVER`.
+
[NOTE]
====
When a system is upgraded from Red Hat Enterprise Linux version 7.3 to 7.4, the
`docker` service attempts to use `/var` with the `STORAGE_DRIVER` of extfs. The
use of extfs as the `STORAGE_DRIVER` causes errors. See the following bug for
more info regarding the error:

* https://bugzilla.redhat.com/show_bug.cgi?id=1490910[Bugzilla ID: 1490910]
====
+
----
DEVS=/dev/xvdb
VG=docker_vol
DATA_SIZE=95%VG
STORAGE_DRIVER=overlay2
CONTAINER_ROOT_LV_NAME=dockerlv
CONTAINER_ROOT_LV_MOUNT_PATH=/var/lib/docker
CONTAINER_ROOT_LV_SIZE=100%FREE
----

. Set up the storage:
+
----
# docker-storage-setup
----

. Start the `docker` and `atomic-openshift-node` services:
+
----
# systemctl start docker atomic-openshift-node
----

. With the storage modified to use `overlay2`, enable the node to be
schedulable in order to accept new incoming pods.
+
From a master instance, or as a cluster administrator:
+
----
$ oc adm manage-node ${NODE} --schedulable=true

ose-master01.example.com   Ready,SchedulingDisabled   24m       v1.6.1+5115d708d7
ose-master02.example.com   Ready,SchedulingDisabled   24m       v1.6.1+5115d708d7
ose-master03.example.com   Ready,SchedulingDisabled   24m       v1.6.1+5115d708d7
ose-infra-node01.example.com   Ready                      24m       v1.6.1+5115d708d7
ose-infra-node02.example.com   Ready                      24m       v1.6.1+5115d708d7
ose-infra-node03.example.com   Ready                      24m       v1.6.1+5115d708d7
ose-app-node01.example.com   Ready                      24m       v1.6.1+5115d708d7
ose-app-node02.example.com   Ready                      24m       v1.6.1+5115d708d7
----

////
=== Docker Backup
The Docker daemon uses different configuration files stored in the
`/etc/sysconfig` directory:

* `/etc/sysconfig/docker`
* `/etc/sysconfig/docker-network`
* `/etc/sysconfig/docker-storage`
* `/etc/sysconfig/docker-storage-setup`

NOTE: `/etc/sysconfig/docker-storage-setup` is used to create the Docker storage
and it creates the `/etc/sysconfig/docker-storage` file, so even if it is not
critical, it can be helpful to backup as well.

This snippet can be used:

----
$ tar -czvf docker-config-$(hostname)-$(date +%Y%m%d).tar.gz /etc/sysconfig/docker*
----
////