:_content-type: ASSEMBLY
include::_attributes/common-attributes.adoc[]
[id="preparing-serverless-install"]
= Preparing to install {ServerlessProductName}
:context: preparing-serverless-install

toc::[]

Read the following information about supported configurations and prerequisites before you install {ServerlessProductName}.

// OCP specific docs
For {ocp-product-title}:

* {ServerlessProductName} is supported for installation in a restricted network environment.

* {ServerlessProductName} currently cannot be used in a multi-tenant configuration on a single cluster.


[id="about-serverless-supported-configs"]
== Supported configurations

The set of supported features, configurations, and integrations for {ServerlessProductName}, current and past versions, are available at the link:https://access.redhat.com/articles/4912821[Supported Configurations page].


[id="about-serverless-scalability-performance"]
== Scalability and performance on {ocp-product-title}

{ServerlessProductName} has been tested with a configuration of 3 main nodes and 3 worker nodes, each of which has 64 CPUs, 457 GB of memory, and 394 GB of storage each.

The maximum number of Knative services that can be created using this configuration is 3,000. This corresponds to the link:https://docs.openshift.com/container-platform/latest/scalability_and_performance/planning-your-environment-according-to-object-maximums.html#cluster-maximums-major-releases_object-limits[{ocp-product-title} Kubernetes services limit of 10,000], since 1 Knative service creates 3 Kubernetes services.

The average scale from zero response time was approximately 3.4 seconds, with a maximum response time of 8 seconds, and a 99.9th percentile of 4.5 seconds for a simple Quarkus application. These times might vary depending on the application and the runtime of the application.


// OCP specific docs

[id="install-serverless-operator-before-you-begin"]

// OSD and ROSA docs
[NOTE]
====
The following section on defining cluster size requirements applies to these distributions:

* {ocp-product-title}
* {dedicated-product-title}
* {rosa-product-title}
====

include::modules/serverless-cluster-sizing-req.adoc[leveloffset=+1]


[id="install-serverless-operator-scaling-with-machinesets"]
== Scaling your cluster using compute machine sets on {ocp-product-title}

You can use the {ocp-product-title} `MachineSet` API to manually scale your cluster up to the desired size. The minimum requirements usually mean that you must scale up one of the default compute machine sets by two additional machines. See link:https://docs.openshift.com/container-platform/latest/machine_management/manually-scaling-machineset.html#manually-scaling-machineset[Manually scaling a compute machine set].

include::modules/serverless-cluster-sizing-req-additional.adoc[leveloffset=+2]

// TODO: Add OSD specific docs for auto scaling compute machine sets? These docs aren't available for OSD so we need to look into what's required to doc here.
// QE thread related: https://coreos.slack.com/archives/CD87JDUB0/p1643986092796179


[id="additional-resources_preparing-serverless-install"]
[role="_additional-resources"]
== Additional resources in {ocp-product-title} documentation

* link:https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html#olm-restricted-networks[Using Operator Lifecycle Manager on restricted networks]
* link:https://docs.openshift.com/container-platform/latest/operators/understanding/olm-understanding-operatorhub.html#olm-operatorhub-overview[Understanding OperatorHub]
* link:https://docs.openshift.com/container-platform/latest/installing/cluster-capabilities.html#cluster-capabilities[Cluster capabilities]

