[[install-config-installing-stand-alone-registry]]
= Installing a stand-alone deployment of OpenShift container image registry
{product-author}
{product-version]
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

{product-title} is a fully-featured enterprise solution that includes an
integrated container image registry called
xref:../architecture/infrastructure_components/image_registry.adoc#integrated-openshift-registry[OpenShift
Container Registry] (OCR). Instead of deploying {product-title} as a full
Platform-as-a-Service environment for developers, you can install OCR as a
stand-alone container image registry to run on-site or in the cloud.

When installing a stand-alone deployment of OCR, a cluster of masters and nodes
is still installed, similar to a typical {product-title} installation. Then, the
container image registry is deployed to run on the cluster. This stand-alone
deployment option is useful for administrators that want a container image registry
but do not require the full {product-title} environment that includes the
developer-focused web console and application build and deployment tools.

OCR provides the following capabilities:

- A user-focused registry web console, link:http://cockpit-project.org/[Cockpit].
- xref:../install_config/registry/securing_and_exposing_registry.adoc#securing-the-registry[Secured traffic]
by default, served via TLS.
- Global
xref:../install_config/configuring_authentication.adoc#install-config-configuring-authentication[identity provider authentication].
- A
xref:../architecture/core_concepts/projects_and_users.adoc#architecture-core-concepts-projects-and-users[project namespace]
model to enable teams to collaborate through
xref:../architecture/additional_concepts/authorization.adoc#architecture-additional-concepts-authorization[role-based access control (RBAC)]
authorization.
- A
xref:../architecture/infrastructure_components/kubernetes_infrastructure.adoc#architecture-infrastructure-components-kubernetes-infrastructure[Kubernetes-based cluster]
to manage services.
- An image abstraction called
xref:../architecture/core_concepts/builds_and_image_streams.adoc#image-streams[image streams]
to enhance image management.

Administrators can deploy a stand-alone OCR to manage a registry
separately that supports multiple {product-title} clusters. A stand-alone OCR
also enables administrators to separate their registry to satisfy their own
security or compliance requirements.

[[registry-minimum-hardware-requirements]]
== Minimum hardware requirements

Installing a stand-alone OCR has the following hardware requirements:

- Physical or virtual system or an instance running on a public or private IaaS.
- Base OS:
ifdef::openshift-origin[]
Fedora 21, CentOS 7.4, or
endif::[]
RHEL 7.5 or later with the "Minimal" installation option and the latest packages from the
RHEL 7 Extras channel, or RHEL Atomic Host 7.4.5 or later.
- NetworkManager 1.0 or later.
- 2 vCPU.
- Minimum 16 GB RAM.
- Minimum 15 GB hard disk space for the file system containing *_/var/_*.
- An additional minimum 15 GB unallocated space for Docker's storage back end;
see xref:host_preparation.adoc#configuring-docker-storage[Configuring Docker Storage]
for details.

[IMPORTANT]
====
{product-title} supports servers with x86_64 or IBM POWER architecture. If you
use IBM POWER servers to host cluster nodes, you can only use IBM POWER servers.
====

[NOTE]
====
To meet the *_/var/_* file system sizing requirements in RHEL Atomic Host
you must modify the default configuration. See
https://access.redhat.com/documentation/en/red-hat-enterprise-linux-atomic-host/version-7/getting-started-with-containers/#managing_storage_in_red_hat_enterprise_linux_atomic_host[Managing
Storage in Red Hat Enterprise Linux Atomic Host] for instructions on configuring
this during or after installation.
====

[[registry-supported-system-topologies]]
== Supported system topologies

The following system topologies are supported for stand-alone OCR:

[horizontal]
All-in-one::
A single host that includes the master, node, and registry components.
Multiple masters (Highly-Available)::
Three hosts with all components, master, node, and registry, included on each
with the masters configured for native high-availability.

[[registry-installing]]
== Installing the OpenShift Container Registry

. Review the full cluster installation process, starting with
xref:index.adoc#install-planning[Planning Your Installation]. Installing OCR
uses the same process but requires a few specific settings in the inventory
file. The installation documentation includes a comprehensive list of available
Ansible variables for the inventory file.

. Complete the
xref:host_preparation.adoc#install-config-install-host-preparation[host preparation]
steps.

. Create an
xref:../install/configuring_inventory_file.adoc#install-config-configuring-inventory-file[inventory file]
in the *_/etc/ansible/hosts_* directory:
+
[IMPORTANT]
====
To install a standalone OCR, you must set `deployment_subtype=registry` in the
inventory file in the `[OSEv3:vars]` section.
====
+
Use the following example inventory files for the different supported system
topologies:
+
.All-in-one stand-alone OpenShift Container Registry inventory file
----
# Create an OSEv3 group that contains the masters and nodes groups
[OSEv3:children]
masters
nodes
etcd

# Set variables common for all OSEv3 hosts
[OSEv3:vars]
# SSH user, this user should allow ssh based auth without requiring a password
ansible_ssh_user=root

openshift_master_default_subdomain=apps.test.example.com

# If ansible_ssh_user is not root, ansible_become must be set to true
#ansible_become=true

openshift_deployment_type=openshift-enterprise
deployment_subtype=registry <1>
openshift_hosted_infra_selector="" <2>

# uncomment the following to enable htpasswd authentication; defaults to DenyAllPasswordIdentityProvider
#openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider'}]

# host group for masters
[masters]
registry.example.com

# host group for etcd
[etcd]
registry.example.com

# host group for nodes
[nodes]
registry.example.com openshift_node_group_name='node-config-all-in-one'
----
<1> Set `deployment_subtype=registry` to ensure installation of stand-alone OCR and
not a full {product-title} environment.
<2> Allows the registry and its web console to be scheduled on the single host.
+
.Multiple masters (highly-available) stand-alone OpenShift Container Registry inventory file
----
# Create an OSEv3 group that contains the master, nodes, etcd, and lb groups.
# The lb group lets Ansible configure HAProxy as the load balancing solution.
# Comment lb out if your load balancer is pre-configured.
[OSEv3:children]
masters
nodes
etcd
lb

# Set variables common for all OSEv3 hosts
[OSEv3:vars]
ansible_ssh_user=root
openshift_deployment_type=openshift-enterprise
deployment_subtype=registry <1>

openshift_master_default_subdomain=apps.test.example.com

# Uncomment the following to enable htpasswd authentication; defaults to
# DenyAllPasswordIdentityProvider.
#openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider'}]

# Native high availability cluster method with optional load balancer.
# If no lb group is defined installer assumes that a load balancer has
# been preconfigured. For installation the value of
# openshift_master_cluster_hostname must resolve to the load balancer
# or to one or all of the masters defined in the inventory if no load
# balancer is present.
openshift_master_cluster_method=native
openshift_master_cluster_hostname=openshift-internal.example.com
openshift_master_cluster_public_hostname=openshift-cluster.example.com

# apply updated node-config-compute group defaults
openshift_node_groups=[{'name': 'node-config-compute', 'labels': ['node-role.kubernetes.io/compute=true'], 'edits': [{'key': 'kubeletArguments.pods-per-core','value': ['20']}, {'key': 'kubeletArguments.max-pods','value': ['250']}, {'key': 'kubeletArguments.image-gc-high-threshold', 'value':['90']}, {'key': 'kubeletArguments.image-gc-low-threshold', 'value': ['80']}]}]

# enable ntp on masters to ensure proper failover
openshift_clock_enabled=true

# host group for masters
[masters]
master1.example.com
master2.example.com
master3.example.com

# host group for etcd
[etcd]
etcd1.example.com
etcd2.example.com
etcd3.example.com

# Specify load balancer host
[lb]
lb.example.com

# host group for nodes, includes region info
[nodes]
master[1:3].example.com openshift_node_group_name='node-config-master-infra'
node1.example.com       openshift_node_group_name='node-config-compute'
node2.example.com       openshift_node_group_name='node-config-compute'
----
<1> Set `deployment_subtype=registry` to ensure installation of stand-alone OCR and
not a full {product-title} environment.

. Install the stand-alone OCR. The process is similar to a full
xref:index.adoc#install-planning[cluster installation] process.
+
[IMPORTANT]
====
The host that you run the Ansible playbook on must have at least 75MiB of free
memory per host in the inventory file.
====
+
.. Before you deploy a new cluster, change to the cluster directory and run the *_prerequisites.yml_* playbook:
+
----
$ cd /usr/share/ansible/openshift-ansible
$ ansible-playbook  [-i /path/to/inventory] \ <1>
    playbooks/prerequisites.yml
----
<1> If your inventory file is not in the *_/etc/ansible/hosts_* directory,
specify `-i` and the path to the inventory file.
+
You must run this playbook only one time.

.. To initiate installation, change to the playbook directory and run the *_deploy_cluster.yml_* playbook:
+
----
$ cd /usr/share/ansible/openshift-ansible
$ ansible-playbook  [-i /path/to/inventory] \ <1>
    playbooks/deploy_cluster.yml
----
<1> If your inventory file is not in the *_/etc/ansible/hosts_* directory,
specify `-i` and the path to the inventory file.
