[[getting-started-accessing-your-cluster]]
= Accessing Your Services
ifdef::openshift-dedicated[]
:cluster-admin-name: Dedicated cluster administrator
:cluster-admin-role: dedicated-cluster-admin
:project-admin-role: dedicated-project-admin
endif::[]
ifdef::openshift-aro[]
:cluster-admin-name: Customer cluster administrator
:cluster-admin-role: customer-admin-cluster
:project-admin-role: customer-admin-project
endif::[]
:toc: macro
:toc-title:
:data-uri:
:prewrap!:

toc::[]

ifdef::openshift-dedicated[]
[[access-your-cluster-overview]]
== Access your cluster

Once your {product-title} cluster is configured and ready to use, you can access
it through the following paths:

* *Cluster ID*: The unique cluster name provided by the customer during provisioning. It is lowercase, and only contains letters, numbers, and hyphens.

* *Console URL*: The {product-title} URL for the
xref:../architecture/infrastructure_components/web_console.adoc#architecture-infrastructure-components-web-console[web
console].
+
----
https://console.<cluster-id>.openshift.com
----

* *API URL*: The {product-title} URL for the OpenShift and Kubernetes
xref:../rest_api/index.adoc#rest-api-index[REST API].
+
----
https://api.<cluster-id>.openshift.com
----

* *Registry URL*: The {product-title} URL for the private
xref:../architecture/infrastructure_components/image_registry.adoc#architecture-infrastructure-components-image-registry[image
registry]. In addition to containing all images used by {product-title}, `podman pull` or `docker
pull` and `podman push` or `docker push` can be used directly on the registry.
+
----
https://registry.<cluster-id>.openshift.com
----

* *Metrics API URL*: The {product-title} URL for the
link:https://docs.openshift.com/container-platform/3.9/install_config/cluster_metrics.html#cluster-metrics-accessing-hawkular-metrics-directly[Hawkular
Metrics API].
+
----
https://metrics.<cluster-id>.openshift.com
----

* *Logging URL*: The {product-title} URL for the aggregate logging Kibana interface.
+
----
https://logs.<cluster-id>.openshift.com
----

* If an authentication callback URL is necessary, you can configure it with:
+
----
https://api.<cluster-id>.openshift.com/oauth2callback/<IdP name>
----
endif::[]

ifdef::openshift-aro[]
[[access-your-cluster-overview]]
== Access your cluster

Once your {product-title} cluster is configured and ready to use, you can access
it through the following paths:

* *Cluster ID*: The cluster ID assigned by the Azure service.

* *Cluster Region*: The cluster region specified when the cluster was provisioned.
+
----
https://openshift.<cluster-id>.<cluster-region>.azmosa.io/
----

* *API URL*: The {product-title} URL for the OpenShift and Kubernetes
xref:../rest_api/index.adoc#rest-api-index[REST API].
+
----
https://openshift.<cluster-id>.<cluster-region>.azmosa.io/
----

* *Registry URL*: The {product-title} URL for the private
xref:../architecture/infrastructure_components/image_registry.adoc#architecture-infrastructure-components-image-registry[image
registry]. In addition to containing all images used by {product-title}, `podman pull` or `docker
pull` and `podman push` or `docker push` can be used directly on the registry.
+
----
https://docker-registry.apps.<cluster-id>.<cluster-region>.azmosa.io/
----
endif::[]


ifdef::openshift-dedicated[]
include::getting_started/topics/configuring_AWS_VPC.adoc[]

[[configuring-your-application-routes]]
== Configure your application routes

When your cluster is provisioned, an AWS elastic load balancer (ELB) is created
to route application traffic into the cluster. The domain for your ELB is
configured to route application traffic via
`http(s)://*.<shard-id>.<cluster-id>.openshiftapps.com`. The `<shard-id>` is a
four-character string that is communicated to you after initial provisioning.

If you want to use custom domain names for your application routes, you should
set up a CNAME record in your DNS host to point to
*_elb.<shard-id>.<cluster-id>.openshiftapps.com_*. While `elb` is recommended as a
reminder for where this record is pointing, you can use any string for this
value. You can create these CNAME records for each custom route you have, or you
can create a wildcard CNAME record. For example:

----
*.openshift.example.com    CNAME    elb.1234.my-example.openshiftapps.com
----

This allows you to create routes like *_app1.openshift.example.com_* and
*_app2.openshift.example.com_* without having to update your DNS every time.

Customers with configured VPC peering or VPN connections have the option of
requesting a second ELB, so that application routes can be configured as
internal-only or externally available. The domain for this ELB will be identical
to the first, with a different `<shard-id>` value. By default, application
routes are handled by the internal-only router. To expose an application or
service externally, you must create a new route with a specific label,
`route=external`.

To expose a new route for an existing service, apply the label `route=external`
and define a host name that contains the secondary, public router shard ID:

----
$ oc expose service <service-name> -l route=external --name=<custom-route-name> --hostname=<custom-hostname>.<shard-id>.<cluster-id>.openshiftapps.com
----

Alternatively, you can use a custom domain:

----
$ oc expose service <service-name> -l route=external --name=<custom-route-name> --hostname=<custom-domain>
----
endif::[]

ifdef::openshift-dedicated[]
[[expose-tcp-services]]
== Expose TCP Services

{product-title} xref:../architecture/networking/routes.adoc#architecture-core-concepts-routes[routes] expose applications by proxying traffic through HTTP/HTTPS(SNI)/TLS(SNI)
to xref:../architecture/core_concepts/pods_and_services.adoc#architecture-core-concepts-pods-and-services[pods and services]. A link:https://kubernetes.io/docs/concepts/services-networking/#loadbalancer[LoadBalancer]
service creates an AWS Elastic Load Balancer (ELB) for your {product-title} cluster, enabling direct TCP access to applications exposed by your LoadBalancer service.

[NOTE]
====
LoadBalancer services require an additional purchase. Contact your sales team if you are interested in using LoadBalancer services for your {product-title} cluster.
====

=== Check your LoadBalancer Quota

By purchasing LoadBalancer services, you are provided with a quota of LoadBalancers available for your {product-title} cluster.

----
$ oc describe clusterresourcequota service-loadbalancers
Name:       service-loadbalancers
Labels:     <none>
Annotations:    <none>
Resource        Used    Hard
--------        ----    ----
services.loadbalancers  0   4
----

=== Expose TCP Service

You can expose your applications over an external LoadBalancer service, enabling access over the public Internet.

----
$ oc expose dc httpd-example --type=LoadBalancer --name=lb-service
service/lb-service exposed
----

=== Create an Internal-Only TCP Service

You can alternatively expose your applications internally only, enabling access only through AWS VPC Peering or a VPN connection.

----
$ oc expose dc httpd-example --type=LoadBalancer --name=internal-lb --dry-run -o yaml | awk '1;/metadata:/{ print "  annotations:\n    service.beta.kubernetes.io/aws-load-balancer-internal: 0.0.0.0/0" }' | oc create -f -
service/internal-lb exposed
----

=== Use your TCP Service

Once your LoadBalancer service is created, you can access your service by using the URL provided to you by {product-title}.
The `LoadBalancer Ingress` value is a URL unique to your service that remains static as long as the service is not deleted.
If you prefer to use a custom domain, you can create a CNAME DNS record for this URL.

----
$ oc describe svc lb-service
Name:                     lb-service
Namespace:                default
Labels:                   app=httpd-example
Annotations:              <none>
Selector:                 name=httpd-example
Type:                     LoadBalancer
IP:                       10.120.182.252
LoadBalancer Ingress:     a5387ba36201e11e9ba901267fd7abb0-1406434805.us-east-1.elb.amazonaws.com
Port:                     <unset>  8080/TCP
TargetPort:               8080/TCP
NodePort:                 <unset>  31409/TCP
Endpoints:                <none>
Session Affinity:         None
External Traffic Policy:  Cluster
----
endif::[]

ifdef::openshift-aro[]
[[expose-tcp-services]]
== Expose TCP Services

{product-title} xref:../architecture/networking/routes.adoc#architecture-core-concepts-routes[routes] expose applications by proxying traffic through HTTP/HTTPS(SNI)/TLS(SNI)
to xref:../architecture/core_concepts/pods_and_services.adoc#architecture-core-concepts-pods-and-services[pods and services]. A link:https://kubernetes.io/docs/concepts/services-networking/#loadbalancer[LoadBalancer]
service creates an Azure Elastic Load Balancer (ELB) for your {product-title} cluster, enabling direct TCP access to applications exposed by your LoadBalancer service.

=== Check your LoadBalancer Quota

----
$ oc describe clusterresourcequota service-loadbalancers
Name:       service-loadbalancers
Labels:     <none>
Annotations:    <none>
Resource        Used    Hard
--------        ----    ----
services.loadbalancers  0   4
----

=== Expose TCP Service

You can expose your applications over an external LoadBalancer service, enabling access over the public Internet.

----
$ oc expose dc httpd-example --type=LoadBalancer --name=lb-service
service/lb-service exposed
----

=== Create an Internal-Only TCP Service

You can alternatively expose your applications internally only, enabling access only through Azure VNet Peering.

----
$ oc expose dc httpd-example --type=LoadBalancer --name=internal-lb --dry-run -o yaml | awk '1;/metadata:/{ print "  annotations:\n    service.beta.kubernetes.io/azure-load-balancer-internal: \"true\"" }' | oc create -f -
service/internal-lb exposed
----

=== Use your TCP Service

Once your LoadBalancer service is created, you can access your service by using the IP provided to you by {product-title}.
The `LoadBalancer Ingress` value is a URL unique to your service that remains static as long as the service is not deleted.
You can specify an Azure DNS label for the service using the service.beta.kubernetes.io/azure-dns-label-name annotation.
If you prefer to use a custom domain, you can create a CNAME DNS record for this URL.

----
$ oc describe svc internal-lb
Name:                     internal-lb
Namespace:                cake
Labels:                   app=cakephp-mysql-persistent
                          template=cakephp-mysql-persistent
                          template.openshift.io/template-instance-owner=3a53eabd-6b11-11e9-948c-000d3ab9a700
Annotations:              service.beta.kubernetes.io/azure-load-balancer-internal=0.0.0.0/0
Selector:                 name=cakephp-mysql-persistent
Type:                     LoadBalancer
IP:                       172.30.166.170
LoadBalancer Ingress:     52.155.223.79
Port:                     <unset>  8080/TCP
TargetPort:               8080/TCP
NodePort:                 <unset>  30823/TCP
Endpoints:                10.128.2.9:8080
Session Affinity:         None
External Traffic Policy:  Cluster
----
endif::[]

ifdef::openshift-dedicated[]
[[access-your-cluster-monitoring-tools]]
== {product-title} monitoring tools

{product-title} relies on three systems for providing important monitoring and cluster information to customers.

[[access-your-cluster-dedicated-portal]]
=== Access your {product-title} portal

The first system is the link:https://dedicated.openshift.com[{product-title} Portal]. This provides customers
an overview of cluster information, including: utilized memory, utilized CPU, number of users, number of projects,
subscription information, and maintenance information. Our SRE team also uses the {product-title} Portal for
scheduling and controlling maintenance events for clusters. The {product-title} Portal is responsible for
emailing *Customer Admins*, a group that can manage other users for an organization, when a maintenance event is available to be scheduled. It can also be used
by Customer Admins to invite other users to view the clusters on the Dedicated Portal.

[NOTE]
====
The memory and CPU metrics displayed on the {product-title} Portal represent current machine usage and do not reflect actual schedulable resource availability.
====

[[access-your-cluster-status-updates]]
=== Receive status updates

The second system is the link:https://status-dedicated.openshift.com/[Status Portal] powered by
link:https://www.statuspage.io/[StatusPage]. There is an API link between the {product-title} Portal
and the Status Portal that allows maintenance events created and updated in the {product-title} Portal
to be reflected in the Status Portal. Once a maintenance event is created and scheduled in the
{product-title} Portal, the Status Portal is responsible for all emails related to that maintenance
event going forward. The Status Portal can also be used manually for sending customers important information
about their cluster, e.g., logging space low or expiring certificates.

You were initially invited to the Status Portal as part of the on-boarding process, and you should have
received an invitation email. If your email has already been invited, you can also subscribe to notifications
via, SMS, or RSS by changing your preferences in the Status Portal. To request additional emails be invited to
the Status Portal, please create a support case requesting this.

[NOTE]
====
If a mailing list is specified as a Status Portal subscriber, it's possible that anyone on the mailing list may inadvertently unsubscribe
the entire mailing list from receiving status updates. It is the customer's responsibility to ensure that we always have at least one subscribed
customer contact in the Status Portal.
====

[[access-your-cluster-grafana-dashboard]]
=== Viewing cluster requests and limits

Finally, the third system is the built-in {product-title} Grafana dashboard. You can access the Grafana dashboard from the
xref:./dedicated_administrators.adoc#gs-dedicated-admin-accessing-cluster-administrator-console[Cluster Administrator console],
under the Monitoring -> Dashboards navigation link. This provides you with current and historical metrics regarding memory and CPU requests
and limits with cluster-wide, node, namespace, and pod granularity.

[[access-your-cluster-support]]
== Request support

If you have questions about your environment or need to open a support ticket, you can open or view a support case in the link:https://access.redhat.com/support/cases/#/case/list[Red Hat Customer
Portal].
endif::[]

ifdef::openshift-aro[]
[[access-your-cluster-status-updates]]
== Receive status updates

Overall service status/health information is available at link:https://azure.microsoft.com/en-us/status/[].

[[access-your-cluster-support]]
== Request support

If you have questions about your environment or need to open a Microsoft Azure support ticket,
you can open or view a support case in the
link:https://support.microsoft.com/en-us/help/4026305/sql-contact-microsoft-azure-support[Microsoft Azure Support
Portal].
endif::[]

[[access-your-cluster-next-steps]]
== Next steps

You can download the {product-title} command line tools from your clusterâ€™s
xref:../architecture/infrastructure_components/web_console.adoc#web-console-cli-downloads[web
console]. For help getting started with command line tools, see the
xref:../cli_reference/get_started_cli.adoc#cli-reference-get-started-cli[Get
Started with the CLI guide]. You can also visit the
xref:../getting_started/developers_console.adoc#getting-started-developers-console[Getting
Started Guide for developers].

{cluster-admin-name}s should view the
xref:../admin_guide/index.adoc#admin-guide-index[Cluster Administration
Overview] for detailed information on available roles and permissions. This
section also includes important topics such as
xref:../admin_guide/quota.adoc#admin-guide-quota[managing
quotas] and xref:../admin_guide/service_accounts.adoc#admin-guide-service-accounts[configuring service
accounts].

ifdef::openshift-aro[]
All {product-title} clusters are configured using the NetworkPolicy SDN.
Project admins can set NetworkPolicy objects on their projects.
Cluster admins can also set EgressNetworkPolicies.

endif::[]

ifdef::openshift-dedicated[]
If your cluster has been configured with the
xref:../admin_guide/managing_networking.adoc#admin-guide-networking-networkpolicy[NetworkPolicy
SDN], {product-title} administrators are able to create and modify NetworkPolicy
objects. NetworkPolicy, by default, allows traffic communication between
projects. Denying traffic between projects can be enabled by the creation of two
xref:../admin_guide/managing_networking.adoc#admin-guide-networking-networkpolicy-setting-default[NetworkPolicy
objects].
endif::[]
