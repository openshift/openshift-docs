[id="ocp-4-4-release-notes"]
= {product-title} {product-version} release notes
include::modules/common-attributes.adoc[]
:context: release-notes

toc::[]

Red Hat {product-title} provides developers and IT organizations with a hybrid
cloud application platform for deploying both new and existing applications on
secure, scalable resources with minimal configuration and management overhead.
{product-title} supports a wide selection of programming languages and
frameworks, such as Java, JavaScript, Python, Ruby, and PHP.

Built on Red Hat Enterprise Linux and Kubernetes, {product-title}
provides a more secure and scalable multi-tenant operating system for todayâ€™s
enterprise-class applications, while delivering integrated application runtimes
and libraries. {product-title} enables organizations to meet security, privacy,
compliance, and governance requirements.

[id="ocp-4-4-about-this-release"]
== About this release

// Copied from 4.3; update when more information is available.

Red Hat {product-title}
(link:https://access.redhat.com/errata/RHBA-2020:0581[RHBA-2020:0581]) is now
available. This release uses link:https://v1-17.docs.kubernetes.io/docs/setup/release/notes/[Kubernetes 1.17] with CRI-O runtime. New features, changes, and known issues that pertain to
{product-title} {product-version} are included in this topic.

{product-title} {product-version} clusters are available at
https://cloud.redhat.com/openshift. The {cloud-redhat-com}
application for {product-title} allows you to deploy OpenShift clusters to
either on-premise or cloud environments.

{product-title} {product-version} is supported on Red Hat Enterprise Linux 7.6 or
later, as well as {op-system-first} 4.4.

You must use {op-system} for the control plane, which are also known as master machines, and
can use either {op-system} or Red Hat Enterprise Linux 7.6 or later for
compute machines, which are also known as worker machines.

[IMPORTANT]
====
Because only Red Hat Enterprise Linux version 7.6 or later is supported for compute
machines, you must not upgrade the Red Hat Enterprise Linux compute machines to
version 8.
====

[id="ocp-4-4-new-features-and-enhancements"]
== New features and enhancements

This release adds improvements related to the following components and concepts.

[id="ocp-4-4-installation-and-upgrade"]
=== Installation and upgrade

[id="ocp-4-4-installing-cluster-on-azure-upi"]
==== Installing a cluster on Microsoft Azure using user-provisioned infrastructure

{product-title} 4.4 introduces support for installing a cluster on Azure using
user-provisioned infrastructure. Running user-provisioned infrastructure on
Azure lets you use customizations your environment might require, like
regulatory, security, and operational control.

You can incorporate example Azure Resource Manager (ARM) templates provided by
Red Hat to assist in the deployment process, or create your own. You are also
free to create the required resources through other methods; the ARM templates
are just an example.

See xref:../installing/installing_azure/installing-azure-user-infra.adoc#installing-azure-user-infra[Installing a cluster on Azure using ARM templates]
for details.

[id="ocp-4-4-installing-cluster-on-openstack-upi"]
==== Installing a cluster on OpenStack using user-provisioned infrastructure

{product-title} 4.4 introduces support for installing a cluster on
{rh-openstack-first} that runs on infrastructure that you provide.
Using your own infrastructure allows you to integrate your cluster with existing
infrastructure and modifications. For example, you must create all
{rh-openstack} resources, like Nova servers, Neutron ports, and security groups.
Red Hat provides Ansible playbooks to help you with the deployment process.

You can also install a cluster on {rh-openstack} with Kuryr using your own
infrastructure.

// Incorporate links when available:
//../installing/installing_openstack/installing-openstack-user.adoc#installing-openstack-user[Installing a cluster on OpenStack on your own infrastructure]
//../installing/installing_openstack/installing-openstack-user-kuryr.adoc#installing-openstack-user-kuryr[Installing a cluster on OpenStack with Kuryr on your own infrastructure]

[id="ocp-4-4-installing-cluster-on-openstack-no-longer-requires-swift-storage-service"]
==== Installing a cluster on OpenStack no longer requires the Swift object storage service

Beginning with version 4.4, {product-title} no longer requires that the Swift
object storage service be present on the {rh-openstack} cloud where it is
installed. If Swift is not available for the {product-title} installation, the
installer uses the Cinder block storage and Glance image registry services in
its place.

//For more information, see Installing a cluster on OpenStack using your own infrastructure (link when published).

[id="ocp-4-4-clusters-installed-on-openstack-support-self-signed-certs"]
==== Clusters installed on OpenStack support self-signed certificates

{product-title} 4.4 can now be installed on {rh-openstack} clouds that use
self-signed certificates for authorization.

//For more information, see Installing a cluster on OpenStack using your own infrastructure (link when published).

[id="ocp-4-4-security"]
=== Security

[id="ocp-4-4-bound-service-account-tokens"]
==== Support for bound service account tokens

{product-title} 4.4 provides support for bound service account tokens, which improves the ability to integrate with cloud provider identity access management (IAM) services, such as AWS IAM.

For more information, see xref:../authentication/bound-service-account-tokens.adoc#bound-service-account-tokens[Using bound service account tokens].

[id="ocp-4-4-kube-apiserver-check-certs-before-tokens"]
==== kube-apiserver checks client certificates before tokens

In previous versions of {product-title}, the kube-apiserver checked tokens
before client certificates for authentication. Now kube-apiserver checks client
certificates before tokens.

For example, if you had a `system:admin` kubeconfig and ran the `oc --token=foo get pod`
command in previous versions of {product-title}, it would authenticate as a user
with token `foo`. Now it authenticates as `system:admin`. The recommendation for
past releases was to impersonate a user with the parameter `--as` in such cases
instead of overriding the token when using a client certificate; this is no
longer necessary.

[id="ocp-4-4-nodes"]
=== Nodes

[id="ocp-4-4-evicting-pods-using-descheduler-tp"]
==== Evicting Pods using the descheduler (Technology Preview)

The descheduler provides the ability to evict a running Pod so that the Pod can
be rescheduled onto a more suitable node.

You can benefit from descheduling Pods in situations such as the following:

* Nodes are underutilized or overutilized.
* Pod and node affinity requirements, such as taints or labels, have changed and
the original scheduling decisions are no longer appropriate for certain nodes.
* Node failure requires Pods to be moved.
* New nodes are added to clusters.

See xref:../nodes/scheduling/nodes-descheduler.adoc#nodes-descheduler[Evicting Pods using the descheduler]
for more information.

[id="ocp-4-4-cluster-monitoring"]
=== Cluster monitoring

[id="ocp-4-4-monitoring-dashboards-in-web-console"]
==== Monitoring Dashboards in web console

The Dashboards view is now available from the Monitoring section in the web
console. This lets you view metrics that bring transparency to the
{product-title} cluster and its dependent components.

[id="ocp-4-4-logging"]
=== Logging

[id="ocp-4-4-web-console"]
=== Web console

[id="ocp-4-4-marketplace-integration-in-operator-hub"]
==== IBM Marketplace integration in OperatorHub

IBM Marketplace is now integrated with the OperatorHub, which is located in the
{product-title} web console. This integration allows you to install and manage
Operators hosted on the IBM Marketplace from within the OperatorHub interface.

[id="ocp-4-4-edit-apps-in-topology-view"]
==== Edit applications in the Topology view

You can now edit applications from the Developer perspective by using the
Topology view.

[id="ocp-4-4-create-helm-releases"]
==== Create Helm releases

You can now create Helm releases from the Helm charts that are provided in the
Developer Catalog.

[id="ocp-4-4-networking"]
=== Networking

////
[id="ocp-4-4-sctp-on-ocp"]
==== Stream Control Transmission Protocol (SCTP) on {product-title}

SCTP is a reliable message based protocol that runs on top of an IP network.
When enabled, you can use SCTP as a protocol with both Pods and Services.

//For more information, see
//../networking/using-sctp.adoc#using-sctp[Using SCTP].
////

[id="ocp-4-4-storage"]
=== Storage

[id="ocp-4-4-persistent-storage-csi-snapshots"]
==== Persistent storage using CSI snapshots (Technology Preview)

You can now use the Container Storage Interface (CSI) to create, restore, and delete a volume snapshot. This feature is enabled by default in Technology Preview.

[id="ocp-4-4-persistent-storage-csi-cloning"]
==== Persistent storage using CSI cloning (Technology Preview)

You can now use the Container Storage Interface (CSI) to clone storage volumes after they have already been created. This feature is enabled by default in Technology Preview.

[id="ocp-4-4-scale"]
=== Scale

[id="ocp-4-4-scale-cluster-maximums"]
==== Cluster maximums

Updated guidance around
xref:../scalability_and_performance/planning-your-environment-according-to-object-maximums.adoc#planning-your-environment-according-to-object-maximums[Cluster
maximums] for {product-title} {product-version} is now available.

The {product-version} tested maximum for the number of Pods per node is 500.

Use the link:https://access.redhat.com/labs/ocplimitscalculator/[{product-title}
Limit Calculator] to estimate cluster limits for your environment.

[id="ocp-4-4-operators"]
=== Operators

[id="ocp-4-4-etcd-cluster-operator"]
==== etcd cluster Operator

{product-title} 4.4 introduces the etcd cluster Operator, which handles the scaling of etcd and provisioning etcd dependencies such as TLS certificates. The etcd cluster Operator simplifies the disaster recovery procedure to restore to a previous cluster state, automates the addition of etcd members, provides more accurate etcd member health reporting, and reports events to assist with debugging the etcd cluster.

With this update, the names of the following disaster recovery scripts were changed:

* `etcd-snapshot-backup.sh` is now `cluster-backup.sh`.
* `etcd-snapshot-restore.sh` is now `cluster-restore.sh`.

For more information, see xref:../backup_and_restore/disaster_recovery/about-disaster-recovery.adoc#about-dr[About disaster recovery].

[id="ocp-4-4-insights-operator-anonymized-csr"]
==== The Insights Operator now collects anonymized CSRs

With this enhancement, the Insights Operator periodically collects anonymized
certificate signing requests (CSR) to identify CSRs that are not verified in
Kubernetes or have not been approved. Additionally, the Insights Operator collects
data if certificates are valid. As a result, this helps improve the {product-title}
customer support experience.

[id="ocp-4-4-remove-samples-operator-when-unable-to-connect"]
==== Remove Samples Operator if it cannot connect to registry.redhat.io

Sample imagestreams are not created if the Samples Operator cannot connect to
`registry.redhat.io` during installation. This ensures that sample content
installation does not fail {product-title} cluster installation.

You can xref:../openshift_images/samples-operator-alt-registry.adoc#installation-restricted-network-samples_samples-operator-alt-registry[configure alternate or mirrored registries]
to bypass this issue if it arises during your cluster installation.

[id="ocp-4-4-notable-technical-changes"]
== Notable technical changes

{product-title} 4.4 introduces the following notable technical changes.

[discrete]
[id="ocp-4-4-sending-cluster-logs-using-fluent-syslog-plug-in"]
=== Sending cluster logs using the Fluentd syslog plug-in (RFC 3164)

Due to changes introduced with the Log Forwarding feature in {product-title}
4.3, you could no longer use the Fluentd syslog plug-in to forward logs to an
external syslog server. In {product-title} 4.4, this functionality is restored
and you can use the syslog plug-in. The procedure to configure the plug-in is
different in {product-title} version 4.4 than it was in version 4.2. For more
information, see
xref:../logging/config/cluster-logging-external.adoc#cluster-logging-collector-syslog_cluster-logging-external[Sending logs using the Fluentd syslog plug-in (RFC 3164)].

[id="ocp-4-4-unsupported-features"]
=== Unsupported features

[id="ocp-4-4-oc-secrets-subcommands"]
==== OpenShift CLI secrets subcommands

The following `oc secrets` subcommands that were deprecated in {product-title}
3.9 are no longer available:

* `new`
* `new-basicauth`
* `new-dockercfg`
* `new-sshauth`

You must use the `oc create secret` command instead.

[id="ocp-4-4-oc-build-logs-command"]
==== OpenShift CLI build-logs command

The `oc build-logs` command was deprecated in {product-title} 3.11 and has been
removed. You must use `oc logs` instead.

[id="ocp-4-4-deprecated-features"]
=== Deprecated features

[id="ocp-4-4-oc-config-flag"]
==== OpenShift CLI config flag

The `--config` flag used with `oc` is deprecated. You should start using the
`--kubeconfig` flag instead.

[id="ocp-4-4-oc-timeout-flag"]
==== OpenShift CLI timeout flag

The `--timeout` flag used with `oc rsh` is deprecated. You should start using
the `--request-timeout` flag instead.

[id="ocp-4-4-oc-editor"]
==== OpenShift editor

The `OS_EDITOR` is deprecated. Users should start using `KUBE_EDITOR` or
`EDITOR` instead.

[id="ocp-4-4-machinecidr-network-param"]
==== machineCIDR network parameter

The `machineCIDR` network parameter used in the `install-config.yaml` file is
now deprecated. You should use `machineNetwork.cidr` instead.

[id="ocp-4-4-deprecation-of-operatorsources"]
==== Deprecation of OperatorSources, CatalogSourceConfigs, and packaging format

[id="ocp-4-4-marketplace-apis-deprecated"]
OperatorSources and CatalogSourceConfigs are deprecated from OperatorHub. The
following related APIs will be removed in a future release:

* `operatorsources.operators.coreos.com/v1`
* `catalogsourceconfigs.operators.coreos.com/v2`
* `catalogsourceconfigs.operators.coreos.com/v1`

The Operator Framework's current packaging format is also being deprecated in a
future release, to be replaced by a new bundle format. As a result, the
following command will also be deprecated at that time:

* `oc adm catalog build`

For more information on the upcoming new Operator bundle format and Operator
Package Manager CLI (`opm`), see the link:https://docs.okd.io/latest/operators/understanding_olm/olm-understanding-olm.html#olm-new-bundle-opm_olm-understanding-olm[upstream OKD documentation].

[id="ocp-4-4-bug-fixes"]
== Bug fixes

[id="ocp-4-4-technology-preview"]
== Technology Preview features

Some features in this release are currently in Technology Preview. These
experimental features are not intended for production use. Note the
following scope of support on the Red Hat Customer Portal for these features:

link:https://access.redhat.com/support/offerings/techpreview[Technology Preview
Features Support Scope]

In the table below, features are marked with the following statuses:

* *TP*: _Technology Preview_
* *GA*: _General Availability_
* *-*: Deprecated or removed from the release
* *Blank*: Not available and was released as a new feature later

.Technology Preview Tracker
[cols="4",options="header"]
|====
|Feature |OCP 4.2 |OCP 4.3 |OCP 4.4

|Prometheus Cluster Monitoring
|GA
|GA
|GA

|Precision Time Protocol (PTP)
|-
|TP
|

|CRI-O for runtime Pods
|GA
|GA
|GA

|`oc` CLI Plug-ins
|TP
|TP
|

|Service Catalog
|GA
|-
|-

|Template Service Broker
|GA
|-
|-

|OpenShift Ansible Service Broker
|GA
|-
|-

|Network Policy
|GA
|GA
|GA

|Multus
|GA
|GA
|GA

|New Add Project Flow
|GA
|GA
|GA

|Search Catalog
|GA
|GA
|GA

|Cron Jobs
|GA
|GA
|GA

|Kubernetes Deployments
|GA
|GA
|GA

|StatefulSets
|GA
|GA
|GA

|Explicit Quota
|GA
|GA
|GA

|Mount Options
|GA
|GA
|GA

|System Containers for Docker, CRI-O
|-
|-
|-

|Hawkular Agent
|-
|-
|-

|Pod PreSets
|-
|-
|-

|experimental-qos-reserved
|TP
|TP
|

|Pod sysctls
|GA
|GA
|GA

|Central Audit
|-
|-
|-

|Static IPs for External Project Traffic
|GA
|GA
|GA

|Template Completion Detection
|GA
|GA
|GA

|`replicaSet`
|GA
|GA
|GA

|Clustered MongoDB Template
|-
|-
|-

|Clustered MySQL Template
|-
|-
|-

|ImageStreams with Kubernetes Resources
|GA
|GA
|GA

|Device Manager
|GA
|GA
|GA

|Persistent Volume Resize
|GA
|GA
|GA

|Huge Pages
|GA
|GA
|GA

|CPU Pinning
|GA
|GA
|GA

|Admission Webhooks
|GA
|GA
|GA

|External provisioner for AWS EFS
|TP
|TP
|TP

|Pod Unidler
|TP
|TP
|

|Node Problem Detector
|TP
|TP
|

|Ephemeral Storage Limit/Requests
|TP
|TP
|

|Descheduler
|-
|-
|TP

|CephFS Provisioner
|-
|-
|-

|Podman
|TP
|TP
|

|Kuryr CNI Plug-in
|TP
|GA
|GA

|Sharing Control of the PID Namespace
|TP
|TP
|

|Manila Provisioner
|-
|-
|-

|Cluster Administrator console
|GA
|GA
|GA

|Cluster Autoscaling
|GA
|GA
|GA

|Container Storage Interface (CSI)
|GA
|GA
|GA

|Operator Lifecycle Manager
|GA
|GA
|GA

|Red Hat OpenShift Service Mesh
|GA
|GA
|GA

|"Fully Automatic" Egress IPs
|GA
|GA
|GA

|Pod Priority and Preemption
|GA
|GA
|GA

|Multi-stage builds in Dockerfiles
|GA
|GA
|GA

|OVN-Kubernetes Pod network provider
|TP
|TP
|TP

|HPA custom metrics adapter based on Prometheus
|TP
|TP
|

|Machine health checks
|TP
|GA
|GA

|Persistent Storage with iSCSI
|TP
|GA
|GA

|Raw Block with iSCSI
|TP
|GA
|GA

|Raw Block with Cinder
|
|TP
|TP

|OperatorHub
|GA
|GA
|GA

|Three-node bare metal deployments
|TP
|TP
|

|SR-IOV Network Operator
|TP
|GA
|GA

|Helm CLI
|
|TP
|GA

|Service Binding
|
|TP
|

|Log forwarding
|
|TP
|

|User workload monitoring
|
|TP
|TP

|OpenShift Serverless
|TP
|TP
|

|Compute Node Topology Manager
|
|TP
|

|CSI volume snapshots
|
|
|TP

|CSI volume cloning
|
|
|TP

|====

[id="ocp-4-4-known-issues"]
== Known issues

* There is an issue with the Machine Config Operator (MCO) supporting Day 2
proxy support, which describes when an existing non-proxied
cluster is reconfigured to use a proxy. The MCO should apply newly configured
proxy CA certificates in a ConfigMap to the {op-system} trust bundle; this is
not working. As a workaround, you must manually add the proxy CA certificate to
your trust bundle and then update the trust bundle:
+
----
$ cp /opt/registry/certs/<my_root_ca>.crt /etc/pki/ca-trust/source/anchors/
$ update-ca-trust extract
$ oc adm drain <node>
$ systemctl reboot
----
+
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1784201[*BZ#1784201*])

* When using a self-signed {rh-openstack-first} 16 cluster, you cannot pull from
or push to an internal image registry. As a workaround, you must set
`spec.disableRedirects = true` in the `configs.imageregistry/cluster` resource.
This allows the client to pull the image layers from the image registry rather
than from links directly from Swift.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1810461[*BZ#1810461*])

* The cluster proxy configuration `HTTP_PROXY` is only available for
{product-title} components, not user applications. As a workaround, you must run
the following command to enable cluster proxy configuration for user
applications:
+
----
$ oc set env dc/jenkins \
    http_proxy=$(oc get proxy cluster -o jsonpath='{.status.httpProxy}') \
    https_proxy=$(oc get proxy cluster -o jsonpath='{.status.httpsProxy}') \
    no_proxy=$(oc get proxy cluster -o jsonpath='{.status.noProxy}')
----
+
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1780125[*BZ#1780125*])

* All `git clone` operations that go through an HTTPS proxy fail. HTTP proxies
can be used successfully.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1750650[*BZ#1750650*])

* All `git clone` operations fail in builds running behind a proxy if the source
URIs use the `git://` or `ssh://` scheme.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1751738[*BZ#1751738*])

* When using a mirror to build images, the build fails when the pull secret for
the mirror registry only links to the builder service account. The pull secret
must also link to the build config object.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1810904[*BZ#1810904*])

* In {rh-openstack-first} 13 with Kuryr, if FIPS is disabled, you cannot enable
the service catalog. The `controller-manager` and `apiserver` Pods show a status
of `CrashLoopBackOff`.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1821589[*BZ#1821589*])

* Installing {rh-openstack} 16 with Kuryr does not work due to the
`ovn_controller` crashing after initial setup.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1812009[*BZ#1812009*])

* The Red Hat Virtualization (RHV) machine `instance-state` annotation and the
`providerStatus.instanceState` status do not always match. This mismatch causes
the client to fail or incorrectly patch the RHV machine status.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1815394[*BZ#1815394*])

* When scaling up a MachineSet on RHV, the new machine cannot exit the
`Provisioned` phase. This causes the machine to never run.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1815435[*BZ#1815435*], link:https://bugzilla.redhat.com/show_bug.cgi?id=1817853[*BZ#1817853*])

* {product-title} cluster autoscaling on RHV fails due to cluster resource
computation errors.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1822118[*BZ#1822118*])
