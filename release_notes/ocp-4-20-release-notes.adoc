:_mod-docs-content-type: ASSEMBLY
[id="ocp-4-20-release-notes"]
= {product-title} {product-version} release notes
include::_attributes/common-attributes.adoc[]
:context: release-notes

toc::[]

Red{nbsp}Hat {product-title} provides developers and IT organizations with a hybrid cloud application platform for deploying both new and existing applications on secure, scalable resources with minimal configuration and management. {product-title} supports a wide selection of programming languages and frameworks, such as Java, JavaScript, Python, Ruby, and PHP.

Built on {op-system-base-full} and Kubernetes, {product-title} provides a more secure and scalable multitenant operating system for today's enterprise-class applications, while delivering integrated application runtimes and libraries. {product-title} enables organizations to meet security, privacy, compliance, and governance requirements.

[id="ocp-4-20-about-this-release_{context}"]
== About this release

// TODO: Update with the relevant information closer to release.
{product-title} (link:https://access.redhat.com/errata/RHSA-202X:XXXX[RHSA-202X:XXXXX]) is now available. This release uses link:https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.33.md[Kubernetes 1.33] with CRI-O runtime. New features, changes, and known issues that pertain to {product-title} {product-version} are included in this topic.

{product-title} {product-version} clusters are available at https://console.redhat.com/openshift. From the {hybrid-console}, you can deploy {product-title} clusters to either on-premises or cloud environments.

You must use {op-system} machines for the control plane and for the compute machines.
//Removed the note per https://issues.redhat.com/browse/GRPA-3517
//Removed paragraph about the RHEL package because mode workers are removed from 4.19, per Scott Dodson
//Even-numbered release lifecycle verbiage (Comment in for even-numbered releases)

Starting from {product-title} 4.14, the Extended Update Support (EUS) phase for even-numbered releases increases the total available lifecycle to 24 months on all supported architectures, including `x86_64`, 64-bit ARM (`aarch64`), {ibm-power-name} (`ppc64le`), and {ibm-z-name} (`s390x`) architectures. Beyond this, Red{nbsp}Hat also offers a 12-month additional EUS add-on, denoted as _Additional EUS Term 2_, that extends the total available lifecycle from 24 months to 36 months. The Additional EUS Term 2 is available on all architecture variants of {product-title}. For more information about support for all versions, see the link:https://access.redhat.com/support/policy/updates/openshift[Red Hat {product-title} Life Cycle Policy].

//Odd-numbered release lifecycle verbiage (Comment in for odd-numbered releases)
////
The support lifecycle for odd-numbered releases, such as {product-title} {product-version}, on all supported architectures, including `x86_64`, 64-bit ARM (`aarch64`), {ibm-power-name} (`ppc64le`), and {ibm-z-name} (`s390x`) architectures is 18 months. For more information about support for all versions, see the link:https://access.redhat.com/support/policy/updates/openshift[Red Hat {product-title} Life Cycle Policy].

Commencing with the {product-title} 4.14 release, Red{nbsp}Hat is simplifying the administration and management of Red{nbsp}Hat shipped cluster Operators with the introduction of three new life cycle classifications; Platform Aligned, Platform Agnostic, and Rolling Stream. These life cycle classifications provide additional ease and transparency for cluster administrators to understand the life cycle policies of each Operator and form cluster maintenance and upgrade plans with predictable support boundaries. For more information, see link:https://access.redhat.com/webassets/avalon/j/includes/session/scribe/?redirectTo=https%3A%2F%2Faccess.redhat.com%2Fsupport%2Fpolicy%2Fupdates%2Fopenshift_operators[OpenShift Operator Life Cycles].
////

// Added in 4.14. Language came directly from Kirsten Newcomer.
{product-title} is designed for FIPS. When running {op-system-base-full} or {op-system-first} booted in FIPS mode, {product-title} core components use the {op-system-base} cryptographic libraries that have been submitted to NIST for FIPS 140-2/140-3 Validation on only the `x86_64`, `ppc64le`, and `s390x` architectures.

For more information about the NIST validation program, see link:https://csrc.nist.gov/Projects/cryptographic-module-validation-program/validated-modules[Cryptographic Module Validation Program]. For the latest NIST status for the individual versions of {op-system-base} cryptographic libraries that have been submitted for validation, see link:https://access.redhat.com/articles/2918071#fips-140-2-and-fips-140-3-2[Compliance Activities and Government Standards].

[id="ocp-4-20-add-on-support-status_{context}"]
== {product-title} layered and dependent component support and compatibility

The scope of support for layered and dependent components of {product-title} changes independently of the {product-title} version. To determine the current support status and compatibility for an add-on, refer to its release notes. For more information, see the link:https://access.redhat.com/support/policy/updates/openshift[Red Hat {product-title} Life Cycle Policy].

[id="ocp-4-20-new-features-and-enhancements_{context}"]
== New features and enhancements

This release adds improvements related to the following components and concepts:

[id="ocp-release-notes-api_{context}"]
=== API server

==== Extended loopback certificate validity to three years for kube-apiserver

Before this update, the self-signed loopback certificate for the Kubernetes API Server expired after one year. With this release, the expiration date of the certificate is extended to three years.

==== Dry-run option is connected to 'oc delete istag'

Before this update, deleting an `istag` resource with the `--dry-run=server` option unintentionally caused actual deletion of the image from the server. This unexpected deletion occurred due to the `dry-run` option being implemented incorrectly in the `oc delete istag` command. With this release, the `dry-run` option is wired to the `oc delete istag` command. As a result, the accidental deletion of image objects is prevented and the `istag` object remains intact when using the `--dry-run=server` option.

[id="ocp-release-notes-auth_{context}"]
=== Authentication and authorization

[id="ocp-release-notes-documentation_{context}"]
=== Documentation

[id="ocp-release-notes-edge-computing_{context}"]
=== Edge computing

[id="ocp-release-edge-computing-networkpolicy-support-for-lvms_{context}"]
==== NetworkPolicy support for the {lvms} Operator

The {lvms} Operator now applies Kubernetes `NetworkPolicy` objects during installation to restrict network communication to only the required components. This feature enforces default network isolation for {lvms} deployments on {product-title} clusters.

[id="ocp-release-edge-computing-hostname-label-for-pv_{context}"]
==== Support for hostname labelling for persistent volumes created by using the {lvms} Operator

When you create a persistent volume (PV) by using the {lvms} Operator, the PV now includes the `kubernetes.io/hostname` label. This label shows which node the PV is located on, making it easier to identify the node associated with a workload. This change only applies to newly created PVs. Existing PVs are not modified.

[id="ocp-release-edge-computing-default-namespace_{context}"]
==== Default namespace for the {lvms} Operator

The default namespace for the {lvms} Operator is now `openshift-lvm-storage`. You can still install {lvms} in a custom namespace.

[id="ocp-release-edge-computing-default-clusterinstance_{context}"]
==== SiteConfig CR to ClusterInstance CR migration tool

{product-title} {product-version} introduces the `siteconfig-converter` tool to help migrate managed clusters from using a `SiteConfig` custom resource (CR) to a `ClusterInstance` CR. Using a `SiteConfig` CR to define a managed cluster is deprecated and will be removed in a future release. The `ClusterInstance` CR provides a more unified and generic approach to defining clusters and is the preferred method for managing cluster deployments in the {ztp} workflow.

Using the `siteconfig-converter` tool, you can convert `SiteConfig` CRs to `ClusterInstance` CRs and then incrementally migrate one or more clusters at a time. Existing and new pipelines run in parallel, so you can migrate clusters in a controlled, phased manner and without downtime.

[NOTE]
====
The `siteconfig-converter` tool does not convert SiteConfig CRs that use the deprecated `spec.clusters.extraManifestPath` field.
====

For more information, see xref:../edge_computing/ztp-migrate-clusterinstance.adoc#ztp-migrate-clusterinstance[Migrating from SiteConfig CRs to ClusterInstance CRs].

[id="ocp-release-notes-extensions_{context}"]
=== Extensions ({olmv1})

[id="ocp-release-notes-hcp_{context}"]
=== Hosted control planes

Because {hcp} releases asynchronously from {product-title}, it has its own release notes. For more information, see xref:../hosted_control_planes/hosted-control-planes-release-notes.adoc#hosted-control-planes-release-notes[{hcp-capital} release notes].

[id="ocp-release-notes-ibm-power_{context}"]
=== {ibm-power-title}

The {ibm-power-name} release on {product-title} {product-version} adds improvements and new capabilities to {product-title} components.

This release introduces support for the following features on {ibm-power-title}:

[id="ocp-release-notes-ibm-z_{context}"]
=== {ibm-z-title} and {ibm-linuxone-title}

The {ibm-z-name} and {ibm-linuxone-name} release on {product-title} {product-version} adds improvements and new capabilities to {product-title} components.

This release introduces support for the following features on {ibm-z-name} and {ibm-linuxone-name}:


[id="ocp-release-notes-ibm-z-power-support-matrix_{context}"]
=== {ibm-power-title}, {ibm-z-title}, and {ibm-linuxone-title} support matrix

Starting in {product-title} 4.14, Extended Update Support (EUS) is extended to the {ibm-power-name} and the {ibm-z-name} platform. For more information, see the link:https://access.redhat.com/support/policy/updates/openshift-eus[OpenShift EUS Overview].

.CSI Volumes
[cols="2,1,1",options="header"]
|====
|Feature |{ibm-power-name} |{ibm-z-name} and {ibm-linuxone-name}

|Cloning
|Supported
|Supported

|Expansion
|Supported
|Supported

|Snapshot
|Supported
|Supported
|====

.Multus CNI plugins
[cols="2,1,1",options="header"]
|====
|Feature |{ibm-power-name} |{ibm-z-name} and {ibm-linuxone-name}

|Bridge
|Supported
|Supported

|Host-device
|Supported
|Supported

|IPAM
|Supported
|Supported

|IPVLAN
|Supported
|Supported
|====

.{product-title} features
[cols="3,1,1",options="header"]
|====
|Feature |{ibm-power-name} |{ibm-z-name} and {ibm-linuxone-name}

|Adding compute nodes to on-premise clusters using {oc-first}
|Supported
|Supported

|Alternate authentication providers
|Supported
|Supported

|Agent-based Installer
|Supported
|Supported

|Assisted Installer
|Supported
|Supported

|Automatic Device Discovery with Local Storage Operator
|Unsupported
|Supported

|Automatic repair of damaged machines with machine health checking
|Unsupported
|Unsupported

|Cloud controller manager for {ibm-cloud-name}
|Supported
|Unsupported

|Controlling overcommit and managing container density on nodes
|Unsupported
|Unsupported

|CPU manager
|Supported
|Supported

|Cron jobs
|Supported
|Supported

|Descheduler
|Supported
|Supported

|Egress IP
|Supported
|Supported

|Encrypting data stored in etcd
|Supported
|Supported

|FIPS cryptography
|Supported
|Supported

|Helm
|Supported
|Supported

|Horizontal pod autoscaling
|Supported
|Supported

|Hosted control planes
|Supported
|Supported

|IBM Secure Execution
|Unsupported
|Supported

|Installer-provisioned Infrastructure Enablement for {ibm-power-server-name}
|Supported
|Unsupported

|Installing on a single node
|Supported
|Supported

|IPv6
|Supported
|Supported

|Monitoring for user-defined projects
|Supported
|Supported

|Multi-architecture compute nodes
|Supported
|Supported

|Multi-architecture control plane
|Supported
|Supported

|Multipathing
|Supported
|Supported

|Network-Bound Disk Encryption - External Tang Server
|Supported
|Supported

|Non-volatile memory express drives (NVMe)
|Supported
|Unsupported

|nx-gzip for Power10 (Hardware Acceleration)
|Supported
|Unsupported

|oc-mirror plugin
|Supported
|Supported

|OpenShift CLI (`oc`) plugins
|Supported
|Supported

|Operator API
|Supported
|Supported

|OpenShift Virtualization
|Unsupported
|Supported

|OVN-Kubernetes, including IPsec encryption
|Supported
|Supported

|PodDisruptionBudget
|Supported
|Supported

|Precision Time Protocol (PTP) hardware
|Unsupported
|Unsupported

|{openshift-local-productname}
|Unsupported
|Unsupported

|Scheduler profiles
|Supported
|Supported

|Secure Boot
|Unsupported
|Supported

|Stream Control Transmission Protocol (SCTP)
|Supported
|Supported

|Support for multiple network interfaces
|Supported
|Supported

|The `openshift-install` utility to support various SMT levels on {ibm-power-name} (Hardware Acceleration)
|Supported
|Unsupported

|Three-node cluster support
|Supported
|Supported

|Topology Manager
|Supported
|Unsupported

|z/VM Emulated FBA devices on SCSI disks
|Unsupported
|Supported

|4K FCP block device
|Supported
|Supported
|====

.Operators
[cols="2,1,1",options="header"]
|====
|Feature |{ibm-power-name} |{ibm-z-name} and {ibm-linuxone-name}

|{cert-manager-operator}
|Supported
|Supported

|Cluster Logging Operator
|Supported
|Supported

|Cluster Resource Override Operator
|Supported
|Supported

|Compliance Operator
|Supported
|Supported

|Cost Management Metrics Operator
|Supported
|Supported

|File Integrity Operator
|Supported
|Supported

|HyperShift Operator
|Supported
|Supported

|{ibm-power-server-name} Block CSI Driver Operator
|Supported
|Unsupported

|Ingress Node Firewall Operator
|Supported
|Supported

|Local Storage Operator
|Supported
|Supported

|MetalLB Operator
|Supported
|Supported

|Network Observability Operator
|Supported
|Supported

|NFD Operator
|Supported
|Supported

|NMState Operator
|Supported
|Supported

|OpenShift Elasticsearch Operator
|Supported
|Supported

|Vertical Pod Autoscaler Operator
|Supported
|Supported
|====

.Persistent storage options
[cols="2,1,1",options="header"]
|====
|Feature |{ibm-power-name} |{ibm-z-name} and {ibm-linuxone-name}
|Persistent storage using iSCSI
|Supported ^[1]^
|Supported ^[1]^,^[2]^

|Persistent storage using local volumes (LSO)
|Supported ^[1]^
|Supported ^[1]^,^[2]^

|Persistent storage using hostPath
|Supported ^[1]^
|Supported ^[1]^,^[2]^

|Persistent storage using Fibre Channel
|Supported ^[1]^
|Supported ^[1]^,^[2]^

|Persistent storage using Raw Block
|Supported ^[1]^
|Supported ^[1]^,^[2]^

|Persistent storage using EDEV/FBA
|Supported ^[1]^
|Supported ^[1]^,^[2]^
|====
[.small]
--
1. Persistent shared storage must be provisioned by using either {rh-storage-first} or other supported storage protocols.
2. Persistent non-shared storage must be provisioned by using local storage, such as iSCSI, FC, or by using LSO with DASD, FCP, or EDEV/FBA.
--

[id="ocp-release-notes-insights-operator-enhancements_{context}"]
=== Insights Operator

[id="ocp-release-notes-installation-and-update_{context}"]
=== Installation and update

[id="ocp-4-20-installation-and-update-vsphere-multiple-nics_{context}"]
==== Installing a cluster on {vmw-full} with multiple network interface controllers (Generally Available)

{product-title} 4.18 enabled you to install a {vmw-full} cluster with multiple network interface controllers (NICs) for a node as a Technology Preview feature. This feature is now Generally Available.

For more information, see xref:../installing/installing_vsphere/ipi/installing-vsphere-installer-provisioned-customizations.adoc#installation-vsphere-multiple-nics_installing-vsphere-installer-provisioned-customizations[Configuring multiple NICs].

For an existing {vmw-short} cluster, you can add multiple subnets by using xref:../machine_management/creating_machinesets/creating-machineset-vsphere.adoc#machineset-vsphere-multiple-nics_creating-machineset-vsphere[compute machine sets].

[id="ocp-release-notes-installation-gcp-xpn-dns-zones_{context}"]
==== Installing a cluster on {gcp-full} into a shared VPC specifying a DNS private zone in a third project

With this release, you can specify the location of a DNS private zone when installing a cluster on {gcp-short} into a shared VPC. The private zone can be located in a service project that is distinct from the host project or main service project.

For more information, see xref:../installing/installing_gcp/installation-config-parameters-gcp.adoc#installation-configuration-parameters-additional-gcp_installation-config-parameters-gcp[Additional {gcp-short} configuration parameters].

[id="ocp-release-notes-installation-azure-encrypted-vnet_{context}"]
==== Installing a cluster on {azure-full} with virtual network encryption

With this release, you can install a cluster on {azure-short} using encrypted virtual networks. You are required to use {azure-short} virtual machines that have the `premiumIO` parameter set to `true`. See Microsoft's documentation about link:https://learn.microsoft.com/en-us/azure/virtual-network/how-to-create-encryption?tabs=portal[Creating a virtual network with encryption] and link:https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-encryption-overview#requirements[Requirements and Limitations] for more information.

[id="ocp-release-notes-installation-firewall-updates_{context}"]
==== Firewall requirements when installing a cluster that uses {ibm-title} Cloud Paks

With this release, if you install a cluster using {ibm-title} Cloud Paks, you must allow outbound access to `icr.io` and `cp.icr.io` on port 443. This access is required for {ibm-title} Cloud Pak container images. For more information, see xref:../installing/install_config/configuring-firewall.adoc#configuring-firewall[Configuring your firewall].

[id="ocp-release-notes-installation-azure-confidential-vms_{context}"]
==== Installing a cluster on {azure-full} using Intel TDX Confidential VMs

With this release, you can install a cluster on {azure-short} using Intel-based Confidential VMs. The following machine sizes are now supported:

* DCesv5-series
* DCedsv5-series
* ECesv5-series
* ECedsv5-series

For more information, see xref:../installing/installing_azure/ipi/installing-azure-customizations.adoc#installation-azure-confidential-vms_installing-azure-customizations[Enabling confidential VMs].

[id="ocp-release-notes-machine-config-operator_{context}"]
=== Machine Config Operator

[id="ocp-release-notes-machine-config-operator-boot_{context}"]
==== Updated boot images for vSphere now supported (Technology Preview)

Updated boot images is now supported as a Technology Preview feature for {vmw-first} clusters. This feature allows you configure your cluster to update the node boot image whenever you update your cluster. By default, the boot image in your cluster is not updated along with your cluster. For more information, see xref:../machine_configuration/mco-update-boot-images.adoc#mco-update-boot-images[Updated boot images].

[id="ocp-release-notes-machine-config-operator-ocl-ga_{context}"]
==== {image-mode-os-on-caps} reboot improvements

The following machine configuration changes no longer cause a reboot of nodes with on-cluster custom layered images:

* Modifying the configuration files in the `/var` or `/etc` directory
* Adding or modifying a systemd service
* Changing SSH keys
* Removing mirroring rules from `ICSP`, `ITMS`, and `IDMS` objects
* Changing the trusted CA, by updating the `user-ca-bundle` configmap in the `openshift-config` namespace

For more information, see xref:../machine_configuration/mco-coreos-layering.adoc#coreos-layering-configuring-on-limitations_mco-coreos-layering[On-cluster image mode known limitations].

[id="ocp-release-notes-machine-config-operator-boot-image_{context}"]
==== {image-mode-os-on-caps} status reporting improvements

When {image-mode-os-lower} is configured, there are improvements to error reporting including the following changes:

* In certain scenarios after the custom layered image has been built and pushed, errors could cause the build process to fail. If this happens, the MCO now reports the errors and the `machineosbuild` object and builder pod are reported as failed.

* The `oc describe mcp` output has a new `ImageBuildDegraded` status field that reports if a custom layered image build has failed.

[id="ocp-release-notes-machine-config-operator-cert-changes_{context}"]
==== Setting the kernel type parameter is now supported on {image-mode-os-on-lower} nodes

You can now use the `kernelType` parameter in a `MachineConfig` object on nodes with on-cluster custom layered images in order to install a realtime kernel on the node. Previously, on nodes with on-cluster custom layered images the `kernelType` parameter was ignored. For information, see xref:../machine_configuration/machine-configs-configure.adoc#nodes-nodes-rtkernel-arguments_machine-configs-configure[Adding a real-time kernel to nodes].

[id="ocp-release-notes-machine-config-operator-pin_{context}"]
==== Pinning images to nodes

In clusters with slow, unreliable connections to an image registry, you can use a `PinnedImageSet` object to pull the images in advance, before they are needed, then associate those images with a machine config pool. This ensures that the images are available to the nodes in that pool when needed. The `must-gather` for the Machine Config Operator includes all `PinnedImageSet` objects in the cluster. For more information, see xref:../machine_configuration/machine-config-pin-preload-images-about.adoc#machine-config-pin-preload-images_machine-config-operator[Pinning images to nodes].

[id="ocp-release-notes-machine-config-operator-mcn_{context}"]
==== Improved MCO state reporting is now generally available

The machine config nodes custom resource, which you can use to monitor the progress of machine configuration updates to nodes, is now generally available.

You can now view the status of updates to custom machine config pools in addition to the control plane and worker pools. The functionality for the feature has not changed. However, some of the information in the command output and in the status fields in the `MachineConfigNode` object has been updated. The `must-gather` for the Machine Config Operator now includes all `MachineConfigNodes` objects in the cluster. For more information, see xref:../machine_configuration/index.adoc#checking-mco-node-status_machine-config-overview[About checking machine config node status].

[id="ocp-release-notes-machine-management_{context}"]
=== Machine management

[id="ocp-4-20-capi-aws-capacity-preferences_{context}"]
==== Additional {aws-short} Capacity Reservation configuration options

On clusters that manage machines with the Cluster API, you can specify additional constraints to determine whether your compute machines use {aws-short} capacity reservations. For more information, see xref:../machine_management/cluster_api_machine_management/cluster_api_provider_configurations/cluster-api-config-options-aws.adoc#machine-feature-agnostic-capacity-reservation_cluster-api-config-options-aws[Capacity Reservation configuration options].

[id="ocp-release-notes-machine-management-ca-scale-up_{context}"]
==== Cluster autoscaler scale up delay

You can now configure a delay before the cluster autoscaler recognizes newly pending pods and schedules the pods to a new node by using the `spec.scaleUp.newPodScaleUpDelay` parameter in the `ClusterAutoscaler` CR. If the node remains unscheduled after the delay, the cluster autoscaler can scale up a new node. This delay gives the cluster autoscaler additional time to locate an appropriate node or it can wait for space on an existing pod to become available. For more information, see xref:../machine_management/applying-autoscaling.adoc#configuring-clusterautoscaler_applying-autoscaling[Configuring the cluster autoscaler].

[id="ocp-release-notes-monitoring_{context}"]
=== Monitoring

[id="ocp-release-notes-networking_{context}"]
=== Networking

[id="ocp-4-20-support-for-bgp-routing-protocol_{context}"]
==== Support for the BGP routing protocol

The Cluster Network Operator (CNO) now supports enabling Border Gateway Protocol (BGP) routing. With BGP, you can import and export routes to the underlying provider network and use multi-homing, link redundancy, and fast convergence. BGP configuration is managed with the `FRRConfiguration` custom resource (CR).

When upgrading from an earlier version of {product-title} in which you installed the MetalLB Operator, you must manually migrate your custom frr-k8s configurations from the `metallb-system` namespace to the `openshift-frr-k8s` namespace. To move these CRs, enter the following commands:

. To create the `openshift-frr-k8s` namespace, enter the following command:
+
[source,terminal]
----
$ oc create namespace openshift-frr-k8s
----

. To automate the migration, create a `migrate.sh` file with the following content:
+
[source,bash]
----
#!/bin/bash
OLD_NAMESPACE="metallb-system"
NEW_NAMESPACE="openshift-frr-k8s"
FILTER_OUT="metallb-"
oc get frrconfigurations.frrk8s.metallb.io -n "${OLD_NAMESPACE}" -o json |\
  jq -r '.items[] | select(.metadata.name | test("'"${FILTER_OUT}"'") | not)' |\
  jq -r '.metadata.namespace = "'"${NEW_NAMESPACE}"'"' |\
  oc create -f -
----

. To run the migration script, enter the following command:
+
[source,terminal]
----
$ bash migrate.sh
----

. To verify that the migration succeeded, enter the following command:
+
[source,terminal]
----
$ oc get frrconfigurations.frrk8s.metallb.io -n openshift-frr-k8s
----

After the migration is complete, you can remove the `FRR-K8s` custom resources from the `metallb-system` namespace.

For more information, see xref:../networking/advanced_networking/bgp_routing/about-bgp-routing.adoc#about-bgp-routing[About BGP routing].

[id="ocp-4-20-support-for-route-advertisements-cudns-with-bgp_{context}"]
==== Support for route advertisements for cluster user-defined networks (CUDNs) with Border Gateway Protocol (BGP)

With route advertisements enabled, the OVN-Kubernetes network plugin supports the direct advertisement of routes for pods and services associated with cluster user-defined networks (CUDNs) to the provider network. This feature enables some of the following benefits:

- Learns routes to pods dynamically
- Advertises routes dynamically
- Enables layer 3 notifications of EgressIP failovers in addition to the layer 2 ones based on gratuitous ARPs.
- Supports external route reflectors, which reduces the number of BGP connections required in large networks

For more information, see xref:../networking/advanced_networking/route_advertisements/about-route-advertisements.adoc#about-route-advertisements[About route advertisements].

[id="ocp-release-notes-ptp-logging-config_{context}"]
==== Configuring enhanced PTP logging

You can now configure enhanced log reduction for the PTP Operator to reduce the volume of logs generated by the `linuxptp-daemon`.

This feature provides a periodic summary of filtered logs, which is not available with basic log reduction. Optionally, you can set a specific interval for the summary logs and a threshold in nanoseconds for the master offset logs.

For more information, see xref:../networking/advanced_networking/ptp/configuring-ptp.adoc#cnf-configuring-enhanced-log-reduction-for-linuxptp_configuring-ptp[Configuring enhanced PTP logging].

[id="ocp-4-20-networking-arm-dual-oc_{context}"]
==== PTP ordinary clocks with added redundancy on AArch64 nodes (Technology Preview)

With this release, you can configure PTP ordinary clocks with added redundancy on AArch64 architecture nodes that use the following dual-port NICs only:

* NVIDIA ConnectX-7 series
* NVIDIA BlueField-3 series, in NIC mode

This feature is available as a Technology Preview. For more information, see xref:../networking/advanced_networking/ptp/about-ptp.adoc#ptp-dual-ports-oc_about-ptp[Using dual-port NICs to improve redundancy for PTP ordinary clocks].

[id="ocp-release-notes-bond-cni-load-balancing_{context}"]
==== Load balancing configuration with bond CNI plugin (Technology Preview)

In this release you can now specify the transmit hash policy for load balancing across the aggregated interfaces with the `xmitHashPolicy` as part of bond CNI plugin configuration. This feature is available as a Technology Preview.

For more information, see xref:../networking/multiple_networks/secondary_networks/creating-secondary-nwt-other-cni.adoc#nw-multus-bond-cni-object_configuring-additional-network-cni[Configuration for a Bond CNI secondary network].

[id="ocp-4-20-networking-namespaced-sriov-app-owners_{context}"]
==== SR-IOV network management in application namespaces

With {product-title} {product-version}, you can now create and manage SR-IOV networks directly within your application namespaces. This new feature provides greater control over your network configurations and helps simplify your workflow.

Previously, creating an SR-IOV network required a cluster administrator to configure it for you. Now, you can manage these resources directly in your own namespace, which offers several key benefits:

* Increased autonomy and control: You can now create your own `SriovNetwork` objects, removing the need to involve a cluster administrator for network configuration tasks.

* Enhanced security: Managing resources within your own namespace improves security by providing better separation between applications and helps prevent unintentional misconfigurations.

* Simplified permissions: You can now simplify permissions and reduce operational overhead by using namespaced SR-IOV networks.

For more information, see xref:../networking/hardware_networks/configuring-namespaced-sriov-resources.html#configuring-namespaced-sriov-resources[Configuring namespaced SR-IOV resources].

[id="ocp-release-notes-nodes_{context}"]
=== Nodes

[id="ocp-release-notes-machine-config-operator-sigtore_{context}"]
==== sigstore support is now generally available

Support for sigstore `ClusterImagePolicy` and `ImagePolicy` objects is now generally available. The API version is now `config.openshift.io/v1`. For more information, see xref:../nodes/nodes-sigstore-using.adoc#nodes-sigstore-using[Manage secure signatures with sigstore].

[NOTE]
====
The default `openshift` cluster image policy is Technology Preview and is active only in clusters that have enabled Technology Preview features.
====

[id="ocp-release-notes-machine-config-operator-sigtore-pki_{context}"]
=== Support for sigstore bring your own PKI (BYOPKI) image validation

You can now use sigstore `ClusterImagePolicy` and `ImagePolicy` objects to generate BYOPKI config to the `policy.json` file, enabling you to verify image signatures with link:https://developers.redhat.com/articles/2025/09/08/verify-cosign-bring-your-own-pki-signature-openshift?source=sso#configure_openshift_for_pki_verification[BYOPKI]. For more information, see xref:../nodes/nodes-sigstore-using.adoc#nodes-sigstore-configure-parameters_nodes-sigstore-using[About cluster and image policy parameters].

[id="ocp-release-notes-machine-config-operator-namespace_{context}"]
==== Linux user namespace support is now generally available

Support for deploying pods and containers into Linux user namespaces is now generally available and enabled by default. Running pods and containers in individual user namespaces can mitigate several vulnerabilities that a compromised container can pose to other pods and the node itself. This change also includes two new security context constraints, `restricted-v3` and `nested-container`, that are specifically designed for use with user namespaces. You can also configure the `/proc` file system in pods as `unmasked`. For more information, see xref:../nodes/pods/nodes-pods-user-namespaces.adoc#nodes-pods-user-namespaces[Running pods in Linux user namespaces].

[id="ocp-release-notes-machine-config-operator-in-place_{context}"]
==== Adjust pod resource levels without pod disruption

By using the in-place pod resizing feature, you can apply a resize policy to change the CPU and memory resources for containers within a running pod without re-creating or restarting the pod. For more information, see xref:../nodes/pods/nodes-pods-adjust-resources-in-place.adoc#nodes-pods-adjust-resources-in-place[Manually adjust pod resource levels].

[id="ocp-release-notes-machine-config-operator-mount-oci_{context}"]
==== Mounting an OCI image into a pod

You can you use an image volume to mount an Open Container Initiative (OCI)-compliant container image or artifact directly into a pod.

// Activate link when assembly/module is available: For more information, see ../nodes/pods/nodes-pods-image-volume.adoc#odes-pods-image-volume[Mounting an OCI image into a pod].

[id="ocp-release-notes-machine-config-operator-allocate-gpu_{context}"]
==== Allocating specific GPUs to pods (Technology Preview)

You can now enable pods to request GPUs based on specific device attributes, such as product name, GPU memory capacity, compute capability, vendor name, and driver version. These attributes are exposed by the by using a third-party DRA resource driver that you install.

// Activate link when assembly/module is available: For more information, see /nodes/pods/nodes-pods-allocate-dra.adoc#nodes-pods-allocate-dra[Allocating GPUs to pods].

[id="ocp-release-notes-openshift-cli_{context}"]
=== OpenShift CLI (oc)

[id="ocp-oc-adm-upgrade-recommend_{context}"]
==== Introducing the oc adm upgrade recommend command (General Availability)

Formerly Technology Preview and now Generally Available, the `oc adm upgrade recommend` command allows system administrators to perform a pre-update check on their {product-title} clusters using the command line interface (CLI). The pre-update check helps identify potential issues, enabling users to address them before initiating an update. By running the precheck command and inspecting the output, users can prepare for updating their cluster and make informed decisions about when to start an update.

For more information, see xref:../updating/updating_a_cluster/updating-cluster-cli.adoc#update-upgrading-cli[Updating a cluster by using the CLI].

[id="ocp-oc-adm-upgrade-status_{context}"]
==== Introducing the oc adm upgrade status command (General Availability)

Formerly Technology Preview and now Generally Available, the `oc adm upgrade status` command allows cluster administrators to get high-level summary information about the state of their {product-title} cluster update using the command line interface (CLI). Three types of information are provided when you enter the command: control plane information, worker node information, and health insights.

The command is not currently supported on Hosted Control Plane (HCP) clusters.

For more information, see xref:../updating/updating_a_cluster/updating-cluster-cli.adoc#update-upgrading-cli[Updating a cluster by using the CLI].

[id="ocp-release-notes-osdk_{context}"]
=== Operator development

[id="ocp-release-notes-osdk-base-images_{context}"]
==== Supported Operator base images

include::snippets/osdk-release-notes-operator-images.adoc[]

[id="ocp-release-notes-postinstallation-configuration_{context}"]
=== Postinstallation configuration

[id="ocp-release-notes-rhcos_{context}"]
=== {op-system-first}

[id="ocp-4-20-kdump-ga-support"]
==== Investigate kernel crashes with kdump (General Availability)

With this update, `kdump` is now Generally Available for all supported architectures, including `x86_64`, `arm64`, `s390x`, and `ppc64le`. This enhancement enables users to diagnose and resolve kernel problems more efficiently.

[id="ocp-release-notes-scalability-and-performance_{context}"]
=== Scalability and performance

[id="ocp-release-notes-numa-resources-operator-replicas_{context}"]
==== Configuring NUMA-aware scheduler replicas and high availability (Technology Preview)

In {product-title} {product-version}, the NUMA Resources Operator automatically enables high availability (HA) mode by default. In this mode, the NUMA Resources Operator creates one scheduler replica for each control-plane node in the cluster to ensure redundancy. This default behavior occurs if the `spec.replicas` field is not specified in the `NUMAResourcesScheduler` Custom Resource (CR). Alternatively, you can explicitly set a specific number of scheduler replicas to override the default HA behavior or disable the scheduler entirely by setting the `spec.replicas` field to `0`.

For more information, see xref:../scalability_and_performance/cnf-numa-aware-scheduling.adoc#cnf-managing-ha-nrop_numa-aware[Managing high availability (HA) for the NUMA-aware scheduler].

[id="ocp-4-20-receive-packet-steering-disabled_{context}"]
==== Receive Packet Steering (RPS) is now disabled by default

With this release, Receive Packet Steering (RPS) is no longer configured when Performance Profile is applied. The RPS configuration affects containers that perform networking system calls, such as send, directly within latency-sensitive threads. To avoid latency impacts when RPS is not configured, move networking calls to helper threads or processes.

The previous RPS configuration resolved latency issues at the expense of overall pod kernel networking performance. The current default configuration promotes transparency by requiring developers to address the underlying application design instead of obscuring performance impacts.

To revert to the previous behavior, add the `performance.openshift.io/enable-rps` annotation to the PerformanceProfile manifest:

[source,yaml]
----
apiVersion: performance.openshift.io/v2
kind: PerformanceProfile
metadata:
  name: example-performanceprofile
  annotations:
    performance.openshift.io/enable-rps: "enable"
----

[NOTE]
====
This action restores the prior functionality at the cost of globally reducing networking performance for all pods.
====

[id="ocp-release-notes-security_{context}"]
=== Security

[id="ocp-release-notes-storage_{context}"]
=== Storage

[id="ocp-release-notes-web-console_{context}"]
=== Web console


[id="ocp-release-notable-technical-changes_{context}"]
== Notable technical changes

[id="notable-technical-changes-mosc-naming_{context}"]
=== MachineOSConfig naming changes

The name of the `MachineOSConfig` object used with {image-mode-os-on-lower} must now be the same as the machine config pool where you want to deploy the custom layered image. Previously, you could use any name. This change was made to prevent attempts to use multiple `MachineOSConfig` objects with each machine config pool.

[id="ocp-4-20-oc-mirror-v2-verify-creds_{context}"]
=== oc-mirror plugin v2 verifies credentials and certificates before mirroring operations

With this update, the oc-mirror plugin v2 now verifies information such as registry credentials, DNS name, and SSL certificates before populating the cache and beginning mirroring operations.
This prevents users from discovering certain problems only after the cache is populated and mirroring has begun.

[id="ocp-release-deprecated-removed-features_{context}"]
== Deprecated and removed features


[id="ocp-release-note-images-dep-rem_{context}"]
=== Images deprecated and removed features

.Images deprecated and removed tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|Cluster Samples Operator
|Deprecated
|Deprecated
|Deprecated
|====


[id="ocp-release-note-install-dep-rem_{context}"]
=== Installation deprecated and removed features

.Installation deprecated and removed tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|`--cloud` parameter for `oc adm release extract`
|Deprecated
|Deprecated
|Deprecated

|CoreDNS wildcard queries for the `cluster.local` domain
|Deprecated
|Deprecated
|Deprecated

|`compute.platform.openstack.rootVolume.type` for {rh-openstack}
|Deprecated
|Deprecated
|Deprecated

|`controlPlane.platform.openstack.rootVolume.type` for {rh-openstack}
|Deprecated
|Deprecated
|Deprecated

|`ingressVIP` and `apiVIP` settings in the `install-config.yaml` file for installer-provisioned infrastructure clusters
|Deprecated
|Deprecated
|Deprecated

|Package-based {op-system-base} compute machines
|Deprecated
|Removed
|Removed

|`platform.aws.preserveBootstrapIgnition` parameter for {aws-first}
|Deprecated
|Deprecated
|Deprecated

|Installing a cluster on {aws-short} with compute nodes in {aws-short} Outposts
|Deprecated
|Deprecated
|Deprecated
|====

// No deprecated or removed features for 3 consecutive releases
//
// [id="ocp-release-note-monitoring-dep-rem_{context}"]
// === Monitoring deprecated and removed features

// .Monitoring deprecated and removed tracker
// [cols="4,1,1,1",options="header"]
// |====
// |Feature |4.18 |4.19 |4.20
// |====


[id="ocp-release-note-networking-dep-rem_{context}"]
=== Networking deprecated and removed features

.Networking deprecated and removed tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|iptables
|Deprecated
|Deprecated
|Deprecated

|====


[id="ocp-release-note-node-dep-rem_{context}"]
=== Node deprecated and removed features

.Node deprecated and removed tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|`ImageContentSourcePolicy` (ICSP) objects
|Deprecated
|Deprecated
|Deprecated

|Kubernetes topology label `failure-domain.beta.kubernetes.io/zone`
|Deprecated
|Deprecated
|Deprecated

|Kubernetes topology label `failure-domain.beta.kubernetes.io/region`
|Deprecated
|Deprecated
|Deprecated

|cgroup v1
|Deprecated
|Removed
|Removed
|====


[id="ocp-release-note-cli-dep-rem_{context}"]
=== OpenShift CLI (oc) deprecated and removed features

.OpenShift CLI (oc) deprecated and removed tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19|4.20

|oc-mirror plugin v1
|Deprecated
|Deprecated
|Deprecated
|====


[id="ocp-release-note-operators-dep-rem_{context}"]
=== Operator lifecycle and development deprecated and removed features

// "Operator lifecycle" refers to OLMv0 and "development" refers to Operator SDK

.Operator lifecycle and development deprecated and removed tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|Operator SDK
|Deprecated
|Removed
|Removed

|Scaffolding tools for Ansible-based Operator projects
|Deprecated
|Removed
|Removed

|Scaffolding tools for Helm-based Operator projects
|Deprecated
|Removed
|Removed

|Scaffolding tools for Go-based Operator projects
|Deprecated
|Removed
|Removed

|Scaffolding tools for Hybrid Helm-based Operator projects
|Removed
|Removed
|Removed

|Scaffolding tools for Java-based Operator projects
|Removed
|Removed
|Removed

// Do not remove the SQLite database... entry until otherwise directed by the Operator Framework PM
|SQLite database format for Operator catalogs
|Deprecated
|Deprecated
|Deprecated
|====


[id="ocp-hardware-an-driver-dep-rem_{context}"]
=== Specialized hardware and driver enablement deprecated and removed features

.Specialized hardware and driver enablement deprecated and removed tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20
|====


=== Storage deprecated and removed features

.Storage deprecated and removed tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|Persistent storage using FlexVolume
|Deprecated
|Deprecated
|Deprecated

|AliCloud Disk CSI Driver Operator
|Removed
|Removed
|Removed

|Shared Resources CSI Driver Operator
|Removed
|Removed
|Removed
|====


[id="ocp-clusters-dep-rem_{context}"]
=== Updating clusters deprecated and removed features

.Updating clusters deprecated and removed tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20
|====


[id="ocp-release-note-web-console-dep-rem_{context}"]
=== Web console deprecated and removed features

.Web console deprecated and removed tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|`useModal` hook for dynamic plugin SDK
|General Availability
|Deprecated
|Deprecated

|Patternfly 4
|Deprecated
|Removed
|Removed

|====


[id="ocp-release-note-workloads-dep-rem_{context}"]
=== Workloads deprecated and removed features

.Workloads deprecated and removed tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|`DeploymentConfig` objects
|Deprecated
|Deprecated
|Deprecated
|====

[id="ocp-release-deprecated-features_{context}"]
=== Deprecated features

[id="ocp-release-removed-features_{context}"]
=== Removed features

.APIs removed from Kubernetes 1.32
[cols="2,2,2,1",options="header",]
|===
|Resource |Removed API |Migrate to |Notable changes

|
|
|
|

|===

[id="ocp-release-bug-fixes_{context}"]
== Bug fixes
//Bug fix work for TELCODOCS-750
//Bare Metal Hardware Provisioning / OS Image Provider
//Bare Metal Hardware Provisioning / baremetal-operator
//Bare Metal Hardware Provisioning / cluster-baremetal-operator
//Bare Metal Hardware Provisioning / ironic"
//CNF Platform Validation
//Cloud Native Events / Cloud Event Proxy
//Cloud Native Events / Cloud Native Events
//Cloud Native Events / Hardware Event Proxy
//Cloud Native Events
//Driver Toolkit
//Installer / Assisted installer
//Installer / OpenShift on Bare Metal IPI
//Networking / ptp
//Node Feature Discovery Operator
//Performance Addon Operator
//Telco Edge / HW Event Operator
//Telco Edge / RAN
//Telco Edge / TALO
//Telco Edge / ZTP


[id="ocp-release-note-api-auth-bug-fixes_{context}"]
=== API Server and Authentication


[id="ocp-release-note-bare-metal-hardware-bug-fixes_{context}"]
=== Bare Metal Hardware Provisioning




[id="ocp-release-note-cloud-compute-bug-fixes_{context}"]
=== Cloud Compute






[id="ocp-release-note-cluster-autoscaler-bug-fixes_{context}"]
=== Cluster Autoscaler





[id="ocp-release-note-cluster-override-admin-operator-bug-fixes_{context}"]
=== Cluster Resource Override Admission Operator





[id="ocp-release-note-cluster-version-operator-bug-fixes_{context}"]
=== Cluster Version Operator






[id="ocp-release-note-image-streams-bug-fixes_{context}"]
=== ImageStreams






[id="ocp-release-note-installer-bug-fixes_{context}"]
=== Installer









[id="ocp-release-note-machine-config-operator-bug-fixes_{context}"]
=== Machine Config Operator






[id="ocp-release-note-management-console-bug-fixes_{context}"]
=== Management Console








[id="ocp-release-note-monitoring-bug-fixes_{context}"]
=== Monitoring




[id="ocp-release-note-networking-bug-fixes_{context}"]
=== Networking









[id="ocp-release-note-node-bug-fixes_{context}"]
=== Node





[id="ocp-release-note-node-tuning-operator-bug-fixes_{context}"]
=== Node Tuning Operator (NTO)




[id="ocp-release-note-observability-bug-fixes_{context}"]
=== Observability




[id="ocp-release-note-oc-mirror-bug-fixes_{context}"]
=== oc-mirror







[id="ocp-release-note-oc-cli-bug-fixes_{context}"]
=== OpenShift CLI (oc)




[id="ocp-release-note-olm-bug-fixes_{context}"]
=== Operator Lifecycle Manager (OLM)






[id="ocp-release-note-operator-controller-manager-bug-fixes_{context}"]
=== Operator Controller Manager




[id="ocp-release-note-pao-bug-fixes_{context}"]
=== Performance Addon Operator






[id="ocp-release-note-samples-operator-bug-fixes_{context}"]
=== Samples Operator






[id="ocp-release-note-storage-bug-fixes_{context}"]
=== Storage







[id="ocp-release-note-rhcos-bug-fixes_{context}"]
=== {op-system-first}




[id="ocp-release-technology-preview-tables_{context}"]
== Technology Preview features status

Some features in this release are currently in Technology Preview. These experimental features are not intended for production use. Note the following scope of support on the Red{nbsp}Hat Customer Portal for these features:

link:https://access.redhat.com/support/offerings/techpreview[Technology Preview Features Support Scope]

In the following tables, features are marked with the following statuses:

* _Not Available_
* _Technology Preview_
* _General Availability_
* _Deprecated_
* _Removed_



[id="ocp-release-notes-auth-tech-preview_{context}"]
=== Authentication and authorization Technology Preview features

.Authentication and authorization Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|Pod security admission restricted enforcement
|Technology Preview
|Technology Preview
|Technology Preview

|Direct authentication with an external OIDC identity provider
|Not Available
|Technology Preview
|Technology Preview

|====


[id="ocp-release-notesedge-computing-tp-features_{context}"]
=== Edge computing Technology Preview features

.Edge computing Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|Accelerated provisioning of {ztp}
|Technology Preview
|Technology Preview
|Technology Preview

|Enabling disk encryption with TPM and PCR protection
|Technology Preview
|Technology Preview
|Technology Preview
|====


[id="ocp-release-notes-extensions-tech-preview_{context}"]
=== Extensions Technology Preview features

// "Extensions" refers to OLMv1

.Extensions Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|{olmv1-first}
|General Availability
|General Availability
|General Availability

|{olmv1} runtime validation of container images using sigstore signatures
|Technology Preview
|Technology Preview
|Technology Preview

|{olmv1} permissions preflight check for cluster extensions
|Not Available
|Technology Preview
|Technology Preview

|{olmv1} deploying a cluster extension in a specified namespace
|Not Available
|Technology Preview
|Technology Preview
|====


[id="ocp-release-notes-installing-tech-preview_{context}"]
=== Installation Technology Preview features

.Installation Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

// All GA in 4.17 notes for oci-first
|Adding kernel modules to nodes with kvc
|Technology Preview
|Technology Preview
|Technology Preview

|Enabling NIC partitioning for SR-IOV devices
|General Availability
|General Availability
|General Availability

|User-defined labels and tags for {gcp-first}
|General Availability
|General Availability
|General Availability

|Installing a cluster on Alibaba Cloud by using Assisted Installer
|Technology Preview
|Technology Preview
|Technology Preview

|Installing a cluster on {azure-first} with confidential VMs
|Technology Preview
|General Availability
|General Availability

|Mount shared entitlements in BuildConfigs in RHEL
|Technology Preview
|Technology Preview
|Technology Preview

|OpenShift zones support for vSphere host groups
|Not Available
|Technology Preview
|Technology Preview

|Selectable Cluster Inventory
|Technology Preview
|Technology Preview
|Technology Preview

|Installing a cluster on {gcp-short} using the Cluster API implementation
|General Availability
|General Availability
|General Availability

|Enabling a user-provisioned DNS on {gcp-short}
|Not Available
|Technology Preview
|Technology Preview

|Installing a cluster on {vmw-full} with multiple network interface controllers
|Technology Preview
|Technology Preview
|General Availability

|Using bare metal as a service
|Not Available
|Technology Preview
|Technology Preview
|====


[id="ocp-release-notes-mco-tech-preview_{context}"]
=== Machine Config Operator Technology Preview features

.Machine Config Operator Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|Improved MCO state reporting (`oc get machineconfignode`)
|Technology Preview
|Technology Preview
|General Availability

|Image mode for OpenShift/On-cluster RHCOS image layering for {aws-short} and {gcp-short}
|Technology Preview
|General Availability
|General Availability

|Image mode for OpenShift/On-cluster RHCOS image layering for {vmw-short}
|Not available
|Not available
|Technology Preview

|====


[id="ocp-release-notes-machine-management-tech-preview_{context}"]
=== Machine management Technology Preview features

.Machine management Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|Managing machines with the Cluster API for {aws-full}
|Technology Preview
|Technology Preview
|Technology Preview

|Managing machines with the Cluster API for {gcp-full}
|Technology Preview
|Technology Preview
|Technology Preview

|Managing machines with the Cluster API for {azure-full}
|Technology Preview
|Technology Preview
|Technology Preview

|Managing machines with the Cluster API for {vmw-full}
|Technology Preview
|Technology Preview
|Technology Preview

|Managing machines with the Cluster API for bare metal
|Not Available
|Technology Preview
|Technology Preview

|Cloud controller manager for {ibm-power-server-name}
|Technology Preview
|Technology Preview
|Technology Preview

|Adding multiple subnets to an existing {vmw-full} cluster by using compute machine sets
|Technology Preview
|Technology Preview
|Technology Preview

|Configuring Trusted Launch for {azure-full} virtual machines by using machine sets
|Technology Preview
|General Availability
|General Availability

|Configuring {azure-short} confidential virtual machines by using machine sets
|Technology Preview
|General Availability
|General Availability
|====


[id="ocp-release-notes-monitoring-tech-preview_{context}"]
=== Monitoring Technology Preview features

.Monitoring Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|Metrics Collection Profiles
|Technology Preview
|General Availability
|General Availability

|====


[id="ocp-release-notes-multi-arch-tech-preview_{context}"]
=== Multi-Architecture Technology Preview features

.Multi-Architecture Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|`kdump` on `arm64` architecture
|Technology Preview
|Technology Preview
|General Availability

|`kdump` on `s390x` architecture
|Technology Preview
|Technology Preview
|General Availability

|`kdump` on `ppc64le` architecture
|Technology Preview
|Technology Preview
|General Availability

|Support for configuring the image stream import mode behavior
|Technology Preview
|Technology Preview
|Technology Preview
|====


[id="ocp-release-notes-networking-tech-preview_{context}"]
=== Networking Technology Preview features

.Networking Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|eBPF manager Operator
|Technology Preview
|Technology Preview
|Technology Preview

|Advertise using L2 mode the MetalLB service from a subset of nodes, using a specific pool of IP addresses
|Technology Preview
|Technology Preview
|Technology Preview

|Updating the interface-specific safe sysctls list
|Technology Preview
|Technology Preview
|Technology Preview

|Egress service custom resource
|Technology Preview
|Technology Preview
|Technology Preview

|VRF specification in `BGPPeer` custom resource
|Technology Preview
|Technology Preview
|Technology Preview

|VRF specification in `NodeNetworkConfigurationPolicy` custom resource
|Technology Preview
|General Availability
|General Availability

|Host network settings for SR-IOV VFs
|General Availability
|General Availability
|General Availability

|Integration of MetalLB and FRR-K8s
|General Availability
|General Availability
|General Availability

|Automatic leap seconds handling for PTP grandmaster clocks
|General Availability
|General Availability
|General Availability

|PTP events REST API v2
|General Availability
|General Availability
|General Availability

|OVN-Kubernetes customized `br-ex` bridge on bare metal
|General Availability
|General Availability
|General Availability

|OVN-Kubernetes customized `br-ex` bridge on {vmw-short} and {rh-openstack}
|Technology Preview
|Technology Preview
|Technology Preview

|Live migration to OVN-Kubernetes from OpenShift SDN
|Not Available
|Not Available
|Not Available

|User-defined network segmentation
|General Availability
|General Availability
|General Availability

|Dynamic configuration manager
|Technology Preview
|Technology Preview
|Technology Preview

|SR-IOV Network Operator support for Intel C741 Emmitsburg Chipset
|Technology Preview
|Technology Preview
|Technology Preview

|Gateway API and Istio for Ingress management
|Technology Preview
|General Availability
|General Availability

|Dual-port NIC for PTP ordinary clock
|Not Available
|Technology Preview
|Technology Preview

|DPU Operator
|Not Available
|Technology Preview
|Technology Preview

|Fast IPAM for the Whereabouts IPAM CNI plugin
|Not Available
|Technology Preview
|Technology Preview

|Unnumbered BGP peering
|Not Available
|Technology Preview
|Technology Preview

|Load balancing across the aggregated bonded interface with xmitHashPolicy
|Not Available
|Not Available
|Technology Preview
|====


[id="ocp-release-notes-nodes-tech-preview_{context}"]
=== Node Technology Preview features

.Nodes Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|`MaxUnavailableStatefulSet` featureset
|Technology Preview
|Technology Preview
|Technology Preview

|sigstore support
|Technology Preview
|Technology Preview
|General Availability

|Default sigstore `openshift` cluster image policy
|Technology Preview
|Technology Preview
|Technology Preview

|Linux user namespace support
|Technology Preview
|Technology Preview
|General Availability

|Attribute-Based GPU Allocation
|Not Available
|Not Available
|Technology Preview
|====


[id="ocp-release-notes-oc-cli-tech-preview_{context}"]
=== OpenShift CLI (oc) Technology Preview features

.OpenShift CLI (`oc`) Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|oc-mirror plugin v2
|General Availability
|General Availability
|General Availability

|oc-mirror plugin v2 enclave support
|General Availability
|General Availability
|General Availability

|oc-mirror plugin v2 delete functionality
|General Availability
|General Availability
|General Availability
|====


[id="ocp-release-notes-operator-lifecycle-tech-preview_{context}"]
=== Operator lifecycle and development Technology Preview features

// "Operator lifecycle" refers to OLMv0 and "development" refers to Operator SDK

.Operator lifecycle and development Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|{olmv1-first}
|General Availability
|General Availability
|General Availability

|Scaffolding tools for Hybrid Helm-based Operator projects
|Removed
|Removed
|Removed

|Scaffolding tools for Java-based Operator projects
|Removed
|Removed
|Removed
|====


[id="ocp-release-notes-rhcos-tech-preview_{context}"]
=== {rh-openstack-first} Technology Preview features

.{rh-openstack} Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|{rh-openstack} integration into the {cluster-capi-operator}
|Technology Preview
|Technology Preview
|Technology Preview

|Control plane with `rootVolumes` and `etcd` on local disk
|General Availability
|General Availability
|General Availability

|Hosted control planes on {rh-openstack} 17.1
|Not Available
|Technology Preview
|Technology Preview
|====


[id="ocp-release-notes-scalability-tech-preview_{context}"]
=== Scalability and performance Technology Preview features

.Scalability and performance Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|{factory-prestaging-tool}
|Technology Preview
|Technology Preview
|Technology Preview

|Hyperthreading-aware CPU manager policy
|Technology Preview
|Technology Preview
|Technology Preview

|Mount namespace encapsulation
|Technology Preview
|Technology Preview
|Technology Preview

|Node Observability Operator
|Technology Preview
|Technology Preview
|Technology Preview

|Increasing the etcd database size
|Technology Preview
|Technology Preview
|Technology Preview

|Using {rh-rhacm} `PolicyGenerator` resources to manage {ztp} cluster policies
|Technology Preview
|General Availability
|General Availability

|Pinned Image Sets
|Technology Preview
|Technology Preview
|Technology Preview

|Configuring NUMA-aware scheduler replicas and high availability
|Not available
|Not available
|Technology Preview
|====


[id="ocp-release-notes-special-hardware-tech-preview_{context}"]
=== Specialized hardware and driver enablement Technology Preview features

.Specialized hardware and driver enablement Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20
|====


[id="ocp-release-notes-storage-tech-preview_{context}"]
=== Storage Technology Preview features

.Storage Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|AWS EFS storage CSI usage metrics
|General Availability
|General Availability
|General Availability

|Automatic device discovery and provisioning with Local Storage Operator
|Technology Preview
|Technology Preview
|Technology Preview

|Azure File CSI snapshot support
|Technology Preview
|Technology Preview
|Technology Preview

|Azure File cross-subscription support
|Not Available
|General Availability
|General Availability

|Shared Resources CSI Driver in OpenShift Builds
|Technology Preview
|Technology Preview
|Technology Preview

|{secrets-store-operator}
|General Availability
|General Availability
|General Availability

|CIFS/SMB CSI Driver Operator
|General Availability
|General Availability
|General Availability

|VMware vSphere multiple vCenter support
|General Availability
|General Availability
|General Availability

|Disabling/enabling storage on vSphere
|Technology Preview
|General Availability
|General Availability

|Increasing max number of volumes per node for vSphere
|Not Available
|Technology Preview
|Technology Preview

|RWX/RWO SELinux Mount
|Developer Preview
|Developer Preview
|Developer Preview

|Migrating CNS Volumes Between Datastores
|Developer Preview
|General Availability
|General Availability

|CSI volume group snapshots
|Technology Preview
|Technology Preview
|Technology Preview

|GCP PD supports C3/N4 instance types and hyperdisk-balanced disks
|General Availability
|General Availability
|General Availability

|GCP Filestore supports Workload Identity
|General Availability
|General Availability
|General Availability

|OpenStack Manila support for CSI resize
|General Availability
|General Availability
|General Availability

|Volume Attribute Classes
|Not Available
|Technology Preview
|Technology Preview
|====


[id="ocp-release-notes-web-console-tech-preview_{context}"]
=== Web console Technology Preview features

.Web console Technology Preview tracker
[cols="4,1,1,1",options="header"]
|====
|Feature |4.18 |4.19 |4.20

|{ols-official} in the {product-title} web console
|Technology Preview
|Technology Preview
|Technology Preview
|====

[id="ocp-release-known-issues_{context}"]
== Known issues





[id="ocp-telco-core-release-known-issues_{context}"]



[id="ocp-storage-core-release-known-issues_{context}"]



[id="ocp-release-asynchronous-errata-updates_{context}"]
== Asynchronous errata updates

Security, bug fix, and enhancement updates for {product-title} {product-version} are released as asynchronous errata through the Red{nbsp}Hat Network. All {product-title} {product-version} errata is https://access.redhat.com/downloads/content/290/[available on the Red Hat Customer Portal]. See the https://access.redhat.com/support/policy/updates/openshift[{product-title} Life Cycle] for more information about asynchronous errata.

Red{nbsp}Hat Customer Portal users can enable errata notifications in the account settings for Red{nbsp}Hat Subscription Management (RHSM). When errata notifications are enabled, users are notified through email whenever new errata relevant to their registered systems are released.

[NOTE]
====
Red{nbsp}Hat Customer Portal user accounts must have systems registered and consuming {product-title} entitlements for {product-title} errata notification emails to generate.
====

This section will continue to be updated over time to provide notes on enhancements and bug fixes for future asynchronous errata releases of {product-title} {product-version}. Versioned asynchronous releases, for example with the form {product-title} {product-version}.z, will be detailed in subsections. In addition, releases in which the errata text cannot fit in the space provided by the advisory will be detailed in subsections that follow.

[IMPORTANT]
====
For any {product-title} release, always review the instructions on xref:../updating/updating_a_cluster/updating-cluster-web-console.adoc#updating-cluster-web-console[updating your cluster] properly.
====

//Update with relevant advisory information
[id="ocp-4-20-0-ga_{context}"]
=== RHSA-202X:XXXXX - {product-title} {product-version}.0 image release, bug fix, and security update advisory

Issued: DD MMM YYYY

{product-title} release {product-version}.0, which includes security updates, is now available. The list of bug fixes that are included in the update is documented in the link:https://access.redhat.com/errata/RHSA-202X:XXXXX[RHSA-202X:XXXXX] advisory. The RPM packages that are included in the update are provided by the link:https://access.redhat.com/errata/RHEA-202X:XXXX[RHEA-202X:XXXX] advisory.

Space precluded documenting all of the container images for this release in the advisory.

You can view the container images in this release by running the following command:

[source,terminal]
----
$ oc adm release info 4.20.0 --pullspecs
----

[id="ocp-4-20-0-updating_{context}"]
==== Updating
To update an {product-title} 4.20 cluster to this latest release, see xref:../updating/updating_a_cluster/updating-cluster-cli.adoc#updating-cluster-cli[Updating a cluster using the CLI].

//replace 4.y.z for the correct values for the release. You do not need to update oc to run this command.
