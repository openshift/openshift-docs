:_mod-docs-content-type: ASSEMBLY
include::_attributes/common-attributes.adoc[]
[id="preparing-serverless-install"]
= Preparing to install {ServerlessProductName}
:context: preparing-serverless-install

toc::[]

Read the following information about supported configurations and prerequisites before you install {ServerlessProductName}.

// OCP specific docs
ifdef::openshift-enterprise[]
[id="install-serverless-operator-before-you-begin"]

* {ServerlessProductName} is supported for installation in a restricted network environment.

* {ServerlessProductName} currently cannot be used in a multi-tenant configuration on a single cluster.
endif::[]

[id="about-serverless-supported-configs"]
== Supported configurations

The set of supported features, configurations, and integrations for {ServerlessProductName}, current and past versions, are available at the link:https://access.redhat.com/articles/4912821[Supported Configurations page].

ifdef::openshift-enterprise[]
[id="about-serverless-scalability-performance"]
== Scalability and performance

{ServerlessProductName} has been tested with a configuration of 3 main nodes and 3 worker nodes, each of which has 64 CPUs, 457 GB of memory, and 394 GB of storage each.

The maximum number of Knative services that can be created using this configuration is 3,000. This corresponds to the xref:../../scalability_and_performance/planning-your-environment-according-to-object-maximums.adoc#cluster-maximums-major-releases_object-limits[{product-title} Kubernetes services limit of 10,000], since 1 Knative service creates 3 Kubernetes services.

The average scale from zero response time was approximately 3.4 seconds, with a maximum response time of 8 seconds, and a 99.9th percentile of 4.5 seconds for a simple Quarkus application. These times might vary depending on the application and the runtime of the application.
endif::[]

// OCP specific docs
ifdef::openshift-enterprise[]
[id="install-serverless-operator-before-you-begin"]

include::modules/serverless-cluster-sizing-req.adoc[leveloffset=+1]

[id="install-serverless-operator-scaling-with-machinesets"]
== Scaling your cluster using compute machine sets

You can use the {product-title} `MachineSet` API to manually scale your cluster up to the desired size. The minimum requirements usually mean that you must scale up one of the default compute machine sets by two additional machines. See xref:../../machine_management/manually-scaling-machineset.adoc#manually-scaling-machineset[Manually scaling a compute machine set].

include::modules/serverless-cluster-sizing-req-additional.adoc[leveloffset=+2]

// TODO: Add OSD specific docs for auto scaling compute machine sets? These docs aren't available for OSD so we need to look into what's required to doc here.
// QE thread related: https://coreos.slack.com/archives/CD87JDUB0/p1643986092796179
endif::[]

// OSD and ROSA docs
ifdef::openshift-dedicated,openshift-rosa[]
include::modules/serverless-cluster-sizing-req.adoc[leveloffset=+1]
endif::[]


[id="additional-resources_preparing-serverless-install"]
[role="_additional-resources"]
== Additional resources
ifdef::openshift-enterprise[]
* xref:../../disconnected/using-olm.adoc#olm-restricted-networks[Using Operator Lifecycle Manager in disconnected environments]
* xref:../../operators/understanding/olm-understanding-operatorhub.adoc#olm-operatorhub-overview[Understanding OperatorHub]
* xref:../../installing/overview/cluster-capabilities.adoc#cluster-capabilities[Cluster capabilities]
endif::[]
