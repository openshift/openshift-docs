include::modules/serverless-document-attributes.adoc[]
[id="gpu-resources"]
= Using NVIDIA GPU resources with serverless applications
:context: gpu-resources
include::modules/common-attributes.adoc[]

toc::[]

NVIDIA supports experimental use of GPU resources on {product-title}.
See link:https://docs.nvidia.com/datacenter/kubernetes/openshift-on-gpu-install-guide/index.html[{product-title} on NVIDIA GPU accelerated clusters] for more information about setting up GPU resources on {product-title}.

After GPU resources are enabled for your {product-title} cluster, you can specify GPU requirements for a Knative service using the `kn` CLI.

.Procedure

You can specify a GPU resource requirement when you create a Knative service using `kn`.

. Create a service.
. Set the GPU resource requirement limit to `1` by using `nvidia.com/gpu=1`:
+

[source,terminal]
----
$ kn service create hello --image docker.io/knativesamples/hellocuda-go --limit nvidia.com/gpu=1
----

+
A GPU resource requirement limit of `1` means that the service has 1 GPU resource dedicated.
Services do not share GPU resources. Any other services that require GPU resources must wait until the GPU resource is no longer in use.
+
A limit of 1 GPU also means that applications exceeding usage of 1 GPU resource are restricted.
If a service requests more than 1 GPU resource, it is deployed on a node where the GPU resource requirements can be met.

.Updating GPU requirements for a Knative service using `kn`

* Update the service. Change the GPU resource requirement limit to `3` by using `nvidia.com/gpu=3`:

[source,terminal]
----
$ kn service update hello --limit nvidia.com/gpu=3
----

== Additional resources
* For more information about limits, see xref:../../applications/quotas/quotas-setting-per-project.adoc[Setting resource quotas for extended resources].
