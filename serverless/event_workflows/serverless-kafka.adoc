include::modules/serverless-document-attributes.adoc[]
[id="serverless-kafka"]
= Knative Kafka
include::modules/common-attributes.adoc[]
:context: serverless-kafka

toc::[]

:FeatureName: Apache Kafka on {ServerlessProductName}
include::modules/technology-preview.adoc[leveloffset=+2]

You can use the `KafkaChannel` channel type and `KafkaSource` event source with {ServerlessProductName}.
To do this, you must install the Knative Kafka components, and configure the integration between {ServerlessProductName} and a supported link:https://access.redhat.com/documentation/en-us/red_hat_amq/7.6/html/amq_streams_on_openshift_overview/index[Red Hat AMQ Streams] cluster.

[NOTE]
====
Knative Kafka is not currently supported for IBM Z and IBM Power Systems.
====

The {ServerlessOperatorName} provides the Knative Kafka API that can be used to create a `KnativeKafka` custom resource:

.Example `KnativeKafka` custom resource
[source,yaml]
----
apiVersion: operator.serverless.openshift.io/v1alpha1
kind: KnativeKafka
metadata:
    name: knative-kafka
    namespace: knative-eventing
spec:
    channel:
        enabled: true <1>
        bootstrapServers: <bootstrap_server> <2>
    source:
        enabled: true <3>
----
<1> Enables developers to use the `KafkaChannel` channel type in the cluster.
<2> A comma-separated list of bootstrap servers from your AMQ Streams cluster.
<3> Enables developers to use the `KafkaSource` event source type in the cluster.

// Install Kafka
include::modules/serverless-install-kafka-odc.adoc[leveloffset=+1]

[id="serverless-kafka-channel-link"]
== Using Kafka channels

Create a xref:../../serverless/channels/serverless-creating-channels.adoc#serverless-creating-channels[Kafka channel].

[id="serverless-kafka-source-link"]
== Using Kafka source

Create a xref:../../serverless/event_sources/serverless-kafka-source.adoc#serverless-kafka-source[Kafka event source].

// Configure TLS and SASL for Kafka
[id="serverless-kafka-authentication"]
== Configuring authentication for Kafka

In production, Kafka clusters are often secured using the TLS or SASL authentication methods. This section shows how to configure the Kafka channel to work against a protected Red Hat AMQ Streams (Kafka) cluster using TLS or SASL.

[NOTE]
====
If you choose to enable SASL, Red Hat recommends to also enable TLS.
====

include::modules/serverless-kafka-tls.adoc[leveloffset=+2]
include::modules/serverless-kafka-sasl.adoc[leveloffset=+2]
include::modules/serverless-kafka-sasl-public-certs.adoc[leveloffset=+2]
