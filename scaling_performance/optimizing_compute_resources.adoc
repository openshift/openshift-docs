[[scaling-performance-compute-resources]]
= Optimizing Compute Resources
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

[[scaling-performance-overcomitting]]
== Overcommitting

You can use overcommit procedures so that resources such as CPU and memory are
more accessible to the parts of your cluster that need them.

Note that when you overcommit, there is a risk that another application may not
have access to the resources it requires when it needs them, which will result
in reduced performance. However, this may be an acceptable trade-off in favor of
increased density and reduced costs. For example, development, quality assurance
(QA), or test environments may be overcommited, whereas production might not be.

{product-title} implements resource management through the compute resource model and
quota system. See the documentation for more information about the
xref:../dev_guide/compute_resources.adoc#dev-guide-compute-resources[OpenShift resource model].

For more information and strategies for overcommiting, see the
xref:../admin_guide/overcommit.adoc#admin-guide-overcommit[Overcommitting documentation in the Cluster
Administration Guide].

[[scaling-performance-image-considerations]]
== Image Considerations

[[scaling-performance-predeployed-image]]
=== Using a Pre-deployed Image to Improve Efficiency

You can create a base {product-title} image with a number of tasks built-in to
improve efficiency, maintain configuration consistency on all node hosts, and
reduce repetitive tasks. This is known as a pre-deployed image.

For example, because every node requires the `ose-pod` image in order to run
pods, each node has to periodically connect to the Docker registry in order to
pull the latest image. This can become problematic when you have 100 nodes
attempting this at the same time, and can lead to resource contention on the
image registry, waste of network bandwidth, and increased pod launch times.

To build a pre-deployed image:

* Create an instance of the type and size required.
* Ensure a dedicated storage device is available for Docker local image or container storage, separate from any persistent volumes for containers.
* Fully update the system, and ensure Docker is installed.
* Ensure the host has access to all yum repositories.
* link:https://access.redhat.com/documentation/en/red-hat-enterprise-linux-atomic-host/7/getting-started-with-containers/chapter-8-managing-storage-with-docker-formatted-containers[Set up thin-provisioned LVM storage].
* Pre-seed your commonly used images (such as the *rhel7* base image), as well as
{product-title} infrastructure container images (*ose-pod*, *ose-deployer*,
etc.) into your pre-deployed image.

Ensure that pre-deployed images are configured for any appropriate cluster
configurations, such as being able to run on
xref:../install_config/configuring_openstack.adoc#install-config-configuring-openstack[OpenStack],
or
xref:../install_config/configuring_aws.adoc#install-config-configuring-aws[AWS],
as well as any other cluster configurations.

[[scaling-performance-prepulling-images]]
=== Pre-pulling Images

To efficiently produce images, you can pre-pull any necessary container images
to all node hosts. This means the image does not have to be initially pulled,
which saves time and performance over slow connections, especially for images,
such as xref:../creating_images/s2i.adoc#creating-images-s2i[S2I], metrics, and logging, which can be large.

This is also useful for machines that cannot access the registry for security
purposes.

Alternatively, you can use a local image instead of the default of a specified registry. To do this:

. Pull from local images by setting the `imagePullPolicy` parameter of a pod configuration to `IfNotPresent` or `Never`.

. Ensure that all nodes in the cluster have the same images saved locally.

[NOTE]
====
Pulling from a local registry is suitable if you can control node configuration.
However, it will not work reliably on cloud providers that do not replace nodes
automatically, such as GCE. If you are running on Google Container Engine (GKE),
there will already be a *_.dockercfg_* file on each node with Google Container
Registry  credentials.
====

[[scaling-performance-debugging]]
== Debugging {product-title} Using the RHEL Tools Container

Red Hat distributes a *rhel-tools* container, containing tools that aid in debugging scaling or performance problems. This container:

* Allows users to deploy minimal footprint container hosts by moving packages out of the base distribution and into this support container.
* Provides debugging capabilities for Red Hat Enterprise Linux 7 Atomic Host, which has an immutable packet tree. *rhel-tools* includes utilities such as tcpdump, sosreport, git, gdb, perf, and many more common system administration utilities.

Use the *rhel-tools* container with the following:

----
# atomic run rhel7/rhel-tools
----

See the link:https://access.redhat.com/documentation/en/red-hat-enterprise-linux-atomic-host/7/getting-started-with-containers/chapter-11-using-the-atomic-tools-container-image[RHEL Tools Container documentation] for more information.

[[scaling-performance-debugging-using-oa-image]]
== Debugging {product-title} Using the OpenShift-Ansible Image

Red Hat distributes an https://github.com/openshift/openshift-ansible/blob/master/README_CONTAINER_IMAGE.md[openshift-ansible image], with specific checks focused on detecting common deployment issues.
Use the following checks to help detect potential issues:

[[diagnostic-checks]]
.Diagnostic Checks
[options="header"]
|===

|Check Name |Purpose

|`*etcd_imagedata_size*`
|This check measures the total size of OpenShift image data in an etcd cluster.
Fails if the calculated size exceeds a user-defined limit. If no limit is specified, this check will fail if the size of OpenShift image data exceeds a certain amount of the currently used space in the etcd cluster.

A failure from this check indicates that a significant amount of space in etcd is being taken up by OpenShift image data, which can destabilize an etcd cluster.

A user-defined limit may be set by passing the variable `etcd_max_image_data_size_bytes=40000000000` to the `openshift_health_checker` role.
This example limit will cause the check to fail if the total size of OpenShift image data stored in etcd exceeds `40GB`.

A user-defined value may be set for this variable by passing it as an option to the role:

`# ansible-playbook -i /etc/ansible/hosts playbooks/common/openshift-checks/check.yml -e etcd_max_image_data_size_bytes=40000000000`

It may also be passed as part of the `OPTS` variable, if running the playbook through the Docker image:

`# docker run ... -e OPTS="-v -e etcd_max_image_data_size_bytes=40000000000"`

See below for a complete example of running checks with the Docker image.

|`*etcd_traffic*`
|This check detects higher-than-normal traffic on an etcd host. Fails if a `journalctl` log entry with an etcd sync duration warning is found.

For further information on improving etcd performance, see the link:host_practices.adoc[Host Practices documentation].

|`*logging_index_time*`
|This check detects higher-than-normal time delays between log creation and log aggregation by Elasticsearch in a logging stack deployment.
Fails if a user-defined timeout is reached before logs are able to be queried through Elasticsearch.

A user-defined timeout may be set by passing the variable `openshift_check_logging_index_timeout_seconds=30` to the `openshift_health_checker` role.
This example timeout will cause the check to fail if a newly-created Kibana log is not able to be queried via Elasticsearch after `30 seconds`.

A user-defined value may be set for this variable by passing it as an option to the role:

`# ansible-playbook -i /etc/ansible/hosts playbooks/common/openshift-checks/health.yml -e openshift_check_logging_index_timeout_seconds=30`

For further information on additional logging-stack checks, see the link:../admin_guide/diagnostics_tool.adoc#additional-cluster-health-checks[Diagnostics Tool documentation].
|===


Use the *openshift-ansible* diagnostic checks with the following:

----
# docker run -u `id -u` \
       -v $HOME/.ssh/id_rsa:/opt/app-root/src/.ssh/id_rsa:Z,ro \
       -v /etc/ansible/hosts:/tmp/inventory:ro \
       -e INVENTORY_FILE=/tmp/inventory \
       -e OPTS="-v" \
       -e PLAYBOOK_FILE=playbooks/common/openshift-checks/health.yml \
ifdef::openshift-enterprise[]
       openshift3/ose-ansible
endif::[]
ifdef::openshift-origin[]
        openshift/origin-ansible
endif::[]
----

See the link:../admin_guide/diagnostics_tool.adoc#additional-cluster-health-checks[Diagnostics Tool documentation] for more information on additional checks provided by the *openshift-ansible* image.


