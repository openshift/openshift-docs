[[dev-guide-pod-autoscaling]]
= Pod Autoscaling
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:

toc::[]

== Overview

A horizontal pod autoscaler, defined by a `*HorizontalPodAutoscaler*` object,
specifies how the system should automatically increase or decrease the scale of
a replication controller or deployment configuration, based on metrics collected
from the pods that belong to that replication controller or deployment
configuration.

ifdef::openshift-enterprise[]
[NOTE]
====
Horizontal pod autoscaling is supported starting in OpenShift Enterprise 3.1.1.
====
endif::[]

ifdef::openshift-origin,openshift-enterprise[]
[[req-for-using-hpas]]
== Requirements for Using Horizontal Pod Autoscalers

In order to use horizontal pod autoscalers, your cluster administrator must have
xref:../install_config/cluster_metrics.adoc#install-config-cluster-metrics[properly configured cluster
metrics].
endif::openshift-origin,openshift-enterprise[]

[[hpa-supported-metrics]]
== Supported Metrics

The following metrics are supported by horizontal pod autoscalers:

.Metrics
[cols="3a,8a",options="header"]
|===

|Metric |Description

|CPU utilization
|Percentage of the xref:../dev_guide/compute_resources.adoc#dev-cpu-requests[requested CPU]

|Memory utilization
|Percentage of the requested memory.
|===

[[hpa-autoscaling]]
== Autoscaling

You can create a horizontal pod autoscaler with the `oc autoscale` command and
specify the minimum and maximum number of pods you want to run, as well as the
CPU utilization your pods should target.

After a horizontal pod autoscaler is created, it begins attempting to query
Heapster for metrics on the pods. It may take one to two minutes before Heapster
obtains the initial metrics.

After metrics are available in Heapster, the horizontal pod autoscaler computes
the ratio of the current metric utilization with the desired metric utilization,
and scales up or down accordingly. The scaling will occur at a regular interval,
but it may take one to two minutes before metrics make their way into Heapster.

For replication controllers, this scaling corresponds directly to the replicas
of the replication controller. For deployment configurations, scaling corresponds
directly to the replica count of the deployment configuration. Note that autoscaling
applies only to the latest deployment in the `Complete` phase.

[[creating-a-hpa]]
== Autoscaling for CPU Utilization

Use the `oc autoscale` command and specify at least the maximum number of pods
you want to run at any given time. You can optionally specify the minimum number
of pods and the average CPU utilization your pods should target, otherwise those
are given default values from the {product-title} server.

For example:

----
$ oc autoscale dc/frontend --min 1 --max 10 /
  --cpu-percent=80 deploymentconfig "frontend" autoscaled
----

The above example creates a horizontal pod autoscaler with the following
definition:

.Horizontal Pod Autoscaler Object Definition
====
[source,yaml,options="nowrap"]
----
apiVersion: extensions/v1beta1
kind: HorizontalPodAutoscaler
metadata:
  name: frontend <1>
spec:
  scaleRef:
    kind: DeploymentConfig <2>
    name: frontend <3>
    apiVersion: v1 <4>
    subresource: scale
  minReplicas: 1 <5>
  maxReplicas: 10 <6>
  cpuUtilization:
    targetPercentage: 80 <7>
----
<1> The name of this horizontal pod autoscaler object
<2> The kind of object to scale
<3> The name of the object to scale
<4> The API version of the object to scale
<5> The minimum number of replicas to which to scale down
<6> The maximum number of replicas to which to scale up
<7> The percentage of the requested CPU that each pod should ideally be using
====

[[pod-autoscaling-memory]]
== Autoscaling for Memory Utilization

Use the `oc autoscale` command and specify the maximum number of pods to run at
any given time. Optionally, you can specify the minimum number of pods and the
average memory utilization your pods should target as well, otherwise those are
given default values from the {product-title} server.

. Memory-base autoscaling is only available with the v2alpha1 version of the autoscaling API.
  It must be enabled in your cluster's `master-config.yaml` file:
+
----
...
apiServerArguments:
  runtime-config:
  - apis/autoscaling/v2alpha1=true
...
----

. Unlike CPU-based autoscaling, memory-based autoscaling requires specifying the autoscaler
  using YAML instead of using the `oc autoscale` command.  Place the following in a file,
  such as `hpa.yaml`:
+
[source,yaml,options="nowrap"]
----
apiVersion: autoscaling/v2alpha1
kind: HorizontalPodAutoscaler
metadata:
  name: hpa-resource-metrics-memory <1>
spec:
  scaleTargetRef:
    apiVersion: apps/v1beta1 <2>
    kind: ReplicationController <3>
    name: hello-hpa-memory <4>
  minReplicas: 1 <5>
  maxReplicas: 10 <6>
  metrics:
  - type: Resource
    resource:
      name: memory
      targetAverageUtilization: 50 <7>
----
<1> The name of this horizontal pod autoscaler object
<2> The API version of the object to scale
<3> The kind of object to scale
<4> The name of the object to scale
<5> The minimum number of replicas to which to scale down
<6> The maximum number of replicas to which to scale up
<7> The average percentage of the requested memory that each pod should be using

. Finally, create the autoscaler from the above file:
+
----
$ oc create -f hpa.yaml
----
+


[[viewing-a-hpa]]
== Viewing a Horizontal Pod Autoscaler

To view the status of a horizontal pod autoscaler:

====
----
$ oc get hpa/frontend
NAME              REFERENCE                                 TARGET    CURRENT   MINPODS        MAXPODS   AGE
frontend          DeploymentConfig/default/frontend/scale   80%       79%       1              10        8d

$ oc describe hpa/frontend
Name:                           frontend
Namespace:                      default
Labels:                         <none>
CreationTimestamp:              Mon, 26 Oct 2015 21:13:47 -0400
Reference:                      DeploymentConfig/default/frontend/scale
Target CPU utilization:         80%
Current CPU utilization:        79%
Min pods:                       1
Max pods:                       10
----
====
