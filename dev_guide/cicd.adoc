[[dev-guide-cicd]]
= CI / CD in {product-title}
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:

toc::[]

== Overview

This topic will focus on continuous integration and continuous delivery (`*CI/CD*`) of applications with {product-title}.  In particular, the goal is to
illustrate how various concepts, infrastructure, hook points, and tools within {product-title} facilitate `*CI/CD*`.  And with this foundation, {product-title}
facilitates the promotion of your application through the pipeline, from development, then test, and ultimately to production.

Now, when you consider the following variables:

- whether your team is small or large
- whether your team is co-located or geographically disperse
- whether your resources are isolated or shared (or how much isolation or sharing can you afford)
- whether your processes are fully automated, manual (including the need for human initiated approvals), or some combination of the two
- whether your processes fall under the waterfall, agile, or devops methodologies, or have elements of any of the three

the matrix that maps scenarios to solutions can seem complex.

However, this article will overcome and demystify this.  And it will cherry-pick and consolidate items discussed throughout {product-title} documentation and
re-present them, but with a specific focus on `*CI/CD*`.

After a brief, high level inventory of components and concepts, followed by a mapping of items either available in {product-title} or easily accessible from {product-title}, to that inventory,
a series of use cases are provided to illustrate how to best leverage {product-title} in this space.

Mixed into the discussion at various points will be references to the {product-title} Jenkins image as the `*CI/CD*` engine.  With the {product-title} Jenkins Image's accompanying {product-title} templates and
baked-in set of plugins and configuration that greatly ease the integration between Jenkins and {product-title} combined with the burgeoning list of `*CI/CD*` centric features in
{product-title} itself, including the Jenkins Pipeline `*BuildConfigStrategy*`, a powerful `*CI/CD*` solution emerges.  That solution includes the ability to auto-provision a Jenkins server to run within
your {product-title} environment, as well as directly reference and initiate Jenkins Pipeline Jobs.

[[inventory-summary]]
== Summary of Application Components And Relevant Tools

Spoiler alert:  the "application" is more than just the source code written in say Java, Perl, Python, Ruby, or NodeJS.  It is more now than the static web
content, the integration scripts, the associated configuration for the language specific runtimes for the application, or the application specific archives
consumed by those language specific runtimes.

By pulling in {product-title}, and its combined foundation of Kubernetes and Docker, additional application artifacts now minimally include:

- Images with their rich set of metadata and associated tooling
- Environment Variables, which are injected into Containers for application use
- API Objects of {product-title}, which are injected into Containers for application use
- API Objects of {product-title}, which dictate how {product-title} manages Containers and Pods

And the second bullet there should serve as a reminder:  the lines between development and operations have blurred, and we want to improve the interaction between the two .... we now have "DevOps".

But while the inventory of concerns has increased, many of the concepts and semantics around managing those concerns are thankfully very similar:

- versioning
- portability
- isolation
- upgrade and update
- hooks (into various flows)

We'll next map these concerns to what is either available in or accessible from {product-title} for each problem domain.

[[versioning]]
== Versioning

Versioning in this topic's context refers to designating each of the components of your application to the stage in the `*CI/CD*` pipeline their readiness dictates they should reside.

For your source code (in the classic sense), the {product-title} `*Build*`, `*BuildRequest*`, and `*BuildConfig*` objects are of course the starting point.  They expose the most typically used
features of the `*SCM*` (most notably Git) to access the appropriate version of your source code (commit IDs, branches, context directories, etc.) and build the source code.

But source code management (`*SCM*`) tooling is also leveraged throughout the industry for managing many artifacts beyond what classically is defined as source code.
{product-title} also promotes such a strategy.

And where a `*SCM*` is not appropriate, most notably for managing the evolution of container Images, we have the {product-title} Internal Image Registry and `*ImageStreams*`. 

[[api-objects]]
=== API Objects

As is highlighted throughout {product-title} documentation, every API Object can be expressed via either JSON or YAML.  That JSON or YAML can be stored in and retrieved from a
`*SCM*` system in order to leverage its versioning related capabilities, including the creation of branches, assignment of and query on various labels or tags associated to versions.

Also, the API Objects are designed such that there are portions of the object which specify the desired state of the system, and other
portions which reflect the *status* or current state of the system.  Inputs and outputs in other words.  The input portions, when expressed in JSON/YAML, in particular are items
that fit naturally as `*SCM*` artifacts.

[NOTE]
Remember, the input or specification portions of the API Objects can be totally static or dynamic in the sense that variable substitution via template processing is possible on actual instantiation.

More on all this later when we dive into the more precise examples.

[[s2i]]
=== Image construction

The next re-introduction of previously discussed items in {product-title} documentation: the Dockerfiles or S2I scripts and config files used to compose images are "source" in every sense, and are typically
managed via source code management tooling in `*SCM*` repositories as well.  Tag, label, and manage versions of those artifacts.  Check out varying versions of those artifacts during the build jobs
of your `*CI/CD*` tooling if it makes sense to vary the image composition in that way at different points of your `*CI/CD*` pipeline (though admittedly, such manipulations are most likely to occur in
the earlier, development type stages). 

[[image-streams]]
=== Images themselves and ImageStreams

As noted earlier,  Images are now artifacts of your application.  And in some cases, an Image (especially one produced by an {product-title} `*Build*`) might encapsulate the entirety of your application.
The new application binary if you will.

To date, Images are not managed in a `*SCM*`system (just like binaries were not).  However, just as installable artifacts and repositories (i.e. RPMs, RPM repo's) arose with similar semantics to `*SCMs*`,
similar constructs and terminology around image management that are eerily similar to `*SCMs*`have arisen:

- image registry == SCM server
- image repository == SCM repository
- `*ImageStream*` == SCM branch
- `*ImageStreamTag*` == SCM branch tag

{product-title} builds, or the explicit use of `docker push` with the proper credentials, allows for storage of images in the {product-title} image registry (conceptually similar to `git push`).

The `oc import-image` is a specialized form of `docker pull`, as it pulls images from external registries and puts them into the {product-title} image registry (conceptually similar to a `git clone`).

And analogous to `docker tag`, which is really analogous to `git tag`, the `oc tag` command allows you to control the destination of different versions of your image in an {product-title} `*ImageStream*`.
And note that `oc tag` also allows you to copy specific versions of an Image from one `*ImageStream*` to another, even across different `*Projects*` in a `*Cluster*`.

Coupled with `*ImageChangeTriggers*`, the use of `oc tag` forms the simplest, building block of *promotion* within {product-title}.

And in the context of running the {product-title} Jenkins Image, with the {product-title} Pipeline Plugin for Jenkins installed and available, the "Tag {product-title} Image" Jenkins build step is essentially an `oc tag` under the covers.
Coupled with the additional Jenkins build steps that allow verification of {product-title} `*Services*` and `*ReplicationControllers*`, the building blocks to validate changes prior to promoting them via tagging take shape.

More on this later when we dive into the more precise examples of the use of these tools.

[[portability]]
== Portability

Building upon how various {product-title} API Objects and Docker Images count as elements of your application (in addition to the classic binary executables / consumables produced by traditional programming
language files), once you've decided that a usable version of the application is available for a given stage of your pipeline, the next consideration is how can you migrate those API Objects and Images into the
corresponding staging environments of your pipeline.  And in the case of API Objects (much more *mutable* than Images), you quite possibly will need to transform them in some fashion as you propagate them
through the pipeline to various environments.

=== Images

First, the simpler of the two (the immutability tenet and the common Docker based interfaces help once again), Images:

- multiple `*Projects*` can access the same `*ImageStreams*`within a {product-title} Internal Image Registry
- multiple `*Clusters*` can access the same external Docker registries

The CLI commands like `oc tag`, `oc import-image` noted in the Versioning section are tools for propagating and transferring in addition to versioning.

See the specific examples and scenarios below.

=== API Objects

You can get the exact state that instant of an API object, via `oc get`, or obtain versions of the object suitable for recreation (i.e. the *specification* elements noted earlier), with dynamic, environment specific data removed,
via `oc export`.  However, more likely, the `oc export` command, will often be more appropriate since it can filter out the dynamic, specific state of an API Object, and only retrieve the configuartion and specification aspects.
The `oc export` command could also prove useful in structuring the API Objects for your application since it can facilitate the creation of re-usable templates.  And if needed, `oc export` has the flexibility to allow the retrieveal of
specific *runtime* elements of an API Object that are reusable across the different runtime environments of your `*CI/CD*` pipeline.

And when you check out said JSON/YAML from the `*SCM*` and run `oc create` (in the case of objects) or `oc process` (in the case of templates) to create in a given environment of your `*CI/CD*` pipeline, there are a
plethora of commands to edit objects in the API server once they are created. These commands enable small transformations which may be necessary when migrating API objects between stages of your `*CI/CD*` pipeline. 

Look at the help for `oc edit`, `oc set`, `oc label`, `oc annotate`, `oc patch`, `oc apply`.  And specific usages are provided in the detailed examples below.

GGM editorial note: how far down the `oc` rabbit hole do we want to go down here vs. the specific examples ....

See the specific examples and scenarios below.

[[isolation]]
== Isolation

Isolation as a concept applies in a couple of ways to our topic of `*CI/CD*` within {product-title}. First, in looking at {product-title} itself:
- The additional constructs pulled in by {product-title}:  Containers, `*Pods*`, `*Projects*`, and even entire `*Clusters*`, are all additions to
the existing set of ways to isolate various aspects of your enterprise
- And they provide great flexibility with respect to *when*, *where*, and *how* you isolate

Then, in an analogous sense, your IT organization undoubtedly has various ways in which portions are isolated from each other
based on how it is structured:

- Location: is your organization spread out across different cities, different countries, different continents?
- IT assets:  do different parts of your organization exclusively own or share the various assets?
- Collaboration: which groups in your organization work closely or often together, and which ones do not collaborate?  Perhaps portions of your enterprise need to be explicitly isolated?

Naturally then, you will map (or already have mapped) your organization to the {product-title} constructs.  Some basic rules of thumb to remember:
GGM editorial note ... for now, have gone "all in" on drawing connections and analogies between {product-title} concepts and more traditional SW development ones, like ImageStream == git branch
GGM editorial note ... not 100% sure yet how much it will fly

- a `*BuildConfig*` maps to a Git source repository
- an Image encapsulates the resulting *binary* of a source repository
- just like specific branches of a Git source repository are created and tagged with a version-relevant label when they reach some form of completion, and the associated binaries produced from those branches
are given the same version-relevant label and made available for download from a website, you can similarly apply labels/tags to your Image (the new *binary* that stems from your source code) and make it available
for *download* within your enterprise from the `*ImageStream*` (again, think branch) housed in the given {product-title} Internal Image Registry.
- consider how your various source repository permissions are laid out today ... who can tag, who can merge, who can commit, who can upload various versions of publicly released or private pre-release binaries for
download, who can even access publicly released or private pre-release binaries
- also consider that existing source and binary repositories that you leverage today probably employ *mirrors* based on geographic location
- an {product-title} `*Project*` is an aggregation that realistically could be applied across whatever existing structures you have;  certainly the *Project* terminology is used often in tools focused on software development;
the key point to consider is that an {product-title} `*Project*` is the most natural containment for permissions and roles that can be associated with the various {product-title} API Objects; think about how your permissions and
roles are currently structured (or think about the structure you want to move to if you realize that {product-title} gives you more power than you used to have)
- an {product-title} `*Cluster*` contains many `*Projects*` (i.e. the {product-title} Master of a `*Cluster*` == `*SCM*` server), and implies a single (etcd) database where the various `*Controllers*` can typically communicate
over reliable networks, and leverage *co-located* hardware ... somewhat analogous to a a single mirror, where something external synchronizes it with other mirrors, which are located in different geographies
(cities, states, regions, countries, continents)
GGM editorial note .... can a Cluster be even say building wide ???? can it span multiple floors, or are its performance needs too demanding??? ... are we too close to the capacity planning slippery slope

Some implications of how you isolate:

- As noted above with `*ImageStreams*`, promotion flows are possible both within a project and between projects serviced by the same {product-title} Internal Registry where tagging of Images trigger
`*Deployments*` in separate `*Projects*` and/or `*Pods*`, where different teams in your organization perform different levels of validation against those different `*Pods*`.
- But if computer processing or capacity concern reach the point that you can't share an {product-title} Master and Internal Registry across all your projects ...
- Or  if you want to make sure *team A* can't accidentally misconfigure resources for *team B*
- Or if you want to make sure that say a problem with *application A* does not inadvertently impact running instances of *application B* ...
- Or if your organization maintains separate versions of the requisite database(s) that service your application(s), and those versions are strictly isolated ....
- Or if your application's network activity is as such that you want to isolate that activity at various stages of validation within your pipeline (say performance testing vs. integration testing) ...
- then you isolate first along `*Project*` lines (where perhaps there is some duplication of API Objects) and the `*Cluster*` lines (where there it total duplication, and more like change in various connection settings to
account for environment changes)

More on this later when we dive into the more precise examples.


[[upgrade-update]]
== Upgrade and Update

{product-title} `*Deployments*` are the mechanism for handling upgrade/update.

`*Deployments*` have strategies that determine the process of deployment (how the older version is brought down, how the new version is brought up), and liveness and readiness probes (http requests or operating
system level commands) for determining if the deployment is successful.

Irrespective of how the deployment is triggered, the state of the deployment can be monitored from the {product-title} WebConsole, the {product-title} CLI, and in the case of `*CI/CD*` pipeline flows from Jenkins, from the
Deployment related steps provide by the {product-title} Pipeline Plugin.  The {product-title} Pipeline Plugin has steps to verify if a `*Service*` is responsive, if a given number of `*Replicas*` are up, or if a `*Deployment*`
has been triggered based on an Image change.

Hence, various points in the pipeline can be marked as successful or failed if there are problems with the deployment.

[[Hooks]]
== Hooks

`*Deployments*` provide pre, mid and post hook points (before spinning up new versions, before bringing down old versions, after bringing down old versions).  Operating system level commands and scripts
can be specified at each of these hook points.  From a `*CI/CD*` perspective, those commands can include tagging of images, or the addition of labels to API Objects that can be later queried by
certain stages of the `*CI/CD*` pipeline.

Similarly, `*BuildConfigs*` have hooks that facilitate testing or staging in a pipeline.  The post-commit build hook allow for scripts to be executed in an ephemeral container based on an image just produced
by an {product-title} build.  This can serve as an early sniff test of your application, most likely early in the `*CI/CD*` pipeline.

And webhooks allow you to trigger {product-title} `*Builds*` based on changes in your `*SCM*`.  So you can initiate early stage `*CI/CD*` flows if you like as new development work on the applications commence.
In fact, the resulting builds could trigger a build of the {product-title} Jenkins Pipeline build strategy, which could in turn trigger execution of Pipeline jobs already defined in Jenkins, or the BuildConfig itself can have
the Jenkinsfile contents for the Pipeline job.  And the mere instantiation of Jenkins Pipeline `*BuildConfig*` can lead to the auto provisioning of a Jenkins server for your {product-title} `*Project*`.

`*ImageChangeTriggers*` can initiate `*Builds*` of `*BuildConfigs*`.  Where again, those `*BuildConfigs*` can now include references to Jenkinsfile's
and Pipeline jobs in Jenkins.  And `*ImageChangeTriggers*` can initiate `*Deployments*` to occur.  Tagging a new version of an image in order to spin up the Deployment that will service
the testing around a given stage in your `*CI/CD*` pipeline is again one of the main use cases.

[[scenarios-example]]
== Scenarios and Examples


[[simple]]
=== Simple


[[non-trivial]]
=== Non-Trivial


[[Complex]]
=== Complex


