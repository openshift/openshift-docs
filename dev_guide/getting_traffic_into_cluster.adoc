[[getting-traffic-into-cluster]]
<<<<<<< a55509629bdca7cc36be6291aab684d8a75da460
= Getting Traffic Into The Cluster
=======
= Getting Traffic into the Cluster
>>>>>>> Document how to get traffic into the cluster
{product-author}
{product-version]
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

ifdef::openshift-origin,openshift-enterprise,openshift-dedicated[]
== Overview
There are many ways to access the cluster. This section describes some
commonly used approaches.

The recommendation is:

<<<<<<< a55509629bdca7cc36be6291aab684d8a75da460
- If you have HTTP/HTTPS -- Use the
xref:../dev_guide/getting_traffic_into_cluster.adoc#using-a-router[Router],
- If you have a TLS-encrypted protocol other than HTTPS (i.e., TLS with
the SNI header) --
Use the xref:../dev_guide/getting_traffic_into_cluster.adoc#using-a-router[Router],
- Otherwise -- Use
xref:../dev_guide/getting_traffic_into_cluster.adoc#using-the-loadbalancer[LoadBalancer],
xref:../dev_guide/getting_traffic_into_cluster.adoc#using-externalIP[ExternalIP], or
xref:../dev_guide/getting_traffic_into_cluster.adoc#using-nodeport[NodePort].

TCP or UDP offers several approaches:

- Use the non-cloud
xref:../dev_guide/getting_traffic_into_cluster.adoc#using-the-loadbalancer[LoadBalancer],
but that limits you to a single ingress IP (can be a VIP, but still will be
a single machine for initial load balancing). It simplifies the admin job,
but uses one IP per service.
- Manually assign
xref:../dev_guide/getting_traffic_into_cluster.adoc#using-externalIP[ExternalIPs]
to the service. Here you can assign a set of IPs, so can have multiple
machines for the incoming load balancing. But this requires elevated
permissions to assign, and manual tracking of what IP:ports that have been used.
- Use xref:../dev_guide/getting_traffic_into_cluster.adoc#using-nodeport[NodePorts]
to expose the service on ALL nodes in the cluster. This is more wasteful
of scarce port resources. However, it is a little easier to set up multiple.
Again, this requires more privilege.

The router is the most common way to access the cluster.
This is limited to HTTP/HTTPS(SNI)/TLS(SNI) which covers web applications.
=======
- If you have HTTP/HTTPS, use the xref:using-a-router[router].
- If you have a TLS-encrypted protocol other than HTTPS (for example, TLS with
the SNI header), use
the xref:../dev_guide/getting_traffic_into_cluster.adoc#using-a-router[router].
- Otherwise, use xref:using-the-loadbalancer[Load Balancer],
xref:using-externalIP[ExternalIP], or xref:using-nodeport[NodePort].

TCP or UDP offers several approaches:

- Use the non-cloud xref:using-the-loadbalancer[Load Balancer]. This limits you to
a single ingress IP (which can be a virtual IP (VIP), but still is a single machine for
initial load balancing). It simplifies the administrator's job, but uses one IP
per service.
- Manually assign xref:using-externalIP[ExternalIPs] to the service. You can
assign a set of IPs, so you can have multiple machines for the incoming load
balancing. However, this requires elevated permissions to assign, and manual
tracking of what IP:ports that are used.
- Use xref:using-nodeport[NodePorts]
to expose the service on _all_ nodes in the cluster. This is more wasteful
of scarce port resources. However, it is slightly easier to set up multiple.
Again, this requires more privileges.

The router is the most common way to access the cluster. This is limited to
HTTP/HTTPS(SNI)/TLS(SNI), which covers web applications.
>>>>>>> Document how to get traffic into the cluster

ExternalIP or NodePort is useful when the HTTP protocol is not being used or
non-standard ports are in use. There is more manual setup and monitoring
involved.

<<<<<<< a55509629bdca7cc36be6291aab684d8a75da460
The admin needs to set up the external to the cluster networking environment
so that requests can reach the cluster. For example, names can be configured
into 
xref:../install_config/install/prerequisites.adoc#prereq-dns[DNS]
to point to specific nodes or other IP addresses in the cluster.
The DNS wildcard feature can be used to confiugre a subset of names to an
IP address in the cluster.  This is convenient when using routers because
it allows the users to set up routes within the cluster without further
admin attention.

The admin must make sure the local firewall on each node permits the
request to reach the IP address.

The xref:../admin_guide/high_availability.adoc#admin-guide-high-availability[High Availability] section
describes how to make this highly available using replicated services.

endif::[]


=======
The administrator must set up the external port to the cluster networking
environment so that requests can reach the cluster. For example, names can be
configured into
xref:../install_config/install/prerequisites.adoc#prereq-dns[DNS] to point to
specific nodes or other IP addresses in the cluster. The DNS wildcard feature
can be used to configure a subset of names to an IP address in the cluster. This
is convenient when using routers because it allows the users to set up routes
within the cluster without further administrator attention.

The administrator must ensure that the local firewall on each node permits the
request to reach the IP address.

The xref:../admin_guide/high_availability.adoc#admin-guide-high-availability[High
Availability] section describes how to make this highly available using
replicated services.
endif::[]

>>>>>>> Document how to get traffic into the cluster
[[using-a-router]]
== Using a Router

This is the most common way to access the cluster. A
xref:../install_config/configuring_routing.adoc#install-config-configuring-routing[router]
is configured to accept external requests and proxy them based on the
<<<<<<< a55509629bdca7cc36be6291aab684d8a75da460
configured routes.  This is limited to HTTP/HTTPS(SNI)/TLS(SNI) which
covers web applications.

An administrator can create a
xref:../install_config/install/prerequisites.adoc#prereq-dns[wild-card DNS]
entry, and then set up a router, after that the users can self-service
the ingress without having to bother the admins. The router has controls
to allow the admin to specify whether the users can self-provision
hostnames, or if they must fit a pattern the admin defines. The other
solutions require the admin to do it, or it requires that they delegate
a lot of privilege.

A set of routes can be created in the various projects. The overall
set of routes is available to the set of routers. Each router selects
from the set of routes.  All routers see all routes unless restricted
by labels on the router, this is called router
xref:../architecture/core_concepts/routes.adoc#router-sharding[sharding].

The xref:../admin_guide/high_availability.adoc#admin-guide-high-availability[High Availability]
section describes how to configure a router for high availability service
using multiple replicas.

[[using-the-loadbalancer]]
== Using a Service of Type LoadBalancer

There are load balancers available on
xref:../install_config/configuring_aws.adoc#install-config-configuring-aws[AWS] and
xref:../install_config/configuring_gce.adoc#install-config-configuring-gce[GCE] clouds as well as
xref:../admin_guide/tcp_ingress_external_ports.adoc#admin-guide-expose-external-ports[non-cloud].

The non-cloud
xref:../admin_guide/tcp_ingress_external_ports.adoc#admin-guide-expose-external-ports[LoadBalancer] allocates
a unique IP from a configured pool. This limits you to a single ingress IP
(can be a VIP, but still will be a single machine for initial load balancing).
It simplifies the admin job by providing the needed IP address, but uses one
IP per service.

Load balancing is described
link:http://kubernetes.io/docs/user-guide/services/#type-loadbalancer[here].
=======
configured routes. This is limited to HTTP/HTTPS(SNI)/TLS(SNI), which
covers web applications.

An administrator can create a
xref:../install_config/install/prerequisites.adoc#prereq-dns[wildcard DNS]
entry, and then set up a router. Afterward, the users can self-service the
ingress without having to contact the administrators. The router has controls to
allow the administrator to specify whether the users can self-provision host
names, or if they must fit a pattern the administrator defines. The other
solutions require the administrator to do the provisioning, or they require that
the administrator delegates a lot of privilege.

A set of routes can be created in the various projects. The overall set of
routes is available to the set of routers. Each router selects from the set of
routes. All routers see all routes unless restricted by labels on the router,
which is called router
xref:../architecture/core_concepts/routes.adoc#router-sharding[sharding].

The
xref:../admin_guide/high_availability.adoc#admin-guide-high-availability[High
Availability] section describes how to configure a router for high availability
service using multiple replicas.

[[using-the-loadbalancer]]
== Using a Load Balancer Service

link:http://kubernetes.io/docs/user-guide/services/#type-loadbalancer[Load balancers] are available on
xref:../install_config/configuring_aws.adoc#install-config-configuring-aws[AWS]
and
xref:../install_config/configuring_gce.adoc#install-config-configuring-gce[GCE]
clouds, and
xref:../admin_guide/tcp_ingress_external_ports.adoc#admin-guide-expose-external-ports[non-cloud]
options are also available.

The non-cloud
xref:../admin_guide/tcp_ingress_external_ports.adoc#admin-guide-expose-external-ports[load
balancer] allocates a unique IP from a configured pool. This limits you to a
single ingress IP, which can be a VIP, but still will be a single machine for
initial load balancing. The non-cloud load balancer simplifies the
administrator's job by providing the needed IP address, but uses one IP per
service.
>>>>>>> Document how to get traffic into the cluster

[[using-externalIP]]
== Using a Service ExternalIP

The user can manually assign
link:http://kubernetes.io/docs/user-guide/services/#external-ips[ExternalIPs]
to the service. The supplied list of IP addresses are used for load balancing
incoming requests. The service port is opened on all nodes running kube-proxy.
<<<<<<< a55509629bdca7cc36be6291aab684d8a75da460
Doing this requires elevated permissions to assign, and manual tracking of the
=======
ExternalIPs require elevated permissions to assign, and manual tracking of the
>>>>>>> Document how to get traffic into the cluster
IP:ports that are in use.

An externally visible IP can be configured in one of several ways:

<<<<<<< a55509629bdca7cc36be6291aab684d8a75da460
- manually configure the ExternalIP with a known external IP address.
- configure ExternalIP to a
xref:../admin_guide/high_availability.adoc#admin-guide-high-availability[VIP]
that is generated from (VRRP)
- In a cloud (xref:../install_config/configuring_aws.adoc#install-config-configuring-aws[AWS] or
xref:../install_config/configuring_gce.adoc#install-config-configuring-gce[GCE])
use type=LoadBalancer
- In a non-cloud environment, configure an ingressIP range (IngressIPNetworkCIDR),
service.type=LoadBalancer and service.port.ingressIP

The admin must make sure the external IPs are routed to the nodes and local
firewall rules on all nodes allow access to the open port.

Use the same nodes as the router but advertise them with VRRP and use
the DNS address of the router nodes.


=======
- Manually configure the ExternalIP with a known external IP address.
- Configure ExternalIP to a
xref:../admin_guide/high_availability.adoc#admin-guide-high-availability[VIP]
that is generated from (VRRP).
- In a cloud (xref:../install_config/configuring_aws.adoc#install-config-configuring-aws[AWS] or
xref:../install_config/configuring_gce.adoc#install-config-configuring-gce[GCE])
use `type=LoadBalancer`
- In a non-cloud environment, configure an ingressIP range (IngressIPNetworkCIDR),
`service.type=LoadBalancer` and `service.port.ingressIP`.

The administrator must ensure the external IPs are routed to the nodes and local
firewall rules on all nodes allow access to the open port.

Use the same nodes as the router, but advertise them with VRRP and use
the DNS address of the router nodes.

>>>>>>> Document how to get traffic into the cluster
[[using-nodeport]]
== Using a Service NodePort

Use NodePorts to expose the service nodePort on all nodes in the cluster.
NodePorts are in the 30-60k range by default, which means a NodePort is
<<<<<<< a55509629bdca7cc36be6291aab684d8a75da460
unlikely to match a service's intended port (e.g., 8080 might be exposed
as 31020).  This use of ports is wasteful of scarce port resources.
However, it is a little easier to set up. Again, this requires more privilege.

The admin must make sure the external IPs are routed to the nodes and local
=======
unlikely to match a service's intended port (for example, 8080 may be exposed
as 31020). This use of ports is wasteful of scarce port resources.
However, it is slightly easier to set up. Again, this requires more privileges.

The administrator must ensure the external IPs are routed to the nodes and local
>>>>>>> Document how to get traffic into the cluster
firewall rules on all nodes allow access to the open port.

NodePorts and externalIP are independent and both can be used concurrently.

[[virtual-ip]]
== Using Virtual IPs

All of the approaches can expose
<<<<<<< a55509629bdca7cc36be6291aab684d8a75da460
xref:../admin_guide/high_availability.adoc#admin-guide-high-availability[VIPs] (virtual IPs). The Virtual
IPs are generated from the VRRP protocol.


[[edge-load-balancer]]
== Edge LoadBalancer
=======
xref:../admin_guide/high_availability.adoc#admin-guide-high-availability[VIPs].
The VIPs are generated from the VRRP protocol.


[[edge-load-balancer]]
== Edge Load Balancer
>>>>>>> Document how to get traffic into the cluster

An edge xref:../install_config/routing_from_edge_lb.adoc#install-config-routing-from-edge-lb[load balancer]
can be used to accept traffic from outside networks and proxy the traffic
to pods inside the cluster.

<<<<<<< a55509629bdca7cc36be6291aab684d8a75da460
In this configuration the internal pod network is visible to the outside.

=======
In this configuration, the internal pod network is visible to the outside.
>>>>>>> Document how to get traffic into the cluster
