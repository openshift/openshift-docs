// Module included in the following assemblies:
//
// * list of assemblies where this module is included


[id="preparing-the-provision-node-for-openshift-install_{context}"]
= Preparing the Provision Node for Openshift Install

Perform the following steps need to prepare the environment.

. Log in to the provision node via `ssh`.

. Create a user (for example, `kni`) to deploy as non-root and provide that user `sudo` privileges.
+
----
# useradd kni
# echo "kni ALL=(root) NOPASSWD:ALL" | tee -a /etc/sudoers.d/kni
# chmod 0440 /etc/sudoers.d/kni
----

. Create an `ssh` key for the new user.
+
----
# su - kni -c "ssh-keygen -t rsa -f /home/kni/.ssh/id_rsa -N ''"
----

. Use Red Hat Subscription Manager to register your environment.
+
----
# subscription-manager register --username=<user> --password=<pass> --auto-attach
# subscription-manager repos --enable=rhel-8-for-x86_64-appstream-rpms --enable=rhel-8-for-x86_64-baseos-rpms
----
+
[NOTE]
====
For more information about Red Hat Subscription Manager, see https://access.redhat.com/documentation/en-us/red_hat_subscription_management/1/html-single/rhsm/index[Using and Configuring Red Hat Subscription Manager].
====

. Install the following packages.
+
----
# dnf install -y libvirt qemu-kvm mkisofs python3-devel jq ipmitool
----

. Modify the user to add the `libvirt` group to the newly created user.
+
----
# usermod --append --groups libvirt <user>
----

. Start `firewalld`, enable the `http` service, and enable port 5000.
+
----
# systemctl start firewalld
# firewall-cmd --zone=public --add-service=http --permanent
# firewall-cmd --add-port=5000/tcp --zone=libvirt  --permanent
# firewall-cmd --add-port=5000/tcp --zone=public   --permanent
# firewall-cmd --reload
----

. Start and enable the `libvirtd` service.
+
----
# systemctl start libvirtd
# systemctl enable libvirtd --now
----

. Create the default storage pool and start it.
+
----
# virsh pool-define-as --name default --type dir --target /var/lib/libvirt/images
# virsh pool-start default
# virsh pool-autostart default
----

. Configure networking.
+
[NOTE]
====
This step can also be run from the console.
====
+
----
# You will be disconnected, but reconnect via your ssh session after running
export PUB_CONN=<baremetal_nic_name>
export PROV_CONN=<prov_nic_name>
nohup bash -c '
    nmcli con down "$PROV_CONN"
    nmcli con down "$PUB_CONN"
    nmcli con delete "$PROV_CONN"
    nmcli con delete "$PUB_CONN"
    # RHEL 8.1 appends the word "System" in front of the connection, delete in case it exists
    nmcli con down "System $PUB_CONN"
    nmcli con delete "System $PUB_CONN"
    nmcli connection add ifname provisioning type bridge con-name provisioning
    nmcli con add type bridge-slave ifname "$PROV_CONN" master provisioning
    nmcli connection add ifname baremetal type bridge con-name baremetal
    nmcli con add type bridge-slave ifname "$PUB_CONN" master baremetal
    nmcli con down "$PUB_CONN";pkill dhclient;dhclient baremetal
    nmcli connection modify provisioning ipv4.addresses 172.22.0.1/24 ipv4.method manual
    nmcli con down provisioning
    nmcli con up provisioning
'
----

. `ssh` back into your terminal session (if required).

. Verify the connection bridges have been properly created.
+
----
# nmcli con show
----
+
----
NAME               UUID                                  TYPE      DEVICE
baremetal          4d5133a5-8351-4bb9-bfd4-3af264801530  bridge    baremetal
provisioning       43942805-017f-4d7d-a2c2-7cb3324482ed  bridge    provisioning
virbr0             d9bca40f-eee1-410b-8879-a2d4bb0465e7  bridge    virbr0
bridge-slave-eno1  76a8ed50-c7e5-4999-b4f6-6d9014dd0812  ethernet  eno1
bridge-slave-eno2  f31c3353-54b7-48de-893a-02d2b34c4736  ethernet  eno2
----

. Login in as the new user on the provision node.
+
----
# su - kni
----

. Copy the pull secret (`pull-secret.txt`) generated earlier and place it in the Provision node new user home directory.
