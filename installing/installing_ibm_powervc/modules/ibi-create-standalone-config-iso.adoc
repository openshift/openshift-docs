// Module included in the following assemblies:
//
// * edge_computing/ibi-edge-image-based-install.adoc 

:_mod-docs-content-type: PROCEDURE
[id="create-standalone-config-iso_{context}"]
= Deploying a {sno} cluster using the openshift-install program

You can use the `openshift-install` program to configure and deploy a host that you preinstalled with an image-based installation. To configure the target host with site-specific details, you must create the following resources:

* The `install-config.yaml` installation manifest
* The `image-based-config.yaml` manifest

The `openshift-install` program uses these resources to generate a configuration ISO that you attach to the preinstalled target host to complete the deployment.

[NOTE]
====
For more information about the specifications for the `image-based-config.yaml` manifest, see "Reference specifications for the image-based-config.yaml manifest".
====

.Prerequisites

* You preinstalled a host with {sno} using an image-based installation.
* You downloaded the latest version of the `openshift-install` program.
* You created a pull secret to authenticate pull requests. For more information, see "Using image pull secrets".

.Procedure

. Create a working directory by running the following:
+
[source,terminal]
----
$ mkdir ibi-config-iso-workdir <1>
----
<1> Replace `ibi-config-iso-workdir` with the name of your working directory.

. Create the installation manifest:

.. Create a YAML file that defines the `install-config` manifest:
+
--
.Example `install-config.yaml` file
[source,yaml]
----
apiVersion: v1
metadata:
  name: sno-cluster-name
baseDomain: host.example.com
compute:
  - architecture: amd64
    hyperthreading: Enabled
    name: worker
    replicas: 0
controlPlane:
  architecture: amd64
  hyperthreading: Enabled
  name: master
  replicas: 1
networking:
  machineNetwork: <1>
  - cidr: 192.168.200.0/24
  #- cidr: fd01::/64
platform:
  none: {}
fips: false
cpuPartitioningMode: "AllNodes"
pullSecret: '{"auths":{"<your_pull_secret>"}}}'
sshKey: 'ssh-rsa <your_ssh_pub_key>'
----
<1> For dual-stack networking, you can specify both IPv4 and IPv6 CIDRs using a list format. The first CIDR in the list is the primary address family and must match the primary address family of the seed cluster.

[IMPORTANT]
====
If your cluster deployment requires a proxy configuration, you must do the following:

* Create a seed image from a seed cluster featuring a proxy configuration. The proxy configurations do not have to match.
* Configure the `machineNetwork` field in your installation manifest.
====
--

.. Save the file in your working directory. 

. Optional. Create a configuration template in your working directory by running the following command:
+
[source,terminal]
----
$ openshift-install image-based create config-template --dir ibi-config-iso-workdir/
----
+
.Example output
[source,terminal]
----
INFO Config-Template created in: ibi-config-iso-workdir
----
+
The command creates the `image-based-config.yaml` configuration template in your working directory:
+
[source,yaml]
----
#
# Note: This is a sample ImageBasedConfig file showing
# which fields are available to aid you in creating your
# own image-based-config.yaml file.
#
apiVersion: v1beta1
kind: ImageBasedConfig
metadata:
  name: example-image-based-config
additionalNTPSources:
  - 0.rhel.pool.ntp.org
  - 1.rhel.pool.ntp.org
hostname: change-to-hostname
releaseRegistry: quay.io
# networkConfig contains the network configuration for the host in NMState format.
# See https://nmstate.io/examples.html for examples.
networkConfig:
  interfaces:
    - name: eth0
      type: ethernet
      state: up
      mac-address: 00:00:00:00:00:00
      ipv4:
        enabled: true
        address:
          - ip: 192.168.122.2
            prefix-length: 23
        dhcp: false
----

. Edit your configuration file:
+
.Example `image-based-config.yaml` file
[source,yaml]
----
#
# Note: This is a sample ImageBasedConfig file showing
# which fields are available to aid you in creating your
# own image-based-config.yaml file.
#
apiVersion: v1beta1
kind: ImageBasedConfig
metadata:
  name: sno-cluster-name
additionalNTPSources:
  - 0.rhel.pool.ntp.org
  - 1.rhel.pool.ntp.org
hostname: host.example.com
releaseRegistry: quay.io
# networkConfig contains the network configuration for the host in NMState format.
# See https://nmstate.io/examples.html for examples.
networkConfig:
    interfaces:
      - name: ens1f0
        type: ethernet
        state: up
        ipv4:
          enabled: true
          dhcp: false
          auto-dns: false
          address:
            - ip: 192.168.200.25
              prefix-length: 24
        ipv6:
          enabled: false
    dns-resolver:
      config:
        server:
          - 192.168.15.47
          - 192.168.15.48
    routes:
      config:
      - destination: 0.0.0.0/0
        metric: 150
        next-hop-address: 192.168.200.254
        next-hop-interface: ens1f0
----

. Create the configuration ISO in your working directory by running the following command:
+
[source,terminal]
----
$ openshift-install image-based create config-image --dir ibi-config-iso-workdir/
----
+
.Example output
[source,terminal]
----
INFO Adding NMConnection file <ens1f0.nmconnection> 
INFO Consuming Install Config from target directory 
INFO Consuming Image-based Config ISO configuration from target directory 
INFO Config-Image created in: ibi-config-iso-workdir/auth
----
+
View the output in the working directory:
+
.Example output
[source,terminal]
----
ibi-config-iso-workdir/
├── auth
│   ├── kubeadmin-password
│   └── kubeconfig
└── imagebasedconfig.iso
----

. Attach the `imagebasedconfig.iso` to the preinstalled host using your preferred method and restart the host to complete the configuration process and deploy the cluster.

.Verification
When the configuration process completes on the host, access the cluster to verify its status.

. Export the `kubeconfig` environment variable to your kubeconfig file by running the following command:
+
[source,terminal]
----
$ export KUBECONFIG=ibi-config-iso-workdir/auth/kubeconfig
----

. Verify that the cluster is responding by running the following command:
+
[source,terminal]
----
$ oc get nodes
----
+
.Example output
[source,terminal]
----
NAME                                         STATUS   ROLES                  AGE     VERSION
node/sno-cluster-name.host.example.com       Ready    control-plane,master   5h15m   v1.34.2
----