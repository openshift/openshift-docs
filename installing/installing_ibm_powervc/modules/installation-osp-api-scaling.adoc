// Module included in the following assemblies:
//
// * networking/load-balancing-openstack.adoc

:_mod-docs-content-type: PROCEDURE
[id="installation-osp-api-scaling_{context}"]
= Scaling clusters by using Octavia

[role="_abstract"]
To ensure high availability and distribute traffic across multiple cluster API access points in {product-title} on {rh-openstack}, create an Octavia load balancer. Configuring your cluster to use multiple balancers prevents network bottlenecks and ensures continuous access to your API services.

.Prerequisites

* Octavia is available on your {rh-openstack-first} deployment.

.Procedure

. From the command-line interface (CLI), create an Octavia load balancer that uses the Amphora driver:
+
[source,terminal]
----
$ openstack loadbalancer create --name API_OCP_CLUSTER --vip-subnet-id <id_of_worker_vms_subnet>
----
+
You can use a name of your choice instead of `API_OCP_CLUSTER`.

. After the load balancer becomes active, create listeners:
+
[source,terminal]
----
$ openstack loadbalancer listener create --name API_OCP_CLUSTER_6443 --protocol HTTPS--protocol-port 6443 API_OCP_CLUSTER
----
+
[NOTE]
====
To view the status of the load balancer, enter `openstack loadbalancer list`.
====

. Create a pool that uses the round-robin algorithm and has session persistence enabled:
+
[source,terminal]
----
$ openstack loadbalancer pool create --name API_OCP_CLUSTER_pool_6443 --lb-algorithm ROUND_ROBIN --session-persistence type=<source_IP_address> --listener API_OCP_CLUSTER_6443 --protocol HTTPS
----

. To ensure that control-plane machines are available, create a health monitor:
+
[source,terminal]
----
$ openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type TCP API_OCP_CLUSTER_pool_6443
----

. Add the control plane machines as members of the load balancer pool:
+
[source,terminal]
----
$ for SERVER in $(MASTER-0-IP MASTER-1-IP MASTER-2-IP)
do
  openstack loadbalancer member create --address $SERVER  --protocol-port 6443 API_OCP_CLUSTER_pool_6443
done
----

. Optional: To reuse the cluster API floating IP address, unset it:
+
[source,terminal]
----
$ openstack floating ip unset $API_FIP
----

. Add either the unset `API_FIP` or a new address to the created load balancer VIP:
+
[source,terminal]
----
$ openstack floating ip set  --port $(openstack loadbalancer show -c <vip_port_id> -f value API_OCP_CLUSTER) $API_FIP
----
+
Your cluster now uses Octavia for load balancing.