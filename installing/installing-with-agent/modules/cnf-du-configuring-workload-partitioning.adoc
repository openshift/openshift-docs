// Module included in the following assemblies:
//
// *scalability_and_performance/cnf-provisioning-and-installing-a-distributed-unit.adoc

[id="cnf-du-configuring-workload-partitioning_{context}"]

= Configuring workload partitioning

The following procedure outlines a high level, end to end workflow that installs a cluster with workload partitioning enabled and pods that
are correctly scheduled to run on the management CPU partition.

. Create a machine config manifest to configure CRI-O to partition management workloads. The cpuset that you specify must match the reserved cpuset that you specified in the performance-addon-operator profile.

. Create another machine config manifest to write a configuration file for kubelet to enable the same workload partition. The file is only readable by the kubelet.

. Run `openshift-install` to create the standard manifests, adds their extra manifests from steps 1 and 2, then creates the cluster.

. For pods and namespaces that are correctly annotated, the CPU request values are zeroed out and converted to `<workload-type>.workload.openshift.io/cores`. This modified resource allows the pods to be constrained to the restricted CPUs.

. The single node cluster starts with management components constrained to a subset of available CPUs.
