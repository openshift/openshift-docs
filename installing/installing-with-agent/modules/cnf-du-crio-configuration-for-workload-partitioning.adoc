// Module included in the following assemblies:
//
// *scalability_and_performance/cnf-provisioning-and-deploying-a-distributed-unit.adoc

[id="cnf-du-crio-configuration-for-workload-partitioning_{context}"]

= CRI-O configuration for workload partitioning

In support of workload partitioning, CRI-O supports new configuration settings. The configuration file is delivered to a host as part of a machine config.

[source,terminal]
----
[crio.runtime.workloads.{workload-type}]
  activation_annotation = "target.workload.openshift.io/<workload-type>" <1>
  annotation_prefix = "resources.workload.openshift.io" <2>
  resources = { "cpushares" = 0, "cpuset" = "0-1,52-53" } <3>
----
<1> Use the `activation_annotation` field to match pods that should be treated as having the workload type. The annotation key on the pod is compared for an exact match against the value specified in the configuration file. In this release, the only supported workload-type is `management`.

<2> The `annotation_prefix` is the start of the annotation key that passes settings from the admission hook down to CRI-O.

<3> The `resources` map associates annotation suffixes with default values. CRI-O defines a well-known set of resources and other values are not allowed. The `cpuset` value must match the kubelet configuration file and the reserved `cpuset` in the applied PerformanceProfile.

In the management workload case, it is configured as follows:

[source,terminal]
----
[crio.runtime.workloads.management]
  activation_annotation = "target.workload.openshift.io/management"
  annotation_prefix = "resources.workload.openshift.io"
  resources = { "cpushares" = 0, "cpuset" = "0-1,52-53" }
----

Pods that have the `target.workload.openshift.io/management` annotation will have their `cpuset` configured to the value from the appropriate workload configuration. The CPU shares for each container in the pod are configured according to the `management.workload.openshift.io/cores` resource limit, which ensures the pod's CPU shares are enforced.
