// Module included in the following assemblies:
//
// *scalability_and_performance/cnf-provisioning-and-installing-a-distributed-unit.adoc

[id="cnf-du-partitioning-management-workloads_{context}"]

= Partitioning management workloads

You can isolate the {product-title} services, cluster management workloads, and infrastructure pods to run on a reserved
set of CPUs. This is useful for resource-constrained environments,
such as such as a single-node cluster, where you want to reserve most of
the CPU resources for user workloads and configure {product-title} to run on a fixed
number of CPUs within the host.

Server resources installed at the edge, such as cores, are expensive and limited. Application workloads require nearly all cores and the resources consumed by infrastructure is a key reason for the selection of a vRAN infrastructure. A hypothetical distributed unit (DU) example is an unusually resource-intensive workload, typically requiring 20 dedicated cores. Partitioning management workloads mitigates much of this activity by separating management tasks from normal workloads.

When you use workload partitioning, the CPU resources used by {product-title} for cluster management are isolated to a partitioned set of CPU resources on a single node cluster with a DU profile applied. This falls broadly into two categories:

* Isolates cluster management functions to the defined number of CPUs. All cluster management functions operate solely on that `cpuset`.

* Tunes the cluster configuration (with the applied DU profile) so the actual CPU usage fits within the assigned `cpuset`.

[NOTE]
====
This feature is only available on single node cluster in this release.
====

The minimum number of reserved CPUs required for the management partition for a single node cluster is four CPU HTs. Inclusion of Operators or workloads outside of the set of accepted management pods requires additional CPU HTs.

Workload partitioning isolates the workloads away from the non-management workloads using the normal scheduling capabilities of Kubernetes to manage the number of pods that can be placed onto those cores, and avoids mixing cluster management workloads and user workloads.

To fully leverage workload partitioning, you need to install the Performance Addon Operator and apply the performance profile.

The concept of cluster management workloads is flexible and can encompass:

* All {product-title} core components necessary to run the cluster.

* Any add-on Operators necessary to make up the platform as defined by the customer.

* Operators or other components from third-party vendors that the customer deems as management rather than operational.

** Adding management workloads might require additional CPU resources to be added to the partition.

Workload partitioning introduces a new extended resource of `<workload-type>.workload.openshift.io/cores` for each CPU pool, workload-type, defined in the configuration file. Kubelet advertises these new resources. When workload partitioning is enabled, it represents all of the CPU capacity of the host, not just the CPU pool.
