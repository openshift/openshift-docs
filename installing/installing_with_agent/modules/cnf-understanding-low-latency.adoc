// Module included in the following assemblies:
// Epic CNF-78 (4.4)
// * scalability_and_performance/cnf-performance-addon-operator-for-low-latency-nodes.adoc

:_content-type: CONCEPT
[id="cnf-understanding-low-latency_{context}"]
= Understanding low latency

The emergence of Edge computing in the area of Telco / 5G plays a key role in
reducing latency and congestion problems and improving application performance.

Simply put, latency determines how fast data (packets) moves from the sender to
receiver and returns to the sender after processing by the receiver. Obviously,
maintaining a network architecture with the lowest possible delay of latency
speeds is key for meeting the network performance requirements of 5G. Compared
to 4G technology, with an average latency of 50ms, 5G is targeted to reach
latency numbers of 1ms or less. This reduction in latency boosts wireless
throughput by a factor of 10.

Many of the deployed applications in the Telco space require low latency that
can only tolerate zero packet loss. Tuning for zero packet loss helps mitigate
the inherent issues that degrade network performance. For more information, see
link:https://www.redhat.com/en/blog/tuning-zero-packet-loss-red-hat-openstack-platform-part-1[Tuning
for Zero Packet Loss in {rh-openstack-first}].

The Edge computing initiative also comes in to play for reducing latency rates.
Think of it as literally being on the edge of the cloud and closer to the user.
This greatly reduces the distance between the user and distant data centers,
resulting in reduced application response times and performance latency.

Administrators must be able to manage their many Edge sites and local services
in a centralized way so that all of the deployments can run at the lowest
possible management cost. They also need an easy way to deploy and configure
certain nodes of their cluster for real-time low latency and high-performance
purposes. Low latency nodes are useful for applications such as Cloud-native
Network Functions (CNF) and Data Plane Development Kit (DPDK).

{product-title} currently provides mechanisms to tune software on an
{product-title} cluster for real-time running and low latency (around <20
microseconds reaction time). This includes tuning the kernel and {product-title}
set values, installing a kernel, and reconfiguring the machine. But this method
requires setting up four different Operators and performing many configurations
that, when done manually, is complex and could be prone to mistakes.

{product-title} provides a Performance Addon Operator to implement automatic
tuning to achieve low latency performance for OpenShift applications.
The cluster administrator uses this performance profile configuration that makes
it easier to make these changes in a more reliable way. The administrator can
specify whether to update the kernel to kernel-rt, reserve CPUs for cluster and operating system housekeeping duties, including pod infra containers, and isolate CPUs for application containers to run the workloads.
