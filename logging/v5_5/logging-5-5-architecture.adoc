:_content-type: ASSEMBLY
[id="logging-architecture-5-5"]
= Understanding logging architecture
include::_attributes/common-attributes.adoc[]
:context: logging-architecture

toc::[]

include::snippets/logging-log-types-snip.adoc[]

The {logging} contains 4 logical components:

Collector:: Reads container log data from each node.

Forwarder::	Forwards log data to configured outputs.

Store:: Stores log data for analysis; the default output for the forwarder.

Exploration:: GUI and command line UI tools to search, query, and view stored logs.

These components are managed by Operators, and Custom Resource (CR) YAML files.

[id="logging-collector-understanding_{context}"]
== Understanding the collector
In prior releases, link:https://docs.fluentd.org/[Fluentd] was the default collector. Currently link:https://vector.dev/docs/[Vector] is offered as an alternative.

Either collector uses the following sources:

* journald for all system logs
* `/var/log/pods/*.log` for all container logs

If you configure your log collector to collect audit logs, it gets them from `/var/log/audit/audit.log`. Audit logs from the Kubernetes API server are stored in the `/var/log/kube-apiserver/audit.log` file. Audit logs from the OpenShift API server are stored in the `/var/log/openshift-apiserver/audit.log` file.

The logging collector is a daemon set that deploys pods to each {product-title} node. System and infrastructure logs are generated by journald log messages from the operating system, the container runtime, and {product-title}. Node logs are generated by the node filesystem. Container logs are generated by the CRI-O container engine. The collector collects the logs from these sources and forwards them internally or externally as configured in the `ClusterLogForwarder` custom resource.


== Understanding log forwarding



== Understanding the log store



== Understanding logging exploration



== Understanding logging Operators

[options="header"]
|================================================================================================
| Operator       | Red Hat OpenShift Logging  | Loki Operator  | OpenShift Elasticsearch Operator
| APIs Provided  | Cluster Log Forwarder      | LokiStack      | Elasticsearch
|                | Cluster Logging            | AlertingRule   | Kibana
|                |                            | RecordingRule  |
|                |                            | RulerConfig    |
|================================================================================================


=== Red Hat OpenShift Logging
The `Red Hat Openshift Logging` Operator implements the following custom resources:

ClusterLogging (CL):: Deploys the collector and forwarder which currently are both implemented by a daemonset running on each node.
ClusterLogForwarder (CLF):: Generates collector configuration to forward logs per user configuration.

=== Loki Operator
The `Loki` Operator implements the following custom resources

LokiStack::
RulerConfig::   Technology Preview
AlertingRule::  Technology Preview
RecordingRule:: Technology Preview


=== OpenShift Elasticsearch Operator
The `OpenShift Elasticsearch` Operator implements the following custom resources:

ElasticSearch:: Configure and deploy an Elasticsearch instance as the default log store.
Kibana:: Configure and deploy Kibana instance to search, query and view logs.


== Log Record Data Model
