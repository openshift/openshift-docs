:context: dedicated-efk-logging
[id="dedicated-efk-logging"]
= Configuring cluster logging in {product-title}
include::modules/common-attributes.adoc[]

As an {product-title} cluster administrator, you can deploy cluster logging
to aggregate logs for a range of services.

{product-title} clusters can perform logging tasks using the Elasticsearch
Operator. Cluster logging is configured through the Curator tool to retain logs
for two days.

Cluster logging is configurable using a Cluster Logging Custom Resource (CR)
deployed in the `openshift-logging` project namespace.

The Cluster Logging Operator watches for changes to Cluster Logging CRs, creates
any missing logging components, and adjusts the logging deployment accordingly.

The Cluster Logging CR is based on the Cluster Logging Custom Resource
Definition (CRD), which defines a complete cluster logging deployment and
includes all the components of the logging stack to collect, store and visualize
logs.

.Sample Cluster Logging Custom Resource (CR)
[source,yaml]
----
apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"
  namespace: "openshift-logging"
spec:
  managementState: "Managed"
  logStore:
    type: "elasticsearch"
    elasticsearch:
      nodeCount: 3
      storage:
        storageClassName: "gp2"
        size: "200Gi"
      redundancyPolicy: "SingleRedundancy"
      nodeSelector:
        node-role.kubernetes.io/worker: ""
      resources:
        request:
          memory: 8G
  visualization:
    type: "kibana"
    kibana:
      replicas: 1
      nodeSelector:
        node-role.kubernetes.io/worker: ""
  curation:
    type: "curator"
    curator:
      schedule: "30 3 * * *"
      nodeSelector:
        node-role.kubernetes.io/worker: ""
  collection:
    logs:
      type: "fluentd"
      fluentd: {}
      nodeSelector:
        node-role.kubernetes.io/worker: ""
----
