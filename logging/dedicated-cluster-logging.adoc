:context: dedicated-cluster-logging
[id="dedicated-cluster-logging"]
= Configuring OpenShift Logging in {product-title}
include::modules/common-attributes.adoc[]

toc::[]

As a cluster administrator, you can deploy OpenShift Logging
to aggregate logs for a range of services.

{product-title} clusters can perform logging tasks using the Elasticsearch
Operator. OpenShift Logging is configured through the Curator tool to retain logs
for two days.

OpenShift Logging is configurable using a `ClusterLogging` custom resource (CR)
deployed in the `openshift-logging` project namespace.

The Cluster Logging Operator watches for changes to `ClusterLogging` CR, creates
any missing logging components, and adjusts the logging environment accordingly.

The `ClusterLogging` CR is based on the `ClusterLogging` custom resource
definition (CRD), which defines a complete OpenShift Logging environment and
includes all the components of the logging stack to collect, store and visualize
logs.

.Sample `ClusterLogging` custom resource (CR)
[source,yaml]
----
apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"
  namespace: "openshift-logging"
spec:
  managementState: "Managed"
  logStore:
    type: "elasticsearch"
    elasticsearch:
      nodeCount: 3
      storage:
        storageClassName: "gp2"
        size: "200Gi"
      redundancyPolicy: "SingleRedundancy"
      nodeSelector:
        node-role.kubernetes.io/worker: ""
      resources:
        limits:
          memory: 16G
        request:
          memory: 16G
  visualization:
    type: "kibana"
    kibana:
      replicas: 1
      nodeSelector:
        node-role.kubernetes.io/worker: ""
  collection:
    logs:
      type: "fluentd"
      fluentd: {}
      nodeSelector:
        node-role.kubernetes.io/worker: ""
----
