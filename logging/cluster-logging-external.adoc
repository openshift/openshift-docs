:_content-type: ASSEMBLY
:context: cluster-logging-external
[id="cluster-logging-external"]
= Forwarding logs to external third-party logging systems
include::_attributes/common-attributes.adoc[]
include::_attributes/attributes-openshift-dedicated.adoc[]

toc::[]

By default, the {logging} sends container and infrastructure logs to the default internal log store defined in the `ClusterLogging` custom resource. However, it does not send audit logs to the internal store because it does not provide secure storage. If this default configuration meets your needs, you do not need to configure the Cluster Log Forwarder.

To send logs to other log aggregators, you use the {product-title} Cluster Log Forwarder. This API enables you to send container, infrastructure, and audit logs to specific endpoints within or outside your cluster. In addition, you can send different types of logs to various systems so that various individuals can access each type. You can also enable Transport Layer Security (TLS) support to send logs securely, as required by your organization.

[NOTE]
====
To send audit logs to the default internal Elasticsearch log store, use the Cluster Log Forwarder as described in xref:../logging/config/cluster-logging-log-store.adoc#cluster-logging-elasticsearch-audit_cluster-logging-store[Forward audit logs to the log store].
====

When you forward logs externally, the {logging} creates or modifies a Fluentd config map to send logs using your desired protocols. You are responsible for configuring the protocol on the external log aggregator.

[IMPORTANT]
====
You cannot use the config map methods and the Cluster Log Forwarder in the same cluster.
====

// The following include statements pull in the module files that comprise
// the assembly. Include any combination of concept, procedure, or reference
// modules required to cover the user story. You can also include other
// assemblies.

include::modules/cluster-logging-collector-log-forwarding-about.adoc[leveloffset=+1]

include::modules/cluster-logging-forwarding-separate-indices.adoc[leveloffset=+1]

include::modules/cluster-logging-collector-log-forwarding-supported-plugins-5-1.adoc[leveloffset=+1]

include::modules/cluster-logging-collector-log-forwarding-supported-plugins-5-2.adoc[leveloffset=+1]

include::modules/cluster-logging-collector-log-forwarding-supported-plugins-5-3.adoc[leveloffset=+1]

include::modules/cluster-logging-collector-log-forwarding-supported-plugins-5-4.adoc[leveloffset=+1]

include::modules/cluster-logging-collector-log-forwarding-supported-plugins-5-5.adoc[leveloffset=+1]

include::modules/cluster-logging-collector-log-forwarding-supported-plugins-5-6.adoc[leveloffset=+1]

include::modules/cluster-logging-collector-log-forward-es.adoc[leveloffset=+1]

include::modules/cluster-logging-collector-log-forward-fluentd.adoc[leveloffset=+1]

include::modules/cluster-logging-collector-log-forward-syslog.adoc[leveloffset=+1]

include::modules/cluster-logging-collector-log-forward-cloudwatch.adoc[leveloffset=+1]

[id="cluster-logging-collector-log-forward-sts-cloudwatch_{context}"]
=== Forwarding logs to Amazon CloudWatch from STS enabled clusters

For clusters with AWS Security Token Service (STS) enabled, you can create an AWS service account manually or create a credentials request by using the
ifdef::openshift-enterprise,openshift-origin[]
xref:../authentication/managing_cloud_provider_credentials/about-cloud-credential-operator.adoc[Cloud Credential Operator(CCO)]
endif::[]
ifdef::openshift-rosa,openshift-dedicated[]
link:https://docs.openshift.com/container-platform/latest/authentication/managing_cloud_provider_credentials/about-cloud-credential-operator.html[Cloud Credential Operator(CCO)]
endif::[]
 utility `ccoctl`.

[NOTE]
====
This feature is not supported by the vector collector.
====

.Prerequisites

* {logging-title-uc}: 5.5 and later


.Procedure
. Create a `CredentialsRequest` custom resource YAML by using the template below:
+
.CloudWatch credentials request template
[source,yaml]
----
apiVersion: cloudcredential.openshift.io/v1
kind: CredentialsRequest
metadata:
  name: <your_role_name>-credrequest
  namespace: openshift-cloud-credential-operator
spec:
  providerSpec:
    apiVersion: cloudcredential.openshift.io/v1
    kind: AWSProviderSpec
    statementEntries:
      - action:
          - logs:PutLogEvents
          - logs:CreateLogGroup
          - logs:PutRetentionPolicy
          - logs:CreateLogStream
          - logs:DescribeLogGroups
          - logs:DescribeLogStreams
        effect: Allow
        resource: arn:aws:logs:*:*:*
  secretRef:
    name: <your_role_name>
    namespace: openshift-logging
  serviceAccountNames:
    - logcollector
----
+
. Use the `ccoctl` command to create a role for AWS using your `CredentialsRequest` CR. With the `CredentialsRequest` object, this `ccoctl` command creates an IAM role with a trust policy that is tied to the specified OIDC identity provider, and a permissions policy that grants permissions to perform operations on CloudWatch resources. This command also creates a YAML configuration file in `/<path_to_ccoctl_output_dir>/manifests/openshift-logging-<your_role_name>-credentials.yaml`. This secret file contains the `role_arn` key/value used during authentication with the AWS IAM identity provider.
+
[source,terminal]
----
$ ccoctl aws create-iam-roles \
--name=<name> \
--region=<aws_region> \
--credentials-requests-dir=<path_to_directory_with_list_of_credentials_requests>/credrequests \
--identity-provider-arn=arn:aws:iam::<aws_account_id>:oidc-provider/<name>-oidc.s3.<aws_region>.amazonaws.com <1>
----
<1> <name> is the name used to tag your cloud resources and should match the name used during your STS cluster install
+
. Apply the secret created:
[source,terminal]
+
----
$ oc apply -f output/manifests/openshift-logging-<your_role_name>-credentials.yaml
----
+
. Create or edit a `ClusterLogForwarder` custom resource:
+
[source,yaml]
----
apiVersion: "logging.openshift.io/v1"
kind: ClusterLogForwarder
metadata:
  name: instance <1>
  namespace: openshift-logging <2>
spec:
  outputs:
   - name: cw <3>
     type: cloudwatch <4>
     cloudwatch:
       groupBy: logType <5>
       groupPrefix: <group prefix> <6>
       region: us-east-2 <7>
     secret:
        name: <your_role_name> <8>
  pipelines:
    - name: to-cloudwatch <9>
      inputRefs: <10>
        - infrastructure
        - audit
        - application
      outputRefs:
        - cw <11>
----
<1> The name of the `ClusterLogForwarder` CR must be `instance`.
<2> The namespace for the `ClusterLogForwarder` CR must be `openshift-logging`.
<3> Specify a name for the output.
<4> Specify the `cloudwatch` type.
<5> Optional: Specify how to group the logs:
+
* `logType` creates log groups for each log type
* `namespaceName` creates a log group for each application name space. Infrastructure and audit logs are unaffected, remaining grouped by `logType`.
* `namespaceUUID` creates a new log groups for each application namespace UUID. It also creates separate log groups for infrastructure and audit logs.
<6> Optional: Specify a string to replace the default `infrastructureName` prefix in the names of the log groups.
<7> Specify the AWS region.
<8> Specify the name of the secret that contains your AWS credentials.
<9> Optional: Specify a name for the pipeline.
<10> Specify which log types to forward by using the pipeline: `application,` `infrastructure`, or `audit`.
<11> Specify the name of the output to use when forwarding logs with this pipeline.

[role="_additional-resources"]
.Additional resources
* link:https://docs.aws.amazon.com/STS/latest/APIReference/welcome.html[AWS STS API Reference]

include::modules/cluster-logging-collector-log-forward-secret-cloudwatch.adoc[leveloffset=+2]

include::modules/cluster-logging-collector-log-forward-loki.adoc[leveloffset=+1]

include::modules/cluster-logging-troubleshooting-loki-entry-out-of-order-errors.adoc[leveloffset=+2]

[role="_additional-resources"]
.Additional resources

* xref:../logging/cluster-logging-exported-fields.adoc#cluster-logging-exported-fields-kubernetes_cluster-logging-exported-fields[Log Record Fields].

* link:https://grafana.com/docs/loki/latest/configuration/[Configuring Loki server]

include::modules/cluster-logging-collector-log-forward-gcp.adoc[leveloffset=+1]

include::modules/logging-forward-splunk.adoc[leveloffset=+1]

include::modules/cluster-logging-collector-log-forward-project.adoc[leveloffset=+1]

include::modules/cluster-logging-collector-log-forward-logs-from-application-pods.adoc[leveloffset=+1]

[role="_additional-resources"]
.Additional resources

ifdef::openshift-enterprise,openshift-origin[]
* xref:../networking/ovn_kubernetes_network_provider/logging-network-policy.adoc#logging-network-policy[Logging for egress firewall and network policy rules]
endif::[]
ifdef::openshift-rosa,openshift-dedicated[]
* link:https://docs.openshift.com/container-platform/latest/networking/ovn_kubernetes_network_provider/logging-network-policy.html#logging-network-policy[Logging for egress firewall and network policy rules]
endif::[]

include::modules/cluster-logging-troubleshooting-log-forwarding.adoc[leveloffset=+1]
