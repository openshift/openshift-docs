:_content-type: ASSEMBLY
[id="logging-architecture"]
= Understanding logging architecture
include::_attributes/common-attributes.adoc[]
:context: logging-architecture

toc::[]

The {logging-title} aggregates the following types of logs:

* `application` - Container logs generated by user applications running in the cluster, in any namespace other than: `default`, `openshift*`, `kube*`.

* `infrastructure` - Logs generated by infrastructure components running in the cluster and {product-title} nodes, such as journal logs. Infrastructure components are pods that run in the `openshift*`, `kube*`, or `default` projects.

* `audit` - Logs generated by auditd, the node audit system, are stored in the `/var/log/audit/audit.log` file.

The {logging} contains 4 logical components:

Collector:: Reads container log data from each node.

Forwarder::	Forwards log data to configured outputs.

Store:: Stores log data for analysis; the default output for the forwarder.

Exploration:: GUI and command line UI tools to search, query, and view stored logs.

These components are managed by Operators, and Custom Resource (CR) YAML files.

[id="logging-collector-understanding_{context}"]
== Understanding the collector
The {logging-title} collects container and node logs. Prior to release 5.4, link:https://docs.fluentd.org/[Fluentd] was the default collector with link:https://vector.dev/docs/[Vector] offered as an alternative. As of release 5.6, Vector is the default collector for logging. Either collector uses the following sources:

* journald for all system logs
* `/var/log/containers/*.log` for all container logs

If you configure your log collector to collect audit logs, it gets them from `/var/log/audit/audit.log`. Audit logs from the Kubernetes API server are stored in the `/var/log/kube-apiserver/audit.log` file. Audit logs from the OpenShift API server are stored in the `/var/log/openshift-apiserver/audit.log` file.

The logging collector is a daemon set that deploys pods to each {product-title} node. System and infrastructure logs are generated by journald log messages from the operating system, the container runtime, and {product-title}. Application logs are generated by the CRI-O container engine. The collector collects the logs from these sources and forwards them internally or externally as configured in the `ClusterLogForwarder` custom resource.

The container runtimes provide minimal information to identify the source of log messages: project, pod name, and container ID. This information is not sufficient to uniquely identify the source of the logs. If a pod with a given name and project is deleted before the log collector begins processing its logs, information from the API server, such as labels and annotations, might not be available. There might not be a way to distinguish the log messages from a similarly named pod and project or trace the logs to their source. This limitation means that log collection and normalization are considered *best effort*.

[IMPORTANT]
====
The available container runtimes provide minimal information to identify the
source of log messages and do not guarantee unique individual log
messages or that these messages can be traced to their source.
====

// ENG - Does https://issues.redhat.com/browse/LOG-2715 make the above invalid?

Logs from any source contain a clusterID, the unique identifier of the cluster in which the Operator is deployed.

.ClusterID query
[source,terminal]
----
$ oc get clusterversion/version -o jsonpath='{.spec.clusterID}{"\n"}'
----

[id="logging-collector-features_{context}"]
=== Collector features
The features supported by the collectors vary. These are compared in the tables below.

:table-caption!:
.Collector Features Comparison
[%collapsible]
====
.Log Sources
[options="header"]
|===============================================================
| Feature                   | Fluentd  | Vector
| App container logs        | &#10003; | &#10003;
| App-specific routing      | &#10003; | &#10003;
| App-specific routing by namespace | &#10003; | &#10003;
| Infra container logs      | &#10003; | &#10003;
| Infra journal logs        | &#10003; | &#10003;
| Kube API audit logs       | &#10003; | &#10003;
| Openshift API audit logs  | &#10003; | &#10003;
| Open Virtual Network (OVN) audit logs| &#10003; | &#10003;
|===============================================================

.Outputs
[options="header"]
|==========================================================
| Feature              | Fluentd  | Vector
| Elasticsearch v5-v7  | &#10003; | &#10003;
| Fluent forward       | &#10003; |
| Syslog RFC3164       | &#10003; |
| Syslog RFC5424       | &#10003; |
| Kafka                | &#10003; | &#10003;
| Cloudwatch           | &#10003; | &#10003;
| Loki                 | &#10003; | &#10003;
|==========================================================

.Authorization and Authentication
[options="header"]
|=================================================================
| Feature                     | Fluentd  | Vector
| Elasticsearch certificates  | &#10003; | &#10003;
| Elasticsearch username / password | &#10003; | &#10003;
| Cloudwatch keys             | &#10003; | &#10003;
| Cloudwatch STS              | &#10003; |
| Kafka certificates          | &#10003; | &#10003;
| Kafka username / password   | &#10003; | &#10003;
| Kafka SASL                  | &#10003; | &#10003;
| Loki bearer token           | &#10003; | &#10003;
|=================================================================

.Normalizations and Transformations
[options="header"]
|============================================================================
| Feature                                | Fluentd  | Vector
| Viaq data model - app                  | &#10003; | &#10003;
| Viaq data model - infra                | &#10003; | &#10003;
| Viaq data model - infra(journal)       | &#10003; | &#10003;
| Viaq data model - Linux audit          | &#10003; | &#10003;
| Viaq data model - kube-apiserver audit | &#10003; | &#10003;
| Viaq data model - OpenShift API audit  | &#10003; | &#10003;
| Viaq data model - OVN                  | &#10003; | &#10003;
| Loglevel Normalization                 | &#10003; | &#10003;
| JSON parsing                           | &#10003; | &#10003;
| Structured Index                       | &#10003; | &#10003;
| Multiline error detection              | &#10003; |
| Multicontainer / split indices         | &#10003; | &#10003;
| Flatten labels                         | &#10003; | &#10003;
| CLF static labels                      | &#10003; | &#10003;
|============================================================================

.Tuning
[options="header"]
|==========================================================
| Feature                | Fluentd  | Vector
| Fluentd readlinelimit  | &#10003; |
| Fluentd buffer         | &#10003; |
| - chunklimitsize       | &#10003; |
| - totallimitsize       | &#10003; |
| - overflowaction       | &#10003; |
| - flushthreadcount     | &#10003; |
| - flushmode            | &#10003; |
| - flushinterval        | &#10003; |
| - retrywait            | &#10003; |
| - retrytype            | &#10003; |
| - retrymaxinterval     | &#10003; |
| - retrytimeout         | &#10003; |
|==========================================================

.Visibility
[options="header"]
|=====================================================
| Feature         | Fluentd  | Vector
| Metrics         | &#10003; | &#10003;
| Dashboard       | &#10003; | &#10003;
| Alerts          | &#10003; |
|=====================================================

.Miscellaneous
[options="header"]
|===========================================================
| Feature               | Fluentd  | Vector
| Global proxy support  | &#10003; | &#10003;
| x86 support           | &#10003; | &#10003;
| ARM support           | &#10003; | &#10003;
| PowerPC support       | &#10003; | &#10003;
| IBM Z support         | &#10003; | &#10003;
| IPV6 support          | &#10003; | &#10003;
| Log event buffering   | &#10003; |
| Disconnected Cluster  | &#10003; | &#10003;
|===========================================================
====

== Understanding the log forwarding



== Understanding the log store



== Understanding logging exploration



== Understanding logging Operators

[options="header"]
|================================================================================================
| Operator       | Red Hat OpenShift Logging  | Loki Operator  | OpenShift Elasticsearch Operator
| APIs Provided  | Cluster Log Forwarder      | LokiStack      | Elasticsearch
|                | Cluster Logging            | AlertingRule   | Kibana
|                |                            | RecordingRule  |
|                |                            | RulerConfig    |
|================================================================================================


=== Red Hat OpenShift Logging
The `Red Hat Openshift Logging` Operator implements the following custom resources:

ClusterLogging (CL):: Deploys the collector and forwarder which currently are both implemented by a daemonset running on each node.
ClusterLogForwarder (CLF):: Generates collector configuration to forward logs per user configuration.

=== Loki Operator
The `Loki` Operator implements the following custom resources

LokiStack::
RulerConfig::   Technology Preview
AlertingRule::  Technology Preview
RecordingRule:: Technology Preview


=== OpenShift Elasticsearch Operator
The `OpenShift Elasticsearch` Operator implements the following custom resources:

ElasticSearch:: Configure and deploy an Elasticsearch instance as the default log store.
Kibana:: Configure and deploy Kibana instance to search, query and view logs.


== Log Record Data Model
