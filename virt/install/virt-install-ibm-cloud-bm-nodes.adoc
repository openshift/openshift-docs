:_mod-docs-content-type: ASSEMBLY
include::_attributes/common-attributes.adoc[]
include::_attributes/attributes-openshift-dedicated.adoc[]
[id="virt-install-ibm-cloud-bm-nodes"]
= Installing {VirtProductName} on {ibm-cloud-title} bare-metal nodes
:context: virt-install-ibm-cloud-bm-nodes

toc::[]

[role="_abstract"]

Install {VirtProductName} on {ibm-cloud-title} bare-metal nodes using Assisted Installer. The {VirtProductName} cluster in the {ibm-cloud-title} environment consists of 6 bare-metal nodes; 3 Master nodes and 3 Worker nodes. All nodes are connected to a private network. An additional virtual machine is required for bootstrapping operations and acting as a Samba server, DHCP server, network gateway, and load balancer. DNS "A" records must be created for the cluster name and subdomains for external access.

Before performing the procedures in this section, ensuring you have the following items:

* An account in {ibm-cloud-title} with permissions to order and operate bare-metal nodes.
* An {ibm-cloud-title} SSL VPN user, to access the SuperMicro IPMI interface of a node.

== Configuring {ibm-cloud-title} for the new cluster

. Create a new virtual server instance in {ibm-cloud-title} at link:https://cloud.ibm.com/gen1/infrastructure/provision/vs to be the Bastion server. This instance is used to run the installation and provide environment services. This virtual server instance has the following properties:

* Type of virtual server: Public
* Operating system: CentOS
* Your public SSH RSA key
+
All other properties should remain their default values.

. Note the private VLAN and subnet the virtual server instance was assigned to at link:https://cloud.ibm.com/classic/network/vlans.

. Provision 6 bare-metal nodes in {ibm-cloud-title} at link:https://cloud.ibm.com/gen1/infrastructure/provision/bm. Use the following values when provisioning the nodes:

* Domain: A subdomain you can add records to.
* Quantity: 6
* Location: The same location as the virtual server instance.
* Storage disks: RAID 1
* Network Interface: Private
* Private VLAN: The same as noted for the virtual server instance.

. Confirm all nodes are provisioned and ready at link:https://cloud.ibm.com/gen1/infrastructure/devices.

. Rename all master nodes as `master0-<domain-name>`, `master1-<domain-name>`, and `master2-<domain-name>`. Replace `<domain-name>` with the domain used when provisioning the nodes.

. Rename all worker nodes as `worker0-<domain-name>`, `worker1-<domain-name>`, and `worker2-<domain-name>`. Replace `<domain-name>` with the domain used when provisioning the nodes.

. Configure the Bastion virtual server instance as a default network gateway.

. Edit `/etc/dhcp/dhcpd.conf` on the Bastion virtual server instance to configure DHCP. The following is an example of this configuration:
+
----
# Set DNS name and DNS server's IP address or hostname
option domain-name  "bm.ibm.cluster.example.com";
option domain-name-servers  8.8.8.8;

# Declare DHCP Server
authoritative;

# The default DHCP lease time
default-lease-time 600;

# Set the maximum lease time
max-lease-time 7200;

# Set Network address, subnet mask and gateway

subnet 10.60.128.0 netmask 255.255.255.192 {
  # Range of IP addresses to allocate
  range dynamic-bootp 10.60.128.10 10.60.128.35;
  # Provide broadcast address
  option broadcast-address 10.60.128.63;
  # Set default gateway
  option routers 10.60.128.38;
----
+
[NOTE]
====
Replace the example values with values applicable to your network configuration.
====

. Restart DHCP on the Bastion virtual server instance:
+
----
$ systemctl restart dhcpd
----

. Enable IP forwarding on the Bastion virtual server instance:
+
----
$ sysctl -w net.ipv4.ip_forward=1
----

. Verify IP forwarding is enabled on the Bastion virtual server instance:
+
----
$ sysctl -p /etc/sysctl.conf
----

. Restart the network service on the Bastion virtual server instance:
+
----
$ service network restart
----

. Verify if `firewalld` is enabled on the Bastion virtual server instance:
+
----
$ firewall-cmd --state
----

. If the `firewalld` service is not enabled on the Bastion virtual server instance, enable and start the service:
+
----
$ systemctl enable firewalld
$ systemctl start firewalld
----

. Add network address translation (NAT) rules to the `firewalld` service:
+
----
$ firewall-cmd --add-masquerade --permanent
$ firewall-cmd --reload
----

== Creating the new cluster using Assisted Installer

. Log in to the Assisted Installer service.

. Create a new cluster. The new cluster has the following properties:

* Cluster name : The name used to identify the cluster under the base domain.
* Base domain : The domain used to provision the bare-metal nodes in ????.

. Click Next.

. Click Generate Discovery ISO.

. Provide your public SSH RSA key when prompted. and provide your SSH RSA public key.

. Copy and save the generated `wget` command for the ISO file. This will be used later to connect to the cluster nodes.

. Install Samba server on the Bastion virtual server instance:
+
----
$ dnf install samba
----

. Enable Samba server on the Bastion virtual server instance:
+
----
$ systemctl enable smb --now
----

. Configure NAT rules for the Samba server:
+
----
$ firewall-cmd --permanent --zone=FedoraWorkstation --add-service=samba
$ firewall-cmd --reload
----

. Configure a root user password:
+
----
$ sudo smbpasswd -a root
----

. Create a share directory:
+
----
$ mkdir <share_directory>
----
+
Replace `<share_directory>` with the share directory name.

. Navigate to the share directory and download the Assisted Installer ISO file using the `wget` command generated in *Creating the new cluster using Assisted Installer*.

. Edit `/etc/samba/smb.conf` to use the following configuration:
+
-----
[global]
      log level = 3
          workgroup = SAMBA
          security = user

          passdb backend = tdbsam

          printing = cups
          printcap name = cups
          load printers = yes
          cups options = raw

      server min protocol = NT1
      ntlm auth = yes

[share]
      comment = ISO Files
      path = /root/share
      browseable = yes
      public = no
      read only = no
      directory mode = 0555
      valid users = root
-----
+
[NOTE]
====
For a more detailed example of the `smb.conf` file, see `smb.conf.example`.
====

. Save the configuration changes.

. Verify the configuration:
+
----
$ testparm
----

. Restart the Samba service:
+
----
$ systemctl restart smb
----

. Verify the Samba service is running and active:
+
----
$ systemctl status smb
----

Restart SMB service and verify it is running and active :
Raw

. Configure SSL VPN access to {ibm-cloud-title}:
.. Perform the procedure at link:https://cloud.ibm.com/docs/iaas-vpn?topic=iaas-vpn-getting-started.
.. Download and install the MotionPro SSL VPN client.
.. Connect to the appropriate {ibm-cloud-title} endpoint as described at link:https://www.ibm.com/cloud/vpn-access:
+
----
$ sudo MotionPro --host $<vpn_endpoint> --user $<vpn_username> --passwd $<vpn_password>
----
+
where:

<vpn_endpoint>:: The appropriate SSL VPN endpoint.
<vpn_username>:: The SSL VPN user name you configured.
<vpn_password>:: The SSL VPN password you configured.
+
[NOTE]
=====
Connecting to the {ibm-cloud-title} SSL VPN will disconnect you from any open VPN connections.
=====

. For each bare-metal server, perform the following tasks:
.. Access the server using the IPMI console.
+
[NOTE]
====
The IP address and credentials for IPMI console access is available in the `Remote management` section for each server.
====

.. Mount the Assisted Installer ISO file with the following attributes:
+
* `Virtual Media`: CD-ROM Image
* `Share host`: The private IP address of the Bastion server.
* `Path to image`: The location of the Assisted Installer ISO file.
* `User`: root
* `Password`: The root user password you configured.

.. Click `Save and Mount`.
.. Verify the ISO mounted successfully.
.. Select `Remote Control` > `Power Control` > `Reset Server` > `Perform Action` to restart the server.

. Navigate to the `Assisted Installer` page.

. Select the `OpenShift Virtualization` and `OpenShift Container Storage` checkboxes.

. Select a role for each host. 
+
[NOTE]
====
The cluster should consist of 3 Master (Control Plane) and 3 Worker nodes.
====

. Wait for each node to become ready.

. Click `Next`.

. Select `Cluster Managed Network`.

. Select API VIP and Ingress VIP checkboxes to obtain them from DHCP or set them statically.

. Click `Install`.

. For each bare-metal server, perform the following tasks:
.. Access the server using the IPMI console.
+
[NOTE]
====
The IP address and credentials for IPMI console access is available in the `Remote management` section for each server.
====

.. Select Virtual Media > CD-Rom Image.
.. Click `Unmount`.
.. Select `Remote Control` > `Power Control` > `Reset Server` > `Perform Action` to restart the server.

. Download the `kubeconfig` file.

. Save the `kubeadmin` password.

. Install and configure `haproxy` on the Bastion virtual server instance. 

. Configure `haproxy` for your environment. The following is an example configuration:
+
----
#---------------------------------------------------------------------
# Example configuration for a possible web application.  See the
# full configuration options online.
#
#   https://www.haproxy.org/download/1.8/doc/configuration.txt
#
#---------------------------------------------------------------------

#---------------------------------------------------------------------
# Global settings
#---------------------------------------------------------------------
global
  # to have these messages end up in /var/log/haproxy.log you will
  # need to:
  #
  # 1) configure syslog to accept network log events.  This is done
  # by adding the '-r' option to the SYSLOGD_OPTIONS in
  # /etc/sysconfig/syslog
  #
  # 2) configure local2 events to go to the /var/log/haproxy.log
  #   file. A line like the following can be added to
  #   /etc/sysconfig/syslog
  #
  # local2.*                    /var/log/haproxy.log
  #
  log       127.0.0.1 local2

  chroot    /var/lib/haproxy
  pidfile   /var/run/haproxy.pid
  maxconn   4000
  user      haproxy
  group     haproxy
  daemon

  # turn on stats unix socket
  stats socket /var/lib/haproxy/stats

  # utilize system-wide crypto-policies
  #ssl-default-bind-ciphers PROFILE=SYSTEM
  #ssl-default-server-ciphers PROFILE=SYSTEM

#---------------------------------------------------------------------
# common defaults that all the 'listen' and 'backend' sections will
# use if not designated in their block
#---------------------------------------------------------------------
defaults
  mode                  tcp
  log                   global
  option                httplog
  option                dontlognull
  option http-server-close
  option forwardfor     except 127.0.0.0/8
  option                redispatch
  retries               3
  timeout http-request  10s
  timeout queue         1m
  timeout connect       10s
  timeout client        1m
  timeout server        1m
  timeout http-keep-alive 10s
  timeout check         10s
  maxconn               3000
#---------------------------------------------------------------------
# main frontend which proxys to the backends
#---------------------------------------------------------------------

frontend api
  bind 108.168.136.75:6443
  default_backend controlplaneapi

frontend apiinternal
  bind 108.168.136.75:22623
  default_backend controlplaneapiinternal

frontend secure
  bind 108.168.136.75:443
  default_backend secure

frontend insecure
  bind 108.168.136.75:80
  default_backend insecure

#---------------------------------------------------------------------
# static backend
#---------------------------------------------------------------------

backend controlplaneapi
  balance source
  server api 10.60.128.30:6443 check

backend controlplaneapiinternal
  balance source
  server api 10.60.128.30:22623 check

backend secure
  balance source
  server ingress 10.60.128.34:443 check

backend insecure
  balance source
  server ingress 10.60.128.34:80 check
----

. Save the `haproxy` configuration.

. Configure two DNS Address records (A records) for the subdomain that are externally available over the Internet:
+
----
<bastion_public_ip_address> api.<cluster_name>.<cluster_domain>
<bastion_public_ip_address> *.apps..<cluster_name>.<cluster_domain>
----
+
where:

<bastion_public_ip_address>:: The externally available IP address of the Bastion virtual server instance.
<cluster_name>:: The name assigned to the cluster.
<cluster_domain>:: The domain assigned to the cluster.

. Verify the cluster is accessible using the saved `kubeconfig` and the console link provided during Assisted Installer configuration.
