:_content-type: ASSEMBLY
include::_attributes/common-attributes.adoc[]
[id="preparing-cluster-for-virt"]
= Preparing your cluster for {VirtProductName}
:context: preparing-cluster-for-virt

toc::[]

Review this section before you install {VirtProductName} to ensure that your cluster meets the requirements.

[IMPORTANT]
====
You can use any installation method, including user-provisioned, installer-provisioned, or assisted installer, to deploy {product-title}. However, the installation method and the cluster topology might affect {VirtProductName} functionality, such as snapshots or live migration.
====

.{sno-caps} differences

You can install {VirtProductName} on a single-node cluster. See xref:../../installing/installing_sno/install-sno-preparing-to-install-sno.adoc#install-sno-about-installing-on-a-single-node_install-sno-preparing[About {sno}] for more information. {sno-caps} does not support high availability, which results in the following differences:

* xref:../../nodes/pods/nodes-pods-priority.adoc#priority-preemption-other_nodes-pods-priority[Pod disruption budgets] are not supported.
* xref:../../virt/live_migration/virt-live-migration.adoc#virt-live-migration[Live migration] is not supported.
* Templates or virtual machines that use data volumes or storage profiles must not have the xref:../../virt/live_migration/virt-configuring-vmi-eviction-strategy.adoc#virt-configuring-vmi-eviction-strategy[`evictionStrategy`] set.

.FIPS mode

If you install your cluster in xref:../../installing/installing-fips.adoc#installing-fips-mode_installing-fips[FIPS mode], no additional setup is required for {VirtProductName}.

include::modules/virt-hardware-os-requirements.adoc[leveloffset=+1]

* If your cluster uses worker nodes with different CPUs, live migration failures can occur because different CPUs have different capabilities. To avoid such failures, use CPUs with appropriate capacity for each node and set node affinity on your virtual machines to ensure successful migration. See xref:../../nodes/scheduling/nodes-scheduler-node-affinity.adoc#nodes-scheduler-node-affinity-configuring-required_nodes-scheduler-node-affinity[Configuring a required node affinity rule] for more information.

[role="_additional-resources"]
.Additional resources

* xref:../../architecture/architecture-rhcos.adoc#rhcos-about_architecture-rhcos[About RHCOS].
* link:https://catalog.redhat.com[Red Hat Ecosystem Catalog] for supported CPUs.
* xref:../../storage/index.adoc#storage-overview[Supported storage].

include::modules/virt-cluster-resource-requirements.adoc[leveloffset=+1]

[id="object-maximums_{context}"]
== Object maximums

You must consider the following tested object maximums when planning your cluster:

* xref:../../scalability_and_performance/planning-your-environment-according-to-object-maximums.html#planning-your-environment-according-to-object-maximums[{product-title} object maximums].
* link:https://access.redhat.com/articles/6571671[{VirtProductName} object maximums].

[id="restricted-networks-environments_{context}"]
== Restricted network environments

If you install {VirtProductName} in a restricted environment with no internet connectivity, you must xref:../../operators/admin/olm-restricted-networks.adoc#olm-restricted-networks[configure Operator Lifecycle Manager for restricted networks].

If you have limited internet connectivity, you can xref:../../operators/admin/olm-configuring-proxy-support.adoc#olm-configuring-proxy-support[configure proxy support in Operator Lifecycle Manager] to access the Red Hat-provided OperatorHub.

[id="live-migration_{context}"]
== Live migration

Live migration has the following requirements:

* Shared storage with `ReadWriteMany` (RWX) access mode.
* Sufficient RAM and network bandwidth.
* If the virtual machine uses a host model CPU, the nodes must support the virtual machine's host model CPU.

[id="snapshots-and-cloning_{context}"]
== Snapshots and cloning

See xref:../../virt/virtual_machines/virtual_disks/virt-features-for-storage.adoc#virt-features-for-storage[{VirtProductName} storage features] for snapshot and cloning requirements.

// The HA section actually belongs to OpenShift, not Virt
[id="cluster-high-availability-options_{context}"]
== Cluster high-availability options

You can configure one of the following high-availability (HA) options for your cluster:

* Automatic high availability for xref:../../installing/installing_bare_metal_ipi/ipi-install-overview.adoc#ipi-install-overview[installer-provisioned infrastructure] (IPI) is available by deploying xref:../../machine_management/deploying-machine-health-checks.adoc#machine-health-checks-about_deploying-machine-health-checks[machine health checks].
+
[NOTE]
====
In {product-title} clusters installed using installer-provisioned infrastructure and with MachineHealthCheck properly configured, if a node fails the MachineHealthCheck and becomes unavailable to the cluster, it is recycled. What happens next with VMs that ran on the failed node depends on a series of conditions. See xref:../../virt/virtual_machines/virt-create-vms.adoc#virt-about-runstrategies-vms_virt-create-vms[About RunStrategies for virtual machines] for more detailed information about the potential outcomes and how RunStrategies affect those outcomes.
====

* Automatic high availability for both IPI and non-IPI is available by using the xref:../../nodes/nodes/eco-node-health-check-operator.adoc#node-health-check-operator[Node Health Check Operator] on the {product-title} cluster to deploy the `NodeHealthCheck` controller. The controller identifies unhealthy nodes and uses the Self Node Remediation Operator to remediate the unhealthy nodes.
+
--
ifdef::openshift-enterprise[]
:FeatureName: Node Health Check Operator
include::snippets/technology-preview.adoc[leveloffset=+2]
:!FeatureName:
endif::[]
--

* High availability for any platform is available by using either a monitoring system or a qualified human to monitor node availability. When a node is lost, shut it down and run `oc delete node <lost_node>`.
+
[NOTE]
====
Without an external monitoring system or a qualified human monitoring node health, virtual machines lose high availability.
====
