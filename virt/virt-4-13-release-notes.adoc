:_content-type: ASSEMBLY
[id="virt-4-13-release-notes"]
= {VirtProductName} release notes
include::_attributes/common-attributes.adoc[]
:context: virt-4-13-release-notes

toc::[]

[id="virt-4-13-inclusive-language"]
== Making open source more inclusive

Red Hat is committed to replacing problematic language in our code, documentation, and web properties. We are beginning with these four terms: master, slave, blacklist, and whitelist. Because of the enormity of this endeavor, these changes will be implemented gradually over several upcoming releases. For more details, see link:https://www.redhat.com/en/blog/making-open-source-more-inclusive-eradicating-problematic-language[our CTO Chris Wright's message].


== About Red Hat {VirtProductName}

Red Hat {VirtProductName} enables you to bring traditional virtual machines (VMs) into {product-title} where they run alongside containers, and are managed as native Kubernetes objects.

{VirtProductName} is represented by the image:virt-icon.png[{VirtProductName},40,40] icon.

You can use {VirtProductName} with either the xref:../networking/ovn_kubernetes_network_provider/about-ovn-kubernetes.adoc#about-ovn-kubernetes[OVN-Kubernetes] or the xref:../networking/openshift_sdn/about-openshift-sdn.adoc#about-openshift-sdn[OpenShiftSDN] default Container Network Interface (CNI) network provider.

Learn more about xref:../virt/about-virt.adoc#about-virt[what you can do with {VirtProductName}].

Learn more about xref:../virt/virt-architecture.adoc#virt-how-virt-works_virt-architecture[{VirtProductName} architecture and deployments].

xref:../virt/install/preparing-cluster-for-virt.adoc#preparing-cluster-for-virt[Prepare your cluster] for {VirtProductName}.

include::modules/virt-supported-cluster-version.adoc[leveloffset=+2]

[IMPORTANT]
====
Updating to {VirtProductName} 4.13 from {VirtProductName} 4.12.2 is not supported.
====

[id="virt-guest-os"]
=== Supported guest operating systems
//CNV-16390 Supported guest operating systems
To view the supported guest operating systems for {VirtProductName}, see link:https://access.redhat.com/articles/973163#ocpvirt[Certified Guest Operating Systems in Red Hat OpenStack Platform, Red Hat Virtualization, OpenShift Virtualization and Red Hat Enterprise Linux with KVM].


[id="virt-4-13-new"]
== New and changed features

//CNV-21735 SVVP for 4.13: Ensure platform passes Windows Server Virtualization Validation Program - with RHCOS workers
//NOTE: This is a recurring release note. Modify the existing note text below if recommended by QE.
* {VirtProductName} is certified in Microsoft's Windows Server Virtualization Validation Program (SVVP) to run Windows Server workloads.
+
The SVVP Certification applies to:
+
** Red Hat Enterprise Linux CoreOS workers. In the Microsoft SVVP Catalog, they are named __Red Hat OpenShift Container Platform 4 on RHEL CoreOS 9__.
** Intel and AMD CPUs.

//CNV-21918 Release note: NEW VMs as restricted workloads
* {VirtProductName} now adheres to the `restricted` link:https://kubernetes.io/docs/concepts/security/pod-security-standards/#restricted[Kubernetes pod security standards] profile. To learn more, see the {VirtProductName} xref:../virt/virt-security-policies.adoc#virt-security-policies[security policies] documentation.

//CNV-21919 Release note: NEW RHEL9-based CNV builds available
* {VirtProductName} is now based on {op-system-base-full} 9.
** There is a new {op-system-base} 9 machine type for VMs: `machineType: pc-q35-rhel9.2.0`.
+
All VM templates that are included with {VirtProductName} now use this machine type by default.

// todo: when 4.12.3 releases, uncomment the line below and fix the xref
//** To learn more, see xref .. virt/upgrading-virt.adoc #virt-rhel-9_upgrading-virt[{VirtProductName} on {op-system-base} 9].

//CNV-22041 Release note: NEW Retrieve a portable VM definition (yaml) when exporting a VM or VMSnapshot
* You can now obtain the `VirtualMachine`, `ConfigMap`, and `Secret` manifests from the export server after you export a VM or snapshot. For more information, see xref:../virt/virtual_machines/virt-exporting-vms.adoc#virt-accessing-exported-vm-manifests_virt-exporting-vms[accessing exported VM manifests].

//CNV-22972 Release note: Docs reorg
* The "Logging, events, and monitoring" documentation is now called xref:../virt/support/virt-support-overview.adoc#virt-support-overview[Support]. The monitoring tools documentation has been moved to xref:../virt/support/monitoring/virt-monitoring-overview.adoc#virt-monitoring-overview[Monitoring].

//CNV-25423 Release note: NEW Loki

//CNV-24976 Release note: CHANGE (CLOSED)


// CNV-25423
* You can view and filter aggregated {VirtProductName} logs in the web console by using the xref:../virt/support/virt-troubleshooting.adoc#virt-viewing-logs-loki_virt-troubleshooting[LokiStack].


[id="virt-4-13-quick-starts"]
=== Quick starts

* Quick start tours are available for several {VirtProductName} features. To view the tours, click the *Help* icon *?* in the menu bar on the header of the {VirtProductName} console and then select *Quick Starts*. You can filter the available tours by entering the `virtualization` keyword in the *Filter* field.


//[id="virt-4-13-installation-new"]
//=== Installation


[id="virt-4-13-networking-new"]
=== Networking

//CNV-21838 Release note: NEW OpenShift Virtualization supports jumbo frames with OVN Kubernetes
* You can now xref:../virt/virtual_machines/vm_networking/virt-using-the-default-pod-network-with-virt.adoc#virt-jumbo-frames-vm-pod-nw_virt-using-the-default-pod-network-with-virt[send unfragmented jumbo frame packets] between two virtual machines (VMs) that are connected on the default pod network when you use the OVN-Kubernetes CNI plugin.

[id="virt-4-13-storage-new"]
=== Storage

//CNV-18462 Release note: CHANGE Retire alpha APIs for Storage
* {VirtProductName} storage resources now migrate automatically to the beta API versions. Alpha API versions are no longer supported.

[id="virt-4-13-web-new"]
=== Web console

//CNV-27552 Release note: VM configuration tab
* On the *VirtualMachine details* page, the *Scheduling*, *Environment*, *Network interfaces*, *Disks*, and *Scripts* tabs are displayed on the new xref:../virt/virt-web-console-overview.adoc#ui-virtualmachine-details-configuration[*Configuration* tab].

//CNV-23474 Release note: NEW Paste clipboard into VNC
* You can now xref:../virt/virt-web-console-overview.adoc#ui-virtualmachine-details-console[paste a string] from your clientâ€™s clipboard into the guest when using the VNC console.

//CNV-25427 Release note: NEW Allow VM admin to expose SSH service using LB in the UI
* The *VirtualMachine details* -> *Details* tab now provides a new SSH service type *SSH over LoadBalancer* to expose the SSH service over a load balancer.

//CNV-25574 Release note: NEW UI - Ability to make a hot-plug disk part of the VM
* The option to make a hot-plug volume a persistent volume is added to the xref:../virt/virt-web-console-overview.adoc#ui-virtualmachine-details-disks[*Disks* tab].

//CNV-24128 Release notes: NEW - UI improve error condition display
* There is now a xref:../virt/virt-web-console-overview.adoc#ui-virtualmachine-details-diagnostics[*VirtualMachine details* -> *Diagnostics*] tab where you can view the status conditions of VMs and the snapshot status of volumes.

//CNV-25541 Release note: NEW -- UI can disable graphical display
* You can now enable headless mode for high performance VMs in the web console.

//NOTE: Comment out deprecated and removed features (and their IDs) if not used in a release
//[id="virt-4-13-deprecated-removed"]
//== Deprecated and removed features


//[id="virt-4-13-deprecated"]
//=== Deprecated features
// NOTE: when uncommenting deprecated features list, change the header level below to ===

//Deprecated features are included in the current release and supported. However, they will be removed in a future release and are not recommended for new deployments.


[id="virt-4-13-removed"]
== Removed features

Removed features are not supported in the current release.

//CNV-19043 Release note: CHANGE Remove rhel6 support
* Red Hat Enterprise Linux 6 is no longer supported on {VirtProductName}.

//CNV-23499: Carry over/repeat removed feature from version 4.12
* Support for the legacy HPP custom resource, and the associated storage class, has been removed for all new deployments. In {VirtProductName} {VirtVersion}, the HPP Operator uses the Kubernetes Container Storage Interface (CSI) driver to configure local storage. A legacy HPP custom resource is supported only if it had been installed on a previous version of {VirtProductName}.

//NOTE: Removed features for 4.13 are above this line.

//[id="virt-4-13-changes"]
//== Notable technical changes


[id="virt-4-13-technology-preview"]
== Technology Preview features

Some features in this release are currently in Technology Preview. These experimental features are not intended for production use. Note the following scope of support on the Red Hat Customer Portal for these features:

link:https://access.redhat.com/support/offerings/techpreview[Technology Preview Features Support Scope]

//NOTE: RNs related to 4.13 TP features begin here

//CNV-18095 Release note: NEW [TechPreview] Add Virtual machines CPU metrics
* You can now use xref:../virt/support/monitoring/virt-prometheus-queries.adoc#about-querying-metrics_virt-prometheus-queries[Prometheus] to monitor the following metrics:

** `kubevirt_vmi_cpu_system_usage_seconds` returns the physical system CPU time consumed by the hypervisor.
** `kubevirt_vmi_cpu_user_usage_seconds` returns the physical user CPU time consumed by the hypervisor.
** `kubevirt_vmi_cpu_usage_seconds` returns the total CPU time used in seconds by calculating the sum of the vCPU and the hypervisor usage.

//CNV-18330 Release note: PREVIEW Availability of new checkup capable of verifying cluster's readiness to run DPDK applications in VMs
* You can now run a xref:../virt/support/monitoring/virt-running-cluster-checkups.adoc#virt-checking-cluster-dpdk-readiness_virt-running-cluster-checkups[checkup] to verify if your {product-title} cluster node can run a virtual machine with a Data Plane Development Kit (DPDK) workload with zero packet loss.

//Adding another TP RN as part of CNV-18330: Configuring VM for DPDK
* You can xref:../virt/virtual_machines/vm_networking/virt-attaching-vm-to-sriov-network.adoc#virt-configuring-vm-dpdk_virt-attaching-vm-to-sriov-network[configure your virtual machine to run DPDK workloads] to achieve lower latency and higher throughput for faster packet processing in the user space.

//CNV-18413 Release note: PREVIEW Accessing VMs on secondary networks by using cluster domain name
* You can now xref:../virt/virtual_machines/vm_networking/virt-accessing-vm-secondary-network-fqdn.adoc#virt-accessing-vm-secondary-network-fqdn[access a VM that is attached to a secondary network interface] from outside the cluster by using its fully qualified domain name (FQDN).

//CNV-21991 Release notes: PREVIEW CNV hypershift
//NOTE: Targeted for 4.13.1 per Avital and Pan

//CNV-19436 Release note: NEW Retrieve a temporary token to access the VNC endpoint of a VM
//NOTE: This is a TP item for virt-4.14

//CNV-20965 Release note: PREVIEW Default creation and deployment of common set of instancetypes and preferences that eventually replace common templates
//NOTE: This is a TP item for virt-4.14


//NOTE: Existing 4.12 TP notes begin here

//CNV-20963 leave in
* You can now use Microsoft Windows 11 as a guest operating system. However, {VirtProductName} {VirtVersion} does not support USB disks, which are required for a critical function of BitLocker recovery. To protect recovery keys, use other methods described in the link:https://learn.microsoft.com/en-us/windows/security/information-protection/bitlocker/bitlocker-recovery-guide-plan[BitLocker recovery guide].

[id="virt-4-13-bug-fix"]
== Bug fix

* The virtual machine snapshot restore operation no longer hangs indefinitely due to some persistent volume claim (PVC) annotations created by the Containerized Data Importer (CDI). (link:https://bugzilla.redhat.com/show_bug.cgi?id=2070366[*BZ#2070366*])



[id="virt-4-13-known-issues"]
== Known issues

// No BZ.
// This is in the 4.13 RNs because it references OCP 4.13 and is more visible here.
* {VirtProductName} versions 4.12.2 and earlier are not compatible with {product-title} 4.13. Updating {product-title} to 4.13 is blocked by design in {VirtProductName} 4.12.1 and 4.12.2, but this restriction could not be added to {VirtProductName} 4.12.0. If you have {VirtProductName} 4.12.0, ensure that you do not update {product-title} to 4.13.
+
[IMPORTANT]
====
Your cluster becomes unsupported if you run incompatible versions of {product-title} and {VirtProductName}.
====

//CNV-27681/BZ2183594 Migration of VMs does not complete with descheduler operator enabled
// No BZ# because it is restricted to Red Hat.
* Enabling descheduler evictions on a virtual machine is a Technical Preview feature and might cause failed migrations and unstable scheduling.

* You cannot run {VirtProductName} on a single-stack IPv6 cluster. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2193267[*BZ#2193267*])

* When you use two pods with different SELinux contexts, VMs with the `ocs-storagecluster-cephfs` storage class fail to migrate and the VM status changes to `Paused`. This is because both pods try to access the shared `ReadWriteMany` CephFS volume at the same time. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2092271[*BZ#2092271*])
** As a workaround, use the `ocs-storagecluster-ceph-rbd` storage class to live migrate VMs on a cluster that uses Red Hat Ceph Storage.

//Leave in per Dominik
* If you clone more than 100 VMs using the `csi-clone` cloning strategy, then the Ceph CSI might not purge the clones. Manually deleting the clones might also fail. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2055595[*BZ#2055595*])
** As a workaround, you can restart the `ceph-mgr` to purge the VM clones.

//OCPBUGS-8398 for Dominik
* If you stop a node on a cluster and then use the Node Health Check Operator to bring the node back up, connectivity to Multus might be lost. (link:https://issues.redhat.com/browse/OCPBUGS-8398[*OCPBUGS-8398*])

// Fix targeted for 4.12.1
//Pending reply from Jenia and kmajcher
* The `TopoLVM` provisioner name string has changed in {VirtProductName} 4.12. As a result, the automatic import of operating system images might fail with the following error message (link:https://bugzilla.redhat.com/show_bug.cgi?id=2158521[*BZ#2158521*]):
+
[source,terminal]
----
DataVolume.storage spec is missing accessMode and volumeMode, cannot get access mode from StorageProfile.
----
** As a workaround:
. Update the `claimPropertySets` array of the storage profile:
+
[source,terminal]
----
$ oc patch storageprofile <storage_profile> --type=merge -p '{"spec": {"claimPropertySets": [{"accessModes": ["ReadWriteOnce"], "volumeMode": "Block"}, \
    {"accessModes": ["ReadWriteOnce"], "volumeMode": "Filesystem"}]}}'
----
. Delete the affected data volumes in the `openshift-virtualization-os-images` namespace. They are recreated with the access mode and volume mode from the updated storage profile.

// Fix targeted for 4.12.3.
* When restoring a VM snapshot for storage whose binding mode is `WaitForFirstConsumer`, the restored PVCs remain in the `Pending` state and the restore operation does not progress.
** As a workaround, start the restored VM, stop it, and then start it again. The VM will be scheduled, the PVCs will be in the `Bound` state, and the restore operation will complete. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2149654[*BZ#2149654*])

//New known issues for 4.13 go above this comment
//Leave in per Stu
* VMs created from common templates on a Single Node OpenShift (SNO) cluster display a `VMCannotBeEvicted` alert because the template's default eviction strategy is `LiveMigrate`. You can ignore this alert or remove the alert by updating the VM's eviction strategy. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2092412[*BZ#2092412*])

//Leave in per Simone
* Uninstalling {VirtProductName} does not remove the `feature.node.kubevirt.io` node labels created by {VirtProductName}. You must remove the labels manually. (link:https://issues.redhat.com/browse/CNV-22036[*CNV-22036*])

//Leave in per Kedar
* Windows 11 virtual machines do not boot on clusters running in link:https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/security_hardening/index#con_federal-information-processing-standard-fips_assembly_installing-the-system-in-fips-mode[FIPS mode]. Windows 11 requires a TPM (trusted platform module) device by default. However, the `swtpm` (software TPM emulator) package is incompatible with FIPS. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2089301[*BZ#2089301*])

//BZ-1885605
//Leave in per Petr
* If your {product-title} cluster uses OVN-Kubernetes as the default Container Network Interface (CNI) provider, you cannot attach a Linux bridge or bonding device to a host's default interface because of a change in the host network topology of OVN-Kubernetes. (link:https://bugzilla.redhat.com/show_bug.cgi?id=1885605[*BZ#1885605*])
** As a workaround, you can use a secondary network interface connected to your host, or switch to the OpenShift SDN default CNI provider.

// Leave in
* In some instances, multiple virtual machines can mount the same PVC in read-write mode, which might result in data corruption. (link:https://bugzilla.redhat.com/show_bug.cgi?id=1992753[*BZ#1992753*])
** As a workaround, avoid using a single PVC in read-write mode with multiple VMs.

//Leave in per Stu
* The Pod Disruption Budget (PDB) prevents pod disruptions for migratable virtual machine images. If the PDB detects pod disruption, then `openshift-monitoring` sends a `PodDisruptionBudgetAtLimit` alert every 60 minutes for virtual machine images that use the `LiveMigrate` eviction strategy. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2026733[*BZ#2026733*])
** As a workaround, xref:../monitoring/managing-alerts.adoc#silencing-alerts_managing-alerts[silence alerts].

//Leave in per Stu
* {VirtProductName} links a service account token in use by a pod to that specific pod. {VirtProductName} implements a service account volume by creating a disk image that contains a token. If you migrate a VM, then the service account volume becomes invalid. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2037611[*BZ#2037611*])
** As a workaround, use user accounts rather than service accounts because user account tokens are not bound to a specific pod.

//CNV-26301/BZ2151169 Leave in per Kedar
* In a heterogeneous cluster with different compute nodes, virtual machines that have HyperV Reenlightenment enabled cannot be scheduled on nodes that do not support timestamp-counter scaling (TSC) or have the appropriate TSC frequency. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2151169[*BZ#2151169*])