:_mod-docs-content-type: ASSEMBLY
[id="virt-4-15-release-notes"]
= {VirtProductName} release notes
include::_attributes/common-attributes.adoc[]
:context: virt-4-15-release-notes

toc::[]

include::modules/making-open-source-more-inclusive.adoc[leveloffset=+1]

[id="virt-doc-feedback"]
== Providing documentation feedback

To report an error or to improve our documentation, log in to your link:https://issues.redhat.com[Red Hat Jira account] and submit a link:https://issues.redhat.com/secure/CreateIssueDetails!init.jspa?pid=12323181&issuetype=1&components=12333768&priority=10200&summary=%5BDoc%5D&customfield_12316142[Jira issue].

[id="virt-about-virt"]
== About Red Hat {VirtProductName}

With Red Hat {VirtProductName}, you can bring traditional virtual machines (VMs) into {product-title} and run them alongside containers. In {VirtProductName}, VMs are native Kubernetes objects that you can manage by using the {product-title} web console or the command line.

{VirtProductName} is represented by the image:virt-icon.png[{VirtProductName},40,40] icon.

You can use {VirtProductName} with either the xref:../../networking/ovn_kubernetes_network_provider/about-ovn-kubernetes.adoc#about-ovn-kubernetes[OVN-Kubernetes] or the xref:../../networking/openshift_sdn/about-openshift-sdn.adoc#about-openshift-sdn[OpenShiftSDN] default Container Network Interface (CNI) network provider.

Learn more about xref:../../virt/about_virt/about-virt.adoc#about-virt[what you can do with {VirtProductName}].

Learn more about xref:../../virt/about_virt/virt-architecture.adoc#virt-architecture[{VirtProductName} architecture and deployments].

xref:../../virt/install/preparing-cluster-for-virt.adoc#preparing-cluster-for-virt[Prepare your cluster] for {VirtProductName}.

include::modules/virt-supported-cluster-version.adoc[leveloffset=+2]


[id="virt-guest-os"]
=== Supported guest operating systems
To view the supported guest operating systems for {VirtProductName}, see link:https://access.redhat.com/articles/973163#ocpvirt[Certified Guest Operating Systems in Red Hat OpenStack Platform, Red Hat Virtualization, OpenShift Virtualization and Red Hat Enterprise Linux with KVM].

//Ensure platform passes Windows Server Virtualization Validation Program. Otherwise, comment out the section below.
[id="virt-svvp-certification"]
=== Microsoft Windows SVVP certification

//CNV-31842 SVVP 4.15 Release Note: NEW
//NOTE: This is a recurring release note. Modify the existing note text below if recommended by QE.
{VirtProductName} is certified in Microsoft's Windows Server Virtualization Validation Program (SVVP) to run Windows Server workloads.

The SVVP certification applies to:

* Red Hat Enterprise Linux CoreOS workers. In the Microsoft SVVP Catalog, they are named __Red Hat OpenShift Container Platform 4 on RHEL CoreOS 9__.
* Intel and AMD CPUs.

[id="virt-quick-starts"]
== Quick starts

Quick start tours are available for several {VirtProductName} features. To view the tours, click the *Help* icon *?* in the menu bar on the header of the {product-title} web console and then select *Quick Starts*. You can filter the available tours by entering the keyword `virtualization` in the *Filter* field.


[id="virt-4-15-new"]
== New and changed features

This release adds new features and enhancements related to the following components and concepts:

[id="virt-4-15-installation-update"]
=== Installation and update

//CNV-34680: Metrics update
* You can now use the `kubevirt_vm_created_total` metric (Type: Counter) to query the number of VMs created in a specified namespace.

[id="virt-4-15-infrastructure"]
=== Infrastructure

//CNV-29987: Move instancetype API from v1alpha2 to v1beta1. As of 01/03/2024, this is an In Progress TP RN for 4.14 (CNV-21920).

//CNV-31433: virtio-serial channel for SAP
* Admins can now expose a limited set of host and virtual machine (VM) metrics to a guest VM through a `virtio-serial` port by enabling the `downwardMetrics` feature gate in the `HyperConverged` custom resource (CR), and adding the spec `downwardMetrics`. These metrics can be accessed by using the `vm-dump-metrics` tool.

[id="virt-4-15-virtualization"]
=== Virtualization

//CNV-34757: Guest OS console logs
* You can now enable access to the xref:../../virt/support/virt-troubleshooting.adoc#guest-system-logs_virt-troubleshooting[serial console logs of VM guests] to facilitate troubleshooting. This feature is disabled by default. Cluster administrators can change the default setting for VMs by using the web console or the CLI. Users can toggle guest log access on individual VMs regardless of the cluster-wide default setting.

//CNV-29983: Free page reporting
* Free page reporting is enabled by default.

//CNV-28880: KSM configuration
* You can configure {VirtProductName} to xref:../../virt/virtual_machines/advanced_vm_management/virt-activating-ksm.adoc#virt-activating-ksm[activate kernel samepage merging (KSM)] when a node is overloaded.

[id="virt-4-15-networking"]
=== Networking

//CNV-30164 and CNV-30167: NIC hot plug feature is now GA. This was TP for 4.14. Moved the release note from the TP section to here. Covers both bridge and SR-IOV NICs
* You can xref:../../virt/vm_networking/virt-hot-plugging-network-interfaces.adoc#virt-hot-plugging-network-interfaces[hot plug a secondary network interface] to a running virtual machine (VM). Hot plugging and hot unplugging is supported only for VMs created with {VirtProductName} 4.14 or later. Hot unplugging is not supported for Single Root I/O Virtualization (SR-IOV) interfaces.

//CNV-13680: Connecting OVN-Kubernetes to underlying physical networks. Remove known issue BZ-1885605 after adding this note.
* {VirtProductName} now supports the localnet topology for xref:../../virt/vm_networking/virt-connecting-vm-to-ovn-secondary-network.adoc#virt-connecting-vm-to-ovn-secondary-network[OVN-Kubernetes secondary networks]. A localnet topology connects the secondary network to the physical underlay. This enables both east-west cluster traffic and access to services running outside the cluster, but it requires additional configuration of the underlying Open vSwitch (OVS) system on cluster nodes.

//CNV-30170: NetworkPolicies filtering using IP blocks with OVN-Kubernetes
* An OVN-Kubernetes secondary network is compatible with the xref:../../networking/multiple_networks/configuring-additional-network.adoc#compatibility-with-multi-network-policy_configuring-additional-network[multi-network policy API], which provides the `MultiNetworkPolicy` custom resource definition (CRD) to control traffic flow to and from VMs. You can use the `ipBlock` attribute to define network policy ingress and egress rules for specific CIDR blocks.

//CNV-30296: Running DPDK workloads on SR-IOV is now GA. The TP note from 4.13 should have been part of 4.14 as well.
* xref:../../virt/vm_networking//virt-using-dpdk-with-sriov.adoc#virt-configuring-cluster-dpdk_virt-using-dpdk-with-sriov[Configuring a cluster for DPDK workloads on SR-IOV] was previously Technology Preview and is now generally available.
//CNV-30307
* You can now xref:../../virt/vm_networking/virt-connecting-vm-to-ovn-secondary-network.adoc#virt-creating-nad-localnet-console_virt-connecting-vm-to-ovn-secondary-network[create a network attachment definition (NAD) for localnet topology] by using the {product-title} web console.

[id="virt-4-15-storage"]
=== Storage

//CNV-35029: PVC annotation to explain host-assisted cloning
* When cloning a data volume, the Containerized Data Importer (CDI) chooses an efficient Container Storage Interface (CSI) clone if certain prerequisites are met. Host-assisted cloning, a less efficient method, is used as a fallback. To understand why host-assisted cloning was used, you can check the `cdi.kubevirt.io/cloneFallbackReason` annotation on the cloned persistent volume claim (PVC).


[id="virt-4-15-web"]
=== Web console

//CNV-34697: Instance types is now GA. Move the 4.14 RN from the TP section to here.
* Installing and editing xref:../../virt/virtual_machines/creating_vms_rh/virt-creating-vms-from-instance-types.adoc#virt-creating-vm-instancetype_virt-creating-vms-from-instance-types[customized instance types] and preferences to create a virtual machine (VM) from a volume or persistent volume claim (PVC) was previously Technology Preview and is now generally available.

//CNV-33122: Virtualization page updates for 4.15
* The *Preview features* tab can now be found under *Virtualization* -> *Overview* -> *Settings*.

//CNV-36165: VM disks with persistent reservation.
* You can configure disk sharing for ordinary virtual machine (VM) or LUN-backed VM disks to allow multiple VMs to share the same underlying storage. Any disk to be shared must be in block mode.
+
To allow a LUN-backed block mode VM disk to be shared among multiple VMs, a cluster administrator must enable the SCSI `persistentReservation` feature gate.
+
For more information, see xref:../../virt/virtual_machines/virtual_disks/virt-configuring-shared-volumes-for-vms.adoc#virt-configuring-shared-volumes-for-vms[Configuring shared volumes for virtual machines].

//CNV-36162: Search option in VM configuration tab
* You can now search for VM configuration settings in the *Configuration* tab of the *VirtualMachine details* page.

//CNV-36159: New configuration option "SSH over NodePort service"
* You can now configure *SSH over NodePort service* under *Virtualization* -> *Overview* -> *Settings* -> *Cluster* -> *General settings* -> *SSH configurations*.

//CNV-36603: Mark bootable volumes as favorite
* When creating a VM from an instance type, you can now designate favorite bootable volumes by starring them in the volume list of the {product-title} web console.

//CNV-36464: Run a test that shows that the SR-IOV settings are correct
* You can run a VM xref:../../virt/monitoring/virt-running-cluster-checkups.adoc#virt-measuring-latency-vm-secondary-network_virt-running-cluster-checkups[latency checkup] by using the web console. From the side menu, click *Virtualization* -> *Checkups* -> *Network latency*.
To run your first checkup, click *Install permissions* and then click *Run checkup*.

//CNV-28718: Storage checks
* You can run a storage validation xref:../../virt/monitoring/virt-running-cluster-checkups.adoc#virt-running-cluster-checkups[checkup] by using the web console. From the side menu, click *Virtualization* -> *Checkups* -> *Storage*.
To run your first checkup, click *Install permissions* and then click *Run checkup*.

//CNV-33131: Set KSM from the UI
* You can enable or disable the xref:../../virt/virtual_machines/advanced_vm_management/virt-activating-ksm.adoc#virt-activating-ksm[kernel samepage merging (KSM) activation feature] for all cluster nodes by using the xref:../../virt/virtual_machines/advanced_vm_management/virt-activating-ksm.adoc#virt-configure-ksm-web_virt-activating-ksm[web console].

//CNV-33127: SR-IOV NIC hot plug from the UI

//CNV-31114: Using SSH key secret from another project
* You can now use existing secrets from other projects when xref:../../virt/virtual_machines/virt-accessing-vm-ssh.adoc#static-key-management-vm[adding a public SSH key during VM creation] or when xref:../../virt/virtual_machines/virt-edit-vms.adoc#virt-adding-secret-configmap-service-account-to-vm_virt-edit-vms[adding a secret to an existing VM].

//NOTE: Comment out deprecated and removed features (and their IDs) if not used in a release
[id="virt-4-15-deprecated-removed"]
== Deprecated and removed features


[id="virt-4-15-deprecated"]
=== Deprecated features
// NOTE: when uncommenting deprecated features list, change the Removed features header level below to ===

Deprecated features are included in the current release and supported. However, they will be removed in a future release and are not recommended for new deployments.

//CNV-26426 [DOCS] Release note: Deprecate TTO
* The `tekton-tasks-operator` is deprecated and Tekton tasks and example pipelines are now deployed by the `ssp-operator`.

//CNV-26316: Release note: Align tekton tasks with instancestypes
* The `copy-template`, `modify-vm-template`, and `create-vm-from-template` tasks are deprecated.

//CNV-29048 Release note: Metrics name changes
* Many OpenShift Virtualization metrics have changed or will change in a future version. These changes could affect your custom dashboards. See link:https://access.redhat.com/articles/7028805[OpenShift Virtualization 4.14 metric changes] for details. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2179660[*BZ#2179660*])

//CNV-32032 Release note: DEPRECATED FEATURE (Windows 2012R2 templates deprecated)
* Support for Windows Server 2012 R2 templates is deprecated.


[id="virt-4-15-removed"]
=== Removed features

Removed features are not supported in the current release.

//CNV-23499: Carry over/repeat removed feature from version 4.12 and 4.13
//Check if this is still needed for 4.15
* Support for the legacy HPP custom resource, and the associated storage class, has been removed for all new deployments. In {VirtProductName} {VirtVersion}, the HPP Operator uses the Kubernetes Container Storage Interface (CSI) driver to configure local storage. A legacy HPP custom resource is supported only if it had been installed on a previous version of {VirtProductName}.


[id="virt-4-15-technology-preview"]
== Technology Preview features

Some features in this release are currently in Technology Preview. These experimental features are not intended for production use. Note the following scope of support on the Red Hat Customer Portal for these features:

link:https://access.redhat.com/support/offerings/techpreview[Technology Preview Features Support Scope]

//CNV-28944 Release note: Preview Cluster level eviction strategy change
* You can now configure a xref:../../virt/nodes/virt-node-maintenance.adoc#eviction-strategies[VM eviction strategy] for the xref:../../virt/nodes/virt-node-maintenance.adoc#virt-configuring-cluster-eviction-strategy-cli_virt-node-maintenance[entire cluster].

//CNV-15028: Nested virt in virt hosts. This feature will remain in tech preview indefinitely.
* You can now enable link:https://access.redhat.com/solutions/6692341[nested virtualization on {VirtProductName} hosts].

//CNV-29768: Memory hot plug

//CNV-29882: CPU hot plug

//CNV-33125: Add CPU limits to the UI
* Cluster admins can now enable CPU resource limits on a namespace in the {product-title} web console under *Overview* -> *Settings* -> *Cluster* -> *Preview features*.

[id="virt-4-15-bug-fixes"]
== Bug fixes
* Previously, the `windows-efi-installer` pipeline failed when started with a storage class that had the `volumeBindingMode` set to `WaitForFirstConsumer`. This fix removes the annotation in the `StorageClass` object that was causing the pipelines to fail. (link:https://issues.redhat.com/browse/CNV-32287[*CNV-32287*])

* Previously, if you simultaneously cloned approximately 1000 virtual machines (VMs) using the provided data sources in the `openshift-virtualization-os-images` namespace, not all of the VMs moved to a running state. With this fix, you can clone a large number of VMs concurrently. (link:https://issues.redhat.com/browse/CNV-30083[*CNV-30083*])

* Previously, you could not SSH into a VM by using a `NodePort` service and its associated fully qualified domain name (FQDN) displayed in the web console when using `networkType: OVNKubernetes` in your `install-config.yaml` file. With this update, you can configure the web console so it shows a valid accessible endpoint for SSH `NodePort` services. (link:https://issues.redhat.com/browse/CNV-24889[*CNV-24889*])

* With this update, live migration no longer fails for a virtual machine instance (VMI) after hot plugging a virtual disk. (link:https://issues.redhat.com/browse/CNV-34761[*CNV-34761*])


[id="virt-4-15-known-issues"]
== Known issues

[discrete]
[id="virt-4-15-ki-monitoring"]
==== Monitoring
//fix targeted for 4.16
* The Pod Disruption Budget (PDB) prevents pod disruptions for migratable virtual machine images. If the PDB detects pod disruption, then `openshift-monitoring` sends a `PodDisruptionBudgetAtLimit` alert every 60 minutes for virtual machine images that use the `LiveMigrate` eviction strategy. (link:https://issues.redhat.com/browse/CNV-33834[*CNV-33834*])
** As a workaround, xref:../../monitoring/managing-alerts.adoc#silencing-alerts_managing-alerts[silence alerts].


[discrete]
[id="virt-4-15-ki-nodes"]
==== Nodes
//4.15 Keep per Stu and Simone
* Uninstalling {VirtProductName} does not remove the `feature.node.kubevirt.io` node labels created by {VirtProductName}. You must remove the labels manually. (link:https://issues.redhat.com/browse/CNV-38543[*CNV-38543*])


[discrete]
[id="virt-4-15-ki-storage"]
==== Storage
//4.15 Issue is closed as "Not a bug" but is still a known issue
* If you use Portworx as your storage solution on AWS and create a VM disk image, the created image might be smaller than expected due to the filesystem overhead being accounted for twice. (link:https://issues.redhat.com/browse/CNV-32695[*CNV-32695*])
** As a workaround, you can manually expand the persistent volume claim (PVC) to increase the available space after the initial provisioning process completes.

//4.15 Keep per Adam Litke. Issue is closed as "Won't do" but is still a known issue
* In some instances, multiple virtual machines can mount the same PVC in read-write mode, which might result in data corruption. (link:https://issues.redhat.com/browse/CNV-13500[*CNV-13500*])
** As a workaround, avoid using a single PVC in read-write mode with multiple VMs.

//4.15 Keep per Dominik Holler. A new engineering bug will be created to track this. Reach out to Dominik or Jennifer Abrams to update the bug URL
* If you clone more than 100 VMs using the `csi-clone` cloning strategy, then the Ceph CSI might not purge the clones. Manually deleting the clones might also fail. (link:https://issues.redhat.com/browse/CNV-23501[*CNV-23501*])
** As a workaround, you can restart the `ceph-mgr` to purge the VM clones.



[discrete]
[id="virt-4-15-ki-virtualization"]
==== Virtualization

// new for 4.15
* A critical bug in `qemu-kvm` causes VMs to hang and experience I/O errors after xref:../../virt/virtual_machines/virtual_disks/virt-hot-plugging-virtual-disks.adoc#virt-hot-plugging-virtual-disks[disk hot plug] operations. This issue can also affect the operating system disk and other disks that were not involved in the hot plug operations. If the operating system disk stops working, the root file system shuts down. For more information, see link:https://access.redhat.com/solutions/7055333[Virtual Machine loses access to its disks after hot-plugging some extra disks] in the Red Hat Knowledgebase.
+
[IMPORTANT]
====
Due to package versioning, this bug might reappear after updating {VirtProductName} from 4.13.z or 4.14.z to 4.15.0.
====

//4.15 still unresolved
* When adding a virtual Trusted Platform Module (vTPM) device to a Windows VM, the BitLocker Drive Encryption system check passes even if the vTPM device is not persistent. This is because a vTPM device that is not persistent stores and recovers encryption keys using ephemeral storage for the lifetime of the `virt-launcher` pod. When the VM migrates or is shut down and restarts, the vTPM data is lost. (link:https://issues.redhat.com/browse/CNV-36448[*CNV-36448*])

//4.15 still unresolved
* {VirtProductName} links a service account token in use by a pod to that specific pod. {VirtProductName} implements a service account volume by creating a disk image that contains a token. If you migrate a VM, then the service account volume becomes invalid. (link:https://issues.redhat.com/browse/CNV-33835[*CNV-33835*])
** As a workaround, use user accounts rather than service accounts because user account tokens are not bound to a specific pod.

//4.15 Keep this per Stu, ETA for fixing this issue is 4.18.
* With the release of the link:https://access.redhat.com/errata/RHSA-2023:3722[RHSA-2023:3722] advisory, the TLS `Extended Master Secret` (EMS) extension (link:https://datatracker.ietf.org/doc/html/rfc7627[RFC 7627]) is mandatory for TLS 1.2 connections on FIPS-enabled {op-system-base-full} 9 systems. This is in accordance with FIPS-140-3 requirements. TLS 1.3 is not affected.
+
Legacy OpenSSL clients that do not support EMS or TLS 1.3 now cannot connect to FIPS servers running on RHEL 9. Similarly, RHEL 9 clients in FIPS mode cannot connect to servers that only support TLS 1.2 without EMS. This in practice means that these clients cannot connect to servers on RHEL 6, RHEL 7 and non-RHEL legacy operating systems. This is because the legacy 1.0.x versions of OpenSSL do not support EMS or TLS 1.3. For more information, see link:https://access.redhat.com/solutions/7018256[TLS Extension "Extended Master Secret" enforced with Red Hat Enterprise Linux 9.2].

** As a workaround, update legacy OpenSSL clients to a version that supports TLS 1.3 and configure {VirtProductName} to use TLS 1.3, with the `Modern` TLS security profile type, for FIPS mode.


[discrete]
[id="virt-4-15-ki-webconsole"]
==== Web console
//CNV-38293
* When you first deploy an {product-title} cluster, creating VMs from templates or instance types by using the web console, fails if you do not have `cluster-admin` permissions.
** As a workaround, the cluster administrator must first xref:../../nodes/pods/nodes-pods-configmaps.adoc#nodes-pods-configmap-create-from-console_configmaps[create a config map] to enable other users to use templates and instance types to create VMs. (link: https://issues.redhat.com/browse/CNV-38284[*CNV-38284*])