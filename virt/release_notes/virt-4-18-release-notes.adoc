:_mod-docs-content-type: ASSEMBLY
[id="virt-4-18-release-notes"]
= {VirtProductName} release notes
include::_attributes/common-attributes.adoc[]
:context: virt-4-18-release-notes

toc::[]

[role="_abstract"] 
The release notes summarize new features and enhancements, notable technical changes, and known issues for this release of OpenShift Virtualization. 

[id="virt-doc-feedback"]
== Providing documentation feedback

To report an error or to improve our documentation, log in to your link:https://issues.redhat.com[Red Hat Jira account] and submit a link:https://issues.redhat.com/secure/CreateIssueDetails!init.jspa?pid=12323181&issuetype=1&components=12333768&priority=10200&summary=%5BDoc%5D&customfield_12316142[Jira issue].

[id="virt-about-virt"]
== About Red Hat {VirtProductName}

With Red Hat {VirtProductName}, you can bring traditional virtual machines (VMs) into {product-title} and run them alongside containers. In {VirtProductName}, VMs are native Kubernetes objects that you can manage by using the {product-title} web console or the command line.

{VirtProductName} is represented by the image:virt-icon.png[{VirtProductName},40,40] icon.

You can use {VirtProductName} the xref:../../networking/ovn_kubernetes_network_provider/about-ovn-kubernetes.adoc#about-ovn-kubernetes[OVN-Kubernetes] Container Network Interface (CNI) network provider.

Learn more about xref:../../virt/about_virt/about-virt.adoc#about-virt[what you can do with {VirtProductName}].

Learn more about xref:../../virt/about_virt/virt-architecture.adoc#virt-architecture[{VirtProductName} architecture and deployments].

xref:../../virt/install/preparing-cluster-for-virt.adoc#preparing-cluster-for-virt[Prepare your cluster] for {VirtProductName}.

include::modules/virt-supported-cluster-version.adoc[leveloffset=+2]


[id="virt-guest-os"]
=== Supported guest operating systems
To view the supported guest operating systems for {VirtProductName}, see link:https://access.redhat.com/articles/973163#ocpvirt[Certified Guest Operating Systems in Red Hat OpenStack Platform, Red Hat Virtualization, OpenShift Virtualization and Red Hat Enterprise Linux with KVM].

//Ensure platform passes Windows Server Virtualization Validation Program. Otherwise, comment out the section below.
[id="virt-svvp-certification"]
=== Microsoft Windows SVVP certification

//CNV-47134 SVVP 4.18 Release Note: New
//NOTE: This is a recurring release note. Modify the existing note text below if recommended by QE.
{VirtProductName} is certified in Microsoft's Windows Server Virtualization Validation Program (SVVP) to run Windows Server workloads.

The SVVP certification applies to:

* Red Hat Enterprise Linux CoreOS workers. In the Microsoft SVVP Catalog, they are named __Red Hat OpenShift Container Platform 4 on RHEL CoreOS 9__.
* Intel and AMD CPUs.

[id="virt-quick-starts"]
== Quick starts

Quick start tours are available for several {VirtProductName} features. To view the tours, click the *Help* icon *?* in the menu bar on the header of the {product-title} web console and then select *Quick Starts*. You can filter the available tours by entering the keyword `virtualization` in the *Filter* field.


[id="virt-4-18-new"]
== New and changed features

This release adds new features and enhancements related to the following components and concepts:

//[id="virt-4-18-installation-update"]
//=== Installation and update

//[id="virt-4-18-infrastructure"]
//=== Infrastructure

[id="virt-4-18-virtualization"]
=== Virtualization
//CNV-48244: Instance types hotplug GA
* You can now xref:../../virt/creating_vm/virt-creating-vms-from-instance-types.adoc#virt-change-vm-instance-type_virt-creating-vms-from-instance-types[change the instance type] associated with a running virtual machine (VM) without restarting the VM. This feature was previously Technology Preview and is now generally available.

// CNV-48296: TP to GA
* You can now export VMs that have a virtual Trusted Platform Module (vTPM) device added to them, create snapshots of these VMs, and restore the VMs from snapshots. Note that cloning a VM with a vTPM device attached to it or creating a new VM from its snapshot is not supported.

// CNV-57546: Update 4.18 CNV Virt release notes to include also about RWO support
* With the addition of the `ReadWriteOnce` (RWO) `Filesystem` support, you can now use any storage class for disks that persist the VM state such as vTPM or EFI. Previously, the storage class had to be of type `Filesystem` with the `ReadWriteMany` (RWX) access mode to persist across VM reboots.

[id="virt-4-18-networking"]
=== Networking
//CNV-47162: Primary UDN
* You can now connect a VM to a xref:../../virt/vm_networking/virt-connecting-vm-to-primary-udn.adoc#virt-connecting-vm-to-primary-udn[user-defined network (UDN)] on the primary interface of the VM.

//CNV-47161: UDN on AWS
* You can now use primary user-defined networks for VMs on a public cloud.

//[id="virt-4-18-storage"]
//=== Storage

[id="virt-4-18-web"]
=== Web console

//CNV-50927: Disk resize from vm view
* You can now xref:../../virt/managing_vms/virtual_disks/virt-expanding-vm-disks.adoc#virt-expanding-vm-disk-pvc_virt-expanding-vm-disks[increase the size of the persistent volume claim (PVC) of a VM disk in the web console] without leaving the *VirtualMachines* page and with the VM running.

//CNV-51079: Release note: NEW bulk vm operations
* You can now xref:../../virt/managing_vms/virt-controlling-vm-states.adoc#virt-controlling-multiple-vms-web_virt-controlling-vm-states[control the state of multiple virtual machines] from the {product-title} web console.

//CNV-55734: Release note: NNS topology view
* As a cluster administrator, you can xref:../../networking/k8s_nmstate/k8s-nmstate-updating-node-network-config.adoc#virt-viewing-network-state-of-node-console_k8s-nmstate-updating-node-network-config[view the state of the node network of the cluster (NNS) in the form of a topology diagram]. The NNS topology diagram displays all node components (network interface controllers, bridges, bonds, and VLANs), their properties and configurations, and connections between the nodes. You can open the topology diagram from the *NodeNetworkState* page of the web console.

[id="virt-4-18-monitoring"]
=== Monitoring

//CNV-47048: Release note: announce the availability of new VM metrics
* You can now view virtual machine (VM) workload metrics for allocated storage, CPU, and network resources. Admins can use these metrics to determine resource allocation and capacity planning.
+
For a complete list of virtualization metrics, see link:https://github.com/kubevirt/monitoring/blob/main/docs/metrics.md[KubeVirt components metrics].

[id="virt-4-18-documentation"]
=== Documentation improvements

//CNV:56899: Release note: NEW
* You can now find information about virtual machines in 3 new sections in the {VirtProductName} documentation:
+
** xref:../../virt/creating_vm/virt-creating-vms-from-instance-types.adoc#virt-creating-vms-from-instance-types[Creating a virtual machine] documents basic VM creation.
+
** xref:../../virt/creating_vms_advanced/advanced-vm-creation-overview.adoc#advanced-vm-creation-overview[Advanced VM creation] documents advanced ways to create VMs.
+
** xref:../../virt/managing_vms/virt-installing-qemu-guest-agent.adoc#virt-installing-qemu-guest-agent[Managing VMs] documents all procedures relevant to managing VMs, both basic and advanced.
+
These sections include streamlined and improved content.

[id="virt-4-18-notable-technical-changes"]
=== Notable technical changes

//CNV-56538 and 45704: Automatic boot source updates when changing the default storage class
* Changing the default storage class automatically deletes and re-imports existing boot sources. If boot source images were stored as volume snapshots and no default storage class is set, the snapshots are cleaned up and new data volumes are created but will not import until a default storage class is configured.

[id="virt-4-18-deprecated-removed"]
== Deprecated and removed features
//NOTE: Comment out deprecated and removed features (and their IDs) if not used in a release

[role="_abstract"] 
The deprecated and removed features section lists the features that are no longer supported or planned for removal in this release of OpenShift Virtualization.

[id="virt-4-18-deprecated"]
=== Deprecated features
// NOTE: When uncommenting deprecated features list, change the Removed features header level below to ===


//CNV-26316: Release note: Align tekton tasks with instancestypes
* The `copy-template`, `modify-vm-template`, and `create-vm-from-template` tasks are deprecated.

//CNV-32032 Release note: DEPRECATED FEATURE (Windows 2012R2 templates deprecated)
* Support for Windows Server 2012 R2 templates is deprecated.

//CNV-34681: Deprecated alerts
* The alerts `KubeVirtComponentExceedsRequestedMemory` and `KubeVirtComponentExceedsRequestedCPU` are deprecated. You can safely xref:../../observability/monitoring/managing-alerts/managing-alerts-as-an-administrator.adoc#silencing-alerts-adm_managing-alerts-as-an-administrator[silence]  them.

[id="virt-4-18-removed"]
=== Removed features

Removed features are no longer supported in {VirtProductName}.

//CNV-51635: remove tekton-tasks-operator informaiton form release notes
* The `tekton-tasks-operator`` is removed. The Tekton tasks and example pipelines are now available in the task catalog (ArtifactHub).

[id="virt-4-18-technology-preview_{context}"]
== Technology Preview features

Some features in this release are currently in Technology Preview. These experimental features are not intended for production use. Note the following scope of support on the Red Hat Customer Portal for these features:

link:https://access.redhat.com/support/offerings/techpreview[Technology Preview Features Support Scope]

//CNV-52362: IBM Z
* You can use {VirtProductName} on an {product-title} cluster that has been deployed in a logical partition (LPAR) on {ibm-z-name} and {ibm-linuxone-name} (s390x architecture) systems. For more information, see xref:../../virt/install/preparing-cluster-for-virt.adoc#ibm-z-linuxone-compatibility_preparing-cluster-for-virt[{ibm-z-title} and {ibm-linuxone-title} compatibility].

// CNV-47365: Release note: TP to GA
* You can now use the {product-title} web console to xref:../../virt/managing_vms/virtual_disks/virt-migrating-storage-class.adoc#virt-migrating-storage-class[migrate one or more disks attached to a virtual machine (VM) to a different storage class]. For the storage class migration to be successful, the VM must be running and the cluster must have a node available for live migration of the VM.
+
[NOTE]
====
Storage live migration is not enabled by default in the `HyperConverged` custom resource. To enable the required feature gates, follow the workaround documented in link:https://access.redhat.com/solutions/7089972[Enable VM storage live migration in {VirtProductName}] in the Red{nbsp}Hat knowledge base.
====

//[id="virt-4-18-bug-fixes"]
//== Bug fixes
//
[id="virt-4-18-known-issues"]
== Known issues

//[discrete]
//[id="virt-4-18-ki-monitoring"]
//==== Monitoring
//
[discrete]
[id="virt-4-18-ki-networking"]
==== Networking
//CNV-38746
* When you update from {product-title} 4.12 to a newer minor version, VMs that use the `cnv-bridge` Container Network Interface (CNI) fail to live migrate. (link:https://access.redhat.com/solutions/7069807[])
** As a workaround, change the `spec.config.type` field in your `NetworkAttachmentDefinition` manifest from `cnv-bridge` to `bridge` before performing the update.

[discrete]
[id="virt-4-18-ki-nodes"]
==== Nodes
//CNV-38543 - 4.16 Still an issue
* Uninstalling {VirtProductName} does not remove the `feature.node.kubevirt.io` node labels created by {VirtProductName}. You must remove the labels manually. (link:https://issues.redhat.com/browse/CNV-38543[*CNV-38543*])

//BZ 2151169
* In a heterogeneous cluster with different compute nodes, virtual machines that have HyperV reenlightenment enabled cannot be scheduled on nodes that do not support timestamp-counter scaling (TSC) or have the appropriate TSC frequency. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2151169[*BZ#2151169*])

[discrete]
[id="virt-4-18-ki-storage"]
==== Storage
//CNV-23501: 4.16 - Keep per Dominik Holler
* If you clone more than 100 VMs using the `csi-clone` cloning strategy, then the Ceph CSI might not purge the clones. Manually deleting the clones might also fail. (link:https://issues.redhat.com/browse/CNV-23501[*CNV-23501*])
** As a workaround, you can restart the `ceph-mgr` to purge the VM clones.

// CNV-55104: 4.18 - Unresolved
* If you perform storage class migration for a stopped VM, the VM might not be able to start because of a missing bootable device. To prevent this, do not attempt storage class migration if the VM is not running. (link:https://issues.redhat.com/browse/CNV-55104[*CNV-55104*])
+
--
:FeatureName: Storage class migration
include::snippets/technology-preview.adoc[]
--

[discrete]
[id="virt-4-18-ki-virtualization"]
==== Virtualization

//CNV-56998 is doc issue; CNV-56659 is original issue
* Virtual machine instance migrations might fail during workload updates or when a large number of migrations are triggered. This is more likely to occur if there are at least 400 pending migrations, undefined migrations, or a combination of both. (link:https://issues.redhat.com/browse/CNV-56659[*CNV-56659*])
** As a workaround, follow the procedure in the link:https://access.redhat.com/solutions/7108359[Red{nbsp}Hat Knowledgebase solution for this issue].

//CNV-36448: 4.16 - Unresolved
* When adding a virtual Trusted Platform Module (vTPM) device to a Windows VM, the BitLocker Drive Encryption system check passes even if the vTPM device is not persistent. This is because a vTPM device that is not persistent stores and recovers encryption keys using ephemeral storage for the lifetime of the `virt-launcher` pod. When the VM migrates or is shut down and restarts, the vTPM data is lost. (link:https://issues.redhat.com/browse/CNV-36448[*CNV-36448*])

//CNV-33835: 4.16 - Unresolved
* {VirtProductName} links a service account token in use by a pod to that specific pod. {VirtProductName} implements a service account volume by creating a disk image that contains a token. If you migrate a VM, then the service account volume becomes invalid. (link:https://issues.redhat.com/browse/CNV-33835[*CNV-33835*])
** As a workaround, use user accounts rather than service accounts because user account tokens are not bound to a specific pod.

[discrete]
[id="virt-4-16-ki-webconsole_{context}"]
==== Web console
//CNV-38594: 4.16 - Still an issue per Guohua
* When you create a persistent volume claim (PVC) by selecting *With Data upload form* from the *Create PersistentVolumeClaim* list in the web console, uploading data to the PVC by using the *Upload Data* field fails. (link:https://issues.redhat.com/browse/CNV-37607[*CNV-37607*])

[discrete]
[id="virt-4-18-ki-ibm-z_{context}"]
==== {ibm-z-title} and {ibm-linuxone-title}

--
:FeatureName: Using {VirtProductName} with s390x architecture
include::snippets/technology-preview.adoc[]
--

* When you create a VM by using {op-system-base-full} container disk images for s390x architecture, call traces referencing `virtio_balloon` free page reporting print to the VM console. This is due to a kernel bug. (link:https://issues.redhat.com/browse/OCPBUGS-51113[OCPBUGS-51113])
** As a workaround, disable memory ballooning for the VM by adding the following parameter to the VM YAML configuration: `spec.domain.devices.autoattachMemBalloon: false`. 
+
You can also disable free page reporting of memory ballooning for all new VMs. To do so, edit the `HyperConverged` CR and add the parameter `spec.virtualMachineOptions.disableFreePageReporting: true`.

// cnv-56889 - boot mode
* In the web console, the *Boot mode* list for an s390x VM incorrectly includes *BIOS*, *UEFI*, and *UEFI (secure)* boot modes. If you select one of these modes for an s390x-based VM, the operation fails. This is because VMs based on s390x architecture can only use the *IPL* boot mode. (link:https://issues.redhat.com/browse/CNV-56889[CNV-56889])

// cnv-56890 - threads
* In the web console, it is erroneously possible to define multiple CPU threads for a VM based on s390x architecture. If you define multiple CPU threads, the VM enters a `CrashLoopBackOff` state with the error `qemu-kvm: S390 does not support more than 1 threads`. (link:https://issues.redhat.com/browse/CNV-56890[CNV-56890])
