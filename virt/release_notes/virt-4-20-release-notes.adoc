:_mod-docs-content-type: ASSEMBLY
include::_attributes/common-attributes.adoc[]
[id="virt-4-20-release-notes"]
= {VirtProductName} release notes
:context: virt-4-20-release-notes

toc::[]

[id="virt-doc-feedback_{context}"]
== Providing documentation feedback

To report an error or to improve our documentation, log in to your link:https://issues.redhat.com[Red Hat Jira account] and submit a link:https://issues.redhat.com/secure/CreateIssueDetails!init.jspa?pid=12323181&issuetype=1&components=12333768&priority=10200&summary=%5BDoc%5D&customfield_12316142[Jira issue].

[id="virt-about-virt_{context}"]
== About Red Hat {VirtProductName}

With Red Hat {VirtProductName}, you can bring traditional virtual machines (VMs) into {product-title} and run them alongside containers. In {VirtProductName}, VMs are native Kubernetes objects that you can manage by using the {product-title} web console or the command line.

{VirtProductName} is represented by the image:virt-icon.png[{VirtProductName},40,40] icon.

You can use {VirtProductName} the xref:../../networking/ovn_kubernetes_network_provider/about-ovn-kubernetes.adoc#about-ovn-kubernetes[OVN-Kubernetes] Container Network Interface (CNI) network provider.

Learn more about xref:../../virt/about_virt/about-virt.adoc#about-virt[what you can do with {VirtProductName}].

Learn more about xref:../../virt/about_virt/virt-architecture.adoc#virt-architecture[{VirtProductName} architecture and deployments].

xref:../../virt/install/preparing-cluster-for-virt.adoc#preparing-cluster-for-virt[Prepare your cluster] for {VirtProductName}.

include::modules/virt-supported-cluster-version.adoc[leveloffset=+2]

[id="virt-guest-os_{context}"]
=== Supported guest operating systems

To view the supported guest operating systems for {VirtProductName}, see link:https://access.redhat.com/articles/973163#ocpvirt[Certified Guest Operating Systems in Red Hat OpenStack Platform, Red Hat Virtualization, OpenShift Virtualization and Red Hat Enterprise Linux with KVM].

//Ensure platform passes Windows Server Virtualization Validation Program. Otherwise, comment out the section below.
[id="virt-svvp-certification_{context}"]
=== Microsoft Windows SVVP certification

//CNV-47134 SVVP 4.18 Release Note: New
//NOTE: This is a recurring release note. Modify the existing note text below if recommended by QE.
{VirtProductName} is certified in Microsoft's Windows Server Virtualization Validation Program (SVVP) to run Windows Server workloads.

The SVVP certification applies to:

* Red Hat Enterprise Linux CoreOS workers. In the Microsoft SVVP Catalog, they are named __Red{nbsp}Hat {product-title} 4.20__.
* Intel and AMD CPUs.

[id="virt-quick-starts_{context}"]
== Quick starts

Quick start tours are available for several {VirtProductName} features. To view the tours, click the *Help* icon *?* in the menu bar on the header of the {product-title} web console and then select *Quick Starts*. You can filter the available tours by entering the keyword `virtualization` in the *Filter* field.


[id="virt-4-20-new_{context}"]
== New and changed features

This release adds new features and enhancements related to the following components and concepts:

[id="virt-4-20-installation-update_{context}"]
=== Installation and update

//CNV-62403 direct z-stream updates
* You can now directly update {VirtProductName} to a later z-stream (x.y.z) release without applying each intermediate z-stream version.
+
[NOTE]
====
Ensure that you update to the latest z-stream release of your current minor (x.y) version before updating to the next minor version.
====

//CNV-43322 Release notes:TP to GA OCI
* Installing {VirtProductName} on {oci-first-no-rt} is now generally available. For more information, see link:https://access.redhat.com/articles/7118050[{VirtProductName} and Oracle Cloud Infrastructure known issues and limitations] in the Red{nbsp}Hat Knowledgebase, and link:https://github.com/oracle-quickstart/oci-openshift/blob/main/docs/openshift-virtualization.md[Installing {VirtProductName} on OCI] on GitHub.

// CNV-52795 CNV on bare-metal GCP (TP to GA)
* Installing {VirtProductName} on a Google Cloud bare-metal cluster is now generally available. For more information, see xref:compatible-platforms_preparing-cluster-for-virt[{VirtProductName} compatible platforms] and link:https://access.redhat.com/articles/7120382[{VirtProductName} and Google Cloud known storage issues and limitations] in the Red{nbsp}Hat Knowledgebase.


//CNV-58010
* Using {VirtProductName} on a bare-metal cluster installed on an ARM64 (AARCH64) system is now generally available. For more information, see xref:../../virt/install/preparing-cluster-for-virt.adoc#arm-compatibility_preparing-cluster-for-virt[ARM64 compatibility].

//[id="virt-4-20-infrastructure_{context}"]
//=== Infrastructure

[id="virt-4-20-virtualization_{context}"]
=== Virtualization

// CNV-62399
* The descheduler profile `DevKubeVirtRelieveAndMigrate` has been renamed to `KubeVirtRelieveAndMigrate` and is now generally available. The updated profile improves VM eviction stability during live migrations by enabling background evictions and reducing oscillatory behavior. For more information, see xref:../../virt/managing_vms/advanced_vm_management/virt-enabling-descheduler-evictions.adoc#virt-configuring-descheduler-evictions_virt-enabling-descheduler-evictions[Configuring descheduler evictions for virtual machines].

// CNV-30390
* vNUMA topology for VMs is now generally available (GA). By enabling this feature, you opt in to an improved NUMA configuration for VMs, with better performance and optimal resource allocation. For more information, see xref:../../virt/managing_vms/advanced_vm_management/virt-NUMA-topology.adoc#virt-NUMA-topology[Working with NUMA topology for virtual machines].

//CNV-61642
* You can now use the `kube_application_aware_resourcequota` and `kube_application_aware_resourcequota_creation_timestamp` metrics to query the current usage and creation times of the Application-Aware Quota (AAQ) Operator resources. For more information, see xref:../../virt/monitoring/virt-prometheus-queries.adoc#virt-promql-AAQ-metrics_context[AAQ Operator metrics].

[id="virt-4-20-networking_{context}"]
=== Networking

//CNV-62387
* You can now hot plug and hot unplug a secondary network interface to a VM without manually triggering live migration. You do not need permission to create and list `VirtualMachineInstanceMigration` objects. For more information, see xref:../../virt/vm_networking/virt-hot-plugging-network-interfaces.adoc#virt-hot-plugging-bridge-network-interface_virt-hot-plugging-network-interfaces[Hot plugging secondary network interfaces].

//CNV-52857 and CNV-56324
* xref:../../virt/vm_networking/virt-setting-interface-link-state.adoc#virt-setting-interface-link-state[Managing the link state of a virtual machine interface] is now generally available. In previous releases this was a Technology Preview feature.

//CNV-59402
* You can now use the Border Gateway Protocol (BGP) to configure dynamic ingress and egress routing for VMs that are connected to primary user-defined networks. Importing routes from provider networks into OVN-Kubernetes eliminates the need to manually configure routes on hosts. With dynamic egress, you can export VM IP addresses to provider networks, making the VMs directly reachable from outside the cluster. For more information, see xref:../../networking/advanced_networking/route_advertisements/about-route-advertisements.adoc#nw-routeadvertisements-about_about-route-advertisements[Advertise cluster network routes with Border Gateway Protocol].

//[id="virt-4-20-storage_{context}"]
//=== Storage

[id="virt-4-20-web_{context}"]
=== Web console
//CNV-62026
* In the {product-title} web console, the *Migrations* tab of the *Virtualization* page now displays a progress bar for each migrating virtual machine.

//CNV-63497
* When performing live migration of a VM, you can now xref:../../virt/live_migration/virt-initiating-live-migration.adoc#virt-initiating-vm-migration-web_virt-initiating-live-migration[specify the particular node for the VM to migrate to.]
//CNV-61645
* The procedure for hot plugging disks now includes an optional step for selecting a bus type. You can select the `virtio-blk` or the `virtio-scsi` bus type. The `virtio-blk` type is the default. For more information, see xref:../../virt/managing_vms/virtual_disks/virt-hot-plugging-virtual-disks.adoc#virt-hot-plugging-virtual-disks[Hot plugging VM disks].
* The *InstanceTypes* tab on the *Create new VirtualMachine* page now includes options for selecting huge pages. These options appear in the *M* and *CX* series of instance types. They are accessible both through the *Select InstanceType* tiles and in the *Default InstanceType* menu of the *Add volume* dialog box.
+
For more information about selecting huge pages for an instance type, see xref:../../virt/creating_vm/virt-creating-vms-from-instance-types.adoc#virt-creating-vm-instancetype_virt-creating-vms-from-instance-types["Creating a VM from an instance type by using the web console"].

// CNV-63575
* You can now easily identify if NUMA is enabled on your virtual machines. With this update, the `vNUMA` attribute is displayed in the VM details next to the *CPU | Memory* section.

// CNV-62056
* The {product-title} web console now displays read and write latency metrics in the *Top Consumers* tab of the *Virtualization > Overview* pane and in the *Metrics* tab of individual virtual machines. This data can help you evaluate your storage performance in more detail, identify processing slowdowns, and optimize workloads.

[id="virt-4-20-monitoring_{context}"]
=== Monitoring
//CNV-63662
* Added documentation for the `kubevirt_vmi_vcpu_delay_seconds_total` Prometheus metric. This metric reports the time a virtual CPU (vCPU) was queued by the host scheduler but was not running. The updated documentation helps users better understand vCPU queue delays in OpenShift Virtualization environments.

//CNV-59719
* The following xref:../../virt/monitoring/virt-runbooks.adoc#virt-runbooks[alerts for the {CNVOperatorDisplayName}] are now included in the {VirtProductName} runbooks:
+
--
** `HighNodeCPUFrequency`
** `VirtualMachineStuckInUnhealthyState`
** `VirtualMachineStuckOnNode`
** `PersistentVolumeFillingUp`
** `DeprecatedMachineType`
** `HCOGoldenImageWithNoSupportedArchitecture`
** `HCOGoldenImageWithNoArchitectureAnnotation`
** `HCOMultiArchGoldenImagesDisabled`
--
+
For a complete list of virtualization metrics, see the link:https://github.com/openshift/runbooks/tree/master/alerts/openshift-virtualization-operator[openshift/runbooks] Git repository.

//CNV-67575
* Using the xref:../../virt/monitoring/virt-monitoring-vm-health.adoc#virt-define-guest-agent-ping-probe_virt-monitoring-vm-health[guest agent ping probe] to determine if the QEMU guest agent is running on the VM is now generally available. Previously, this feature was provided as a Technology Preview.

//CNV-61311
* Using link:https://learn.microsoft.com/en-us/azure/azure-boost/overview[Microsoft Azure Boost] with {VirtProductName} on Azure Red Hat OpenShift (ARO) is now generally available.


//[id="virt-4-20-documentation_{context}"]
//=== Documentation improvements

[id="virt-4-20-notable-technical-changes_{context}"]
=== Notable technical changes
//CNV-61645
* Before this update, only the `virtio-scsi` bus type could be used for hot plugging disks. With this update, the `virtio-blk` bus type is supported as well.

[id="virt-4-20-deprecated-removed_{context}"]
== Deprecated and removed features

[id="virt-4-20-deprecated_{context}"]
=== Deprecated features
// NOTE: When uncommenting deprecated features list, change the Removed features header level below to ===

Deprecated features are included in the current release and supported. However, they will be removed in a future release and are not recommended for new deployments.

* The `virtctl ssh type/name[.namespace]` target syntax is deprecated. Use the `virtctl ssh` `type/name[/namespace]` syntax instead. Scripts and automation that rely on the deprecated syntax might fail after upgrading. (link:https://issues.redhat.com/browse/CNV-71711[*CNV-71711*])

* The `OperatorConditionsUnhealthy` alert is deprecated. You can safely link:https://docs.redhat.com/en/documentation/monitoring_stack_for_red_hat_openshift/4.20/html/managing_alerts/managing-alerts-as-an-administrator#silencing-alerts_managing-alerts-as-an-administrator[silence] it.

* All hot plugged disks are persistent by default. The use of non-persistent hot plugged disks is deprecated. They will not be supported in future releases.

// CNV-60596
* The RHEL 8 `kubevirt-virtctl` RPM is deprecated. In 4.20, the RPM remains available but prints a deprecation message. Download the `virtctl` binary from the {product-title} web console instead of using the command line. The RPM will be removed in 4.21


[id="virt-4-20-removed_{context}"]
=== Removed features

Removed features are no longer supported in {VirtProductName}.

//CNV-62385
* With this release, support for the Data Plane Development Kit (DPDK) checkup has been removed. You can no longer run a predefined checkup to verify if your {product-title} cluster node can run a VM with a DPDK workload with zero packet loss.

[id="virt-4-20-technology-preview_{context}"]
== Technology Preview features

Some features in this release are currently in Technology Preview. These experimental features are not intended for production use. Note the following scope of support on the Red Hat Customer Portal for these features:

link:https://access.redhat.com/support/offerings/techpreview[Technology Preview Features Support Scope]

//CNV-58005
* You can use {VirtProductName} on link:https://learn.microsoft.com/en-us/azure/azure-boost/overview[Microsoft Azure Boost].

//CNV-62357
* Golden image support for heterogeneous clusters is now available.

//CNV-52861
* You can now use the Plug a Simple Socket Transport (passt) network binding plugin to connect a VM to a primary user-defined network (UDN). For more information, see xref:../../virt/vm_networking/virt-connecting-vm-to-primary-udn.adoc#attaching-vm-to-primary-udn_virt-connecting-vm-to-primary-udn[Attaching a virtual machine to the primary user-defined network].

//CNV-71951
* You can now configure {ibm-name} Secure Execution virtual machines on {ibm-z-name} and {ibm-linuxone-name}. For more information, see xref:../../virt/creating_vm/virt-configuring-ibm-secure-execution-vms-ibm-z.adoc#virt-configuring-ibm-secure-execution-vms-ibm-z[Configuring {ibm-name} Secure Execution virtual machines on {ibm-z-name} and {ibm-linuxone-name}]

// CNV-57725
* As a Technology Preview, {VirtProductName} now provides the inject and eject functionality for virtual CD-ROMs. By using this functionality, you can insert and remove ISO images as CD-ROM volumes in running virtual machines.
+
// ADD XREF TO SECTION WHEN IT IS AVAILABLE: For details, see xref:virt-inserting-cd-roms-in-virtual-machines.html[Inserting CD-ROMs in live virtual machines].

[id="virt-4-20-bug-fixes_{context}"]
== Bug fixes

// CNV-61279
* Restoring a snapshot of a VM after a storage migration no longer fails because of unreferenced `dataVolumeTemplate` objects. The snapshot process now refreshes the data volume templates in the controller revision to match the `volumes` list, ensuring consistent data recovery. (link:https://issues.redhat.com/browse/CNV-61279[*CNV-61279*])

// CNV-48348
* The migration controller in the `virt-handler` pod was redesigned to separate source, target, and VM responsibilities, ensure deterministic completion, and use a unified `VirtualMachineInstance` (VMI) cache. (link:https://issues.redhat.com/browse/CNV-48348[*CNV-48348*])

// CNV-61740
* On s390x systems, VMs created from a template with the *Boot from CD* option now boot correctly. CD-ROM devices are attached as SCSI instead of SATA, which is not supported on s390x architecture. (link:https://issues.redhat.com/browse/CNV-61740[*CNV-61740*])

[id="virt-4-20-known-issues_{context}"]
== Known issues

//[id="virt-4-20-ki-monitoring_{context}"]
//=== Monitoring

[id="virt-4-20-ki-installation-update_{context}"]
=== Installation and update

//CNV-70798
* When upgrading from {VirtProductName} 4.19 to 4.20, you must remove the `wasp-agent` component before initating the upgrade. For more information about removing the `wasp-agent` component, see xref:../../virt/post_installation_configuration/virt-configuring-higher-vm-workload-density.adoc#virt-removing-wasp-agent_virt-configuring-higher-vm-workload-density[Removing the wasp-agent component].

[id="virt-4-20-ki-networking_{context}"]
=== Networking

//CNV-38746: According to Petr, this will remain relevant as long as 4.12 is available. Anyone upgrading from 4.12 could be affected. Version 4.12 is supported until January 2026
* When you update from {product-title} 4.12 to a newer minor version, VMs that use the `cnv-bridge` Container Network Interface (CNI) fail to live migrate. (link:https://access.redhat.com/solutions/7069807[])
** As a workaround, change the `spec.config.type` field in your `NetworkAttachmentDefinition` manifest from `cnv-bridge` to `bridge` before performing the update.

//CNV-69039
* {SMProductName} 3.1.1 and Istio versions 1.25 and later are incompatible with {VirtProductName} {VirtVersion} because the annotation `traffic.sidecar.istio.io/kubevirtInterfaces` is deprecated. (link:https://issues.redhat.com/browse/OSSM-10883[*OSSM-10883*])
** As a workaround, when installing {SMProductShortName} for integration with {VirtProductName}, select version 3.0.4 and Istio 1.24.4 instead of the default versions that are displayed in the web console.


[id="virt-4-20-ki-nodes_{context}"]
=== Nodes

//CNV-38543: According to Stu, this remains an issue in 4.20
* Uninstalling {VirtProductName} does not remove the `feature.node.kubevirt.io` node labels created by {VirtProductName}. You must remove the labels manually. (link:https://issues.redhat.com/browse/CNV-38543[*CNV-38543*])

[id="virt-4-20-ki-storage_{context}"]
=== Storage

//CNV-70866
* Attempting a storage live migration from the {product-title} web console might hang and fail to create a destination `PersistentVolumeClaim` (PVC). This issue occurs because the web console does not detect a label that marks source PVCs previously used for migration. When this label is present, the migration cannot proceed successfully. (link:https://issues.redhat.com/browse/CNV-70866[*CNV-70866*])
** As a workaround, use the {mtc-first} web console or create the `MigPlan` resource manually by using the CLI to perform the migration.

[id="virt-4-20-ki-virtualization_{context}"]
=== Virtualization

//CNV-61066
* Live migration fails if the VM name exceeds 47 characters. (link:https://issues.redhat.com/browse/CNV-61066[*CNV-61066*])

// CNV-70330
* Live migration might fail if you are migrating a VM which has vNUMA enabled, and the `topologyManagerPolicy` setting in the KubeletConfig is configured with `none`. This is due to conflicting NUMA cells in the Topology Manager policy. (link:https://issues.redhat.com/browse/CNV-70330[*CNV-70330*])
** As a workaround, configure the `topologyManagerPolicy` setting in the KubeletConfig to use either the `best-effort` or `single-numa-node` policies.

//CNV-33835: Per German, this was targeted for 4.20 but moved to 4.21 (see also CNV-27131)
* {VirtProductName} links a service account token in use by a pod to that specific pod. {VirtProductName} implements a service account volume by creating a disk image that contains a token. If you migrate a VM, then the service account volume becomes invalid. (link:https://issues.redhat.com/browse/CNV-33835[*CNV-33835*])
** As a workaround, use user accounts rather than service accounts because user account tokens are not bound to a specific pod.

//[id="virt-4-20-ki-webconsole_{context}"]
//=== Web console

[id="virt-4-20-ki-ibm-z_{context}"]
=== {ibm-z-title} and {ibm-linuxone-title}

// CNV-56889: Matan indicated this will remain in 4.20 but is targeted for 4.21
* VMs based on s390x architecture can only use the *IPL* boot mode. However, in the {product-title} web console, the *Boot mode* list for s390x VMs incorrectly includes *BIOS*, *UEFI*, and *UEFI (secure)* boot modes. If you select one of these modes for an s390x-based VM, the operation fails. (link:https://issues.redhat.com/browse/CNV-56889[CNV-56889])
