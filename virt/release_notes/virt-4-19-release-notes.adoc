:_mod-docs-content-type: ASSEMBLY
[id="virt-4-19-release-notes"]
= {VirtProductName} release notes
include::_attributes/common-attributes.adoc[]
:context: virt-4-19-release-notes

toc::[]

[id="virt-doc-feedback_{context}"]
== Providing documentation feedback

To report an error or to improve our documentation, log in to your link:https://issues.redhat.com[Red Hat Jira account] and submit a link:https://issues.redhat.com/secure/CreateIssueDetails!init.jspa?pid=12323181&issuetype=1&components=12333768&priority=10200&summary=%5BDoc%5D&customfield_12316142[Jira issue].

[id="virt-about-virt_{context}"]
== About Red Hat {VirtProductName}

With Red Hat {VirtProductName}, you can bring traditional virtual machines (VMs) into {product-title} and run them alongside containers. In {VirtProductName}, VMs are native Kubernetes objects that you can manage by using the {product-title} web console or the command line.

{VirtProductName} is represented by the image:virt-icon.png[{VirtProductName},40,40] icon.

You can use {VirtProductName} the xref:../../networking/ovn_kubernetes_network_provider/about-ovn-kubernetes.adoc#about-ovn-kubernetes[OVN-Kubernetes] Container Network Interface (CNI) network provider.

Learn more about xref:../../virt/about_virt/about-virt.adoc#about-virt[what you can do with {VirtProductName}].

Learn more about xref:../../virt/about_virt/virt-architecture.adoc#virt-architecture[{VirtProductName} architecture and deployments].

xref:../../virt/install/preparing-cluster-for-virt.adoc#preparing-cluster-for-virt[Prepare your cluster] for {VirtProductName}.

include::modules/virt-supported-cluster-version.adoc[leveloffset=+2]


[id="virt-guest-os_{context}"]
=== Supported guest operating systems
To view the supported guest operating systems for {VirtProductName}, see link:https://access.redhat.com/articles/973163#ocpvirt[Certified Guest Operating Systems in Red Hat OpenStack Platform, Red Hat Virtualization, OpenShift Virtualization and Red Hat Enterprise Linux with KVM].

//Ensure platform passes Windows Server Virtualization Validation Program. Otherwise, comment out the section below.
[id="virt-svvp-certification_{context}"]
=== Microsoft Windows SVVP certification

//CNV-47134 SVVP 4.18 Release Note: New
//NOTE: This is a recurring release note. Modify the existing note text below if recommended by QE.
{VirtProductName} is certified in Microsoft's Windows Server Virtualization Validation Program (SVVP) to run Windows Server workloads.

The SVVP certification applies to:

* Red Hat Enterprise Linux CoreOS workers. In the Microsoft SVVP Catalog, they are named __Red Hat OpenShift Container Platform 4 on RHEL CoreOS 9__.
* Intel and AMD CPUs.

[id="virt-quick-starts_{context}"]
== Quick starts

Quick start tours are available for several {VirtProductName} features. To view the tours, click the *Help* icon *?* in the menu bar on the header of the {product-title} web console and then select *Quick Starts*. You can filter the available tours by entering the keyword `virtualization` in the *Filter* field.


[id="virt-4-19-new_{context}"]
== New and changed features

This release adds new features and enhancements related to the following components and concepts:

//[id="virt-4-19-installation-update_{context}"]
//=== Installation and update
//[id="virt-4-19-installation-update"]
//=== Installation and update

[id="virt-4-19-infrastructure_{context}"]
=== Infrastructure
//[id="virt-4-19-infrastructure"]
//=== Infrastructure

//CNV-49593
* You can now prevent the inadvertent deletion of a virtual machine (VM) by xref:../../virt/managing_vms/virt-enabling-disabling-vm-delete-protection.adoc#virt-enabling-disabling-vm-delete-protection[enabling delete protection for the VM]. You can also disable delete protection that has been set for a VM.
+
As a cluster administrator, you can prevent users from enabling VM delete protection xref:../../virt/managing_vms/virt-enabling-disabling-vm-delete-protection.adoc#virt-removing-vm-delete-protection_virt-enabling-disabling-vm-delete-protection[by removing the option at the cluster level].

[id="virt-4-19-virtualization_{context}"]
=== Virtualization

//CNV-54747
* You can now choose to expand virtual machines (VMs) using instance types and preferences. For more information, see link:https://access.redhat.com/solutions/7107803[Using InstancetypeReferencePolicy to expand VirtualMachines] in the Red Hat Customer Portal.
//CNV-58007
* {op-system-base-full} 10 is added as a certified guest operating system. For a complete list of supported guest operating systems, see link:https://access.redhat.com/articles/4234591[Certified Guest Operating Systems in OpenShift Virtualization].

//CNV-54610: Release note: Mass machine type change procedure
* You can now xref:../../virt/managing_vms/virt-edit-vms.adoc#virt-updating-multiple-vms_virt-edit-vms[update the machine type of multiple virtual machines (VMs) at the same time] from the {oc-first}.

[id="virt-4-19-networking_{context}"]
=== Networking

//CNV-30151 NNCP to enable LLDP
* You can now xref:../../networking/k8s_nmstate/k8s-nmstate-updating-node-network-config.adoc#virt-example-enabling-lldp-policy_k8s-nmstate-updating-node-network-config[configure a `NodeNetworkConfigurationPolicy` manifest] to enable the Link Layer Discovery Protocol (LLDP) listener for all ethernet ports in your {product-title} cluster.
//CNV-55191 Host network configuration visualization
* You can now create a new Node Network Configuration Policy (NNCP) in the topology view of the cluster and see its graphical representation in real time. Clicking *Create* on the *Node network configuration* page opens a form for configuring the elements of the new NNCP, and the NNCP is also displayed as a diagram.

//CNV-52856 UDN localnet
* You can now use the OVN-Kubernetes localnet network topology to connect a VM to a xref:../../virt/vm_networking/virt-connecting-vm-to-secondary-udn.adoc#virt-connecting-vm-to-secondary-udn[secondary user-defined network].


[id="virt-4-19-storage_{context}"]
=== Storage

//CNV-55497 Doc: PVC source support for DataImportCron
* You can now use a PVC as the source of a custom `DataImportCron` in the `dataImportCronTemplates` section of the `HyperConverged` custom resource (CR). See xref:../../virt/storage/virt-automatic-bootsource-updates.adoc#virt-automatic-bootsource-updates[Managing automatic boot source updates] for more information.

//CNV-58547 UI - Bulk Storage Class Migration within a single cluster
* By using the {product-title} web console, you can now xref:../../virt/managing_vms/virt-migrating-vms-in-single-cluster-to-different-storage-class.adoc#virt-migrating-bulk-vms-different-storage-class-web_virt-migrating-vms-in-single-cluster-to-different-storage-class[migrate VMs in bulk from one storage class to another storage class].


[id="virt-4-19-web_{context}"]
=== Web console

// CNV-52871 - Doc: Multi IOthread with fast storage
* You can now xref:../../virt/managing_vms/virt-edit-vms.adoc#virt-configure-multiple-iothreads_virt-edit-vms[configure multiple IOThreads for virtual machines that use fast storage], such as SSD (solid-state drive) or NVMe (non-volatile memory express). This improves I/O performance by enabling multiple threads for disk access.

// CNV-56843:
* On the *VirtualMachines* page, you can now xref:../../virt/support/virt-support-overview.adoc#virt-web-console_virt-support-overview[see the summary of CPU, memory, and storage usage by your VMs]. To restrict this summary to the VMs in a specific project, select the project name in the tree view.

// CNV-55958:
* On the *VirtualMachines* page, you can now xref:../../virt/managing_vms/virt-list-vms.adoc#virt-listing-vms-web_virt-list-vms[navigate between your VMs by using the tree view].

//CNV-56275
* An attempt to xref:../../virt/managing_vms/virt-controlling-vm-states.adoc#virt-controlling-vm-states[stop, restart, or pause a VM or multiple VMs] now displays a confirmation dialog.

//CNV-55965
* You can now access xref:../../virt/managing_vms/virt-controlling-vm-states.adoc#virt-controlling-vm-states[the commands of the *Options* menu] {kebab} from the tree view by right-clicking the VM. If you right-click a project and select a command, the action is applied to all VMs in the project.
//CNV-59097
* You can now perform bulk actions on multiple virtual machines (VMs), including adding or removing labels, viewing the number of VMs selected for deletion, and moving VMs to a folder within the same namespace.

// CNV-56003:
* On the *VirtualMachines* page, you can now xref:../../virt/managing_vms/virt-list-vms.adoc#virt-organize-vms-web_virt-list-vms[use the tree view to organize VMs in folders] and drag and drop VMs to these folders.

// CNV-56266: Advanced search for VMs
* You can now xref:../../virt/managing_vms/virt-manage-vmis.adoc#virt-searching-vmis-web_virt-manage-vmis[search for virtual machines] by fields such as name, project, description, labels, date created, vCPU, and memory. You can also save frequently used search queries.


[id="virt-4-19-monitoring_{context}"]
=== Monitoring

//CNV-59720
* The following xref:../../virt/monitoring/virt-runbooks.adoc#virt-runbooks[alerts for the {CNVOperatorDisplayName}] are now included in the {product-title} runbooks:
** `HAControlPlaneDown`
** `HighCPUWorkload`
** `NodeNetworkInterfaceDown`

//CNV-50346
* New metrics are now available and improve the observability of virtual machines (VMs) and virtual machine instances (VMIs). You can use these metrics to monitor the following VM lifecycle events, resource usage, and migration details:
+
--
** Migration metrics
** vNIC networking information metrics
** Allocated storage size metrics for running and stopped VMs
--
+
In addition, the following VM and VMI metadata metrics are now available:
+
--
** The `pod_name` label in `kubevirt_vmi_info`
** UID in VM and VMI metrics
** The VM creation date
--
+
For a complete list of virtualization metrics, see link:https://github.com/kubevirt/monitoring/blob/main/docs/metrics.md[KubeVirt components metrics].

//[id="virt-4-19-documentation_{context}"]
//=== Documentation improvements


[id="virt-4-19-notable-technical-changes_{context}"]
=== Notable technical changes

// CNV-48243: RN - Support declarative VirtualMachine management with instance types
* VirtualMachines that use instance types and preferences no longer have their specification mutated at runtime to include derived metadata, such as `revisionName`. This metadata is now stored in the `status` field to preserve the declarative VM specification and ensure compatibility.

//CNV-57108
* In {VirtProductName} 4.19, the default permissions for live migration have changed to improve cluster security. Users must now be explicitly granted the `kubevirt.io:migrate` xref:../../virt/about_virt/virt-security-policies.adoc#default-cluster-roles-for-virt_virt-security-policies[cluster role] to create, delete, or update live migration requests. Previously, namespace administrators had these permissions by default. For more information, see xref:../../virt/live_migration/virt-about-live-migration.adoc#virt-about-live-migration-permissions_virt-about-live-migration[About live migration permissions].

[id="virt-4-19-deprecated-removed_{context}"]
== Deprecated and removed features
//NOTE: Comment out deprecated and removed features (and their IDs) if not used in a release

[id="virt-4-19-deprecated_{context}"]
=== Deprecated features
// NOTE: When uncommenting deprecated features list, change the Removed features header level below to ===

Deprecated features are included in the current release and supported. However, they will be removed in a future release and are not recommended for new deployments.

* The `OperatorConditionsUnhealthy` alert is deprecated. You can safely xref:../../observability/monitoring/managing-alerts/managing-alerts-as-an-administrator.adoc#silencing-alerts-adm_managing-alerts-as-an-administrator[silence] it.

//CNV-63003 Release note: Deprecate feature gates
* The following `HyperConverged` custom resource (CR) fields have been deprecated and copied from their original location under the `spec.featureGates` fields to a new location in the `spec` field, where they can be used if needed:

    ** `DeployVmConsoleProxy`
    ** `EnableApplicationAwareQuota`
    ** `EnableCommonBootImageImport`

+
If used in the `spec.featureGates` location, the old fields are ignored.

//[id="virt-4-19-removed_{context}"]
//=== Removed features

//Removed features are no longer supported in {VirtProductName}.

[id="virt-4-19-technology-preview_{context}"]
== Technology Preview features

Some features in this release are currently in Technology Preview. These experimental features are not intended for production use. Note the following scope of support on the Red Hat Customer Portal for these features:

link:https://access.redhat.com/support/offerings/techpreview[Technology Preview Features Support Scope]

//CNV-52857 and CNV-56324
* You can now xref:../../virt/vm_networking/virt-setting-interface-link-state.adoc#virt-setting-interface-link-state[manage the link state] of a primary or secondary virtual machine (VM) interface by using the {product-title} web console or the CLI.

//CNV-58005
* {VirtProductName} is now supported on link:https://learn.microsoft.com/en-us/azure/azure-boost/overview[Azure Boost].

// CNV-58423
* The `DevKubeVirtRelieveAndMigrate` descheduler profile is xref:../../virt/managing_vms/advanced_vm_management/virt-enabling-descheduler-evictions.adoc#nodes-descheduler-profiles_virt-enabling-descheduler-evictions[now available]. This profile enhances the `LongLifecycle` profile by supporting load-aware descheduling, dynamic soft taints, and improved workload rebalancing.

//CNV-62829
* You can now deploy {VirtProductName} on IPv6 single-stack clusters. Support for IPv6 single-stack is limited to the OVN-Kubernetes localnet and Linux bridge Container Network Interface (CNI) plugins.

//[id="virt-4-19-bug-fixes_{context}"]
//== Bug fixes


[id="virt-4-19-known-issues_{context}"]
== Known issues

//[discrete]
//[id="virt-4-19-ki-monitoring_{context}"]
//=== Monitoring

[discrete]
[id="virt-4-19-ki-networking_{context}"]
=== Networking
//CNV-38746
* When you update from {product-title} 4.12 to a newer minor version, VMs that use the `cnv-bridge` Container Network Interface (CNI) fail to live migrate. (link:https://access.redhat.com/solutions/7069807[])
** As a workaround, change the `spec.config.type` field in your `NetworkAttachmentDefinition` manifest from `cnv-bridge` to `bridge` before performing the update.



[discrete]
[id="virt-4-19-ki-nodes_{context}"]
==== Nodes
//CNV-38543 - 4.16 Still an issue
* Uninstalling {VirtProductName} does not remove the `feature.node.kubevirt.io` node labels created by {VirtProductName}. You must remove the labels manually. (link:https://issues.redhat.com/browse/CNV-38543[*CNV-38543*])

[discrete]
[id="virt-4-19-ki-storage_{context}"]
==== Storage

//CNV-61279: 4.19 - Storage Migrate VM with MTC
* Restoring a snapshot of a virtual machine (VM) migrated using Migration Toolkit for Containers (MTC) fails. The restore creates a persistent volume claim (PVC) but not a data volume (DV). The VM spec references a `DataVolumeTemplate` missing from the `volumes` list. (link:https://issues.redhat.com/browse/CNV-61279[*CNV-61279*])
** As a workaround, restart the VM after storage migration and before taking the snapshot. This creates a new controller revision that avoids the issue.

// CNV-55104: 4.18 - Unresolved
* If you perform storage class migration for a stopped VM, the VM might not be able to start because of a missing bootable device. To prevent this, do not attempt storage class migration if the VM is not running. (link:https://issues.redhat.com/browse/CNV-55104[*CNV-55104*])
+
--
:FeatureName: Storage class migration
include::snippets/technology-preview.adoc[]
--

[discrete]
[id="virt-4-19-ki-virtualization_{context}"]
=== Virtualization

//CNV-48348
* When the mode of live migration is *PostCopy*, hot-plugging CPU or memory resource fails. (link:https://issues.redhat.com/browse/CNV-48348[*CNV-48348*])

//CNV-33835: 4.16 - Unresolved
* {VirtProductName} links a service account token in use by a pod to that specific pod. {VirtProductName} implements a service account volume by creating a disk image that contains a token. If you migrate a VM, then the service account volume becomes invalid. (link:https://issues.redhat.com/browse/CNV-33835[*CNV-33835*])
** As a workaround, use user accounts rather than service accounts because user account tokens are not bound to a specific pod.

//CNV-36448
* When adding a virtual Trusted Platform Module (vTPM) device to a Windows VM, the BitLocker Drive Encryption system check passes even if the vTPM device is not persistent. This is because a vTPM device that is not persistent stores and recovers encryption keys using ephemeral storage for the lifetime of the virt-launcher pod. When the VM migrates or is shut down and restarts, the vTPM data is lost. (link:https://issues.redhat.com/browse/CNV-36448[CNV-36448])

//[discrete]
//[id="virt-4-19-ki-webconsole_{context}"]
//=== Web console

[discrete]
[id="virt-4-19-ki-ibm-z_{context}"]
=== {ibm-z-title} and {ibm-linuxone-title}

ifdef::openshift-enterprise[]
:FeatureName: Using {VirtProductName} in a cluster deployed on s390x architecture
include::snippets/technology-preview.adoc[]
:!FeatureName:
endif::[]

// cnv-61740 - s390x VM fails to boot with SATA CD-ROM
* If you create a VM from a template and select *Boot from CD*, the VM fails to boot and the error `unsupported configuration: SATA is not supported with this QEMU binary` is logged. This occurs because the CD-ROM is automatically mounted as a SATA device, which is not supported on s390x architecture. (link:https://issues.redhat.com/browse/CNV-61740[CNV-61740])
** As a workaround, navigate to the VM's *Configuration* ->  *Storage* tab, select the CD-ROM, and change the interface type from *SATA* to *SCSI*.

// cnv-61957 - GPU devices should not be shown in UI
* GPU devices appear in the *Hardware Devices* list for s390x VMs, but GPU support is not available for s390x architecture. You can disregard these list entries. (link:https://issues.redhat.com/browse/CNV-61957[CNV-61957])

// ocpbugs-51113 - ballooning call traces
* When you create a VM by using {op-system-base-full} container disk images for s390x architecture, call traces referencing `virtio_balloon` free page reporting print to the VM console. This is due to a kernel bug. (link:https://issues.redhat.com/browse/OCPBUGS-51113[OCPBUGS-51113])
** As a workaround, disable memory ballooning for the VM by adding the following parameter to the VM YAML configuration: `spec.domain.devices.autoattachMemBalloon: false`.
+
You can also disable free page reporting of memory ballooning for all new VMs. To do so, edit the `HyperConverged` CR and add the parameter `spec.virtualMachineOptions.disableFreePageReporting: true`.

// cnv-56889 - boot mode
* VMs based on s390x architecture can only use the *IPL* boot mode. However, in the {product-title} web console, the *Boot mode* list for s390x VMs incorrectly includes *BIOS*, *UEFI*, and *UEFI (secure)* boot modes. If you select one of these modes for an s390x-based VM, the operation fails. (link:https://issues.redhat.com/browse/CNV-56889[CNV-56889])

// cnv-56890 - threads
* In the {product-title} web console, it is erroneously possible to define multiple CPU threads for a VM based on s390x architecture. If you define multiple CPU threads, the VM enters a `CrashLoopBackOff` state with the `qemu-kvm: S390 does not support more than 1 threads` error. (link:https://issues.redhat.com/browse/CNV-56890[CNV-56890])


