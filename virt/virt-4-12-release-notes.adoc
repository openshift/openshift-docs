:_content-type: ASSEMBLY
[id="virt-4-12-release-notes"]
= {VirtProductName} release notes
include::_attributes/common-attributes.adoc[]
:context: virt-4-12-release-notes

toc::[]

== About Red Hat {VirtProductName}

Red Hat {VirtProductName} enables you to bring traditional virtual machines (VMs) into {product-title} where they run alongside containers, and are managed as native Kubernetes objects.

{VirtProductName} is represented by the image:virt-icon.svg[{VirtProductName},40,40] logo.

You can use {VirtProductName} with either the xref:../networking/ovn_kubernetes_network_provider/about-ovn-kubernetes.adoc#about-ovn-kubernetes[OVN-Kubernetes] or the xref:../networking/openshift_sdn/about-openshift-sdn.adoc#about-openshift-sdn[OpenShiftSDN] default Container Network Interface (CNI) network provider.

Learn more about xref:../virt/about-virt.adoc#about-virt[what you can do with {VirtProductName}].

Learn more about xref:../virt/virt-architecture.adoc#virt-how-virt-works_virt-architecture[{VirtProductName} architecture and deployments].

xref:../virt/install/preparing-cluster-for-virt.adoc#preparing-cluster-for-virt[Prepare your cluster] for {VirtProductName}.

include::modules/virt-supported-cluster-version.adoc[leveloffset=+2]

[id="virt-guest-os"]
=== Supported guest operating systems
//CNV-16390 Supported guest operating systems
To view the supported guest operating systems for {VirtProductName}, refer to link:https://access.redhat.com/articles/973163#ocpvirt[Certified Guest Operating Systems in Red Hat OpenStack Platform, Red Hat Virtualization and OpenShift Virtualization].

[id="virt-4-12-inclusive-language"]
== Making open source more inclusive

Red Hat is committed to replacing problematic language in our code, documentation, and web properties. We are beginning with these four terms: master, slave, blacklist, and whitelist. Because of the enormity of this endeavor, these changes will be implemented gradually over several upcoming releases. For more details, see link:https://www.redhat.com/en/blog/making-open-source-more-inclusive-eradicating-problematic-language[our CTO Chris Wright's message].

[id="virt-4-12-new"]
== New and changed features

//CNV-15207 SVVP for 4.11: Ensure platform passes Windows Server Virtualization Validation Program - with RHCOS workers
//NOTE: This is a recurring release note. Modify the existing note text below if recommended by QE.
* OpenShift Virtualization is certified in Microsoft's Windows Server Virtualization Validation Program (SVVP) to run Windows Server workloads.
+
The SVVP Certification applies to:
+
** Red Hat Enterprise Linux CoreOS workers. In the Microsoft SVVP Catalog, they are named __Red Hat OpenShift Container Platform 4 on RHEL CoreOS 8__.
** Intel and AMD CPUs.

//CNV-18488 SVVP for 4.12

//CNV-21611-2
* {VirtProductName} no longer uses the image:Operator_Icon-OpenShift_Virtualization-5.png[{VirtProductName},40,40] logo. {VirtProductName} is now represented by the image:virt-icon.svg[{VirtProductName},40,40] logo for versions 4.9 and later.

//CNV-15830 Memory dump.
* You can create a VM memory dump for forensic analysis by using the xref:../virt/virt-using-the-cli-tools.adoc#vm-memory-dump-commands_virt-using-the-cli-tools[`virtctl memory-dump` command].

//CNV-20148 VM export
* You can xref:../virt/virtual_machines/virt-exporting-vms.adoc#virt-exporting-vms[export and download a volume] from a virtual machine (VM), a VM snapshot, or a persistent volume claim (PVC) to recreate it on a different cluster or in a different namespace on the same cluster by using the `virtctl vmexport` command or by creating a `VirtualMachineExport` custom resource. You can also export the memory-dump for forensic analysis.

//CNV-17984 Comply with cluster-wide crypto policy


//CNV-17986 New alerts added


//CNV-19780 CNV Maturity and dataVolumeTemplates


//CNV-17909 On-Prems Cluster Multi-Tenancy with OpenShift Virtualization and Hypershift


//CNV-20149 Accurate VM status incl. error cases


//CNV-20476 Advanced life-cycle actions for VMs (Pause/Unpause, Suspend/Resume, Forced restart)


//CNV-18772 Virtualization Overview page redesign

//CNV-20483 Additional metrics for the overview dashboard


//CNV-20526  Integration with OpenShift Tekton Pipelines


//CNV-18462 Retire storage alpha apis


//CNV-20181 Comply with cluster-wide crypto policy


//CNV-16553 Virtual Machine Data Protection


//CNV-16414
* {VirtProductName} has runbooks to help you troubleshoot issues that trigger alerts. The alerts are displayed on the *Virtualization* -> *Overview* page of the web console. Each runbook defines an alert and provides steps to diagnose and resolve the issue. This feature was previously introduced as a Technology Preview and is now generally available.


[id="virt-4-12-quick-starts"]
=== Quick starts

* Quick start tours are available for several {VirtProductName} features. To view the tours, click the *Help* icon *?* in the menu bar on the header of the {VirtProductName} console and then select *Quick Starts*. You can filter the available tours by entering the `virtualization` keyword in the *Filter* field.

[id="virt-4-12-installation-new"]
=== Installation


//[id="virt-4-12-networking-new"]
//=== Networking



[id="virt-4-12-storage-new"]
=== Storage


[id="virt-4-12-web-new"]
=== Web console
//CNV-20482 Overview page usability enhancements
* The *Virtualization -> Overview* page has the following usability enhancements:

** A *Download virtctl* link is displayed on the upper right corner of the page.
** Resource information is customized for adminstrative and non-administrative users. For example, non-administrative users see only their VMs.
** The *Overview* tab displays the number of VMs and vCPU, memory, and storage usage with charts that show the last 7 days' trend.
** The *Alerts* card on the *Overview* tab displays the alerts grouped by severity.
** The *Top Consumers* tab displays the top consumers of CPU, memory, and storage usage over a configurable time period.
** The *Migrations* tab displays the progress of VM migrations.
** The *Settings* tab displays cluster-wide settings, including live migration limits, live migration network, and templates project.

//CNV-18453 Live migration with shared storage for work intensive workloads
* You can create and manage live migration policies in a single location on the *Virtualization -> MigrationPolicies* page.

//CNV-18769 Add metrics tab to single VM view
* The *Metrics* tab on the *VirtualMachine details* page displays memory, CPU, storage, network, and migration metrics of a VM, over a configurable period of time.

//CNV-20482 Overview page usability enhancements
* The *Virtualization -> Overview* page has the following usability enhancements:

** A *Download virtctl* link is displayed on the upper right corner of the page.
** Resource information is customized for adminstrative and non-administrative users. For example, non-administrative users see only their VMs.
** The *Overview* tab displays the number of VMs and vCPU, memory, and storage usage with charts that show the last 7 days' trend.
** The *Alerts* card on the *Overview* tab displays the alerts grouped by severity.
** The *Top Consumers* tab displays the top consumers of CPU, memory, and storage usage over a configurable time period.
** The *Migrations* tab displays the progress of VM migrations.
** The *Settings* tab displays cluster-wide settings, including live migration limits, live migration network, and templates project.

//CNV-20936 UI - live YAML view
* When you customize a template to create a VM, you can set the *YAML* switch to *ON* on each VM configuration tab to view the live changes in the YAML configuration file alongside the form.

//CNV-18459 UI - CNV settings page


//CNV-18432 UI create live migration page
* The *Migrations* tab on the *Virtualization -> Overview* page displays the progress of virtual machine instance migrations over a configurable time period.

//CNV-17809 Live migration with shared storage for work intensive workloads
* You can now define a dedicated network for live migration to minimize disruption to tenant workloads. To select a network, navigate to *Virtualization* -> *Overview* -> *Settings* -> *Live migration*.

// NOTE: Comment out deprecated and removed features (and their IDs) if not used in a release
[id="virt-4-12-deprecated-removed"]
== Deprecated and removed features

[id="virt-4-12-deprecated"]
=== Deprecated features
// NOTE: when uncommenting deprecated features list, change the header level below to ===

Deprecated features are included in the current release and supported. However, they will be removed in a future release and are not recommended for new deployments.

* In a future release, support for the legacy HPP custom resource, and the associated storage class, will be deprecated. Beginning in {VirtProductName} {VirtVersion}, the HPP Operator uses the Kubernetes Container Storage Interface (CSI) driver to configure local storage. The Operator continues to support the existing (legacy) format of the HPP custom resource and the associated storage class. If you use the HPP Operator, plan to xref:../virt/virtual_machines/virtual_disks/virt-configuring-local-storage-for-vms.adoc#virt-configuring-local-storage-for-vms[create a storage class for the CSI driver] as part of your migration strategy.


[id="virt-4-12-removed"]
=== Removed features


[id="virt-4-12-changes"]
== Notable technical changes


[id="virt-4-12-technology-preview"]
== Technology Preview features

Some features in this release are currently in Technology Preview. These experimental features are not intended for production use. Note the following scope of support on the Red Hat Customer Portal for these features:

link:https://access.redhat.com/support/offerings/techpreview[Technology Preview Features Support Scope]

//CNV-20963
* You can now use Microsoft Windows 11 as a guest operating system. However, {VirtProductName} {VirtVersion} does not support USB disks, which are required for a critical function of BitLocker recovery. To protect recovery keys, use other methods described in the link:https://learn.microsoft.com/en-us/windows/security/information-protection/bitlocker/bitlocker-recovery-guide-plan[BitLocker recovery guide].

* You can now link:https://access.redhat.com/articles/6409731[deploy {VirtProductName} on AWS bare metal nodes].

* Administrators can now declaratively xref:../virt/virtual_machines/advanced_vm_management/virt-configuring-mediated-devices.adoc#virt-configuring-mediated-devices[create and expose mediated devices] such as virtual graphics processing units (vGPUs) by editing the `HyperConverged` CR. Virtual machine owners can then assign these devices to VMs.

//CNV-13660 Inherit static IP from a NIC attached to the bridge
* You can xref:../networking/k8s_nmstate/k8s-nmstate-updating-node-network-config.adoc#capturing-nic-static-ip_k8s-nmstate-updating-node-network-config[transfer the static IP configuration of the NIC attached to the bridge] by applying a single `NodeNetworkConfigurationPolicy` manifest to the cluster.

//CNV-16639
* You can now install {VirtProductName} on IBM Cloud bare-metal servers. Bare-metal servers offered by other cloud providers are not supported.

//CNV-19603
* You can check your {VirtProductName} cluster for compliance issues by installing the xref:../security/compliance_operator/compliance-operator-understanding.adoc#understanding-compliance[Compliance Operator] and running a scan with the xref:../security/compliance_operator/compliance-operator-supported-profiles.adoc#compliance-operator-supported-profiles[`ocp4-moderate` and `ocp4-moderate-node` profiles].

//CNV-17453 Network latency check
* {VirtProductName} now includes a xref:../virt/logging_events_monitoring/virt-running-cluster-checkups.adoc#virt-running-cluster-checkups[diagnostic framework] to run predefined checkups that can be used for cluster maintenance and troubleshooting. You can run a predefined checkup to xref:../virt/logging_events_monitoring/virt-running-cluster-checkups.adoc#virt-measuring-latency-vm-secondary-network_virt-running-cluster-checkups[check network connectivity and latency] for virtual machines on a secondary network.

//CNV-19145 Support live migration policies
* You can create live migration policies with specific parameters, such as bandwidth usage, maximum number of parallel migrations, and timeout, and apply the policies to groups of virtual machines by using virtual machine and namespace labels.

[id="virt-4-12-bug-fixes"]
== Bug fixes

[id="virt-4-12-known-issues"]
== Known issues

* VMs created from common templates on a Single Node OpenShift (SNO) cluster display a `VMCannotBeEvicted` alert because the template's default eviction strategy is `LiveMigrate`. You can ignore this alert or remove the alert by updating the VM's eviction strategy. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2092412[*BZ#2092412*])

//New known issues for 4.12 go above this comment
* Uninstalling {VirtProductName} does not remove the `feature.node.kubevirt.io` node labels created by {VirtProductName}. You must remove the labels manually. (link:https://issues.redhat.com/browse/CNV-22036[*CNV-22036*])

* Some persistent volume claim (PVC) annotations created by the Containerized Data Importer (CDI) can cause the virtual machine snapshot restore operation to hang indefinitely. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2070366[*BZ#2070366*])
** As a workaround, you can remove the annotations manually:
. Obtain the xref:../virt/virtual_machines/virtual_disks/virt-managing-vm-snapshots.adoc#virtual-machine-snapshot-controller-and-custom-resource-definitions-crds[VirtualMachineSnapshotContent] custom resource (CR) name from the `status.virtualMachineSnapshotContentName` value in the `VirtualMachineSnapshot` CR.
. Edit the `VirtualMachineSnapshotContent` CR and remove all lines that contain `k8s.io/cloneRequest`.
. If you did not specify a value for `spec.dataVolumeTemplates` in the `VirtualMachine` object, delete any `DataVolume` and `PersistentVolumeClaim` objects in this namespace where both of the following conditions are true:
+
.. The object's name begins with `restore-`.
.. The object is not referenced by virtual machines.
+
This step is optional if you specified a value for `spec.dataVolumeTemplates`.
. Repeat the xref:../virt/virtual_machines/virtual_disks/virt-managing-vm-snapshots.adoc#virt-restoring-vm-from-snapshot-cli_virt-managing-vm-snapshots[restore operation] with the updated `VirtualMachineSnapshot` CR.

* Windows 11 virtual machines do not boot on clusters running in link:https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/security_hardening/index#con_federal-information-processing-standard-fips_assembly_installing-the-system-in-fips-mode[FIPS mode]. Windows 11 requires a TPM (trusted platform module) device by default. However, the `swtpm` (software TPM emulator) package is incompatible with FIPS. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2089301[*BZ#2089301*])

* The QEMU guest agent on a Fedora 35 virtual machine is blocked by SELinux and does not report data. Other Fedora versions might be affected. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2028762[*BZ#2028762*])
** As a workaround, disable SELinux on the virtual machine, run the QEMU guest agent commands, and then re-enable SELinux.

//BZ-1984442 - keep in RN until it has a permanent place in docs
* If a single node contains more than 50 images, pod scheduling might be imbalanced across nodes. This is because the list of images on a node is shortened to 50 by default. (link:https://bugzilla.redhat.com/show_bug.cgi?id=1984442[*BZ#1984442*])
** As a workaround, you can disable the image limit by xref:../nodes/nodes/nodes-nodes-managing.adoc#nodes-nodes-managing[editing the `KubeletConfig` object] and setting the value of `nodeStatusMaxImages` to `-1`.

//BZ-1885605
* If your {product-title} cluster uses OVN-Kubernetes as the default Container Network Interface (CNI) provider, you cannot attach a Linux bridge or bonding device to a host's default interface because of a change in the host network topology of OVN-Kubernetes. (link:https://bugzilla.redhat.com/show_bug.cgi?id=1885605[*BZ#1885605*])
** As a workaround, you can use a secondary network interface connected to your host, or switch to the OpenShift SDN default CNI provider.

* If you use Red Hat Ceph Storage or Red Hat OpenShift Data Foundation Storage, cloning more than 100 VMs at once might fail. (link:https://bugzilla.redhat.com/show_bug.cgi?id=1989527[*BZ#1989527*])
** As a workaround, you can perform a host-assisted copy by setting `spec.cloneStrategy: copy` in the storage profile manifest. For example:
+
[source,yaml]
----
apiVersion: cdi.kubevirt.io/v1beta1
kind: StorageProfile
metadata:
  name: <provisioner_class>
#   ...
spec:
  claimPropertySets:
  - accessModes:
    - ReadWriteOnce
    volumeMode: Filesystem
  cloneStrategy: copy <1>
status:
  provisioner: <provisioner>
  storageClass: <provisioner_class>
----
<1> The default cloning method set to `copy`.

* In some instances, multiple virtual machines can mount the same PVC in read-write mode, which might result in data corruption. (link:https://bugzilla.redhat.com/show_bug.cgi?id=1992753[*BZ#1992753*])
** As a workaround, avoid using a single PVC in read-write mode with multiple VMs.

* The Pod Disruption Budget (PDB) prevents pod disruptions for migratable virtual machine images. If the PDB detects pod disruption, then `openshift-monitoring` sends a `PodDisruptionBudgetAtLimit` alert every 60 minutes for virtual machine images that use the `LiveMigrate` eviction strategy. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2026733[*BZ#2026733*])
** As a workaround, xref:../monitoring/managing-alerts.adoc#silencing-alerts_managing-alerts[silence alerts].

* {VirtProductName} links a service account token in use by a pod to that specific pod. {VirtProductName} implements a service account volume by creating a disk image that contains a token. If you migrate a VM, then the service account volume becomes invalid. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2037611[*BZ#2037611*])
** As a workaround, use user accounts rather than service accounts because user account tokens are not bound to a specific pod.

* If you configure the `HyperConverged` custom resource (CR) to enable mediated devices before drivers are installed, the new device configuration does not take effect. This issue can be triggered by updates. For example, if `virt-handler` is updated before `daemonset`, which installs NVIDIA drivers, then nodes cannot provide virtual machine GPUs. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2046298[*BZ#2046298*])
** As a workaround:
. Remove `mediatedDevicesConfiguration` and `permittedHostDevices` from the `HyperConverged` CR.
. Update both `mediatedDevicesConfiguration` and `permittedHostDevices` stanzas with the configuration you want to use.

* If you clone more than 100 VMs using the `csi-clone` cloning strategy, then the Ceph CSI might not purge the clones. Manually deleting the clones can also fail. (link:https://bugzilla.redhat.com/show_bug.cgi?id=2055595[*BZ#2055595*])
** As a workaround, you can restart the `ceph-mgr` to purge the VM clones.
