:_mod-docs-content-type: ASSEMBLY
[id="das-operator-using"]
= Using the Dynamic Accelerator Slicer (DAS) Operator
include::_attributes/common-attributes.adoc[]
:context: das-operator-using

toc::[]

[role="_abstract"]
After installing the Dynamic Accelerator Slicer (DAS) Operator, you can use it to dynamically partition GPU accelerators for your workloads. The DAS Operator provides on-demand partitioning of GPUs and scheduler integration that allocates NVIDIA Multi-Instance GPU (MIG) slices.

== About the DAS Operator

The Dynamic Accelerator Slicer (DAS) Operator dynamically partitions GPU accelerators in {product-title}. It currently ships with a reference implementation for NVIDIA Multi-Instance GPU (MIG) and is designed to support additional technologies such as NVIDIA MPS or GPUs from other vendors.

.DAS Operator features
* On-demand partitioning of GPUs via a custom Kubernetes operator
* Scheduler integration that allocates NVIDIA MIG slices through a plugin
* `AllocationClaim` custom resource to track slice reservations

== DAS Operator architecture

The DAS Operator components interact to provide GPU slice allocation. Pods requesting GPU slices are mutated by a webhook to use the `mig.das.com` extended resource. The scheduler plugin tracks slice availability and creates `AllocationClaim` objects processed by the device plugin on each node.

=== MIG scheduler plugin

The plugin integrates with the Kubernetes scheduler and runs through three framework phases:

* **Filter** – ensures the node is MIG capable and stages `AllocationClaim`s for suitable GPUs.
* **Score** – prefers nodes with the most free MIG slice slots after considering existing and staged claims.
* **PreBind** – promotes staged claims on the selected node to `created` and removes the rest.

Once promoted, the device plugin provisions the slices.

The daemonset advertises GPU resources only after the NVIDIA GPU Operator's `ClusterPolicy` reports a **Ready** state. This prevents the scheduler from scheduling pods on a node before the GPU Operator has initialized the drivers.

=== AllocationClaim resource

`AllocationClaim` is a namespaced CRD that records which MIG slice will be prepared for a pod. Claims start in the `staged` state and transition to `created` once all requests are satisfied. Each claim stores the GPU UUID, slice position and pod reference.

//Deploying GPU workloads with DAS
include::modules/das-operator-deploying-workloads.adoc[leveloffset=+1]

//Viewing AllocationClaims
include::modules/das-operator-viewing-allocationclaims.adoc[leveloffset=+1]

//Troubleshooting DAS Operator
include::modules/das-operator-troubleshooting.adoc[leveloffset=+1]

== Additional resources

* xref:../../operators/user/das-operator-installing.adoc#das-operator-installing[Installing the Dynamic Accelerator Slicer Operator]
* xref:../../hardware_enablement/psap-node-feature-discovery-operator.adoc#psap-node-feature-discovery-operator[Node Feature Discovery Operator]
* link:https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/getting-started.html[NVIDIA GPU Operator documentation]