// Module included in the following assemblies:
//
// persistent-storage-csi-vsphere.adoc
//

:content-type: PROCEDURE
[id="persistent-storage-csi-vsphere-top-aware_{context}"]
= Configuring vSphere CSI Topology

{product-title} provides the ability to deploy {product-title} for vSphere on different zones and regions, which allows you to deploy over multiple compute clusters, thus helping to avoid a single point of failure. 

[NOTE]
====
{product-title} on vSphere does not support multiple Datacenters.
====

This is accomplished by defining zone and region categories in vCenter, and then assigning these categories to different failure domains, such as a compute cluster, by creating tags for these zone and region categories. After you have created the appropriate categories, and assigned tags to vCenter objects, you can create additional machinesets that create virtual machines (VMs) that are responsible for scheduling pods in those failure domains.

.Procedure
. In the VMware vCenter vSphere client GUI, define appropriate zone and region catagories and tags.
+
While vSphere allows you to create categories with any arbitrary name, {product-title} strongly recommends use of `openshift-region` and `openshift-zone` names for defining topology.
+
The following example defines two failure domains with one region and two zones:
+
.vSphere topology with one region and two zones
|===
|Compute cluster | Failure domain |Description

|Compute cluster: ocp1, 
Datacenter: Atlanta
|openshift-region: us-east-1 (tag), openshift-zone: us-east-1a (tag)
|This defines a failure domain in region us-east-1 with zone us-east-1a.

|Computer cluster: ocp2, 
Datacenter: Atlanta
|openshift-region: us-east-1 (tag), openshift-zone: us-east-1b (tag)
|This defines a different failure domain within the same region called us-east-1b.
|===
+
For more information about vSphere categories and tags, see the VMware vSphere documentation.

. To allow the container storage interface (CSI) driver to detect this topology, edit the `clusterCSIDriver` object YAML file `driverConfig` section:
* Specify the `openshift-zone` and `openshift-region` categories that you created earlier.
* Set `driverType` to `vSphere`.
+
[source, terminal]
----
~ $ oc edit clustercsidriver csi.vsphere.vmware.com -o yaml
----
+
.Example output
+
[source, terminal]
----
apiVersion: operator.openshift.io/v1
kind: ClusterCSIDriver
metadata:
 name: csi.vsphere.vmware.com
spec:
 logLevel: Normal
 managementState: Managed
 observedConfig: null
 operatorLogLevel: Normal
 unsupportedConfigOverrides: null
 driverConfig: 
  driverType: vSphere <1>
    vSphere:
      topologyCategories: <2>
      - openshift-zone
      - openshift-region
----
<1> Ensure that `driverType` is set to `vSphere`.
<2> `openshift-zone` and `openshift-region` categories created earlier in vCenter.

. Verify that `CSINode` object has topology keys by running the following commands:
+
[source, terminal]
----
~ $ oc get csinode
----
+
.Example output
+
[source, terminal]
----
NAME                        DRIVERS     AGE
co8-4s88d-infra-2m5vd       1           27m
co8-4s88d-master-0          1           70m
co8-4s88d-master-1          1           70m
co8-4s88d-master-2          1           70m
co8-4s88d-worker-j2hmg      1           47m
co8-4s88d-worker-mbb46      1           47m
co8-4s88d-worker-zlk7d      1           47m
----
+
[source, terminal]
----
~ $ oc get csinode co8-4s88d-worker-j2hmg -o yaml
----
+
.Example output
+
[source, terminal]
----
...
spec:
    drivers:
    - allocatable:
        count: 59
    name: csi-vsphere.vmware.com
    nodeID: co8-4s88d-worker-j2hmg
    topologyKeys: <1>
    - topology.csi.vmware.com/openshift-zone
    - topology.csi.vmware.com/openshift-region
----
<1> Topology keys from vSphere `openshift-zone` and `openshift-region` catagories.
+
[NOTE]
=====
`CSINode` objects might take some time to receive updated topology information. After the driver is updated, `CSINode` objects should have topology keys in them.
=====

. Create a tag to assign to datastores across failure domains:
+
When an {product-title} spans more than one failure domain, the datastore might not be shared across those failure domains, which is where topology-aware provisioning of persistent volumes (PVs) is useful. 
+
.. In vCenter, create a category for tagging the datastores. For example, `openshift-zonal-datastore-cat`. You can use any other category name, provided the category uniquely is used for tagging datastores participating in {product-title} cluster. Also, ensure that `StoragePod`, `Datastore`, and `Folder` are selected as Associable Entities for the created category. 
.. In vCenter, create a tag that uses the previously created category. This example uses the tag name `openshift-zonal-datastore`.
.. Assign the previously created tag (in this example `openshift-zonal-datastore`) to each datastore in a failure domain that would be considered for dynamic provisioning.
+
[NOTE]
====
You can use any names you like for categories and tags. The names used in this example are provided as recommendations. Ensure that the tags and categories that you define uniquely identify only datastores that are shared with all hosts in the {product-title} cluster.
====

. Create a storage policy that targets the tag-based datastores in each failure domain:
.. In vCenter, from the main menu, click *Policies and Profiles*.
.. On the *Policies and Profiles* page, in the navigation pane, click *VM Storage Policies*.
.. Click *CREATE*.
.. Type a name for the storage policy.
.. For the rules, choose Tag Placement rules and select the tag and category that targets the desired datastores (in this example, the `openshift-zonal-datastore` tag).
+ 
The datastores are listed in the storage compatibility table.

. Create a new storage class that uses the new zoned storage policy:
.. Click *Storage* > *StorageClasses*.
.. On the *StorageClasses* page, click *Create StorageClass*.
.. Type a name for the new storage class in *Name*.
.. Under *Provisioner*, select *csi.vsphere.vmware.com*. 
.. Under *Additional parameters*, for the StoragePolicyName parameter, set *Value* to the name of the new zoned storage policy that you created earlier.
.. Click *Create*.
+
.Example output
+
[source, yaml]
----
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: zoned-sc <1>
provisioner: csi.vsphere.vmware.com
parameters:
  StoragePolicyName: zoned-storage-policy <2>
reclaimPolicy: Delete
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer
----
<1> New topology aware storage class name.
<2> Specify zoned storage policy.
+
[NOTE]
====
You can also create the storage class by editing the preceding YAML file and running the command `oc create -f $FILE`.
====

.Results
Creating persistent volume claims (PVCs) and PVs from the topology aware storage class are truly zonal, and should use the datastore in their respective zone depending on how pods are scheduled:

[source, terminal]
----
~ $ oc get pv <pv-name> -o yaml
----

.Example output

[source, terminal]
----
...
nodeAffinity:
  required:
    nodeSelectorTerms:
    - matchExpressions:
      - key: topology.csi.vmware.com/openshift-zone <1>
        operator: In  
        values:
        - <openshift-zone>
      -key: topology.csi.vmware.com/openshift-region <1>
        operator: In
        values:
        - <openshift-region>
...
peristentVolumeclaimPolicy: Delete
storageClassName: <zoned-storage-class-name> <2>
volumeMode: Filesystem
...
----
<1> PV has zoned keys.
<2> PV is using the zoned storage class.