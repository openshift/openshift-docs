= OpenShift Metrics Sizing Guidelines
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:

toc::[]

== OpenShift Metrics Basics

Monitoring openshift pods is important task from both, OpenShift administrator and OpenShift user point
of view. OpenShift administrators need a way to monitor pods of interest and see how they perform
 and react if necessary to fix critical issue, at other side OpenShift users also need simple and
 comprehensive overview of pods where their application run.

This guide will provide OpenShift metrics guidlines which OpenShift administrators and users can
follow when trying to dimension openshift metrics for openshift installations

== OpenShift Metrics Installation

Installation of OpenShift metrics is described in https://docs.openshift.com/enterprise/3.2/install_config/cluster_metrics.html[OpenShift Enterprise v3 documentation]
For instruction how to configure Opensift Enterprise Metrics on functional OpenShift cluster, please follow instruction
in https://docs.openshift.com/enterprise/3.2/install_config/cluster_metrics.html[OpenShift Enterprise documentation]

However, it is very important to fulfill below points when starting Opensift metrics in order to avoid potential issues which can appear later during deployment


- It is important to use `persistant_storage=true` parameter. Persistent storage parameter is necessary if we want metrics
data to persist across cassandra metrics pod lifetime.
Prior using `persistant_storage=true` it is necessaary to have available an peristant volume which can be used by metrics cassandra pod.
Please check https://docs.openshift.com/enterprise/3.2/dev_guide/persistent_volumes.html[OpenShift Enterprise documentation - how to create persistant volume]
for detailed instructions how to create Persistent Volume ( PV )

OpenShift metrics supports also https://github.com/openshift/origin-metrics/blob/master/metrics.yaml#L130[dynamically provisioned persistent volumes]
Persistent Volumes ( PV ) and to use this feature with OpenShift metrics, it is necessary for OpenShift metrics to be started with `
DYNAMICALLY_PROVISION_STORAGE=true` parameter. At time only EBS, GCE and Cinder storage backends can be used in order to dynamically
provision persistent volumes for OpenShift. For more inforamtion related to dynamiclly provisioned Persistent Volumes, please check
https://docs.openshift.com/enterprise/3.2/install_config/persistent_storage/dynamically_provisioning_pvs.html[Dynamically Provisioned PVS]


If `persistent_storage=true` parameter is specified, then OpenShift metrics will create PVC and use it
as storage space for cassandra pod withing OpenShift metrics. Important to note, that all what applies for cassandra database performances for case it
it is installed out of OpenShift metrics, also applies on cassandra when deployed as part of OpenShift Metrics. For detailed instructions regarding cassandra databases
is necessary to check official http://cassandra.apache.org/doc/latest/[cassandra documentation]


- If `persistent_storage=false` is used and with intention for metrics data not to live longer than pod lifetime,
then it is recommended to design openshift installation to have `/var` on separate partition ( to accommodate `/lib/origin/openshift.local.volumes/pods`)

This is necessary as space under `/var/lib/origin/openshift.local.volumes/pods` will be used for pods by default as location where to store pod data on OpenShift nodes,
and it is necessary to ensure that massive metrics data collection will not lead to filling up storage space on openshift node and causing openshift node to be unresponsive.
This issue should be solved when issue https://github.com/kubernetes/kubernetes/pull/27199[Initial support for pod eviction based on disk usage] is closed

- For OpenShift metrics variable `HAWKULAR_METRICS_HOSTNAME`  it is necessary to ensure it points to `fqdn` of OpenShift node
where router pod runs. If this is not case when web access will not work as expected

At this point, we assume that metrics pods are up and running after starting metrics as showed in below example
====
----
 # oc get pods -n openshift-infra
 NAME                                          READY             STATUS      RESTARTS          AGE
 hawkular-cassandra-1-l5y4g                    1/1               Running     0                 17h
 hawkular-metrics-1t9so                        1/1               Running     0                 17h
 heapster-febru                                1/1               Running     0                 17h
----
====


if this is not the case, please check OpenShift metrics documentation and ensure OpenShift metrics pods are up and running.

== OpenShift Metrics Dimensioning For OpenShift Enterprise

OpenShift metrics uses Cassandra database as datastore for metrics and current version of Cassandra builtin in
 OpenShift metrics is `CASANDRA_VERSION=2.2.4` with `MAX_HEAP_SIZE=512M` and `NEW_HEAP_SIZE=100M`. It is assumed that these values should
 cover most of OpenShift metrics installations. It is possible to change these values in
 https://github.com/openshift/origin-metrics/blob/master/cassandra/Dockerfile[cassandra docker file]
 prior starting OpenShift metrics


Default time for OpenShift metrics data preservation is specified with parameter `METRIC_DURATION`  in
https://github.com/openshift/origin-metrics/blob/master/metrics.yaml[metrics.yaml configuration file] and has default value of 7 (days).
This means OpenShift metrics will keep data for 7 days before it start to purge old ones from cassandra database and to free
up storage space.

In tests where 1000 pods were monitored ( across 10 OpenShift nodes ) by OpenShift metrics, it was
noticed that for 1000 pods during 24h metrics data collection will cause that cassandra storage space grow at around 2.5 GB.

Based on tests we can say that OpenShift Metrics will collect approximately `0.1MB` of data per hour for OpenShift pod

====
----
(((2.5*10^9)/1000)/24)/10^6 = 0.1 MB/hour
----
====

For the test case when 10000 pods were running in OpenShift cluster ( across 120 OpenShift nodes ) cassandra
load grow up proportionally reflecting bigger number of monitored pods.

====
----
(((11.410*10^9)/1000)/24)/10^6 = 0.475 MB/hour
----
====

[width="80%"]
|================================================
| |1000 pods| 10000 pods
| Cassandra load during 24h time - with default metrics parametres   |2.5GB| 11.4GB
|================================================

Graphically these two test cases are presented on graph below

image::https://raw.githubusercontent.com/ekuric/openshift/master/metrics/1_10kpods.png[1000 pods vs 10000 pods monitored during 24 h]

If default value of 7 (days) for `METRIC_DURATION` and `METRIC_RESOLUTION` of 10 ( seconds ) are preserved,
then it is expected to  that storage requiremetns for cassandra pod would be

[width="80%"]
|================================================
| |1000 pods | 10000 pods
| cassandra storage / week - with default metrics parametres | 20GB | 90GB
|================================================

In last table, it was added 1/10 additionally to expected storage space - as a buffer for unexpected monitored pod number changes
If more pods is monitored and if OpenShift metrics parameters `METRIC_DURATION`  and `METRIC_RESOLUTION`
are changed ( increased value for `METRIC_DURATION` and decreased value for `METRIC_RESOLUTION` parameter ) then above estimated values
should be adapted

== Scaling OpenShift Metrics Pods

One set of metrics pods ( one cassandra/hawkular/heapster pod ) is able to monitor without issues up to 10k pods spread across multiple OpenShift nodes

If there is a need to scale out OpenShift metrics pods, it is an easy process.In order to scale out cassandra pods to
count two replicas follow instructions in https://github.com/openshift/origin-metrics/blob/master/docs/cassandra_scaling.adoc[OpenShift metrics documentation]

In case Openshhift metrics is deployed with `persistant_storage=true` ( what is strongly recommended and it is default option in https://github.com/openshift/origin-metrics/blob/master/metrics.yaml#L127[OpenShift metrics]), it is necessary before scaling out number of OpenShift
metrics cassandra pods to create PV ( Persistent Volume ) which will be used by newly created cassandra pods.

This needs to be done prior scaling out number cassandra pods withing OpenShift metrics system. In case there is not
available Persistent Volume to be used, in that case cassandra pod will fail to start and scaling Opeshift metrics pods will not work.

Check https://docs.openshift.com/enterprise/3.2/dev_guide/persistent_volumes.html[OpenShift Enterprise documentation - how to create persistant volume]
for detailed instructions how to create PV ( Persistent Volume )

To scale out number of OpenShift metrics hawkualar pods to two replicas, run below command on openshift master

====
----
# oc scale -n openshift-infra --replicas=2 rc hawkular-metrics
----
====
It is recommended to pay attention on system load on nodes where OpenShift metrics pods runs and based on that decide
if it is necessary to scale out number of OpenShift metrics pods and spread load across multiple OpenShift nodes.

Scaling OpenShift metrics heapster pods is not recommended


== HPA - Horizontal Pod Autoscaling

OpenShift Enterprise v.3.3 does not provide support https://docs.openshift.com/enterprise/3.2/dev_guide/pod_autoscaling.html[HPA - Horizontal Pod Autoscaling]
for metrics pods and scalling metrics pods. In order to scale out number of OpenShift metrics pods, it is necessary to
scale them using process described above. Horizontal Pod Autoscaling for OpenShift Metrics pods might be supported in future OpenShift Enterprise releases.


