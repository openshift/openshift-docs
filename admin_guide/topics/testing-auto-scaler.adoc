// Module included in the following assemblies:
//
// * admin_guide/cluster-autoscaler.adoc

[id='testing-AWS-cluster-auto-scaler_{context}']
= Testing the auto-scaler

After you add the auto-scaler to your Amazon Web Services (AWS) cluster, you can
confirm that the auto-scaler works by deploying more pods than the current
nodes can run.

.Prerequisites

* You added the auto-scaler to your {product-title} cluster that runs on AWS.

.Procedure

. Create the *_scale-up.yaml_* file that contains the deployment configuration
to test auto-scaling:
+
[source,yaml]
----
apiVersion: apps/v1
kind: Deployment
metadata:
  name: scale-up
  labels:
    app: scale-up
spec:
  replicas: 20 <1>
  selector:
    matchLabels:
      app: scale-up
  template:
    metadata:
      labels:
        app: scale-up
    spec:
      containers:
      - name: origin-base
        image: openshift/origin-base
        resources:
          requests:
            memory: 2Gi
        command:
        - /bin/sh
        - "-c"
        - "echo 'this should be in the logs' && sleep 86400"
      terminationGracePeriodSeconds: 0
----
+
<1> This deployment specifies 20 replicas, but the initial size of the cluster
cannot run all of the pods without first increasing the number of compute nodes.

. Create a namespace for the deployment:
+
[source,terminal]
----
$ oc apply -f - <<EOF
apiVersion: v1
kind: Namespace
metadata:
  name: autoscaler-demo
EOF
----

. Deploy the configuration:
+
[source,terminal]
----
$ oc apply -n autoscaler-demo -f scale-up.yaml
----
+
. View the pods in your namespace:
.. View the running pods in your namespace:
+
[source,terminal]
----
$ oc get pods -n autoscaler-demo | grep Running
cluster-autoscaler-5485644d46-ggvn5   1/1       Running   0          1d
scale-up-79684ff956-45sbg             1/1       Running   0          31s
scale-up-79684ff956-4kzjv             1/1       Running   0          31s
scale-up-79684ff956-859d2             1/1       Running   0          31s
scale-up-79684ff956-h47gv             1/1       Running   0          31s
scale-up-79684ff956-htjth             1/1       Running   0          31s
scale-up-79684ff956-m996k             1/1       Running   0          31s
scale-up-79684ff956-pvvrm             1/1       Running   0          31s
scale-up-79684ff956-qs9pp             1/1       Running   0          31s
scale-up-79684ff956-zwdpr             1/1       Running   0          31s
----
.. View the pending pods in your namespace:
+
[source,terminal]
----
$ oc get pods -n autoscaler-demo | grep Pending
scale-up-79684ff956-5jdnj             0/1       Pending   0          40s
scale-up-79684ff956-794d6             0/1       Pending   0          40s
scale-up-79684ff956-7rlm2             0/1       Pending   0          40s
scale-up-79684ff956-9m2jc             0/1       Pending   0          40s
scale-up-79684ff956-9m5fn             0/1       Pending   0          40s
scale-up-79684ff956-fr62m             0/1       Pending   0          40s
scale-up-79684ff956-q255w             0/1       Pending   0          40s
scale-up-79684ff956-qc2cn             0/1       Pending   0          40s
scale-up-79684ff956-qjn7z             0/1       Pending   0          40s
scale-up-79684ff956-tdmqt             0/1       Pending   0          40s
scale-up-79684ff956-xnjhw             0/1       Pending   0          40s
----
+
These pending pods cannot run until the cluster auto-scaler automatically 
provisions new compute nodes to run the pods on. It
can several minutes for the nodes have a `Ready` state in the cluster.

. After several minutes, check the list of nodes to see if new nodes are ready:
+
[source,terminal]
----
$ oc get nodes
NAME                            STATUS    ROLES     AGE       VERSION
ip-172-31-49-172.ec2.internal   Ready     infra     1d        v1.11.0+d4cacc0
ip-172-31-53-217.ec2.internal   Ready     compute   7m        v1.11.0+d4cacc0
ip-172-31-55-89.ec2.internal    Ready     compute   9h        v1.11.0+d4cacc0
ip-172-31-56-21.ec2.internal    Ready     compute   7m        v1.11.0+d4cacc0
ip-172-31-56-71.ec2.internal    Ready     compute   7m        v1.11.0+d4cacc0
ip-172-31-63-234.ec2.internal   Ready     master    1d        v1.11.0+d4cacc0
----

. When more nodes are ready, view the running pods in your namespace again:
+
[source,terminal]
----
$ oc get pods -n autoscaler-demo
NAME                                  READY     STATUS    RESTARTS   AGE
cluster-autoscaler-5485644d46-ggvn5   1/1       Running   0          1d
scale-up-79684ff956-45sbg             1/1       Running   0          8m
scale-up-79684ff956-4kzjv             1/1       Running   0          8m
scale-up-79684ff956-5jdnj             1/1       Running   0          8m
scale-up-79684ff956-794d6             1/1       Running   0          8m
scale-up-79684ff956-7rlm2             1/1       Running   0          8m
scale-up-79684ff956-859d2             1/1       Running   0          8m
scale-up-79684ff956-9m2jc             1/1       Running   0          8m
scale-up-79684ff956-9m5fn             1/1       Running   0          8m
scale-up-79684ff956-fr62m             1/1       Running   0          8m
scale-up-79684ff956-h47gv             1/1       Running   0          8m
scale-up-79684ff956-htjth             1/1       Running   0          8m
scale-up-79684ff956-m996k             1/1       Running   0          8m
scale-up-79684ff956-pvvrm             1/1       Running   0          8m
scale-up-79684ff956-q255w             1/1       Running   0          8m
scale-up-79684ff956-qc2cn             1/1       Running   0          8m
scale-up-79684ff956-qjn7z             1/1       Running   0          8m
scale-up-79684ff956-qs9pp             1/1       Running   0          8m
scale-up-79684ff956-tdmqt             1/1       Running   0          8m
scale-up-79684ff956-xnjhw             1/1       Running   0          8m
scale-up-79684ff956-zwdpr             1/1       Running   0          8m
...
----
