[[admin-guide-custom-controllers]]
= Creating Custom Controllers
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:

toc::[]



In the Kubernetes API, a controller is a control loop that watches the shared state of a cluster 
through the API server and makes changes in an attempt to move the current state towards the desired state. 
Examples of controllers that ship with Kubernetes today are the 
replication controller, endpoints controller, namespace controller, and service accounts controller.

You can create custom controllers using the `oc observe` command. The command is available as an image named
`openshift/observe:latest` for use with {product-title}.  

//from man page
This command assists in building scripted reactions to changes that occur in Kubernetes or OpenShift resources. 
On startup, observe will list all of the resources of a particular type and execute the provided script on each one. 
Observe watches the server for changes, and will reexecute the script for each update.

The `oc observe` command works best for problems of the form "for every resource X, make sure Y is true". Some
examples of ways observe can be used include: 

  * Ensure every namespace has a quota or limit range object  
  * Ensure every service is registered in DNS by making calls to a DNS API  
  * Send an email alert whenever a node reports 'NotReady'  
  * Watch for the 'FailedScheduling' event and write an IRC message  
  * Dynamically provision persistent volumes when a new PVC is created  
  * Delete pods that have reached successful completion after a period of time.  


=== Using the command to maintain an invariant

The simplest pattern is maintaining an invariant on an object - for example, _every project
should have an annotation that indicates its owner_. 

This simple script ensures that any user without the "owner" annotation gets one set, but preserves
any existing value: 

----
$ cat set_owner.sh
#!/bin/sh
if [[ "$(oc get namespace "$1" --template='{{ .metadata.annotations.owner }}')" == "" ]]; then
  oc annotate namespace "$1" owner=bob
fi
----

Then run `oc observe`:

----
$ oc observe namespaces -- ./set_owner.sh
----

A variation on that pattern is creating another object: "every namespace should have a
quota object based on the resources allowed for an owner". 

=== Using the command for provisioning

The next common of controller pattern is provisioning - making changes in an external system to
match the state of another resource. 

These scripts need to account for deletions that may take place while the observe command is not running. 
You can provide the list of known objects via the
--names command, which should return a newline-delimited list of names or namespace/name pairs. Your
command will be invoked whenever observe checks the latest state on the server - any resources
returned by --names that are not found on the server will be passed to your --delete command. 

For example, you may wish to ensure that every node that is added to Kubernetes is added to your
cluster inventory along with its IP: 

----
$ cat add_to_inventory.sh
#!/bin/sh
echo "$1 $2" >> inventory
sort -u inventory -o inventory

$ cat remove_from_inventory.sh
#!/bin/sh
grep -vE "^$1 " inventory > /tmp/newinventory
mv -f /tmp/newinventory inventory
  
$ cat known_nodes.sh
#!/bin/sh
touch inventory
cut -f 1-1 -d ' ' inventory
----

Then run `oc observe`:

----
$ oc observe nodes -a '{ .status.addresses[0].address }' \
  --names ./known_nodes.sh \
  --delete ./remove_from_inventory.sh \
  -- ./add_to_inventory.sh\
----





To obtain and run the `oc observe` command:

. Run the following command:
+
----
docker run --entrypoint /bin/bash -it openshift/observe:latest
----
+
This command pulls the `openshift/observe:latest`, builds a container, and opens a bash shell to the container.

. Copy in a kubeconfig for your cluster or login using `oc config` or `oc login`.

. Run the following command:
+
----
$ oc observe -h
----

*List all services*

Run the following command to list every service, and any time a service changes, print out info:

----
$ oc observe --all-namespaces services
----

For exanple, the command prints out the project and name for each service as arguments 1 and 2.  

----
$ oc observe --all-namespaces services
# 2017-11-01T18:21:44-04:00 Sync started
# 2017-11-01T18:21:44-04:00 Sync 1068	"" default <1> docker-registry <2>
# 2017-11-01T18:21:44-04:00 Sync 433	"" default kubernetes
# 2017-11-01T18:21:44-04:00 Sync 36694	"" default proxy
# 2017-11-01T18:21:44-04:00 Sync 1162	"" default registry-console
# 2017-11-01T18:21:44-04:00 Sync 998	"" default router
# 2017-11-01T18:21:44-04:00 Sync 20817	"" jenkins-project jenkins
# 2017-11-01T18:21:44-04:00 Sync 20814	"" jenkins-project jenkins-jnlp
# 2017-11-01T18:21:44-04:00 Sync 161454	"" python-project python-app
----

If you create or delete a service in the background, you'll see it show up in this list:.

----
# 2017-11-01T18:28:36-04:00 Sync ended
# 2017-11-01T18:28:36-04:00 Added 249342	"" imagestream my-ruby-app
----

Run the following command to list every service, and any time a service changes, echo:

----
$ oc observe --all-namespaces services -- echo
----

For example The command prints out project and name for each service as arguments 1 and 2.  

----
$ oc observe --all-namespaces services -- echo
# 2017-11-01T18:20:03-04:00 Sync started
# 2017-11-01T18:20:03-04:00 Sync 1068	echo default docker-registry
default docker-registry
# 2017-11-01T18:20:03-04:00 Sync 433	echo default kubernetes
default kubernetes
# 2017-11-01T18:20:03-04:00 Sync 36694	echo default proxy
default proxy
# 2017-11-01T18:20:03-04:00 Sync 1162	echo default registry-console
default registry-console
# 2017-11-01T18:20:03-04:00 Sync 998	echo default router
default router
# 2017-11-01T19:04:16-04:00 Sync 20817	echo jenkins-project jenkins
imagestream jenkins
# 2017-11-01T19:04:16-04:00 Sync 20814	echo jenkins-project jenkins-jnlp
imagestream jenkins-jnlp
# 2017-11-01T19:04:16-04:00 Sync 161454	echo python-project python2
imagestream python2
----

After creating a service:

----
# 2017-11-01T18:34:24-04:00 Sync ended
# 2017-11-01T18:34:24-04:00 Added 249524	echo php mp-php-app
php mp-php-app
----


*Display the service IP*

$ oc observe --all-namespaces services -a '{ .spec.clusterIP }'
# 2017-11-01T18:40:39-04:00 Sync started
# 2017-11-01T18:40:39-04:00 Sync 1068	"" default docker-registry 172.30.203.179
# 2017-11-01T18:40:39-04:00 Sync 433	"" default kubernetes 172.30.0.1
# 2017-11-01T18:40:39-04:00 Sync 36694	"" default proxy 172.30.197.68
# 2017-11-01T18:40:39-04:00 Sync 1162	"" default registry-console 172.30.138.84
# 2017-11-01T18:40:39-04:00 Sync 998	"" default router 172.30.143.207
# 2017-11-01T18:40:39-04:00 Sync 20817	"" imagestream jenkins 172.30.125.105
# 2017-11-01T18:40:39-04:00 Sync 20814	"" imagestream jenkins-jnlp 172.30.207.60
# 2017-11-01T18:40:39-04:00 Sync 249342	"" imagestream my-ruby-app 172.30.253.90
# 2017-11-01T18:40:39-04:00 Sync 161454	"" imagestream python2 172.30.109.9
# 2017-11-01T18:40:39-04:00 Sync 249524	"" php mp-php-app 172.30.48.220

Use `-a` to print a JSONPath style template for each object, which becomes the last argument of the command.   

*Create a File with Services and IPs*

You could create a script to collect all of the services, their project, and IP addresses:

----
$ cat record.sh
#!/bin/sh
echo $1 $2 $3 >> services
----

$1 is the project.
$2 is the service name.
$3 is the service IP.

Then, run the following command:

----
$ oc observe --all-namespaces services -a '{ .spec.clusterIP }' -- ./record.sh
----

All services and their IPs will be recorded in the local file specified in the script, here `services`. 

----
vi services

default docker-registry 172.30.203.179
default kubernetes 172.30.0.1
default proxy 172.30.197.68
default registry-console 172.30.138.84
default router 172.30.143.207
imagestream jenkins 172.30.125.105
imagestream jenkins-jnlp 172.30.207.60
imagestream my-ruby-app 172.30.253.90
imagestream python2 172.30.109.9
php mp-php-app 172.30.48.220
-----

You can extend that to anything you can do with bash.

A more complex case is handling deletions.  for example, you could create an ingress for every service, and delete the ingress if the service gets deleted.  To properly cleanup, we need to know the ingresses that were created this way.

. Create the following scripts:
+
----
$ cat create.sh
#!/bin/sh
echo "{\"kind\":\"Ingress\": \"apiVersion\": \"extensions/v1beta1\",\"metadata\":{\"name\":\"$2\"}, ...}' kubectl create -f - --namespace $1
kubectl annotate ingress/$2 fromservice=true
----
+
This script creates an ingress with the same name as the service and sets an annotation.
+
----
$ cat names.sh
#!/bin/sh
kubectl get ingress --all-namespaces --template '{{ range .items }}{{ if eq (or .metadata.annotation.fromservice "") "true" }}{{ .metadata.namespace }}/{{ .metadata.name }}{{"\n"}}{{ end }}{{ end }}'
----
+
This script walks every ingress and outputs namespace/name for any that have the annotation `fromservice=true`.
+
----
$ cat delete.sh
#!/bin/sh
kubectl delete ingress $2 --namespace=$1
----

. Then, run the follwing command:
+
---
$ oc observe --all-namespaces services --delete ./delete.sh --names=./names.sh -- ./create.sh
----

The combination of those allows the observer to detect that a service has been deleted while it was not running - any ingress that has the annotation was created by a service, and since they match names, that must mean that a service was deleted.  If a user deletes a service directly, we'll get the watch notification - but not if we crashed, or on initial sync.


[Important] 
====
When handling deletes, the previous state of the object may not be available and only the
name/namespace of the object will be passed to   your --delete command as arguments (all custom
arguments are omitted). 
====



Options:
      --all-namespaces=false: If true, list the requested object(s) across all projects. Project in
current context is ignored.
  -a, --argument='': Template for the arguments to be passed to each command in the format defined
by --output.
  -d, --delete='': A command to run when resources are deleted. Specify multiple times to add
arguments.
      --exit-after=0s: Exit with status code 0 after the provided duration, optional.
      --listen-addr=':11251': The name of an interface to listen on to expose metrics and health
checking.
      --maximum-errors=20: Exit after this many errors have been detected with. May be set to -1 for
no maximum.
      --names='': A command that will list all of the currently known names, optional. Specify
multiple times to add arguments. Use to get notifications when objects are deleted.
      --no-headers=false: If true, skip printing information about each event prior to executing the
command.
      --object-env-var='': The name of an env var to serialize the object to when calling the
command, optional.
      --once=false: If true, exit with a status code 0 after all current objects have been
processed.
      --output='jsonpath': Controls the template type used for the --argument flags. Supported
values are gotemplate and jsonpath.
      --print-metrics-on-exit=false: If true, on exit write all metrics to stdout.
      --resync-period=0s: When non-zero, periodically reprocess every item from the server as a Sync
event. Use to ensure external systems are kept up to date.
      --retry-count=2: The number of times to retry a failing command before continuing.
      --retry-on-exit-code=0: If any command returns this exit code, retry up to --retry-count
times.
      --strict-templates=false: If true return an error on any field or map key that is not missing
in a template.
      --type-env-var='': The name of an env var to set with the type of event received ('Sync',
'Updated', 'Deleted', 'Added') to the reaction command or --delete.



