[[admin-guide-custom-controllers]]
= Creating Custom Controllers
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:

toc::[]



In the Kubernetes API a controller is a control loop that watches the shared state of the cluster 
through the apiserver and makes changes attempting to move the current state towards the desired state. 
Examples of controllers that ship with Kubernetes today are the 
replication controller, endpoints controller, namespace controller, and serviceaccounts controller.

You can create custom controllers using the `oc observe` command. The command is available as an image 
`openshift/observe:latest`, so you can run it on a local machine or download the release binary of OpenShift.  


The `oc observe` command helps you build simple controller loops. For example:

* Run a script once for every X in the system, and to re-run that script when X changes
* Get data off X - you shouldn't have to jump through 'jq' hoops if you want to fetch a service IP or annotation value
* Write a correct reconciliation loop against an external system, and help guide you through the gotchas


. Run the following command:
+
----
docker run --entrypoint /bin/bash -it openshift/observe:latest
----

. Copy in a kubeconfig for your cluster or login using `oc config` or `oc login`.

.Run the following command:
+
----
$ oc observe -h
----

*List all services*

Run the following command to list every service, and any time a service changes, print out info:

----
$ oc observe --all-namespaces services
----

For exanple, the command prints out project and name for each service as arguments 1 and 2.  

----
$ oc observe --all-namespaces services
# 2017-11-01T18:21:44-04:00 Sync started
# 2017-11-01T18:21:44-04:00 Sync 1068	"" default <1> docker-registry <2>
# 2017-11-01T18:21:44-04:00 Sync 433	"" default kubernetes
# 2017-11-01T18:21:44-04:00 Sync 36694	"" default proxy
# 2017-11-01T18:21:44-04:00 Sync 1162	"" default registry-console
# 2017-11-01T18:21:44-04:00 Sync 998	"" default router
# 2017-11-01T18:21:44-04:00 Sync 20817	"" jenkins-project jenkins
# 2017-11-01T18:21:44-04:00 Sync 20814	"" jenkins-project jenkins-jnlp
# 2017-11-01T18:21:44-04:00 Sync 161454	"" python-project python-app
----

If you create or delete a service in the background, you'll see it show up in this list (the update, at least).

----
# 2017-11-01T18:28:36-04:00 Sync ended
# 2017-11-01T18:28:36-04:00 Added 249342	"" imagestream my-ruby-app
----

Run the following command to list every service, and any time a service changes, echo:

----
$ oc observe --all-namespaces services -- echo
----

For example The command prints out project and name for each service as arguments 1 and 2.  

----
$ oc observe --all-namespaces services -- echo
# 2017-11-01T18:20:03-04:00 Sync started
# 2017-11-01T18:20:03-04:00 Sync 1068	echo default docker-registry
default docker-registry
# 2017-11-01T18:20:03-04:00 Sync 433	echo default kubernetes
default kubernetes
# 2017-11-01T18:20:03-04:00 Sync 36694	echo default proxy
default proxy
# 2017-11-01T18:20:03-04:00 Sync 1162	echo default registry-console
default registry-console
# 2017-11-01T18:20:03-04:00 Sync 998	echo default router
default router
# 2017-11-01T19:04:16-04:00 Sync 20817	echo jenkins-project jenkins
imagestream jenkins
# 2017-11-01T19:04:16-04:00 Sync 20814	echo jenkins-project jenkins-jnlp
imagestream jenkins-jnlp
# 2017-11-01T19:04:16-04:00 Sync 161454	echo python-project python2
imagestream python2

----

After creating a service:

----
# 2017-11-01T18:34:24-04:00 Sync ended
# 2017-11-01T18:34:24-04:00 Added 249524	echo php mp-php-app
php mp-php-app
----


*Display the service IP*

$ oc observe --all-namespaces services -a '{ .spec.clusterIP }'
# 2017-11-01T18:40:39-04:00 Sync started
# 2017-11-01T18:40:39-04:00 Sync 1068	"" default docker-registry 172.30.203.179
# 2017-11-01T18:40:39-04:00 Sync 433	"" default kubernetes 172.30.0.1
# 2017-11-01T18:40:39-04:00 Sync 36694	"" default proxy 172.30.197.68
# 2017-11-01T18:40:39-04:00 Sync 1162	"" default registry-console 172.30.138.84
# 2017-11-01T18:40:39-04:00 Sync 998	"" default router 172.30.143.207
# 2017-11-01T18:40:39-04:00 Sync 20817	"" imagestream jenkins 172.30.125.105
# 2017-11-01T18:40:39-04:00 Sync 20814	"" imagestream jenkins-jnlp 172.30.207.60
# 2017-11-01T18:40:39-04:00 Sync 249342	"" imagestream my-ruby-app 172.30.253.90
# 2017-11-01T18:40:39-04:00 Sync 161454	"" imagestream python2 172.30.109.9
# 2017-11-01T18:40:39-04:00 Sync 249524	"" php mp-php-app 172.30.48.220

Use `-a` to print a JSONPath style template for each object, which becomes the last argument of the command.   

*Create a File with Services and IPs*

You could create a script to collect all of the services, their project, and IP addresses:

----
$ cat record.sh
#!/bin/sh
echo $1 $2 $3 >> services
----

$1 is the project.
$2 is the service name.
$3 is the service IP.

Then, run the following command:

----
$ oc observe --all-namespaces services -a '{ .spec.clusterIP }' -- ./record.sh
----

All services and their IPs will be recorded in the local file specified in the script, here `services`. 

----
vi services

default docker-registry 172.30.203.179
default kubernetes 172.30.0.1
default proxy 172.30.197.68
default registry-console 172.30.138.84
default router 172.30.143.207
imagestream jenkins 172.30.125.105
imagestream jenkins-jnlp 172.30.207.60
imagestream my-ruby-app 172.30.253.90
imagestream python2 172.30.109.9
php mp-php-app 172.30.48.220
-----

You can extend that to anything you can do with bash.

The more complex case is handling deletions.  Say you want to create an ingress for every service, but if the service gets deleted you want to delete the ingress.  To properly cleanup, we need to know the ingresses that were created this way.

    $ cat create.sh
    #!/bin/sh
    echo "{\"kind\":\"Ingress\": \"apiVersion\": \"extensions/v1beta1\",\"metadata\":{\"name\":\"$2\"}, ...}' kubectl create -f - --namespace $1
    kubectl annotate ingress/$2 fromservice=true
    
    $ cat names.sh
    #!/bin/sh
    kubectl get ingress --all-namespaces --template '{{ range .items }}{{ if eq (or .metadata.annotation.fromservice "") "true" }}{{ .metadata.namespace }}/{{ .metadata.name }}{{"\n"}}{{ end }}{{ end }}'

    $ cat delete.sh
    #!/bin/sh
    kubectl delete ingress $2 --namespace=$1

    $ oc observe --all-namespaces services --delete ./delete.sh --names=./names.sh -- ./create.sh

The first script creates an ingress with the same name as the service and sets an annotation.  The second walks every ingress and outputs namespace/name for any that have the annotation fromservice=true (note that the go template here is actually not enough - you have to check for the annotation being empty because it will error otherwise).  

The combination of those allows the observer to detect that a service has been deleted while it was not running - any ingress that has the annotation was created by a service, and since they match names, that must mean that a service was deleted.  If a user deletes a service directly, we'll get the watch notification - but not if we crashed, or on initial sync.

This reconciliation is tricky to get right - but observe is able to use the exact same pattern and code that Kubernetes uses to ensure we only fix critical reconcile bugs once.

There are other options around failure modes, retries, metrics endpoints, and restart behavior.  Please see the help for more.



